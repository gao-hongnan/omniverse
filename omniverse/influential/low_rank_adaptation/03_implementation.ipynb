{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Implementation\n","\n","[![Twitter Handle](https://img.shields.io/badge/Twitter-@gaohongnan-blue?style=social&logo=twitter)](https://twitter.com/gaohongnan)\n","[![LinkedIn Profile](https://img.shields.io/badge/@gaohongnan-blue?style=social&logo=linkedin)](https://linkedin.com/in/gao-hongnan)\n","[![GitHub Profile](https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&logo=github)](https://github.com/gao-hongnan)\n","![Tag](https://img.shields.io/badge/Tag-Brain_Dump-red)\n","![Tag](https://img.shields.io/badge/Level-Beginner-green)\n","[![Code](https://img.shields.io/badge/View-Code-blue?style=flat-square&logo=github)](https://github.com/gao-hongnan/omniverse/tree/main/omnivault/modules/lora.py)\n","\n","```{contents}\n",":local:\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Merge And Quantize"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%pip install -U -q omniverse==0.0.57"]},{"cell_type":"markdown","metadata":{},"source":["## Dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:13:54.321667Z","iopub.status.busy":"2024-07-21T15:13:54.320724Z","iopub.status.idle":"2024-07-21T15:14:11.346283Z","shell.execute_reply":"2024-07-21T15:14:11.345480Z","shell.execute_reply.started":"2024-07-21T15:13:54.321623Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-21 15:14:01.842773: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-21 15:14:01.842888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-21 15:14:01.974065: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from __future__ import annotations\n","\n","import copy\n","import math\n","from typing import Any, Dict, List, Optional, TypedDict, Union\n","\n","import numpy as np\n","import psutil\n","import torch\n","from datasets import load_dataset\n","from pydantic import BaseModel, Field\n","from rich.pretty import pprint\n","from scipy.special import softmax\n","from sklearn.metrics import (\n","    accuracy_score,\n","    auc,\n","    average_precision_score,\n","    brier_score_loss,\n","    confusion_matrix,\n","    f1_score,\n","    log_loss,\n","    precision_recall_curve,\n","    precision_score,\n","    recall_score,\n","    roc_auc_score,\n","    roc_curve,\n",")\n","from torch import nn\n","from transformers import (\n","    DataCollatorWithPadding,\n","    Qwen2ForSequenceClassification,\n","    Qwen2Tokenizer,\n","    Trainer,\n","    TrainingArguments,\n",")\n","from transformers.trainer_utils import EvalPrediction\n","\n","from omnivault.utils.reproducibility.seed import seed_all"]},{"cell_type":"markdown","metadata":{},"source":["## Setting Up"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:14:11.348289Z","iopub.status.busy":"2024-07-21T15:14:11.347705Z","iopub.status.idle":"2024-07-21T15:14:11.398726Z","shell.execute_reply":"2024-07-21T15:14:11.397955Z","shell.execute_reply.started":"2024-07-21T15:14:11.348262Z"},"trusted":true},"outputs":[],"source":["seed_all(42, seed_torch=True, set_torch_deterministic=False)\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","MAX_LENGTH = 32\n","PADDING = \"longest\"\n","BATCH_SIZE = 32\n","TRUNCATION = True\n","RETURN_TENSORS = \"pt\""]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Preparation"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:14:11.400072Z","iopub.status.busy":"2024-07-21T15:14:11.399793Z","iopub.status.idle":"2024-07-21T15:14:43.552441Z","shell.execute_reply":"2024-07-21T15:14:43.551487Z","shell.execute_reply.started":"2024-07-21T15:14:11.400047Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5d6824c2c3247bfa4daf0cebb010f84","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2a12dbf7b074e62a93f13ff48740a70","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a233d6aa7bf4ad297a73597f5da3143","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d23805490ad4571aa3dd8a62be9d80c","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e170eadc8ade483791857f61f77df8f3","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.04k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35fdffa4accb4cdf879345f3f436fb35","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/8.88k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b7f16d9751b4afbb74d354ce34a2ba9","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/682k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06be5b9116fc4fa997d0e74091522e33","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/2264 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"726836c53a0d4009be317c4917543d60","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/2037 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94f78e68cad34cf2bad9af109bcf1360","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/227 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["class Batch(TypedDict):\n","    sentence: List[str]\n","    labels: List[int]\n","\n","\n","class TokenizedBatch(TypedDict):\n","    input_ids: List[int]\n","    attention_mask: List[int]\n","    labels: List[int]\n","\n","tokenizer = Qwen2Tokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B\", padding_side=\"left\")\n","\n","def preprocess_function(batch: Batch, **kwargs: Any) -> TokenizedBatch:\n","    return tokenizer(batch[\"sentence\"], **kwargs)\n","\n","dataset = load_dataset(\"financial_phrasebank\", \"sentences_allagree\", trust_remote_code=True)[\"train\"]\n","dataset = dataset.rename_column(\"label\", \"labels\")\n","\n","train_valid_split = dataset.train_test_split(test_size=0.1, shuffle=True, stratify_by_column=\"labels\")\n","\n","train_dataset = train_valid_split[\"train\"]\n","valid_dataset = train_valid_split[\"test\"]\n","\n","tokenized_train_dataset = train_dataset.map(\n","    preprocess_function,\n","    fn_kwargs={\"truncation\": TRUNCATION, \"padding\": PADDING, \"max_length\": MAX_LENGTH},\n","    batched=True,\n","    num_proc=psutil.cpu_count(logical=True),\n","    batch_size=1000,\n",").remove_columns([\"sentence\"])\n","\n","tokenized_valid_dataset = valid_dataset.map(\n","    preprocess_function,\n","    fn_kwargs={\"truncation\": TRUNCATION, \"padding\": PADDING, \"max_length\": MAX_LENGTH},\n","    batched=True,\n","    num_proc=psutil.cpu_count(logical=True),\n","    batch_size=1000,\n",").remove_columns([\"sentence\"])\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n","label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n","num_labels = len(id2label)"]},{"cell_type":"markdown","metadata":{},"source":["## Base Model"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:14:43.556314Z","iopub.status.busy":"2024-07-21T15:14:43.555903Z","iopub.status.idle":"2024-07-21T15:15:10.004584Z","shell.execute_reply":"2024-07-21T15:15:10.003640Z","shell.execute_reply.started":"2024-07-21T15:14:43.556274Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e40b0d48677485fa2434e976fad792d","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"598002b1c85149d8bfb547da1029641e","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen1.5-0.5B and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Qwen2ForSequenceClassification</span><span style=\"font-weight: bold\">(</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">  </span><span style=\"font-weight: bold\">(</span>model<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Qwen2Model</span><span style=\"font-weight: bold\">(</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span>embed_tokens<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">151936</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span>layers<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│     </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Qwen2DecoderLayer</span><span style=\"font-weight: bold\">(</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>self_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Qwen2SdpaAttention</span><span style=\"font-weight: bold\">(</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>q_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>k_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>v_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>o_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Qwen2RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Qwen2MLP</span><span style=\"font-weight: bold\">(</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>gate_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2816</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>up_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2816</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>down_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2816</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>act_fn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SiLU</span><span style=\"font-weight: bold\">()</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>input_layernorm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Qwen2RMSNorm</span><span style=\"font-weight: bold\">()</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>post_attention_layernorm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Qwen2RMSNorm</span><span style=\"font-weight: bold\">()</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│     </span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span>norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Qwen2RMSNorm</span><span style=\"font-weight: bold\">()</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">  </span><span style=\"font-weight: bold\">)</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">  </span><span style=\"font-weight: bold\">(</span>score<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n","<span style=\"font-weight: bold\">)</span>\n","</pre>\n"],"text/plain":["\u001b[1;35mQwen2ForSequenceClassification\u001b[0m\u001b[1m(\u001b[0m\n","\u001b[2;32m  \u001b[0m\u001b[1m(\u001b[0mmodel\u001b[1m)\u001b[0m: \u001b[1;35mQwen2Model\u001b[0m\u001b[1m(\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0membed_tokens\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m151936\u001b[0m, \u001b[1;36m1024\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0mlayers\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n","\u001b[2;32m│     \u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m23\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m24\u001b[0m x \u001b[1;35mQwen2DecoderLayer\u001b[0m\u001b[1m(\u001b[0m\n","\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mself_attn\u001b[1m)\u001b[0m: \u001b[1;35mQwen2SdpaAttention\u001b[0m\u001b[1m(\u001b[0m\n","\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mq_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mk_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mv_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mo_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mQwen2RotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mQwen2MLP\u001b[0m\u001b[1m(\u001b[0m\n","\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mgate_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2816\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mup_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2816\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mdown_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2816\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mact_fn\u001b[1m)\u001b[0m: \u001b[1;35mSiLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0minput_layernorm\u001b[1m)\u001b[0m: \u001b[1;35mQwen2RMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mpost_attention_layernorm\u001b[1m)\u001b[0m: \u001b[1;35mQwen2RMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│     \u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mQwen2RMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m  \u001b[0m\u001b[1m)\u001b[0m\n","\u001b[2;32m  \u001b[0m\u001b[1m(\u001b[0mscore\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[1m)\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["base_model = Qwen2ForSequenceClassification.from_pretrained(\n","    \"Qwen/Qwen1.5-0.5B\",\n","    id2label=id2label,\n","    label2id=label2id,\n","    num_labels=num_labels,\n","    problem_type=\"single_label_classification\",\n",")\n","base_model.config.pad_token_id = tokenizer.pad_token_id\n","\n","base_model = base_model.to(DEVICE)\n","pprint(base_model)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:10.006331Z","iopub.status.busy":"2024-07-21T15:15:10.005921Z","iopub.status.idle":"2024-07-21T15:15:10.016256Z","shell.execute_reply":"2024-07-21T15:15:10.015257Z","shell.execute_reply.started":"2024-07-21T15:15:10.006293Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total trainable parameters before LoRA: 463,990,784\n"]}],"source":["def total_trainable_parameters(module: nn.Module) -> int:\n","    \"\"\"Returns the number of trainable parameters in the model.\"\"\"\n","    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n","\n","\n","def total_parameters(module: nn.Module) -> int:\n","    \"\"\"Returns the total number of parameters in the model, including non-trainable.\"\"\"\n","    return sum(p.numel() for p in module.parameters())\n","\n","base_model_total_trainable = total_trainable_parameters(base_model)\n","print(f\"Total trainable parameters before LoRA: {base_model_total_trainable:,}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Metrics"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:10.017780Z","iopub.status.busy":"2024-07-21T15:15:10.017393Z","iopub.status.idle":"2024-07-21T15:15:10.032188Z","shell.execute_reply":"2024-07-21T15:15:10.031327Z","shell.execute_reply.started":"2024-07-21T15:15:10.017754Z"},"trusted":true},"outputs":[],"source":["def compute_metrics_for_single_label_classification(eval_prediction: EvalPrediction) -> Dict[str, float | List[float]]:\n","    logits, labels = eval_prediction.predictions, eval_prediction.label_ids\n","    probs = softmax(logits, axis=-1)\n","\n","    num_classes = logits.shape[1]\n","    preds = np.argmax(probs, axis=1)\n","\n","    metrics = {\n","        \"eval_log_loss\": log_loss(labels, probs),\n","        \"eval_accuracy\": accuracy_score(labels, preds),\n","        \"eval_precision_macro\": precision_score(labels, preds, average=\"macro\", zero_division=0),\n","        \"eval_recall_macro\": recall_score(labels, preds, average=\"macro\", zero_division=0),\n","        \"eval_f1_score_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n","        \"eval_precision_micro\": precision_score(labels, preds, average=\"micro\", zero_division=0),\n","        \"eval_recall_micro\": recall_score(labels, preds, average=\"micro\", zero_division=0),\n","        \"eval_f1_score_micro\": f1_score(labels, preds, average=\"micro\", zero_division=0),\n","        \"eval_confusion_matrix\": confusion_matrix(labels, preds).tolist(),\n","        \"eval_roc_auc\": roc_auc_score(labels, probs, multi_class=\"ovr\"),\n","        \"eval_pr_auc\": average_precision_score(labels, probs, average=\"macro\")\n","    }\n","\n","    if num_classes == 2:\n","        metrics[\"eval_brier_score\"] = brier_score_loss(labels, probs[:, 1], pos_label=1)\n","    else:\n","        brier_scores = [brier_score_loss(labels == i, probs[:, i]) for i in range(num_classes)]\n","        metrics[\"eval_brier_score\"] = np.mean(brier_scores)\n","\n","    if num_classes > 2:\n","        for class_index in range(num_classes):\n","            fpr, tpr, _ = roc_curve(labels == class_index, probs[:, class_index])\n","            roc_auc = auc(fpr, tpr)\n","            precision, recall, _ = precision_recall_curve(labels == class_index, probs[:, class_index])\n","            pr_auc = auc(recall, precision)\n","            metrics[f\"eval_roc_auc_class_{class_index}\"] = roc_auc\n","            metrics[f\"eval_pr_auc_class_{class_index}\"] = pr_auc\n","\n","    return metrics"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate With Pretrained Model"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:10.033655Z","iopub.status.busy":"2024-07-21T15:15:10.033327Z","iopub.status.idle":"2024-07-21T15:15:12.892934Z","shell.execute_reply":"2024-07-21T15:15:12.891819Z","shell.execute_reply.started":"2024-07-21T15:15:10.033632Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_log_loss'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.40178591009753</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.14096916299559473</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_precision_macro'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3000285877644368</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_recall_macro'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3223057644110276</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_f1_score_macro'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.11305118925439782</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_precision_micro'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.14096916299559473</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_recall_micro'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.14096916299559473</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_f1_score_micro'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.14096916299559473</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_confusion_matrix'</span>: <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">132</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]]</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_roc_auc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5319817168701279</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_pr_auc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3596197342614926</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_brier_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.55610225252113</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_roc_auc_class_0'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4730964467005076</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_pr_auc_class_0'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.12580756501576662</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_roc_auc_class_1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5628899835796387</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_pr_auc_class_1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6492525648321494</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_roc_auc_class_2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5599587203302373</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_pr_auc_class_2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2816445108714582</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_loss'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.431046962738037</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.7974</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81.146</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eval_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.367</span>\n","<span style=\"font-weight: bold\">}</span>\n","</pre>\n"],"text/plain":["\u001b[1m{\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_log_loss'\u001b[0m: \u001b[1;36m7.40178591009753\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_accuracy'\u001b[0m: \u001b[1;36m0.14096916299559473\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_precision_macro'\u001b[0m: \u001b[1;36m0.3000285877644368\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_recall_macro'\u001b[0m: \u001b[1;36m0.3223057644110276\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_f1_score_macro'\u001b[0m: \u001b[1;36m0.11305118925439782\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_precision_micro'\u001b[0m: \u001b[1;36m0.14096916299559473\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_recall_micro'\u001b[0m: \u001b[1;36m0.14096916299559473\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_f1_score_micro'\u001b[0m: \u001b[1;36m0.14096916299559473\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_confusion_matrix'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m27\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m132\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m53\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_roc_auc'\u001b[0m: \u001b[1;36m0.5319817168701279\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_pr_auc'\u001b[0m: \u001b[1;36m0.3596197342614926\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_brier_score'\u001b[0m: \u001b[1;36m0.55610225252113\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_roc_auc_class_0'\u001b[0m: \u001b[1;36m0.4730964467005076\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_pr_auc_class_0'\u001b[0m: \u001b[1;36m0.12580756501576662\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_roc_auc_class_1'\u001b[0m: \u001b[1;36m0.5628899835796387\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_pr_auc_class_1'\u001b[0m: \u001b[1;36m0.6492525648321494\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_roc_auc_class_2'\u001b[0m: \u001b[1;36m0.5599587203302373\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_pr_auc_class_2'\u001b[0m: \u001b[1;36m0.2816445108714582\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_loss'\u001b[0m: \u001b[1;36m7.431046962738037\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_runtime'\u001b[0m: \u001b[1;36m2.7974\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_samples_per_second'\u001b[0m: \u001b[1;36m81.146\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'eval_steps_per_second'\u001b[0m: \u001b[1;36m10.367\u001b[0m\n","\u001b[1m}\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["trainer = Trainer(\n","    model=base_model,\n","    args=TrainingArguments(output_dir=\"./artifacts\", report_to=\"none\"),\n","    data_collator=data_collator,\n","    train_dataset=tokenized_train_dataset,\n","    eval_dataset=tokenized_valid_dataset,\n","    compute_metrics=compute_metrics_for_single_label_classification,\n",")\n","\n","valid_metrics = trainer.predict(tokenized_valid_dataset, metric_key_prefix=\"eval\")\n","pprint(valid_metrics.metrics)"]},{"cell_type":"markdown","metadata":{},"source":["## LoRA Implementation"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:12.894515Z","iopub.status.busy":"2024-07-21T15:15:12.894182Z","iopub.status.idle":"2024-07-21T15:15:12.965801Z","shell.execute_reply":"2024-07-21T15:15:12.964985Z","shell.execute_reply.started":"2024-07-21T15:15:12.894488Z"},"trusted":true},"outputs":[],"source":["class LoraConfig(BaseModel):\n","    r: int = Field(..., description=\"Lora attention dimension (the 'rank').\")\n","    lora_alpha: int = Field(..., description=\"The alpha parameter for Lora scaling.\")\n","    lora_dropout: float = Field(..., description=\"The dropout probability for Lora layers.\")\n","    target_modules: List[str] = Field(\n","        default=None,\n","        description=(\n","            \"The names of the modules to apply the adapter to. If specified, only the modules with the specified \"\n","            \"names will be replaced. When passing a string, a regex match will be performed. When passing a list of \"\n","            \"strings, either an exact match will be performed or it is checked if the name of the module ends with any \"\n","            \"of the passed strings. If specified as 'all-linear', all linear/Conv1D modules are chosen, excluding the \"\n","            \"output layer. If not specified, modules are chosen according to the model architecture. If the architecture \"\n","            \"is unknown, an error will be raised—manual specification of target modules is required in such cases.\"\n","        ),\n","    )\n","    modules_to_save: List[str] = Field(\n","        default=None,\n","        description=(\n","            \"\"\"List of modules apart from adapter layers to be set as\n","               trainable and saved in the final checkpoint.\"\"\"\n","        ),\n","    )"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:12.967534Z","iopub.status.busy":"2024-07-21T15:15:12.967153Z","iopub.status.idle":"2024-07-21T15:15:17.746159Z","shell.execute_reply":"2024-07-21T15:15:17.745133Z","shell.execute_reply.started":"2024-07-21T15:15:12.967501Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LoraConfig</span><span style=\"font-weight: bold\">(</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">r</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">lora_alpha</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">lora_dropout</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">target_modules</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'q_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'k_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'v_proj'</span><span style=\"font-weight: bold\">]</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">modules_to_save</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'score'</span><span style=\"font-weight: bold\">]</span>\n","<span style=\"font-weight: bold\">)</span>\n","</pre>\n"],"text/plain":["\u001b[1;35mLoraConfig\u001b[0m\u001b[1m(\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[33mr\u001b[0m=\u001b[1;36m4\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mlora_alpha\u001b[0m=\u001b[1;36m8\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mlora_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mtarget_modules\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'q_proj'\u001b[0m, \u001b[32m'k_proj'\u001b[0m, \u001b[32m'v_proj'\u001b[0m\u001b[1m]\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mmodules_to_save\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'score'\u001b[0m\u001b[1m]\u001b[0m\n","\u001b[1m)\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["lora_config = LoraConfig(\n","    r=4, lora_alpha=8, lora_dropout=0.1, target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"], modules_to_save=[\"score\"]\n",")\n","pprint(lora_config)"]},{"cell_type":"markdown","metadata":{},"source":["We print out the target modules below. For simplicity, we target only the `q`, `k` and `v` layers for now."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:17.749943Z","iopub.status.busy":"2024-07-21T15:15:17.749652Z","iopub.status.idle":"2024-07-21T15:15:17.758905Z","shell.execute_reply":"2024-07-21T15:15:17.757890Z","shell.execute_reply.started":"2024-07-21T15:15:17.749919Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model.layers.0.self_attn.q_proj\n","model.layers.0.self_attn.k_proj\n","model.layers.0.self_attn.v_proj\n","model.layers.1.self_attn.q_proj\n","model.layers.1.self_attn.k_proj\n","model.layers.1.self_attn.v_proj\n","model.layers.2.self_attn.q_proj\n","model.layers.2.self_attn.k_proj\n","model.layers.2.self_attn.v_proj\n","model.layers.3.self_attn.q_proj\n","model.layers.3.self_attn.k_proj\n","model.layers.3.self_attn.v_proj\n","model.layers.4.self_attn.q_proj\n","model.layers.4.self_attn.k_proj\n","model.layers.4.self_attn.v_proj\n","model.layers.5.self_attn.q_proj\n","model.layers.5.self_attn.k_proj\n","model.layers.5.self_attn.v_proj\n","model.layers.6.self_attn.q_proj\n","model.layers.6.self_attn.k_proj\n","model.layers.6.self_attn.v_proj\n","model.layers.7.self_attn.q_proj\n","model.layers.7.self_attn.k_proj\n","model.layers.7.self_attn.v_proj\n","model.layers.8.self_attn.q_proj\n","model.layers.8.self_attn.k_proj\n","model.layers.8.self_attn.v_proj\n","model.layers.9.self_attn.q_proj\n","model.layers.9.self_attn.k_proj\n","model.layers.9.self_attn.v_proj\n","model.layers.10.self_attn.q_proj\n","model.layers.10.self_attn.k_proj\n","model.layers.10.self_attn.v_proj\n","model.layers.11.self_attn.q_proj\n","model.layers.11.self_attn.k_proj\n","model.layers.11.self_attn.v_proj\n","model.layers.12.self_attn.q_proj\n","model.layers.12.self_attn.k_proj\n","model.layers.12.self_attn.v_proj\n","model.layers.13.self_attn.q_proj\n","model.layers.13.self_attn.k_proj\n","model.layers.13.self_attn.v_proj\n","model.layers.14.self_attn.q_proj\n","model.layers.14.self_attn.k_proj\n","model.layers.14.self_attn.v_proj\n","model.layers.15.self_attn.q_proj\n","model.layers.15.self_attn.k_proj\n","model.layers.15.self_attn.v_proj\n","model.layers.16.self_attn.q_proj\n","model.layers.16.self_attn.k_proj\n","model.layers.16.self_attn.v_proj\n","model.layers.17.self_attn.q_proj\n","model.layers.17.self_attn.k_proj\n","model.layers.17.self_attn.v_proj\n","model.layers.18.self_attn.q_proj\n","model.layers.18.self_attn.k_proj\n","model.layers.18.self_attn.v_proj\n","model.layers.19.self_attn.q_proj\n","model.layers.19.self_attn.k_proj\n","model.layers.19.self_attn.v_proj\n","model.layers.20.self_attn.q_proj\n","model.layers.20.self_attn.k_proj\n","model.layers.20.self_attn.v_proj\n","model.layers.21.self_attn.q_proj\n","model.layers.21.self_attn.k_proj\n","model.layers.21.self_attn.v_proj\n","model.layers.22.self_attn.q_proj\n","model.layers.22.self_attn.k_proj\n","model.layers.22.self_attn.v_proj\n","model.layers.23.self_attn.q_proj\n","model.layers.23.self_attn.k_proj\n","model.layers.23.self_attn.v_proj\n"]}],"source":["for module_name, _module in base_model.named_modules():\n","    if any(target_module in module_name for target_module in lora_config.target_modules):\n","        print(module_name)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:17.760789Z","iopub.status.busy":"2024-07-21T15:15:17.760361Z","iopub.status.idle":"2024-07-21T15:15:17.776994Z","shell.execute_reply":"2024-07-21T15:15:17.776056Z","shell.execute_reply.started":"2024-07-21T15:15:17.760758Z"},"trusted":true},"outputs":[],"source":["\"\"\"LoRA: Low-Rank Adaptation of Large Language Models.\n","\n","References\n","----------\n","[1] https://pytorch.org/torchtune/stable/tutorials/lora_finetune.html\n","\"\"\"\n","\n","\n","from __future__ import annotations\n","\n","import math\n","from typing import List\n","\n","import torch\n","from torch import nn\n","\n","\n","def _lora_a_init_params(x: nn.Linear) -> None:\n","    \"\"\"\n","    Initialize LoRA A weight to Kaiming uniform.\n","    \"\"\"\n","    nn.init.kaiming_uniform_(x.weight, a=math.sqrt(5))\n","\n","\n","def _lora_b_init_params(x: nn.Linear) -> None:\n","    \"\"\"\n","    Initialize LoRA B weight to zeros.\n","    \"\"\"\n","    nn.init.zeros_(x.weight)\n","\n","\n","class LoRALinear(nn.Module):\n","    def __init__(self, in_dim: int, out_dim: int, bias: bool, rank: int, alpha: float, dropout: float) -> None:\n","        super().__init__()\n","\n","        # These are the weights from the original pretrained model\n","        self.linear = nn.Linear(in_dim, out_dim, bias=bias)  # weight shape=[out_dim, in_dim]\n","\n","        # These are the new LoRA params. In general rank << in_dim, out_dim - do not put bias here\n","        self.lora_a = nn.Linear(in_features=in_dim, out_features=rank, bias=False)  # weight shape=[rank, in_dim]\n","        self.lora_b = nn.Linear(in_features=rank, out_features=out_dim, bias=False)  # weight shape=[out_dim, rank]\n","\n","        self.rank = rank\n","        self.alpha = alpha\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        self._init_weights()\n","\n","    def _init_weights(self) -> None:\n","        \"\"\"See https://github.com/microsoft/LoRA/blob/4c0333854cb905966f8cc4e9a74068c1e507c7b7/loralib/layers.py#L119.\"\"\"\n","\n","        _lora_a_init_params(self.lora_a)\n","        _lora_b_init_params(self.lora_b)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        # This would be the output of the original model\n","        frozen_out = x @ self.linear.weight.T\n","        if self.linear.bias is not None:\n","            frozen_out += self.linear.bias\n","\n","        # lora_a projects inputs down to the much smaller self.rank,\n","        # then lora_b projects back up to the output dimension\n","        x = self.dropout(x)\n","        lora_out = (x @ self.lora_a.weight.T) @ self.lora_b.weight.T\n","        # Finally, scale by the alpha parameter (normalized by rank)\n","        # and add to the original model's outputs\n","        return frozen_out + (self.alpha / self.rank) * lora_out\n","\n","\n","def apply_lora_to_base_model(\n","    model: nn.Module, rank: int, alpha: float, dropout: float, target_modules: List[str] | None = None\n",") -> None:\n","    \"\"\"Recursively apply LoRA to a model. Only supports applying on `nn.Linear` layers.\"\"\"\n","\n","    for module_name, module in model.named_children():\n","        if isinstance(module, nn.Linear):\n","            if target_modules is None or any(target in module_name for target in target_modules):\n","                setattr(\n","                    model,\n","                    module_name,\n","                    LoRALinear(\n","                        in_dim=module.in_features,\n","                        out_dim=module.out_features,\n","                        rank=rank,\n","                        alpha=alpha,\n","                        dropout=dropout,\n","                        bias=module.bias is not None,\n","                    ),\n","                )\n","        else:\n","            # Recursively apply LoRA to children modules\n","            apply_lora_to_base_model(model=module, rank=rank, alpha=alpha, dropout=dropout, target_modules=target_modules)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:17.778484Z","iopub.status.busy":"2024-07-21T15:15:17.778171Z","iopub.status.idle":"2024-07-21T15:15:17.868712Z","shell.execute_reply":"2024-07-21T15:15:17.867888Z","shell.execute_reply.started":"2024-07-21T15:15:17.778460Z"},"trusted":true},"outputs":[],"source":["base_model_with_adapter = copy.deepcopy(base_model)"]},{"cell_type":"markdown","metadata":{},"source":["We apply recursively the `LoRA` module to the `q`, `k` and `v` layers\n","via `apply_lora_to_base_model`."]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:17.870140Z","iopub.status.busy":"2024-07-21T15:15:17.869849Z","iopub.status.idle":"2024-07-21T15:15:18.548887Z","shell.execute_reply":"2024-07-21T15:15:18.547852Z","shell.execute_reply.started":"2024-07-21T15:15:17.870115Z"},"trusted":true},"outputs":[],"source":["apply_lora_to_base_model(\n","    model=base_model_with_adapter,\n","    rank=lora_config.r,\n","    alpha=lora_config.lora_alpha,\n","    dropout=lora_config.lora_dropout,\n","    target_modules=lora_config.target_modules,\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:18.550313Z","iopub.status.busy":"2024-07-21T15:15:18.549986Z","iopub.status.idle":"2024-07-21T15:15:18.558335Z","shell.execute_reply":"2024-07-21T15:15:18.557382Z","shell.execute_reply.started":"2024-07-21T15:15:18.550286Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total trainable parameters after LoRA before freezing: 464,580,608\n"]}],"source":["base_model_with_adapter_total_trainable = total_trainable_parameters(base_model_with_adapter)\n","print(f\"Total trainable parameters after LoRA before freezing: {base_model_with_adapter_total_trainable:,}\")"]},{"cell_type":"markdown","metadata":{},"source":["First `bias` is default to `True` in original model, but in LoRA we need to have it as `False`. \n","You also see that currently the total trainable parameters are more than base model. Why? "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:18.559886Z","iopub.status.busy":"2024-07-21T15:15:18.559554Z","iopub.status.idle":"2024-07-21T15:15:18.572048Z","shell.execute_reply":"2024-07-21T15:15:18.571122Z","shell.execute_reply.started":"2024-07-21T15:15:18.559856Z"},"trusted":true},"outputs":[{"data":{"text/plain":["589824"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["base_model_with_adapter_total_trainable - base_model_total_trainable"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:18.573630Z","iopub.status.busy":"2024-07-21T15:15:18.573337Z","iopub.status.idle":"2024-07-21T15:15:18.583455Z","shell.execute_reply":"2024-07-21T15:15:18.582584Z","shell.execute_reply.started":"2024-07-21T15:15:18.573606Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["dim = base_model_with_adapter.model.layers[0].self_attn.q_proj.linear.weight.shape[0]\n","layers = base_model_with_adapter.model.layers.__len__()\n","rank = lora_config.r\n","num_target_modules = len(lora_config.target_modules)\n","\n","qkv_lora_weight_params = (dim * rank * 2) * layers * num_target_modules # 2 is the AB 1 each\n","\n","base_model_with_adapter_total_trainable - base_model_total_trainable ==  qkv_lora_weight_params"]},{"cell_type":"markdown","metadata":{},"source":["The additional parameters is basically because we apply to `qkv` where each `qkv` has 24 layers each, so for each layer, say `q_proj` we would have an additional\n","of `1024 * 4 * 2` because matrix A and B are mirrored to version of `[dim, rank]`. \n","\n","Now of course the next step is to freeze the base pretrained weights.\n","Note we DO NOT want to freeze the `score` module as that is our classification head."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:18.585123Z","iopub.status.busy":"2024-07-21T15:15:18.584458Z","iopub.status.idle":"2024-07-21T15:15:18.599915Z","shell.execute_reply":"2024-07-21T15:15:18.598988Z","shell.execute_reply.started":"2024-07-21T15:15:18.585082Z"},"trusted":true},"outputs":[],"source":["for parameter_name, parameter in base_model_with_adapter.named_parameters():\n","    # We will set requires_grad to False if 'lora_' is not in the parameter name AND the parameter name does not contain any of the module names specified in modules_to_save\n","    if \"lora_\" not in parameter_name and not any(\n","        module_name in parameter_name for module_name in lora_config.modules_to_save\n","    ):\n","        parameter.requires_grad = False\n","    else:\n","        # Safeguard here parameters that are part of LoRA or specified modules are trainable\n","        parameter.requires_grad = True"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:18.601685Z","iopub.status.busy":"2024-07-21T15:15:18.601293Z","iopub.status.idle":"2024-07-21T15:15:18.613486Z","shell.execute_reply":"2024-07-21T15:15:18.612650Z","shell.execute_reply.started":"2024-07-21T15:15:18.601651Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total trainable parameters after LoRA after freezing: 592,896\n"]}],"source":["base_model_with_adapter_total_trainable = total_trainable_parameters(base_model_with_adapter)\n","print(f\"Total trainable parameters after LoRA after freezing: {base_model_with_adapter_total_trainable:,}\")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:18.614955Z","iopub.status.busy":"2024-07-21T15:15:18.614683Z","iopub.status.idle":"2024-07-21T15:15:18.625536Z","shell.execute_reply":"2024-07-21T15:15:18.624549Z","shell.execute_reply.started":"2024-07-21T15:15:18.614931Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.1277818483567122"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["(base_model_with_adapter_total_trainable / base_model_total_trainable) * 100"]},{"cell_type":"markdown","metadata":{},"source":["We are only training on `~0.1277%` of the total parameters."]},{"cell_type":"markdown","metadata":{},"source":["## Train LoRA"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:18.627125Z","iopub.status.busy":"2024-07-21T15:15:18.626739Z","iopub.status.idle":"2024-07-21T15:15:21.637738Z","shell.execute_reply":"2024-07-21T15:15:21.636725Z","shell.execute_reply.started":"2024-07-21T15:15:18.627094Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LoraConfig</span><span style=\"font-weight: bold\">(</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">r</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">lora_alpha</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">lora_dropout</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">target_modules</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'q_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'k_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'v_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'o_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gate_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'up_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'down_proj'</span><span style=\"font-weight: bold\">]</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">modules_to_save</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'score'</span><span style=\"font-weight: bold\">]</span>\n","<span style=\"font-weight: bold\">)</span>\n","</pre>\n"],"text/plain":["\u001b[1;35mLoraConfig\u001b[0m\u001b[1m(\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[33mr\u001b[0m=\u001b[1;36m16\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mlora_alpha\u001b[0m=\u001b[1;36m32\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mlora_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mtarget_modules\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'q_proj'\u001b[0m, \u001b[32m'k_proj'\u001b[0m, \u001b[32m'v_proj'\u001b[0m, \u001b[32m'o_proj'\u001b[0m, \u001b[32m'gate_proj'\u001b[0m, \u001b[32m'up_proj'\u001b[0m, \u001b[32m'down_proj'\u001b[0m\u001b[1m]\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mmodules_to_save\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'score'\u001b[0m\u001b[1m]\u001b[0m\n","\u001b[1m)\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["seed_all(42, seed_torch=True, set_torch_deterministic=False)\n","\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.1,\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n","    modules_to_save=[\"score\"],\n",")\n","pprint(lora_config)\n","\n","base_model_with_adapter = copy.deepcopy(base_model)\n","\n","apply_lora_to_base_model(\n","    model=base_model_with_adapter,\n","    rank=lora_config.r,\n","    alpha=lora_config.lora_alpha,\n","    dropout=lora_config.lora_dropout,\n","    target_modules=lora_config.target_modules,\n",")\n","\n","for parameter_name, parameter in base_model_with_adapter.named_parameters():\n","    # We will set requires_grad to False if 'lora_' is not in the parameter name AND the parameter name does not contain any of the module names specified in modules_to_save\n","    if \"lora_\" not in parameter_name and not any(\n","        module_name in parameter_name for module_name in lora_config.modules_to_save\n","    ):\n","        parameter.requires_grad = False\n","    else:\n","        # Safeguard here parameters that are part of LoRA or specified modules are trainable\n","        parameter.requires_grad = True"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:21.639530Z","iopub.status.busy":"2024-07-21T15:15:21.639118Z","iopub.status.idle":"2024-07-21T15:15:21.672267Z","shell.execute_reply":"2024-07-21T15:15:21.671274Z","shell.execute_reply.started":"2024-07-21T15:15:21.639496Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["training_args = TrainingArguments(\n","    do_eval=True,\n","    do_predict=False,\n","    do_train=True,\n","    warmup_ratio=0.0,\n","    learning_rate=6e-4,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    num_train_epochs=10,\n","    report_to=\"none\",\n","    output_dir=\"./artifacts\",\n","    overwrite_output_dir=True,\n","    gradient_accumulation_steps=1,\n","    logging_steps=25,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=32,\n","    save_strategy=\"steps\",\n","    save_steps=128,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    lr_scheduler_type=\"cosine\",\n","    weight_decay=0.0,\n","    save_total_limit=2,\n","    seed=42,\n","    data_seed=42,\n","    half_precision_backend=\"auto\",\n","    optim=\"adamw_torch\",\n","    label_smoothing_factor=0.0,\n","    max_grad_norm=1.0,\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:21.674098Z","iopub.status.busy":"2024-07-21T15:15:21.673675Z","iopub.status.idle":"2024-07-21T15:15:22.046118Z","shell.execute_reply":"2024-07-21T15:15:22.045331Z","shell.execute_reply.started":"2024-07-21T15:15:21.674065Z"},"trusted":true},"outputs":[],"source":["trainer = Trainer(\n","    model=base_model_with_adapter,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=tokenized_train_dataset,\n","    eval_dataset=tokenized_valid_dataset,\n","    compute_metrics=compute_metrics_for_single_label_classification,\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-07-21T15:15:22.047552Z","iopub.status.busy":"2024-07-21T15:15:22.047261Z","iopub.status.idle":"2024-07-21T15:19:48.888895Z","shell.execute_reply":"2024-07-21T15:19:48.887978Z","shell.execute_reply.started":"2024-07-21T15:15:22.047528Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [640/640 04:25, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Log Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision Macro</th>\n","      <th>Recall Macro</th>\n","      <th>F1 Score Macro</th>\n","      <th>Precision Micro</th>\n","      <th>Recall Micro</th>\n","      <th>F1 Score Micro</th>\n","      <th>Confusion Matrix</th>\n","      <th>Roc Auc</th>\n","      <th>Pr Auc</th>\n","      <th>Brier Score</th>\n","      <th>Roc Auc Class 0</th>\n","      <th>Pr Auc Class 0</th>\n","      <th>Roc Auc Class 1</th>\n","      <th>Pr Auc Class 1</th>\n","      <th>Roc Auc Class 2</th>\n","      <th>Pr Auc Class 2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>32</td>\n","      <td>2.532300</td>\n","      <td>1.149722</td>\n","      <td>1.149722</td>\n","      <td>0.466960</td>\n","      <td>0.456524</td>\n","      <td>0.454219</td>\n","      <td>0.424775</td>\n","      <td>0.466960</td>\n","      <td>0.466960</td>\n","      <td>0.466960</td>\n","      <td>[[12, 3, 15], [14, 66, 60], [18, 11, 28]]</td>\n","      <td>0.624885</td>\n","      <td>0.426832</td>\n","      <td>0.226024</td>\n","      <td>0.578849</td>\n","      <td>0.201540</td>\n","      <td>0.738013</td>\n","      <td>0.764325</td>\n","      <td>0.557792</td>\n","      <td>0.288986</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>1.411900</td>\n","      <td>0.881590</td>\n","      <td>0.881590</td>\n","      <td>0.629956</td>\n","      <td>0.367942</td>\n","      <td>0.541270</td>\n","      <td>0.418140</td>\n","      <td>0.629956</td>\n","      <td>0.629956</td>\n","      <td>0.629956</td>\n","      <td>[[23, 7, 0], [20, 120, 0], [37, 20, 0]]</td>\n","      <td>0.778497</td>\n","      <td>0.544018</td>\n","      <td>0.171648</td>\n","      <td>0.771404</td>\n","      <td>0.335984</td>\n","      <td>0.851806</td>\n","      <td>0.888730</td>\n","      <td>0.712281</td>\n","      <td>0.383698</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>1.193600</td>\n","      <td>1.172019</td>\n","      <td>1.172019</td>\n","      <td>0.656388</td>\n","      <td>0.509725</td>\n","      <td>0.421011</td>\n","      <td>0.399458</td>\n","      <td>0.656388</td>\n","      <td>0.656388</td>\n","      <td>0.656388</td>\n","      <td>[[6, 20, 4], [0, 139, 1], [9, 44, 4]]</td>\n","      <td>0.820734</td>\n","      <td>0.592243</td>\n","      <td>0.186765</td>\n","      <td>0.820474</td>\n","      <td>0.385348</td>\n","      <td>0.874959</td>\n","      <td>0.918497</td>\n","      <td>0.766770</td>\n","      <td>0.446123</td>\n","    </tr>\n","    <tr>\n","      <td>128</td>\n","      <td>0.906400</td>\n","      <td>0.915803</td>\n","      <td>0.915803</td>\n","      <td>0.696035</td>\n","      <td>0.739316</td>\n","      <td>0.512281</td>\n","      <td>0.483242</td>\n","      <td>0.696035</td>\n","      <td>0.696035</td>\n","      <td>0.696035</td>\n","      <td>[[14, 16, 0], [0, 140, 0], [14, 39, 4]]</td>\n","      <td>0.874193</td>\n","      <td>0.721981</td>\n","      <td>0.151727</td>\n","      <td>0.828765</td>\n","      <td>0.506458</td>\n","      <td>0.932102</td>\n","      <td>0.949205</td>\n","      <td>0.861713</td>\n","      <td>0.700514</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>1.006300</td>\n","      <td>0.916757</td>\n","      <td>0.916757</td>\n","      <td>0.691630</td>\n","      <td>0.405074</td>\n","      <td>0.592063</td>\n","      <td>0.457581</td>\n","      <td>0.691630</td>\n","      <td>0.691630</td>\n","      <td>0.691630</td>\n","      <td>[[25, 5, 0], [8, 132, 0], [49, 8, 0]]</td>\n","      <td>0.853698</td>\n","      <td>0.718629</td>\n","      <td>0.160593</td>\n","      <td>0.890525</td>\n","      <td>0.696728</td>\n","      <td>0.959113</td>\n","      <td>0.966931</td>\n","      <td>0.711455</td>\n","      <td>0.481235</td>\n","    </tr>\n","    <tr>\n","      <td>192</td>\n","      <td>0.646600</td>\n","      <td>0.556572</td>\n","      <td>0.556572</td>\n","      <td>0.801762</td>\n","      <td>0.758897</td>\n","      <td>0.677151</td>\n","      <td>0.697156</td>\n","      <td>0.801762</td>\n","      <td>0.801762</td>\n","      <td>0.801762</td>\n","      <td>[[18, 6, 6], [1, 139, 0], [9, 23, 25]]</td>\n","      <td>0.926962</td>\n","      <td>0.826036</td>\n","      <td>0.097159</td>\n","      <td>0.925381</td>\n","      <td>0.750799</td>\n","      <td>0.958292</td>\n","      <td>0.962526</td>\n","      <td>0.897214</td>\n","      <td>0.758678</td>\n","    </tr>\n","    <tr>\n","      <td>224</td>\n","      <td>0.414200</td>\n","      <td>0.781973</td>\n","      <td>0.781973</td>\n","      <td>0.775330</td>\n","      <td>0.740313</td>\n","      <td>0.765706</td>\n","      <td>0.708334</td>\n","      <td>0.775330</td>\n","      <td>0.775330</td>\n","      <td>0.775330</td>\n","      <td>[[27, 1, 2], [20, 117, 3], [21, 4, 32]]</td>\n","      <td>0.917313</td>\n","      <td>0.834643</td>\n","      <td>0.117436</td>\n","      <td>0.933164</td>\n","      <td>0.774185</td>\n","      <td>0.953038</td>\n","      <td>0.944113</td>\n","      <td>0.865738</td>\n","      <td>0.780279</td>\n","    </tr>\n","    <tr>\n","      <td>256</td>\n","      <td>0.672900</td>\n","      <td>0.377145</td>\n","      <td>0.377146</td>\n","      <td>0.885463</td>\n","      <td>0.849421</td>\n","      <td>0.839098</td>\n","      <td>0.824764</td>\n","      <td>0.885463</td>\n","      <td>0.885463</td>\n","      <td>0.885463</td>\n","      <td>[[27, 2, 1], [2, 138, 0], [13, 8, 36]]</td>\n","      <td>0.962969</td>\n","      <td>0.921311</td>\n","      <td>0.060094</td>\n","      <td>0.969543</td>\n","      <td>0.870216</td>\n","      <td>0.977258</td>\n","      <td>0.980682</td>\n","      <td>0.942105</td>\n","      <td>0.910672</td>\n","    </tr>\n","    <tr>\n","      <td>288</td>\n","      <td>0.393100</td>\n","      <td>0.400418</td>\n","      <td>0.400418</td>\n","      <td>0.863436</td>\n","      <td>0.825215</td>\n","      <td>0.792272</td>\n","      <td>0.797615</td>\n","      <td>0.863436</td>\n","      <td>0.863436</td>\n","      <td>0.863436</td>\n","      <td>[[23, 4, 3], [3, 137, 0], [9, 12, 36]]</td>\n","      <td>0.955590</td>\n","      <td>0.896320</td>\n","      <td>0.067456</td>\n","      <td>0.961929</td>\n","      <td>0.833168</td>\n","      <td>0.968309</td>\n","      <td>0.970140</td>\n","      <td>0.936533</td>\n","      <td>0.882264</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.299400</td>\n","      <td>0.417757</td>\n","      <td>0.417757</td>\n","      <td>0.885463</td>\n","      <td>0.873151</td>\n","      <td>0.810986</td>\n","      <td>0.837477</td>\n","      <td>0.885463</td>\n","      <td>0.885463</td>\n","      <td>0.885463</td>\n","      <td>[[21, 3, 6], [1, 137, 2], [2, 12, 43]]</td>\n","      <td>0.962225</td>\n","      <td>0.911811</td>\n","      <td>0.058212</td>\n","      <td>0.963113</td>\n","      <td>0.855440</td>\n","      <td>0.975780</td>\n","      <td>0.977580</td>\n","      <td>0.947781</td>\n","      <td>0.899633</td>\n","    </tr>\n","    <tr>\n","      <td>352</td>\n","      <td>0.212100</td>\n","      <td>0.631729</td>\n","      <td>0.631729</td>\n","      <td>0.845815</td>\n","      <td>0.826256</td>\n","      <td>0.749248</td>\n","      <td>0.762732</td>\n","      <td>0.845815</td>\n","      <td>0.845815</td>\n","      <td>0.845815</td>\n","      <td>[[14, 2, 14], [0, 129, 11], [2, 6, 49]]</td>\n","      <td>0.937036</td>\n","      <td>0.864003</td>\n","      <td>0.078483</td>\n","      <td>0.898308</td>\n","      <td>0.746999</td>\n","      <td>0.977094</td>\n","      <td>0.984696</td>\n","      <td>0.935707</td>\n","      <td>0.855737</td>\n","    </tr>\n","    <tr>\n","      <td>384</td>\n","      <td>0.215800</td>\n","      <td>0.920309</td>\n","      <td>0.914577</td>\n","      <td>0.841410</td>\n","      <td>0.865780</td>\n","      <td>0.726316</td>\n","      <td>0.772929</td>\n","      <td>0.841410</td>\n","      <td>0.841410</td>\n","      <td>0.841410</td>\n","      <td>[[18, 9, 3], [0, 140, 0], [3, 21, 33]]</td>\n","      <td>0.957390</td>\n","      <td>0.893919</td>\n","      <td>0.091860</td>\n","      <td>0.955499</td>\n","      <td>0.825081</td>\n","      <td>0.975082</td>\n","      <td>0.974151</td>\n","      <td>0.941589</td>\n","      <td>0.881868</td>\n","    </tr>\n","    <tr>\n","      <td>416</td>\n","      <td>0.159000</td>\n","      <td>0.735958</td>\n","      <td>0.733248</td>\n","      <td>0.876652</td>\n","      <td>0.860057</td>\n","      <td>0.780033</td>\n","      <td>0.811216</td>\n","      <td>0.876652</td>\n","      <td>0.876652</td>\n","      <td>0.876652</td>\n","      <td>[[18, 5, 7], [0, 138, 2], [3, 11, 43]]</td>\n","      <td>0.963676</td>\n","      <td>0.912504</td>\n","      <td>0.073555</td>\n","      <td>0.971743</td>\n","      <td>0.866606</td>\n","      <td>0.976149</td>\n","      <td>0.980248</td>\n","      <td>0.943137</td>\n","      <td>0.889004</td>\n","    </tr>\n","    <tr>\n","      <td>448</td>\n","      <td>0.201800</td>\n","      <td>0.503680</td>\n","      <td>0.503680</td>\n","      <td>0.876652</td>\n","      <td>0.818909</td>\n","      <td>0.800961</td>\n","      <td>0.809249</td>\n","      <td>0.876652</td>\n","      <td>0.876652</td>\n","      <td>0.876652</td>\n","      <td>[[20, 2, 8], [0, 135, 5], [7, 6, 44]]</td>\n","      <td>0.959737</td>\n","      <td>0.901048</td>\n","      <td>0.066298</td>\n","      <td>0.952453</td>\n","      <td>0.831085</td>\n","      <td>0.979803</td>\n","      <td>0.982069</td>\n","      <td>0.946956</td>\n","      <td>0.887234</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.026200</td>\n","      <td>0.855887</td>\n","      <td>0.827394</td>\n","      <td>0.885463</td>\n","      <td>0.851778</td>\n","      <td>0.800459</td>\n","      <td>0.821610</td>\n","      <td>0.885463</td>\n","      <td>0.885463</td>\n","      <td>0.885463</td>\n","      <td>[[19, 3, 8], [0, 137, 3], [4, 8, 45]]</td>\n","      <td>0.957381</td>\n","      <td>0.899668</td>\n","      <td>0.072127</td>\n","      <td>0.963283</td>\n","      <td>0.844908</td>\n","      <td>0.969540</td>\n","      <td>0.972841</td>\n","      <td>0.939319</td>\n","      <td>0.884628</td>\n","    </tr>\n","    <tr>\n","      <td>512</td>\n","      <td>0.066600</td>\n","      <td>0.686846</td>\n","      <td>0.658125</td>\n","      <td>0.894273</td>\n","      <td>0.858992</td>\n","      <td>0.827945</td>\n","      <td>0.842211</td>\n","      <td>0.894273</td>\n","      <td>0.894273</td>\n","      <td>0.894273</td>\n","      <td>[[22, 2, 6], [0, 137, 3], [5, 8, 44]]</td>\n","      <td>0.961652</td>\n","      <td>0.909252</td>\n","      <td>0.063930</td>\n","      <td>0.965990</td>\n","      <td>0.860553</td>\n","      <td>0.974179</td>\n","      <td>0.977094</td>\n","      <td>0.944788</td>\n","      <td>0.894197</td>\n","    </tr>\n","    <tr>\n","      <td>544</td>\n","      <td>0.014200</td>\n","      <td>0.711445</td>\n","      <td>0.689413</td>\n","      <td>0.898678</td>\n","      <td>0.860229</td>\n","      <td>0.837260</td>\n","      <td>0.847945</td>\n","      <td>0.898678</td>\n","      <td>0.898678</td>\n","      <td>0.898678</td>\n","      <td>[[22, 2, 6], [0, 136, 4], [5, 6, 46]]</td>\n","      <td>0.961123</td>\n","      <td>0.906223</td>\n","      <td>0.061705</td>\n","      <td>0.963113</td>\n","      <td>0.848701</td>\n","      <td>0.976190</td>\n","      <td>0.979598</td>\n","      <td>0.944066</td>\n","      <td>0.891514</td>\n","    </tr>\n","    <tr>\n","      <td>576</td>\n","      <td>0.017400</td>\n","      <td>0.785417</td>\n","      <td>0.744421</td>\n","      <td>0.889868</td>\n","      <td>0.863217</td>\n","      <td>0.816834</td>\n","      <td>0.837244</td>\n","      <td>0.889868</td>\n","      <td>0.889868</td>\n","      <td>0.889868</td>\n","      <td>[[21, 3, 6], [0, 137, 3], [4, 9, 44]]</td>\n","      <td>0.961103</td>\n","      <td>0.905028</td>\n","      <td>0.065667</td>\n","      <td>0.963790</td>\n","      <td>0.848383</td>\n","      <td>0.975452</td>\n","      <td>0.980741</td>\n","      <td>0.944066</td>\n","      <td>0.889986</td>\n","    </tr>\n","    <tr>\n","      <td>608</td>\n","      <td>0.012200</td>\n","      <td>0.797757</td>\n","      <td>0.755783</td>\n","      <td>0.889868</td>\n","      <td>0.869070</td>\n","      <td>0.811571</td>\n","      <td>0.835462</td>\n","      <td>0.889868</td>\n","      <td>0.889868</td>\n","      <td>0.889868</td>\n","      <td>[[20, 3, 7], [0, 137, 3], [3, 9, 45]]</td>\n","      <td>0.960987</td>\n","      <td>0.904637</td>\n","      <td>0.066113</td>\n","      <td>0.963959</td>\n","      <td>0.848363</td>\n","      <td>0.975452</td>\n","      <td>0.981116</td>\n","      <td>0.943550</td>\n","      <td>0.888471</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.000900</td>\n","      <td>0.795754</td>\n","      <td>0.753513</td>\n","      <td>0.885463</td>\n","      <td>0.855870</td>\n","      <td>0.805723</td>\n","      <td>0.827210</td>\n","      <td>0.885463</td>\n","      <td>0.885463</td>\n","      <td>0.885463</td>\n","      <td>[[20, 3, 7], [0, 137, 3], [4, 9, 44]]</td>\n","      <td>0.961160</td>\n","      <td>0.904855</td>\n","      <td>0.066205</td>\n","      <td>0.964129</td>\n","      <td>0.848551</td>\n","      <td>0.975698</td>\n","      <td>0.981358</td>\n","      <td>0.943653</td>\n","      <td>0.888699</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=640, training_loss=0.4735630032751942, metrics={'train_runtime': 266.377, 'train_samples_per_second': 76.471, 'train_steps_per_second': 2.403, 'total_flos': 1235801533317120.0, 'train_loss': 0.4735630032751942, 'epoch': 10.0})"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["The accuracy hits around $90\\%$ after 10 epochs. This is a far cry from what\n","an encoder like Deberta can achieve. But this is a good start and shows that\n","the implementation is working."]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["https://huggingface.co/docs/peft/main/en/developer_guides/lora#merge-lora-weights-into-the-base-model"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
