{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Profiling Code With Timeit\n","\n","[![Twitter Handle](https://img.shields.io/badge/Twitter-@gaohongnan-blue?style=social&logo=twitter)](https://twitter.com/gaohongnan)\n","[![LinkedIn Profile](https://img.shields.io/badge/@gaohongnan-blue?style=social&logo=linkedin)](https://linkedin.com/in/gao-hongnan)\n","[![GitHub Profile](https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&logo=github)](https://github.com/gao-hongnan)\n","![Tag](https://img.shields.io/badge/Tag-Brain_Dump-red)\n","![Tag](https://img.shields.io/badge/Level-Beginner-green)\n","[![Code](https://img.shields.io/badge/View-Code-blue?style=flat-square&logo=github)](https://github.com/gao-hongnan/omniverse/blob/40d344316978bc9136b701e26f78ea6854101d1e/omnixamples/profiling/timeit_profiler.py)\n","\n","```{contents}\n",":local:\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# %pip install -q omniverse==0.0.63"]},{"cell_type":"markdown","metadata":{},"source":["## Common Functions\n","\n","This module include GPT model definitions as well as some common config."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T10:57:09.973341Z","iopub.status.busy":"2024-08-11T10:57:09.973003Z","iopub.status.idle":"2024-08-11T10:57:12.090761Z","shell.execute_reply":"2024-08-11T10:57:12.089714Z","shell.execute_reply.started":"2024-08-11T10:57:09.973314Z"},"trusted":true},"outputs":[],"source":["from __future__ import annotations\n","\n","from typing import Literal, Tuple, cast\n","\n","import torch\n","from pydantic import BaseModel\n","from torch import nn\n","\n","from omnivault.modules.activation import GELU, SoftmaxStable\n","from omnivault.transformer.modules.layers.normalization import RMSNorm\n","\n","__tagged__ = \"This code tags to `30d963e` of cs336-stanford-spring2024-assignment1-gpt-from-scratch.\"\n","__reference__ = [\"https://github.com/marcelroed/spring2024-assignment2-systems/blob/master/writeup.pdf\"]\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","class General(BaseModel):\n","    batch_size: int = 16\n","    seed: int = 20230310\n","\n","\n","class ProfilerConfig(BaseModel):\n","    computation: Literal[\"forward\", \"backward\", \"forward_backward\"]\n","    warmup_steps: int | None = None\n","    profile_steps: int\n","    mixed_precision: bool = False\n","\n","\n","class GPTConfig(BaseModel):\n","    approximate: Literal[\"tanh\"] | None = None\n","    activation_name: Literal[\"gelu\"] = \"gelu\"\n","    d_model: int\n","    d_ff: int | None = None\n","    num_heads: int\n","    context_length: int\n","    attn_pdrop: float = 0.0\n","    resid_pdrop: float = 0.0\n","    bias: bool = False\n","    vocab_size: int\n","    num_blocks: int\n","    token_position_pdrop: float = 0.0\n","    weight_tie: bool = False\n","\n","\n","class PositionwiseFeedForward(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int,\n","        d_ff: int | None = None,\n","        bias: bool = False,\n","        activation_name: Literal[\"gelu\"] = \"gelu\",\n","        dropout: float = 0.0,\n","    ) -> None:\n","        super().__init__()\n","\n","        self.d_model = d_model\n","        self.d_ff = d_ff or 4 * d_model\n","        self.bias = bias  # bias False in this exercise\n","        self.activation_name = activation_name\n","        self.dropout = dropout\n","\n","        self.ffn = nn.ModuleDict(\n","            {\n","                # incoming `B x T x D` and we are interested in `T x D` so weight is `D x d_ff`\n","                # so that `Z @ W1 -> (T x D) @ (D x d_ff)`\n","                \"context_fc\": nn.Linear(in_features=self.d_model, out_features=self.d_ff, bias=self.bias),\n","                \"activation\": self.activation,\n","                # apply dropout after activation for random lights out\n","                \"dropout\": nn.Dropout(p=self.dropout, inplace=False),\n","                # incoming is Z @ W1 -> T x d_ff -> (T x d_ff) @ (d_ff x D) project back to D\n","                \"context_projection\": nn.Linear(in_features=self.d_ff, out_features=self.d_model, bias=self.bias),\n","            }\n","        )\n","\n","    @property\n","    def activation(self) -> nn.Module:\n","        if self.activation_name == \"gelu\":\n","            activation = GELU(approximate=None)  # no approx using tanh\n","        else:\n","            raise ValueError(f\"Unsupported activation: {self._activation}\")\n","        return activation\n","\n","    def forward(self, z: torch.Tensor) -> torch.Tensor:\n","        # fmt: off\n","        z = self.ffn[\"context_fc\"](z)           # Z @ W1 = [B, T, D] @ [D, d_ff] = [B, T, d_ff]\n","        z = self.ffn[\"activation\"](z)           # \\sigma(Z @ W1) = [B, T, d_ff]\n","        z = self.ffn[\"dropout\"](z)              # \\dropout(\\sigma(Z @ W1)) = [B, T, d_ff]\n","        z = self.ffn[\"context_projection\"](z)   # \\dropout(\\sigma(Z @ W1)) @ W2 = [B, T, d_ff] @ [d_ff, D] = [B, T, D]\n","        # fmt: on\n","        return z\n","\n","\n","class ScaledDotProductAttention(nn.Module):\n","    def __init__(self, dropout: float = 0.0) -> None:\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(\n","        self,\n","        query: torch.Tensor,\n","        key: torch.Tensor,\n","        value: torch.Tensor,\n","        mask: torch.BoolTensor | None = None,\n","    ) -> Tuple[torch.Tensor, torch.Tensor]:\n","        # fmt: off\n","        T, d_q = query.size(-2), query.size(-1)\n","\n","        attention_scores  = torch.matmul(query, key.transpose(dim0=-2, dim1=-1)) / torch.sqrt(torch.tensor(d_q).float())        # Q @ K.T = [B, H, T, d_q] @ [B, H, d_q, T] = [B, H, T, T]\n","\n","        if mask is not None:\n","            mask = mask[:, :, :T, :T] # type: ignore[assignment]\n","            attention_scores  = attention_scores.masked_fill(mask == 1, float(\"-inf\")) if mask is not None else attention_scores    # [B, H, T, T]\n","\n","        softmax           = SoftmaxStable(dim=-1)\n","        attention_weights = softmax(attention_scores)               # [B, H, T, T]\n","        attention_weights = self.dropout(attention_weights)         # [B, H, T, T]\n","\n","        context_vector    = torch.matmul(attention_weights, value)  # [B, H, T, T] @ [B, H, T, d_v] = [B, H, T, d_v]\n","        # fmt: on\n","        return context_vector, attention_weights\n","\n","\n","class CausalMultiHeadSelfAttention(nn.Module):\n","    context_vector: torch.Tensor\n","    attention_weights: torch.Tensor\n","\n","    def __init__(\n","        self,\n","        d_model: int,\n","        num_heads: int,\n","        context_length: int,\n","        attn_pdrop: float = 0.0,  # pdrop means prob of dropout\n","        resid_pdrop: float = 0.0,\n","        bias: bool = False,\n","    ) -> None:\n","        super().__init__()\n","\n","        assert d_model % num_heads == 0\n","\n","        self.d_model = d_model\n","        self.H = num_heads\n","        self.context_length = context_length\n","        self.attn_pdrop = attn_pdrop\n","        self.resid_pdrop = resid_pdrop\n","        self.bias = bias\n","\n","        self.W_Q = nn.Linear(in_features=self.d_model, out_features=self.d_model, bias=self.bias)\n","        self.W_K = nn.Linear(in_features=self.d_model, out_features=self.d_model, bias=self.bias)\n","        self.W_V = nn.Linear(in_features=self.d_model, out_features=self.d_model, bias=self.bias)\n","\n","        # alias of W_O\n","        self.context_projection = nn.Linear(in_features=self.d_model, out_features=self.d_model, bias=self.bias)\n","\n","        # regularization\n","        self.resid_dropout = nn.Dropout(self.resid_pdrop)\n","\n","        self.attention = ScaledDotProductAttention(dropout=self.attn_pdrop)\n","\n","        # causal mask to ensure that attention is only applied to the left in the input sequence\n","        # register buffer cause not learnable weights\n","        self.register_buffer(\n","            \"causal_mask\",\n","            torch.triu(\n","                torch.ones((self.context_length, self.context_length)).bool(),\n","                diagonal=1,\n","            ).view(1, 1, self.context_length, self.context_length),\n","        )\n","\n","    def forward(self, *, z: torch.Tensor) -> torch.Tensor:\n","        B, T, D = z.size()\n","\n","        # fmt: off\n","        Q: torch.Tensor = self.W_Q(z).contiguous() # Z @ W_Q = [B, T, D] @ [D, D] = [B, T, D]\n","        K: torch.Tensor = self.W_K(z).contiguous() # Z @ W_K = [B, T, D] @ [D, D] = [B, T, D]\n","        V: torch.Tensor = self.W_V(z).contiguous() # Z @ W_V = [B, T, D] @ [D, D] = [B, T, D]\n","\n","        Q = Q.view(B, T, self.H, D // self.H).transpose(dim0=1, dim1=2) # [B, T, D] -> [B, T, H, D // H] -> [B, H, T, D//H]\n","        K = K.view(B, T, self.H, D // self.H).transpose(dim0=1, dim1=2)\n","        V = V.view(B, T, self.H, D // self.H).transpose(dim0=1, dim1=2)\n","\n","        # Now pass them to self attention\n","        self.context_vector, self.attention_weights = self.attention(query=Q, key=K, value=V, mask=self.causal_mask) # ([B, H, T, D // H], [B, H, T, T])\n","        assert isinstance(self.context_vector, torch.Tensor) # do this for type hint in IDE\n","\n","        # Now context vector is shape [B, H, T, D // H] but we want [B, T, D] to matmul with W_O/context_projection\n","        self.context_vector = self.context_vector.transpose(dim0=1, dim1=2).contiguous().view(B, T, D) # merge all heads together\n","        # fmt: on\n","\n","        projected_context_vector: torch.Tensor = self.resid_dropout(\n","            self.context_projection(self.context_vector)  # [B, T, D] @ [D, D] = [B, T, D]\n","        )\n","        return projected_context_vector\n","\n","\n","class GPTBlock(nn.Module):\n","    def __init__(\n","        self,\n","        config: GPTConfig,\n","    ) -> None:\n","        super().__init__()\n","\n","        self.rmns_1 = RMSNorm(d_model=config.d_model, eps=1e-5)\n","        self.attn = CausalMultiHeadSelfAttention(\n","            d_model=config.d_model,\n","            num_heads=config.num_heads,\n","            context_length=config.context_length,\n","            attn_pdrop=config.attn_pdrop,\n","            resid_pdrop=config.resid_pdrop,\n","            bias=config.bias,\n","        )\n","        self.rmns_2 = RMSNorm(d_model=config.d_model, eps=1e-5)\n","        self.ffn = PositionwiseFeedForward(\n","            d_model=config.d_model,\n","            d_ff=config.d_ff,\n","            bias=config.bias,\n","            activation_name=config.activation_name,\n","            dropout=config.resid_pdrop,\n","        )\n","\n","    def forward(self, z: torch.Tensor) -> torch.Tensor:\n","        z = z + self.attn(z=self.rmns_1(z))\n","        z = z + self.ffn(self.rmns_2(z))\n","        return z\n","\n","\n","class GPT(nn.Module):\n","    def __init__(self, config: GPTConfig) -> None:\n","        super().__init__()\n","\n","        self.config = config\n","        self.d_model = config.d_model\n","        self.num_blocks = config.num_blocks\n","        self.vocab_size = config.vocab_size\n","\n","        self.blocks = nn.ModuleList([GPTBlock(config=config) for _ in range(self.num_blocks)])\n","\n","        self.backbone = nn.ModuleDict(\n","            dict(  # noqa: C408\n","                token_embeddings=nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.d_model),\n","                position_embeddings=nn.Embedding(num_embeddings=config.context_length, embedding_dim=self.d_model),\n","                dropout=nn.Dropout(p=config.token_position_pdrop),\n","                layers=self.blocks,\n","                ln_final=RMSNorm(d_model=self.d_model, eps=1e-5),\n","            )\n","        )\n","        self.head = nn.Linear(in_features=self.d_model, out_features=self.vocab_size, bias=config.bias)\n","\n","        self.apply(self._init_weights)\n","\n","        context_projections = \"context_projection.weight\"\n","        # apply special scaled init to the residual projections, per GPT-2 paper\n","        for parameter_name, parameter in self.named_parameters():\n","            # NOTE: W_O is also projection but I did not have foresight to name it as such.\n","            if parameter_name.endswith(context_projections):\n","                mean = 0.0\n","                std_dev = 0.02 / torch.sqrt(torch.tensor(2 * config.num_blocks, dtype=torch.float))\n","                torch.nn.init.normal_(parameter, mean=mean, std=std_dev)\n","\n","        if config.weight_tie:\n","            self.backbone.token_embeddings.weight = self.head.weight\n","\n","    def crop_context_length(self, context_length: int) -> None:\n","        # NOTE: conveniently took Karpathy's implementation here for cropping\n","        assert context_length <= self.config.context_length\n","        self.config.context_length = context_length  # update config\n","\n","        self.backbone.position_embeddings.weight = nn.Parameter(\n","            self.backbone.position_embeddings.weight[:context_length]\n","        )\n","        for block in self.backbone.layers:\n","            if hasattr(block.attn, \"causal_mask\"):\n","                block.attn.causal_mask = block.attn.causal_mask[:, :, :context_length, :context_length]\n","\n","            # update context length attribute in MultiHeadSelfAttention\n","            block.attn.context_length = context_length\n","\n","    def _init_weights(self, module: nn.Module) -> None:\n","        normal_init_modules = (nn.Linear, nn.Embedding)\n","        if isinstance(module, normal_init_modules):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if hasattr(module, \"bias\") and module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","\n","    def forward(self, in_indices: torch.LongTensor) -> torch.FloatTensor:\n","        device = in_indices.device\n","\n","        B, T = in_indices.size()\n","\n","        positions = torch.arange(0, T, dtype=torch.long, device=device)  # [T]\n","        token_embeddings = self.backbone.token_embeddings(in_indices)  # [B, T, D]\n","        positional_embeddings = self.backbone.position_embeddings(positions)  # [T, D]\n","        # fmt: off\n","        positional_embeddings = positional_embeddings.unsqueeze(0) # .expand(B, -1, -1) # [B, T, D]\n","        # fmt: on\n","\n","        z = self.backbone.dropout(token_embeddings + positional_embeddings)  # [B, T, D]\n","\n","        for block in self.backbone.layers:\n","            z = block(z)  # [B, T, D]\n","\n","        z = self.backbone.ln_final(z)  # [B, T, D]\n","\n","        logits = self.head(z)  # [B, T, V]\n","        return cast(torch.FloatTensor, logits)  # [B, T, V]\n","\n","\n","def initialize_model(\n","    config: GPTConfig,\n","    device: str = \"cuda\",\n",") -> GPT:\n","    if config.d_ff is None:\n","        config.d_ff = 4 * config.d_model\n","\n","    model = GPT(config)\n","    return model.to(device)\n","\n","\n","def get_random_batch(\n","    batch_size: int,\n","    context_length: int,\n","    vocab_size: int,\n","    device: str = \"cuda\",\n",") -> Tuple[torch.Tensor, torch.Tensor]:\n","    inputs = torch.randint(  # [B, T]\n","        0,\n","        vocab_size,\n","        (batch_size, context_length),\n","        dtype=torch.long,\n","        device=device,\n","    )\n","\n","    targets = torch.randint(  # [B, T]\n","        0,\n","        vocab_size,\n","        (batch_size, context_length),\n","        dtype=torch.long,\n","        device=device,\n","    )\n","    return inputs, targets"]},{"cell_type":"markdown","metadata":{},"source":["## Timeit Profiler"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T10:57:13.755094Z","iopub.status.busy":"2024-08-11T10:57:13.754699Z","iopub.status.idle":"2024-08-11T10:57:13.776829Z","shell.execute_reply":"2024-08-11T10:57:13.775906Z","shell.execute_reply.started":"2024-08-11T10:57:13.755036Z"},"trusted":true},"outputs":[],"source":["from __future__ import annotations\n","\n","from contextlib import nullcontext\n","from timeit import default_timer\n","from typing import List, Literal, Tuple\n","\n","import numpy as np\n","import torch\n","from pydantic import BaseModel, Field\n","\n","from omnivault.modules.loss import CrossEntropyLoss\n","# from omnixamples.profiling.common import GPT\n","\n","\n","class ProfilingResult(BaseModel):\n","    computation: Literal[\"forward\", \"backward\", \"forward_backward\"] = Field(..., description=\"Type of computation\")\n","    times: List[float] = Field(..., description=\"Raw list of measured times\")\n","    mean_time: float = Field(..., description=\"Mean execution time\")\n","    median_time: float = Field(..., description=\"Median execution time\")\n","    std_dev: float = Field(..., description=\"Standard deviation of execution times\")\n","    min_time: float = Field(..., description=\"Minimum execution time\")\n","    max_time: float = Field(..., description=\"Maximum execution time\")\n","    total_time: float = Field(..., description=\"Total execution time\")\n","    profile_steps: int = Field(..., description=\"Number of profiling runs\")\n","\n","\n","def profile_model(\n","    model: GPT,\n","    batch: Tuple[torch.Tensor, torch.Tensor],\n","    profile_steps: int,\n","    computation: Literal[\"forward\", \"backward\", \"forward_backward\"],\n","    warmup_steps: int | None = None,\n","    mixed_precision: bool = False,\n",") -> ProfilingResult:\n","    device = next(model.parameters()).device\n","    dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n","    mixed_context = torch.autocast(device.type, dtype=dtype) if mixed_precision else nullcontext()\n","    criterion = CrossEntropyLoss()\n","    inputs, targets = batch[0], batch[1]\n","\n","    with mixed_context:  # type: ignore[attr-defined]\n","        if warmup_steps:\n","            for _ in range(warmup_steps):\n","                logits = model(inputs)\n","                loss = criterion(logits, targets)\n","                if computation in [\"backward\", \"forward_backward\"]:\n","                    loss.backward()\n","                torch.cuda.synchronize()\n","\n","        times = np.zeros(profile_steps)\n","\n","        for step in range(profile_steps):\n","            if computation == \"forward\":\n","                start = default_timer()\n","                logits = model(inputs)\n","                loss = criterion(logits, targets)\n","            elif computation == \"backward\":\n","                logits = model(inputs)\n","                loss = criterion(logits, targets)\n","                torch.cuda.synchronize()\n","                start = default_timer()\n","                loss.backward()\n","            elif computation == \"forward_backward\":\n","                start = default_timer()\n","                logits = model(inputs)\n","                loss = criterion(logits, targets)\n","                loss.backward()\n","            else:\n","                raise ValueError(f\"Invalid computation: {computation}\")\n","\n","            torch.cuda.synchronize()\n","            end = default_timer()\n","\n","            time = end - start\n","            times[step] = time\n","\n","    return ProfilingResult(\n","        computation=computation,\n","        times=times.tolist(),\n","        mean_time=float(np.mean(times)),\n","        median_time=float(np.median(times)),\n","        std_dev=float(np.std(times)),\n","        min_time=float(np.min(times)),\n","        max_time=float(np.max(times)),\n","        total_time=float(np.sum(times)),\n","        profile_steps=profile_steps,\n","    )\n"]},{"cell_type":"markdown","metadata":{},"source":["## Main Profiling Code"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T10:57:44.225567Z","iopub.status.busy":"2024-08-11T10:57:44.224810Z","iopub.status.idle":"2024-08-11T10:57:44.573219Z","shell.execute_reply":"2024-08-11T10:57:44.572418Z","shell.execute_reply.started":"2024-08-11T10:57:44.225531Z"},"trusted":true},"outputs":[],"source":["import itertools\n","import logging\n","import sys\n","from typing import Dict, Iterable, Literal, Tuple\n","\n","import pandas as pd\n","import torch\n","from rich.pretty import pprint\n","from tqdm.auto import tqdm\n","\n","from omnivault.utils.reproducibility.seed import seed_all\n","from omnivault.utils.torch_utils.cleanup import purge_global_scope\n","# from omnixamples.profiling.common import GPT, General, GPTConfig, ProfilerConfig, device, get_random_batch\n","# from omnixamples.profiling.timeit_profiler import ProfilingResult, profile_model"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T10:57:45.855869Z","iopub.status.busy":"2024-08-11T10:57:45.855357Z","iopub.status.idle":"2024-08-11T10:57:45.862669Z","shell.execute_reply":"2024-08-11T10:57:45.861829Z","shell.execute_reply.started":"2024-08-11T10:57:45.855838Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-08-11 10:57:45,858 - __main__ - INFO - Device=cuda\n"]}],"source":["logging.basicConfig(\n","    level=logging.INFO,\n","    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n","    handlers=[logging.StreamHandler(sys.stdout)],\n","    force=True,\n",")\n","logger = logging.getLogger(__name__)\n","\n","logger.info(\"Device=%s\", device)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T10:57:59.209529Z","iopub.status.busy":"2024-08-11T10:57:59.209151Z","iopub.status.idle":"2024-08-11T10:58:05.135911Z","shell.execute_reply":"2024-08-11T10:58:05.134886Z","shell.execute_reply.started":"2024-08-11T10:57:59.209502Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ProfilingResult</span><span style=\"font-weight: bold\">(</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">computation</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'forward_backward'</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">times</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4144910469995011</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2255011379993448</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22108890900017286</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22048294700016413</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22087210900008358</span><span style=\"font-weight: bold\">]</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">mean_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2604872299998533</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">median_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22108890900017286</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">std_dev</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0770235424421242</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">min_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22048294700016413</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">max_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4144910469995011</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">total_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3024361499992665</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">profile_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n","<span style=\"font-weight: bold\">)</span>\n","</pre>\n"],"text/plain":["\u001b[1;35mProfilingResult\u001b[0m\u001b[1m(\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[33mcomputation\u001b[0m=\u001b[32m'forward_backward'\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mtimes\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;36m0.4144910469995011\u001b[0m, \u001b[1;36m0.2255011379993448\u001b[0m, \u001b[1;36m0.22108890900017286\u001b[0m, \u001b[1;36m0.22048294700016413\u001b[0m, \u001b[1;36m0.22087210900008358\u001b[0m\u001b[1m]\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mmean_time\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2604872299998533\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mmedian_time\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.22108890900017286\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mstd_dev\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0770235424421242\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mmin_time\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.22048294700016413\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mmax_time\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.4144910469995011\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mtotal_time\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.3024361499992665\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mprofile_steps\u001b[0m=\u001b[1;36m5\u001b[0m\n","\u001b[1m)\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ProfilingResult</span><span style=\"font-weight: bold\">(</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">computation</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'forward_backward'</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">times</span>=<span style=\"font-weight: bold\">[</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22120609100056754</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22078104100000928</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2206222049999269</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22060177200000908</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22016962399993645</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">]</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">mean_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22067614660008986</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">median_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2206222049999269</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">std_dev</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0003337215379814711</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">min_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22016962399993645</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">max_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22120609100056754</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">total_time</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1033807330004493</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">profile_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n","<span style=\"font-weight: bold\">)</span>\n","</pre>\n"],"text/plain":["\u001b[1;35mProfilingResult\u001b[0m\u001b[1m(\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[33mcomputation\u001b[0m=\u001b[32m'forward_backward'\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mtimes\u001b[0m=\u001b[1m[\u001b[0m\n","\u001b[2;32m│   │   \u001b[0m\u001b[1;36m0.22120609100056754\u001b[0m,\n","\u001b[2;32m│   │   \u001b[0m\u001b[1;36m0.22078104100000928\u001b[0m,\n","\u001b[2;32m│   │   \u001b[0m\u001b[1;36m0.2206222049999269\u001b[0m,\n","\u001b[2;32m│   │   \u001b[0m\u001b[1;36m0.22060177200000908\u001b[0m,\n","\u001b[2;32m│   │   \u001b[0m\u001b[1;36m0.22016962399993645\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[1m]\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mmean_time\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.22067614660008986\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mmedian_time\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2206222049999269\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mstd_dev\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0003337215379814711\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mmin_time\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.22016962399993645\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mmax_time\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.22120609100056754\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mtotal_time\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.1033807330004493\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mprofile_steps\u001b[0m=\u001b[1;36m5\u001b[0m\n","\u001b[1m)\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["2024-08-11 10:58:05,131 - __main__ - ERROR - Error deleting variables: name 'gpt_small' is not defined\n"]}],"source":["gpt_small_config = GPTConfig(\n","    context_length=128,\n","    vocab_size=10_000,\n","    d_model=768,\n","    num_blocks=12,\n","    num_heads=12,\n",")\n","general = General()\n","\n","seed_all(general.seed, True, False)\n","\n","batch = get_random_batch(\n","    batch_size=general.batch_size,\n","    context_length=gpt_small_config.context_length,\n","    vocab_size=gpt_small_config.vocab_size,\n",")\n","\n","gpt_small = GPT(gpt_small_config).to(device)\n","\n","results = profile_model(\n","    model=gpt_small,\n","    batch=batch,\n","    warmup_steps=0,\n","    profile_steps=5,\n","    computation=\"forward_backward\",\n","    mixed_precision=False,\n",")\n","\n","pprint(results)\n","\n","results = profile_model(\n","    model=gpt_small,\n","    batch=batch,\n","    warmup_steps=1,\n","    profile_steps=5,\n","    computation=\"forward_backward\",\n","    mixed_precision=False,\n",")\n","\n","pprint(results)\n","\n","purge_global_scope(variable_name_or_names=[\"gpt_small\", \"batch\"])\n","\n","try:\n","    del gpt_small\n","    del batch\n","except NameError as exc:\n","    logger.error(\"Error deleting variables: %s\", exc)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T10:58:31.966675Z","iopub.status.busy":"2024-08-11T10:58:31.966293Z","iopub.status.idle":"2024-08-11T10:58:31.984279Z","shell.execute_reply":"2024-08-11T10:58:31.983110Z","shell.execute_reply.started":"2024-08-11T10:58:31.966640Z"},"trusted":true},"outputs":[],"source":["def create_profile_configs(context_length: int, vocab_size: int) -> Iterable[Tuple[str, GPTConfig, ProfilerConfig]]:\n","    gpt_configs: Dict[str, Dict[str, int]] = {\n","        \"small\": {\"d_model\": 768, \"num_blocks\": 12, \"num_heads\": 12},\n","        \"medium\": {\"d_model\": 1024, \"num_blocks\": 24, \"num_heads\": 16},\n","    }\n","    computations: Tuple[Literal[\"forward\", \"backward\", \"forward_backward\"], ...] = (\n","        \"forward\",\n","        \"backward\",\n","        \"forward_backward\",\n","    )\n","    warmup_steps: Tuple[int, ...] = (0, 1)\n","    mixed_precision_options: Tuple[bool, ...] = (False, True)\n","    profile_steps: Tuple[int, ...] = (5,)\n","\n","    for (config_name, config), computation, warmup, mixed, steps in itertools.product(\n","        gpt_configs.items(),\n","        computations,\n","        warmup_steps,\n","        mixed_precision_options,\n","        profile_steps,\n","    ):\n","        gpt_config = GPTConfig(**config, context_length=context_length, vocab_size=vocab_size)  # type: ignore[arg-type]\n","        profiler_config = ProfilerConfig(\n","            computation=computation,\n","            warmup_steps=warmup,\n","            profile_steps=steps,\n","            mixed_precision=mixed,\n","        )\n","        yield config_name, gpt_config, profiler_config\n","\n","\n","def run_profile(\n","    device: torch.device,\n","    gpt_config: GPTConfig,\n","    profiler_config: ProfilerConfig,\n","    general: General,\n",") -> ProfilingResult:\n","    logger.info(\"Running profile with GPT config: \\n%s\", gpt_config.model_dump_json(indent=4))\n","    logger.info(\"Profiler config: \\n%s\", profiler_config.model_dump_json(indent=4))\n","\n","    seed_all(general.seed, True, False)\n","    batch = get_random_batch(\n","        batch_size=general.batch_size,\n","        context_length=gpt_config.context_length,\n","        vocab_size=gpt_config.vocab_size,\n","    )\n","\n","    gpt = GPT(config=gpt_config).to(device)\n","\n","    result = profile_model(\n","        model=gpt,\n","        batch=batch,\n","        warmup_steps=profiler_config.warmup_steps,\n","        profile_steps=profiler_config.profile_steps,\n","        mixed_precision=profiler_config.mixed_precision,\n","        computation=profiler_config.computation,\n","    )\n","\n","    logger.warning(\"Purging global scope variables `gpt` and `batch` to free up memory.\")\n","    purge_global_scope(variable_name_or_names=[\"gpt\", \"batch\"])\n","    return result\n","\n","\n","def results_to_dataframe(results: Dict[str, ProfilingResult]) -> pd.DataFrame:\n","    data = []\n","    for name, result in results.items():\n","        row = result.model_dump()\n","        row[\"name\"] = name\n","        data.append(row)\n","\n","    df = pd.DataFrame(data)\n","    columns = [\"name\"] + [col for col in df.columns if col != \"name\"]\n","    df = df[columns]\n","    return df\n","\n","\n","def main() -> Dict[str, ProfilingResult]:\n","    context_length = 128\n","    vocab_size = 10_000\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    general = General()\n","\n","    results: Dict[str, ProfilingResult] = {}\n","\n","    all_configs = list(create_profile_configs(context_length, vocab_size))\n","\n","    for config_name, gpt_config, profiler_config in tqdm(all_configs, desc=\"Profiling Configurations\"):\n","        key = (\n","            f\"{config_name}_{profiler_config.computation}_\"\n","            f\"warmup_{profiler_config.warmup_steps}_\"\n","            f\"mixed_{profiler_config.mixed_precision}\"\n","        )\n","        logger.info(\"Running profile for: %s\", key)\n","        results[key] = run_profile(device, gpt_config, profiler_config, general)\n","        logger.info(\"Profile result: \\n%s\\n\\n\\n\", results[key].model_dump_json(indent=4))\n","\n","    return results"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T10:58:52.894186Z","iopub.status.busy":"2024-08-11T10:58:52.893789Z","iopub.status.idle":"2024-08-11T11:02:09.551456Z","shell.execute_reply":"2024-08-11T11:02:09.550521Z","shell.execute_reply.started":"2024-08-11T10:58:52.894157Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52d6ad21e30d4c86856512f9f6b8798a","version_major":2,"version_minor":0},"text/plain":["Profiling Configurations:   0%|          | 0/24 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["2024-08-11 10:58:52,908 - __main__ - INFO - Running profile for: small_forward_warmup_0_mixed_False\n","2024-08-11 10:58:52,909 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:58:52,910 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 10:58:56,410 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward\",\n","    \"times\": [\n","        0.07846403200073837,\n","        0.0737714920005601,\n","        0.07313682499989227,\n","        0.07290069700047752,\n","        0.07229203399947437\n","    ],\n","    \"mean_time\": 0.07411301600022853,\n","    \"median_time\": 0.07313682499989227,\n","    \"std_dev\": 0.0022265049091528,\n","    \"min_time\": 0.07229203399947437,\n","    \"max_time\": 0.07846403200073837,\n","    \"total_time\": 0.37056508000114263,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:58:56,411 - __main__ - INFO - Running profile for: small_forward_warmup_0_mixed_True\n","2024-08-11 10:58:56,413 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:58:56,413 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 10:58:59,672 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward\",\n","    \"times\": [\n","        0.0935192509996341,\n","        0.07841499799997109,\n","        0.07517127899973275,\n","        0.07425991700074519,\n","        0.07425473500006774\n","    ],\n","    \"mean_time\": 0.07912403600003018,\n","    \"median_time\": 0.07517127899973275,\n","    \"std_dev\": 0.007358246850183679,\n","    \"min_time\": 0.07425473500006774,\n","    \"max_time\": 0.0935192509996341,\n","    \"total_time\": 0.39562018000015087,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:58:59,674 - __main__ - INFO - Running profile for: small_forward_warmup_1_mixed_False\n","2024-08-11 10:58:59,675 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:58:59,676 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 10:59:03,039 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward\",\n","    \"times\": [\n","        0.0713498349996371,\n","        0.0709589389998655,\n","        0.07128997600011644,\n","        0.07113105599910341,\n","        0.07112360400060425\n","    ],\n","    \"mean_time\": 0.07117068199986534,\n","    \"median_time\": 0.07113105599910341,\n","    \"std_dev\": 0.00013780312900865102,\n","    \"min_time\": 0.0709589389998655,\n","    \"max_time\": 0.0713498349996371,\n","    \"total_time\": 0.3558534099993267,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:59:03,041 - __main__ - INFO - Running profile for: small_forward_warmup_1_mixed_True\n","2024-08-11 10:59:03,042 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:59:03,043 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 10:59:06,362 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward\",\n","    \"times\": [\n","        0.07369880799979,\n","        0.07382382700052403,\n","        0.07385925299968221,\n","        0.07376415900034772,\n","        0.07382289199995284\n","    ],\n","    \"mean_time\": 0.07379378780005937,\n","    \"median_time\": 0.07382289199995284,\n","    \"std_dev\": 0.00005645197712961995,\n","    \"min_time\": 0.07369880799979,\n","    \"max_time\": 0.07385925299968221,\n","    \"total_time\": 0.3689689390002968,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:59:06,364 - __main__ - INFO - Running profile for: small_backward_warmup_0_mixed_False\n","2024-08-11 10:59:06,365 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:59:06,365 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"backward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 10:59:10,363 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"backward\",\n","    \"times\": [\n","        0.14778646800004935,\n","        0.1506624739995459,\n","        0.15020622800057026,\n","        0.15019696000035765,\n","        0.15047101199979807\n","    ],\n","    \"mean_time\": 0.14986462840006426,\n","    \"median_time\": 0.15020622800057026,\n","    \"std_dev\": 0.0010535790334329838,\n","    \"min_time\": 0.14778646800004935,\n","    \"max_time\": 0.1506624739995459,\n","    \"total_time\": 0.7493231420003212,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:59:10,365 - __main__ - INFO - Running profile for: small_backward_warmup_0_mixed_True\n","2024-08-11 10:59:10,366 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:59:10,367 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"backward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 10:59:14,375 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"backward\",\n","    \"times\": [\n","        0.14960491599958914,\n","        0.15169357899958413,\n","        0.15144059900012508,\n","        0.15148220399987622,\n","        0.15148427300027834\n","    ],\n","    \"mean_time\": 0.15114111419989057,\n","    \"median_time\": 0.15148220399987622,\n","    \"std_dev\": 0.000773164099660496,\n","    \"min_time\": 0.14960491599958914,\n","    \"max_time\": 0.15169357899958413,\n","    \"total_time\": 0.7557055709994529,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:59:14,377 - __main__ - INFO - Running profile for: small_backward_warmup_1_mixed_False\n","2024-08-11 10:59:14,378 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:59:14,379 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"backward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 10:59:18,635 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"backward\",\n","    \"times\": [\n","        0.15043866700034414,\n","        0.15016293000007863,\n","        0.15051599399976112,\n","        0.14995777100011765,\n","        0.15019284299978608\n","    ],\n","    \"mean_time\": 0.15025364100001753,\n","    \"median_time\": 0.15019284299978608,\n","    \"std_dev\": 0.00020125986010833822,\n","    \"min_time\": 0.14995777100011765,\n","    \"max_time\": 0.15051599399976112,\n","    \"total_time\": 0.7512682050000876,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:59:18,637 - __main__ - INFO - Running profile for: small_backward_warmup_1_mixed_True\n","2024-08-11 10:59:18,638 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:59:18,638 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"backward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 10:59:22,886 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"backward\",\n","    \"times\": [\n","        0.15156354600003397,\n","        0.15143018500020844,\n","        0.15140369100026874,\n","        0.15138537599978008,\n","        0.15155341100035002\n","    ],\n","    \"mean_time\": 0.15146724180012824,\n","    \"median_time\": 0.15143018500020844,\n","    \"std_dev\": 0.00007591251522123026,\n","    \"min_time\": 0.15138537599978008,\n","    \"max_time\": 0.15156354600003397,\n","    \"total_time\": 0.7573362090006412,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:59:22,888 - __main__ - INFO - Running profile for: small_forward_backward_warmup_0_mixed_False\n","2024-08-11 10:59:22,890 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:59:22,890 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 10:59:26,934 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"times\": [\n","        0.21832664599969576,\n","        0.22057815300013317,\n","        0.22008085299967206,\n","        0.22023602300032508,\n","        0.22247255000002042\n","    ],\n","    \"mean_time\": 0.2203388449999693,\n","    \"median_time\": 0.22023602300032508,\n","    \"std_dev\": 0.0013218201389535288,\n","    \"min_time\": 0.21832664599969576,\n","    \"max_time\": 0.22247255000002042,\n","    \"total_time\": 1.1016942249998465,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:59:26,936 - __main__ - INFO - Running profile for: small_forward_backward_warmup_0_mixed_True\n","2024-08-11 10:59:26,937 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:59:26,938 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 10:59:30,955 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"times\": [\n","        0.22407326100073988,\n","        0.22444049899968377,\n","        0.22447669499979384,\n","        0.22424623200004135,\n","        0.2243646639999497\n","    ],\n","    \"mean_time\": 0.2243202702000417,\n","    \"median_time\": 0.2243646639999497,\n","    \"std_dev\": 0.00014655353377531386,\n","    \"min_time\": 0.22407326100073988,\n","    \"max_time\": 0.22447669499979384,\n","    \"total_time\": 1.1216013510002085,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:59:30,957 - __main__ - INFO - Running profile for: small_forward_backward_warmup_1_mixed_False\n","2024-08-11 10:59:30,958 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:59:30,958 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 10:59:35,215 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"times\": [\n","        0.22083036900039588,\n","        0.22020937799970852,\n","        0.22077888900003018,\n","        0.2204785499998252,\n","        0.22015970299980836\n","    ],\n","    \"mean_time\": 0.22049137779995362,\n","    \"median_time\": 0.2204785499998252,\n","    \"std_dev\": 0.0002783071457913188,\n","    \"min_time\": 0.22015970299980836,\n","    \"max_time\": 0.22083036900039588,\n","    \"total_time\": 1.1024568889997681,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:59:35,217 - __main__ - INFO - Running profile for: small_forward_backward_warmup_1_mixed_True\n","2024-08-11 10:59:35,218 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 768,\n","    \"d_ff\": null,\n","    \"num_heads\": 12,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 12,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:59:35,219 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 10:59:39,489 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"times\": [\n","        0.22448583999994298,\n","        0.22421371400014323,\n","        0.22419899699980306,\n","        0.224439366000297,\n","        0.22438234299988835\n","    ],\n","    \"mean_time\": 0.22434405200001492,\n","    \"median_time\": 0.22438234299988835,\n","    \"std_dev\": 0.00011720387667794871,\n","    \"min_time\": 0.22419899699980306,\n","    \"max_time\": 0.22448583999994298,\n","    \"total_time\": 1.1217202600000746,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:59:39,491 - __main__ - INFO - Running profile for: medium_forward_warmup_0_mixed_False\n","2024-08-11 10:59:39,492 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:59:39,493 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 10:59:50,458 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward\",\n","    \"times\": [\n","        0.24876118500014854,\n","        0.24528420900060155,\n","        0.2450883880001129,\n","        0.24495568000020285,\n","        0.24501344400050584\n","    ],\n","    \"mean_time\": 0.24582058120031433,\n","    \"median_time\": 0.2450883880001129,\n","    \"std_dev\": 0.0014744814187987805,\n","    \"min_time\": 0.24495568000020285,\n","    \"max_time\": 0.24876118500014854,\n","    \"total_time\": 1.2291029060015717,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 10:59:50,459 - __main__ - INFO - Running profile for: medium_forward_warmup_0_mixed_True\n","2024-08-11 10:59:50,460 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 10:59:50,461 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 11:00:00,845 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward\",\n","    \"times\": [\n","        0.22800831199947424,\n","        0.22234672700051306,\n","        0.22269292600049084,\n","        0.22257933899982163,\n","        0.22283626599983108\n","    ],\n","    \"mean_time\": 0.22369271400002616,\n","    \"median_time\": 0.22269292600049084,\n","    \"std_dev\": 0.002163735205972857,\n","    \"min_time\": 0.22234672700051306,\n","    \"max_time\": 0.22800831199947424,\n","    \"total_time\": 1.1184635700001309,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 11:00:00,847 - __main__ - INFO - Running profile for: medium_forward_warmup_1_mixed_False\n","2024-08-11 11:00:00,848 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 11:00:00,849 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 11:00:12,121 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward\",\n","    \"times\": [\n","        0.24505015699924115,\n","        0.2447970040002474,\n","        0.2449814139999944,\n","        0.24467239400019025,\n","        0.24507564099985757\n","    ],\n","    \"mean_time\": 0.24491532199990615,\n","    \"median_time\": 0.2449814139999944,\n","    \"std_dev\": 0.00015573308791388857,\n","    \"min_time\": 0.24467239400019025,\n","    \"max_time\": 0.24507564099985757,\n","    \"total_time\": 1.2245766099995308,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 11:00:12,123 - __main__ - INFO - Running profile for: medium_forward_warmup_1_mixed_True\n","2024-08-11 11:00:12,124 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 11:00:12,125 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 11:00:22,989 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward\",\n","    \"times\": [\n","        0.22247573399999965,\n","        0.22273382500043226,\n","        0.22256395700060239,\n","        0.22253749899937247,\n","        0.2227441450004335\n","    ],\n","    \"mean_time\": 0.22261103200016805,\n","    \"median_time\": 0.22256395700060239,\n","    \"std_dev\": 0.00010837518017815013,\n","    \"min_time\": 0.22247573399999965,\n","    \"max_time\": 0.2227441450004335,\n","    \"total_time\": 1.1130551600008403,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 11:00:22,991 - __main__ - INFO - Running profile for: medium_backward_warmup_0_mixed_False\n","2024-08-11 11:00:22,992 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 11:00:22,993 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"backward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 11:00:36,042 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"backward\",\n","    \"times\": [\n","        0.4803364019999208,\n","        0.4842157639996003,\n","        0.48418703799961804,\n","        0.4834751440002947,\n","        0.48341351999988547\n","    ],\n","    \"mean_time\": 0.48312557359986386,\n","    \"median_time\": 0.4834751440002947,\n","    \"std_dev\": 0.001435256951747305,\n","    \"min_time\": 0.4803364019999208,\n","    \"max_time\": 0.4842157639996003,\n","    \"total_time\": 2.4156278679993193,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 11:00:36,044 - __main__ - INFO - Running profile for: medium_backward_warmup_0_mixed_True\n","2024-08-11 11:00:36,045 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 11:00:36,046 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"backward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 11:00:49,070 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"backward\",\n","    \"times\": [\n","        0.4554312190002747,\n","        0.4636755310002627,\n","        0.46323080499951175,\n","        0.46364944700053456,\n","        0.46372856899961334\n","    ],\n","    \"mean_time\": 0.4619431142000394,\n","    \"median_time\": 0.46364944700053456,\n","    \"std_dev\": 0.0032607856453568743,\n","    \"min_time\": 0.4554312190002747,\n","    \"max_time\": 0.46372856899961334,\n","    \"total_time\": 2.309715571000197,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 11:00:49,072 - __main__ - INFO - Running profile for: medium_backward_warmup_1_mixed_False\n","2024-08-11 11:00:49,073 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 11:00:49,073 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"backward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 11:01:02,813 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"backward\",\n","    \"times\": [\n","        0.48379133800062846,\n","        0.4842440839993287,\n","        0.48351270700004534,\n","        0.48362178600018524,\n","        0.48389172999941366\n","    ],\n","    \"mean_time\": 0.48381232899992027,\n","    \"median_time\": 0.48379133800062846,\n","    \"std_dev\": 0.00025268062760848447,\n","    \"min_time\": 0.48351270700004534,\n","    \"max_time\": 0.4842440839993287,\n","    \"total_time\": 2.4190616449996014,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 11:01:02,815 - __main__ - INFO - Running profile for: medium_backward_warmup_1_mixed_True\n","2024-08-11 11:01:02,816 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 11:01:02,816 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"backward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 11:01:16,508 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"backward\",\n","    \"times\": [\n","        0.46393922600054793,\n","        0.4636971440004345,\n","        0.4640383700007078,\n","        0.4659291400002985,\n","        0.4634621249997508\n","    ],\n","    \"mean_time\": 0.4642132010003479,\n","    \"median_time\": 0.46393922600054793,\n","    \"std_dev\": 0.0008809659262803036,\n","    \"min_time\": 0.4634621249997508,\n","    \"max_time\": 0.4659291400002985,\n","    \"total_time\": 2.3210660050017395,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 11:01:16,510 - __main__ - INFO - Running profile for: medium_forward_backward_warmup_0_mixed_False\n","2024-08-11 11:01:16,511 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 11:01:16,512 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 11:01:29,358 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"times\": [\n","        0.7304752370000642,\n","        0.727164707999691,\n","        0.7266143320002811,\n","        0.7294365609996021,\n","        0.7265293540003768\n","    ],\n","    \"mean_time\": 0.7280440384000031,\n","    \"median_time\": 0.727164707999691,\n","    \"std_dev\": 0.0016100557130809725,\n","    \"min_time\": 0.7265293540003768,\n","    \"max_time\": 0.7304752370000642,\n","    \"total_time\": 3.6402201920000152,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 11:01:29,359 - __main__ - INFO - Running profile for: medium_forward_backward_warmup_0_mixed_True\n","2024-08-11 11:01:29,360 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 11:01:29,361 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"warmup_steps\": 0,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 11:01:42,075 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"times\": [\n","        0.6820840510008566,\n","        0.684006079000028,\n","        0.6853365530005249,\n","        0.6837199530000362,\n","        0.6839223050010332\n","    ],\n","    \"mean_time\": 0.6838137882004958,\n","    \"median_time\": 0.6839223050010332,\n","    \"std_dev\": 0.0010361814617577633,\n","    \"min_time\": 0.6820840510008566,\n","    \"max_time\": 0.6853365530005249,\n","    \"total_time\": 3.419068941002479,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 11:01:42,077 - __main__ - INFO - Running profile for: medium_forward_backward_warmup_1_mixed_False\n","2024-08-11 11:01:42,078 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 11:01:42,079 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": false\n","}\n","2024-08-11 11:01:56,159 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"times\": [\n","        0.7272930130002351,\n","        0.7277811669991934,\n","        0.7261910039997019,\n","        0.7264165149990731,\n","        0.7264139199996862\n","    ],\n","    \"mean_time\": 0.7268191237995779,\n","    \"median_time\": 0.7264165149990731,\n","    \"std_dev\": 0.0006117052461950424,\n","    \"min_time\": 0.7261910039997019,\n","    \"max_time\": 0.7277811669991934,\n","    \"total_time\": 3.6340956189978897,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n","2024-08-11 11:01:56,161 - __main__ - INFO - Running profile for: medium_forward_backward_warmup_1_mixed_True\n","2024-08-11 11:01:56,162 - __main__ - INFO - Running profile with GPT config: \n","{\n","    \"approximate\": null,\n","    \"activation_name\": \"gelu\",\n","    \"d_model\": 1024,\n","    \"d_ff\": null,\n","    \"num_heads\": 16,\n","    \"context_length\": 128,\n","    \"attn_pdrop\": 0.0,\n","    \"resid_pdrop\": 0.0,\n","    \"bias\": false,\n","    \"vocab_size\": 10000,\n","    \"num_blocks\": 24,\n","    \"token_position_pdrop\": 0.0,\n","    \"weight_tie\": false\n","}\n","2024-08-11 11:01:56,163 - __main__ - INFO - Profiler config: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"warmup_steps\": 1,\n","    \"profile_steps\": 5,\n","    \"mixed_precision\": true\n","}\n","2024-08-11 11:02:09,545 - __main__ - INFO - Profile result: \n","{\n","    \"computation\": \"forward_backward\",\n","    \"times\": [\n","        0.6852539360006631,\n","        0.68381571899954,\n","        0.6833910059995105,\n","        0.6835393290002685,\n","        0.6835425659992325\n","    ],\n","    \"mean_time\": 0.6839085111998429,\n","    \"median_time\": 0.6835425659992325,\n","    \"std_dev\": 0.000686556815682806,\n","    \"min_time\": 0.6833910059995105,\n","    \"max_time\": 0.6852539360006631,\n","    \"total_time\": 3.4195425559992145,\n","    \"profile_steps\": 5\n","}\n","\n","\n","\n"]}],"source":["results = main()"]},{"cell_type":"markdown","metadata":{},"source":["We see `torch.cuda.synchronize()` is scattered to ensure the timing is accurate since CUDA operations\n","are asynchronous and non blocking for CPU operations."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T11:04:13.412783Z","iopub.status.busy":"2024-08-11T11:04:13.412397Z","iopub.status.idle":"2024-08-11T11:04:13.445805Z","shell.execute_reply":"2024-08-11T11:04:13.444858Z","shell.execute_reply.started":"2024-08-11T11:04:13.412754Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>computation</th>\n","      <th>times</th>\n","      <th>mean_time</th>\n","      <th>median_time</th>\n","      <th>std_dev</th>\n","      <th>min_time</th>\n","      <th>max_time</th>\n","      <th>total_time</th>\n","      <th>profile_steps</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>small_forward_warmup_1_mixed_False</td>\n","      <td>forward</td>\n","      <td>[0.0713498349996371, 0.0709589389998655, 0.071...</td>\n","      <td>0.071171</td>\n","      <td>0.071131</td>\n","      <td>0.000138</td>\n","      <td>0.070959</td>\n","      <td>0.071350</td>\n","      <td>0.355853</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>small_forward_warmup_1_mixed_True</td>\n","      <td>forward</td>\n","      <td>[0.07369880799979, 0.07382382700052403, 0.0738...</td>\n","      <td>0.073794</td>\n","      <td>0.073823</td>\n","      <td>0.000056</td>\n","      <td>0.073699</td>\n","      <td>0.073859</td>\n","      <td>0.368969</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>small_forward_warmup_0_mixed_False</td>\n","      <td>forward</td>\n","      <td>[0.07846403200073837, 0.0737714920005601, 0.07...</td>\n","      <td>0.074113</td>\n","      <td>0.073137</td>\n","      <td>0.002227</td>\n","      <td>0.072292</td>\n","      <td>0.078464</td>\n","      <td>0.370565</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>small_forward_warmup_0_mixed_True</td>\n","      <td>forward</td>\n","      <td>[0.0935192509996341, 0.07841499799997109, 0.07...</td>\n","      <td>0.079124</td>\n","      <td>0.075171</td>\n","      <td>0.007358</td>\n","      <td>0.074255</td>\n","      <td>0.093519</td>\n","      <td>0.395620</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>small_backward_warmup_0_mixed_False</td>\n","      <td>backward</td>\n","      <td>[0.14778646800004935, 0.1506624739995459, 0.15...</td>\n","      <td>0.149865</td>\n","      <td>0.150206</td>\n","      <td>0.001054</td>\n","      <td>0.147786</td>\n","      <td>0.150662</td>\n","      <td>0.749323</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>small_backward_warmup_1_mixed_False</td>\n","      <td>backward</td>\n","      <td>[0.15043866700034414, 0.15016293000007863, 0.1...</td>\n","      <td>0.150254</td>\n","      <td>0.150193</td>\n","      <td>0.000201</td>\n","      <td>0.149958</td>\n","      <td>0.150516</td>\n","      <td>0.751268</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>small_backward_warmup_0_mixed_True</td>\n","      <td>backward</td>\n","      <td>[0.14960491599958914, 0.15169357899958413, 0.1...</td>\n","      <td>0.151141</td>\n","      <td>0.151482</td>\n","      <td>0.000773</td>\n","      <td>0.149605</td>\n","      <td>0.151694</td>\n","      <td>0.755706</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>small_backward_warmup_1_mixed_True</td>\n","      <td>backward</td>\n","      <td>[0.15156354600003397, 0.15143018500020844, 0.1...</td>\n","      <td>0.151467</td>\n","      <td>0.151430</td>\n","      <td>0.000076</td>\n","      <td>0.151385</td>\n","      <td>0.151564</td>\n","      <td>0.757336</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>small_forward_backward_warmup_0_mixed_False</td>\n","      <td>forward_backward</td>\n","      <td>[0.21832664599969576, 0.22057815300013317, 0.2...</td>\n","      <td>0.220339</td>\n","      <td>0.220236</td>\n","      <td>0.001322</td>\n","      <td>0.218327</td>\n","      <td>0.222473</td>\n","      <td>1.101694</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>small_forward_backward_warmup_1_mixed_False</td>\n","      <td>forward_backward</td>\n","      <td>[0.22083036900039588, 0.22020937799970852, 0.2...</td>\n","      <td>0.220491</td>\n","      <td>0.220479</td>\n","      <td>0.000278</td>\n","      <td>0.220160</td>\n","      <td>0.220830</td>\n","      <td>1.102457</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>medium_forward_warmup_1_mixed_True</td>\n","      <td>forward</td>\n","      <td>[0.22247573399999965, 0.22273382500043226, 0.2...</td>\n","      <td>0.222611</td>\n","      <td>0.222564</td>\n","      <td>0.000108</td>\n","      <td>0.222476</td>\n","      <td>0.222744</td>\n","      <td>1.113055</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>medium_forward_warmup_0_mixed_True</td>\n","      <td>forward</td>\n","      <td>[0.22800831199947424, 0.22234672700051306, 0.2...</td>\n","      <td>0.223693</td>\n","      <td>0.222693</td>\n","      <td>0.002164</td>\n","      <td>0.222347</td>\n","      <td>0.228008</td>\n","      <td>1.118464</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>small_forward_backward_warmup_0_mixed_True</td>\n","      <td>forward_backward</td>\n","      <td>[0.22407326100073988, 0.22444049899968377, 0.2...</td>\n","      <td>0.224320</td>\n","      <td>0.224365</td>\n","      <td>0.000147</td>\n","      <td>0.224073</td>\n","      <td>0.224477</td>\n","      <td>1.121601</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>small_forward_backward_warmup_1_mixed_True</td>\n","      <td>forward_backward</td>\n","      <td>[0.22448583999994298, 0.22421371400014323, 0.2...</td>\n","      <td>0.224344</td>\n","      <td>0.224382</td>\n","      <td>0.000117</td>\n","      <td>0.224199</td>\n","      <td>0.224486</td>\n","      <td>1.121720</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>medium_forward_warmup_1_mixed_False</td>\n","      <td>forward</td>\n","      <td>[0.24505015699924115, 0.2447970040002474, 0.24...</td>\n","      <td>0.244915</td>\n","      <td>0.244981</td>\n","      <td>0.000156</td>\n","      <td>0.244672</td>\n","      <td>0.245076</td>\n","      <td>1.224577</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>medium_forward_warmup_0_mixed_False</td>\n","      <td>forward</td>\n","      <td>[0.24876118500014854, 0.24528420900060155, 0.2...</td>\n","      <td>0.245821</td>\n","      <td>0.245088</td>\n","      <td>0.001474</td>\n","      <td>0.244956</td>\n","      <td>0.248761</td>\n","      <td>1.229103</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>medium_backward_warmup_0_mixed_True</td>\n","      <td>backward</td>\n","      <td>[0.4554312190002747, 0.4636755310002627, 0.463...</td>\n","      <td>0.461943</td>\n","      <td>0.463649</td>\n","      <td>0.003261</td>\n","      <td>0.455431</td>\n","      <td>0.463729</td>\n","      <td>2.309716</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>medium_backward_warmup_1_mixed_True</td>\n","      <td>backward</td>\n","      <td>[0.46393922600054793, 0.4636971440004345, 0.46...</td>\n","      <td>0.464213</td>\n","      <td>0.463939</td>\n","      <td>0.000881</td>\n","      <td>0.463462</td>\n","      <td>0.465929</td>\n","      <td>2.321066</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>medium_backward_warmup_0_mixed_False</td>\n","      <td>backward</td>\n","      <td>[0.4803364019999208, 0.4842157639996003, 0.484...</td>\n","      <td>0.483126</td>\n","      <td>0.483475</td>\n","      <td>0.001435</td>\n","      <td>0.480336</td>\n","      <td>0.484216</td>\n","      <td>2.415628</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>medium_backward_warmup_1_mixed_False</td>\n","      <td>backward</td>\n","      <td>[0.48379133800062846, 0.4842440839993287, 0.48...</td>\n","      <td>0.483812</td>\n","      <td>0.483791</td>\n","      <td>0.000253</td>\n","      <td>0.483513</td>\n","      <td>0.484244</td>\n","      <td>2.419062</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>medium_forward_backward_warmup_0_mixed_True</td>\n","      <td>forward_backward</td>\n","      <td>[0.6820840510008566, 0.684006079000028, 0.6853...</td>\n","      <td>0.683814</td>\n","      <td>0.683922</td>\n","      <td>0.001036</td>\n","      <td>0.682084</td>\n","      <td>0.685337</td>\n","      <td>3.419069</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>medium_forward_backward_warmup_1_mixed_True</td>\n","      <td>forward_backward</td>\n","      <td>[0.6852539360006631, 0.68381571899954, 0.68339...</td>\n","      <td>0.683909</td>\n","      <td>0.683543</td>\n","      <td>0.000687</td>\n","      <td>0.683391</td>\n","      <td>0.685254</td>\n","      <td>3.419543</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>medium_forward_backward_warmup_1_mixed_False</td>\n","      <td>forward_backward</td>\n","      <td>[0.7272930130002351, 0.7277811669991934, 0.726...</td>\n","      <td>0.726819</td>\n","      <td>0.726417</td>\n","      <td>0.000612</td>\n","      <td>0.726191</td>\n","      <td>0.727781</td>\n","      <td>3.634096</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>medium_forward_backward_warmup_0_mixed_False</td>\n","      <td>forward_backward</td>\n","      <td>[0.7304752370000642, 0.727164707999691, 0.7266...</td>\n","      <td>0.728044</td>\n","      <td>0.727165</td>\n","      <td>0.001610</td>\n","      <td>0.726529</td>\n","      <td>0.730475</td>\n","      <td>3.640220</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            name       computation  \\\n","2             small_forward_warmup_1_mixed_False           forward   \n","3              small_forward_warmup_1_mixed_True           forward   \n","0             small_forward_warmup_0_mixed_False           forward   \n","1              small_forward_warmup_0_mixed_True           forward   \n","4            small_backward_warmup_0_mixed_False          backward   \n","6            small_backward_warmup_1_mixed_False          backward   \n","5             small_backward_warmup_0_mixed_True          backward   \n","7             small_backward_warmup_1_mixed_True          backward   \n","8    small_forward_backward_warmup_0_mixed_False  forward_backward   \n","10   small_forward_backward_warmup_1_mixed_False  forward_backward   \n","15            medium_forward_warmup_1_mixed_True           forward   \n","13            medium_forward_warmup_0_mixed_True           forward   \n","9     small_forward_backward_warmup_0_mixed_True  forward_backward   \n","11    small_forward_backward_warmup_1_mixed_True  forward_backward   \n","14           medium_forward_warmup_1_mixed_False           forward   \n","12           medium_forward_warmup_0_mixed_False           forward   \n","17           medium_backward_warmup_0_mixed_True          backward   \n","19           medium_backward_warmup_1_mixed_True          backward   \n","16          medium_backward_warmup_0_mixed_False          backward   \n","18          medium_backward_warmup_1_mixed_False          backward   \n","21   medium_forward_backward_warmup_0_mixed_True  forward_backward   \n","23   medium_forward_backward_warmup_1_mixed_True  forward_backward   \n","22  medium_forward_backward_warmup_1_mixed_False  forward_backward   \n","20  medium_forward_backward_warmup_0_mixed_False  forward_backward   \n","\n","                                                times  mean_time  median_time  \\\n","2   [0.0713498349996371, 0.0709589389998655, 0.071...   0.071171     0.071131   \n","3   [0.07369880799979, 0.07382382700052403, 0.0738...   0.073794     0.073823   \n","0   [0.07846403200073837, 0.0737714920005601, 0.07...   0.074113     0.073137   \n","1   [0.0935192509996341, 0.07841499799997109, 0.07...   0.079124     0.075171   \n","4   [0.14778646800004935, 0.1506624739995459, 0.15...   0.149865     0.150206   \n","6   [0.15043866700034414, 0.15016293000007863, 0.1...   0.150254     0.150193   \n","5   [0.14960491599958914, 0.15169357899958413, 0.1...   0.151141     0.151482   \n","7   [0.15156354600003397, 0.15143018500020844, 0.1...   0.151467     0.151430   \n","8   [0.21832664599969576, 0.22057815300013317, 0.2...   0.220339     0.220236   \n","10  [0.22083036900039588, 0.22020937799970852, 0.2...   0.220491     0.220479   \n","15  [0.22247573399999965, 0.22273382500043226, 0.2...   0.222611     0.222564   \n","13  [0.22800831199947424, 0.22234672700051306, 0.2...   0.223693     0.222693   \n","9   [0.22407326100073988, 0.22444049899968377, 0.2...   0.224320     0.224365   \n","11  [0.22448583999994298, 0.22421371400014323, 0.2...   0.224344     0.224382   \n","14  [0.24505015699924115, 0.2447970040002474, 0.24...   0.244915     0.244981   \n","12  [0.24876118500014854, 0.24528420900060155, 0.2...   0.245821     0.245088   \n","17  [0.4554312190002747, 0.4636755310002627, 0.463...   0.461943     0.463649   \n","19  [0.46393922600054793, 0.4636971440004345, 0.46...   0.464213     0.463939   \n","16  [0.4803364019999208, 0.4842157639996003, 0.484...   0.483126     0.483475   \n","18  [0.48379133800062846, 0.4842440839993287, 0.48...   0.483812     0.483791   \n","21  [0.6820840510008566, 0.684006079000028, 0.6853...   0.683814     0.683922   \n","23  [0.6852539360006631, 0.68381571899954, 0.68339...   0.683909     0.683543   \n","22  [0.7272930130002351, 0.7277811669991934, 0.726...   0.726819     0.726417   \n","20  [0.7304752370000642, 0.727164707999691, 0.7266...   0.728044     0.727165   \n","\n","     std_dev  min_time  max_time  total_time  profile_steps  \n","2   0.000138  0.070959  0.071350    0.355853              5  \n","3   0.000056  0.073699  0.073859    0.368969              5  \n","0   0.002227  0.072292  0.078464    0.370565              5  \n","1   0.007358  0.074255  0.093519    0.395620              5  \n","4   0.001054  0.147786  0.150662    0.749323              5  \n","6   0.000201  0.149958  0.150516    0.751268              5  \n","5   0.000773  0.149605  0.151694    0.755706              5  \n","7   0.000076  0.151385  0.151564    0.757336              5  \n","8   0.001322  0.218327  0.222473    1.101694              5  \n","10  0.000278  0.220160  0.220830    1.102457              5  \n","15  0.000108  0.222476  0.222744    1.113055              5  \n","13  0.002164  0.222347  0.228008    1.118464              5  \n","9   0.000147  0.224073  0.224477    1.121601              5  \n","11  0.000117  0.224199  0.224486    1.121720              5  \n","14  0.000156  0.244672  0.245076    1.224577              5  \n","12  0.001474  0.244956  0.248761    1.229103              5  \n","17  0.003261  0.455431  0.463729    2.309716              5  \n","19  0.000881  0.463462  0.465929    2.321066              5  \n","16  0.001435  0.480336  0.484216    2.415628              5  \n","18  0.000253  0.483513  0.484244    2.419062              5  \n","21  0.001036  0.682084  0.685337    3.419069              5  \n","23  0.000687  0.683391  0.685254    3.419543              5  \n","22  0.000612  0.726191  0.727781    3.634096              5  \n","20  0.001610  0.726529  0.730475    3.640220              5  "]},"metadata":{},"output_type":"display_data"}],"source":["df = results_to_dataframe(results)\n","\n","df_by_mean = df.sort_values(by='mean_time', ascending=True)\n","display(df_by_mean)"]},{"cell_type":"markdown","metadata":{},"source":["Why is warmup recommended by CS336's lecturers before timing? Across the board you can see that if we keep all other variables constant,\n","then having warmup of 1 step has a much lower standard deviation that those that don't. The basic intuition is that after warmup, the GPU\n","is \"warmed-up\", it is like cold caches in action, and other compilation and optimization that happen under the hood, so warmup is good for stabalisation."]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-08-11T11:14:52.962854Z","iopub.status.busy":"2024-08-11T11:14:52.962482Z","iopub.status.idle":"2024-08-11T11:14:52.981256Z","shell.execute_reply":"2024-08-11T11:14:52.980316Z","shell.execute_reply.started":"2024-08-11T11:14:52.962824Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>computation</th>\n","      <th>times</th>\n","      <th>mean_time</th>\n","      <th>median_time</th>\n","      <th>std_dev</th>\n","      <th>min_time</th>\n","      <th>max_time</th>\n","      <th>total_time</th>\n","      <th>profile_steps</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>20</th>\n","      <td>medium_forward_backward_warmup_0_mixed_False</td>\n","      <td>forward_backward</td>\n","      <td>[0.7304752370000642, 0.727164707999691, 0.7266...</td>\n","      <td>0.728044</td>\n","      <td>0.727165</td>\n","      <td>0.001610</td>\n","      <td>0.726529</td>\n","      <td>0.730475</td>\n","      <td>3.640220</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>medium_forward_backward_warmup_1_mixed_False</td>\n","      <td>forward_backward</td>\n","      <td>[0.7272930130002351, 0.7277811669991934, 0.726...</td>\n","      <td>0.726819</td>\n","      <td>0.726417</td>\n","      <td>0.000612</td>\n","      <td>0.726191</td>\n","      <td>0.727781</td>\n","      <td>3.634096</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            name       computation  \\\n","20  medium_forward_backward_warmup_0_mixed_False  forward_backward   \n","22  medium_forward_backward_warmup_1_mixed_False  forward_backward   \n","\n","                                                times  mean_time  median_time  \\\n","20  [0.7304752370000642, 0.727164707999691, 0.7266...   0.728044     0.727165   \n","22  [0.7272930130002351, 0.7277811669991934, 0.726...   0.726819     0.726417   \n","\n","     std_dev  min_time  max_time  total_time  profile_steps  \n","20  0.001610  0.726529  0.730475    3.640220              5  \n","22  0.000612  0.726191  0.727781    3.634096              5  "]},"metadata":{},"output_type":"display_data"}],"source":["display(df[df[\"name\"].isin([\"medium_forward_backward_warmup_0_mixed_False\", \"medium_forward_backward_warmup_1_mixed_False\"])])"]},{"cell_type":"markdown","metadata":{},"source":["## References And Further Readings\n","\n","-   [https://christianjmills.com/posts/cuda-mode-notes/lecture-001/](https://christianjmills.com/posts/cuda-mode-notes/lecture-001/)\n","-   [https://github.com/marcelroed/spring2024-assignment2-systems/tree/master](https://github.com/marcelroed/spring2024-assignment2-systems/tree/master)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
