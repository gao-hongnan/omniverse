{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Counting in Python\n",
    "\n",
    "In Python, **reference counting** is a memory management technique used to keep\n",
    "track of how many references (or \"pointers\") exist to an object in memory. When\n",
    "an object’s reference count drops to zero, Python automatically frees the memory\n",
    "allocated to that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "a = []\n",
    "b = a\n",
    "a_ref_count = sys.getrefcount(a)\n",
    "print(a_ref_count)  # Output: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `a = []` creates an empty list `[]` and assigns it to variable `a`.\n",
    "2. `b = a` makes `b` reference the same list as `a`.\n",
    "3. `sys.getrefcount(a)` returns the number of references to the list `a` points\n",
    "   to. The count is `3` because:\n",
    "    - `a` references the list.\n",
    "    - `b` references the list.\n",
    "    - The `sys.getrefcount(a)` function temporarily creates another reference\n",
    "      when it’s called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a beginner python programmer, we thank our lucky stars that Python manages\n",
    "memory for us. But, as a good student, we ask, why is managing the reference\n",
    "count important?\n",
    "\n",
    "First, **memory management** helps Python automatically manage memory by\n",
    "keeping track of objects and freeing memory when objects are no longer needed.\n",
    "For example, if we delete the reference `b`, the reference count of `a` drops to\n",
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "del b\n",
    "a_ref_count = sys.getrefcount(a)\n",
    "print(a_ref_count)  # Output: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, **avoiding memory leaks** ensures that memory is reused efficiently and\n",
    "prevents memory from being wasted on unused objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threads and Race Conditions\n",
    "\n",
    "A **race condition** occurs when two or more threads access shared data\n",
    "simultaneously, and the final outcome depends on the sequence of execution.\n",
    "\n",
    "For example, if two threads try to increment a counter from 5 to 6:\n",
    "\n",
    "1. Thread A reads counter (value = 5)\n",
    "2. Thread B reads counter (value = 5)\n",
    "3. Thread A adds 1 (5 + 1 = 6)\n",
    "4. Thread B adds 1 (5 + 1 = 6)\n",
    "5. Thread A writes 6\n",
    "6. Thread B writes 6\n",
    "\n",
    "Even though two increment operations occurred, the counter only increased by 1\n",
    "instead of 2. This happens because both threads read the original value before\n",
    "either could update it. The final result depends on which thread writes last,\n",
    "and the program \"races\" to an incorrect outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show me the code to illustrate the race condition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 10:22:29,521 - DEBUG - Thread 4, starting\n",
      "2024-10-29 10:22:29,522 - DEBUG - Thread 0, starting\n",
      "2024-10-29 10:22:29,522 - DEBUG - Thread 3, starting\n",
      "2024-10-29 10:22:29,522 - DEBUG - Thread 2, starting\n",
      "2024-10-29 10:22:29,523 - DEBUG - Thread 1, starting\n",
      "2024-10-29 10:22:29,951 - INFO - Counter should be 5000000, got 4564365\n"
     ]
    }
   ],
   "source": [
    "\"\"\"With reference to effective python book chapter 54.\n",
    "Ref: https://github.com/bslatkin/effectivepython/blob/master/example_code/item_54.py\n",
    "\"\"\"\n",
    "import logging\n",
    "import threading\n",
    "from threading import Barrier\n",
    "from typing import List\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "NUM_THREADS = 5\n",
    "BARRIER = Barrier(NUM_THREADS)\n",
    "\n",
    "\n",
    "class Counter:\n",
    "    def __init__(self) -> None:\n",
    "        self.count = 0\n",
    "\n",
    "    def increment(self, offset: int) -> None:\n",
    "        self.count += offset\n",
    "\n",
    "def worker(thread_index: int, total_iterations: int, counter: Counter) -> None:\n",
    "    \"\"\"The barrier is used to synchronize the threads so that they all start counting\n",
    "    at the same time. This makes it easier to get a race condition since we wait for\n",
    "    the other threads to start else in the loop we always have an order that the\n",
    "    first thread likely starts first and then the second and so on.\n",
    "    \"\"\"\n",
    "    BARRIER.wait()\n",
    "    logging.debug(\"Thread %s, starting\", thread_index)\n",
    "    for _ in range(total_iterations):\n",
    "        counter.increment(1)\n",
    "\n",
    "\n",
    "def thread_unsafe(total_iterations: int) -> None:\n",
    "    counter = Counter()\n",
    "\n",
    "    threads: List[threading.Thread] = []\n",
    "    for index in range(NUM_THREADS):\n",
    "        thread = threading.Thread(target=worker, args=(index, total_iterations, counter))\n",
    "        threads.append(thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    expected = total_iterations * NUM_THREADS\n",
    "    found = counter.count\n",
    "    logging.info(\"Counter should be %s, got %s\", expected, found)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total_iterations = 10**6\n",
    "\n",
    "    thread_unsafe(total_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protecting Reference Counts with Locks\n",
    "\n",
    "So we circle back a bit to the reference count thingy earlier. Since we saw how\n",
    "race conditions can happen, the same thing can happen to the reference count of\n",
    "an object - which means that the **reference count** of an object can be\n",
    "modified by multiple threads. If two threads try to increment or decrement the\n",
    "reference count simultaneously without protection, it can lead to\n",
    "inconsistencies, such as the case where reference counts might reach zero\n",
    "incorrectly, freeing memory while it’s still in use, causing crashes or bugs.\n",
    "\n",
    "How do we prevent this? We first understand the rough idea of a **lock**.\n",
    "\n",
    "A **lock** is a synchronization mechanism used to control access to shared\n",
    "resources. When a thread acquires a lock, other threads must wait until the lock\n",
    "is released before accessing the resource.\n",
    "\n",
    "-   In the first example without a lock, both threads might read the same\n",
    "    `counter` value before incrementing it, causing some increments to be lost.\n",
    "-   In the second example, the lock ensures that only one thread can modify the\n",
    "    counter at a time.\n",
    "-   The `with lock:` statement automatically acquires the lock before entering\n",
    "    the block and releases it when exiting.\n",
    "-   This guarantees that the final counter value will always be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 10:22:29,959 - DEBUG - Thread 4, starting\n",
      "2024-10-29 10:22:29,959 - DEBUG - Thread 0, starting\n",
      "2024-10-29 10:22:29,959 - DEBUG - Thread 3, starting\n",
      "2024-10-29 10:22:29,960 - DEBUG - Thread 2, starting\n",
      "2024-10-29 10:22:29,960 - DEBUG - Thread 1, starting\n",
      "2024-10-29 10:22:30,821 - INFO - Counter should be 5000000, got 5000000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"With reference to effective python book chapter 54.\n",
    "Ref: https://github.com/bslatkin/effectivepython/blob/master/example_code/item_54.py\n",
    "\"\"\"\n",
    "import logging\n",
    "import threading\n",
    "from threading import Barrier\n",
    "from typing import List\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "NUM_THREADS = 5\n",
    "BARRIER = Barrier(NUM_THREADS)\n",
    "\n",
    "class CounterLock:\n",
    "    def __init__(self) -> None:\n",
    "        self.count = 0\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def increment(self, offset: int) -> None:\n",
    "        with self.lock:\n",
    "            self.count += offset\n",
    "\n",
    "\n",
    "def worker(thread_index: int, total_iterations: int, counter: Counter) -> None:\n",
    "    \"\"\"The barrier is used to synchronize the threads so that they all start counting\n",
    "    at the same time. This makes it easier to get a race condition since we wait for\n",
    "    the other threads to start else in the loop we always have an order that the\n",
    "    first thread likely starts first and then the second and so on.\n",
    "    \"\"\"\n",
    "    BARRIER.wait()\n",
    "    logging.debug(\"Thread %s, starting\", thread_index)\n",
    "    for _ in range(total_iterations):\n",
    "        counter.increment(1)\n",
    "\n",
    "\n",
    "def thread_safe(total_iterations: int) -> None:\n",
    "    counter = CounterLock()\n",
    "\n",
    "    threads: List[threading.Thread] = []\n",
    "    for index in range(NUM_THREADS):\n",
    "        thread = threading.Thread(target=worker, args=(index, total_iterations, counter))\n",
    "        threads.append(thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    expected = total_iterations * NUM_THREADS\n",
    "    found = counter.count\n",
    "\n",
    "    logging.info(\"Counter should be %s, got %s\", expected, found)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total_iterations = 10**6\n",
    "\n",
    "    thread_safe(total_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadlocks\n",
    "\n",
    "A **deadlock** occurs when two or more threads are waiting indefinitely for\n",
    "locks held by each other, preventing them from making progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "class BankAccount:\n",
    "    def __init__(self, id: int, balance: float) -> None:\n",
    "        self.id: int = id\n",
    "        self.balance: float = balance\n",
    "        self.lock: threading.Lock = threading.Lock()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"Account {self.id}: ${self.balance}\"\n",
    "\n",
    "\n",
    "def unsafe_transfer(from_account: BankAccount, to_account: BankAccount, amount: float) -> None:\n",
    "    with from_account.lock:\n",
    "        print(f\"Locked account {from_account.id}\")\n",
    "        time.sleep(0.5)  # Simulate some work and make deadlock more likely\n",
    "        with to_account.lock:\n",
    "            print(f\"Locked account {to_account.id}\")\n",
    "            if from_account.balance >= amount:\n",
    "                from_account.balance -= amount\n",
    "                to_account.balance += amount\n",
    "                print(f\"Transferred ${amount} from Account {from_account.id} to Account {to_account.id}\")\n",
    "\n",
    "\n",
    "def safe_transfer(from_account: BankAccount, to_account: BankAccount, amount: float) -> None:\n",
    "    first: BankAccount = from_account if from_account.id < to_account.id else to_account\n",
    "    second: BankAccount = to_account if from_account.id < to_account.id else from_account\n",
    "\n",
    "    with first.lock:\n",
    "        print(f\"Locked account {first.id}\")\n",
    "        time.sleep(0.5)  # Simulate some work\n",
    "        with second.lock:\n",
    "            print(f\"Locked account {second.id}\")\n",
    "            if from_account.balance >= amount:\n",
    "                from_account.balance -= amount\n",
    "                to_account.balance += amount\n",
    "                print(f\"Transferred ${amount} from Account {from_account.id} to Account {to_account.id}\")\n",
    "\n",
    "\n",
    "account1: BankAccount = BankAccount(1, 1000)\n",
    "account2: BankAccount = BankAccount(2, 1000)\n",
    "\n",
    "print(\"Initial balances:\")\n",
    "print(account1)\n",
    "print(account2)\n",
    "print(\"\\nTrying unsafe transfers (will likely deadlock):\")\n",
    "\n",
    "# Create threads with unsafe transfers (will deadlock)\n",
    "thread1: threading.Thread = threading.Thread(target=unsafe_transfer, args=(account1, account2, 500))\n",
    "thread2: threading.Thread = threading.Thread(target=unsafe_transfer, args=(account2, account1, 300))\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "```\n",
    "\n",
    "1. `thread1` acquires the lock on `account1` and waits to acquire the lock on\n",
    "   `account2`.\n",
    "2. `thread2` acquires the lock on `account2` and waits to acquire the lock on\n",
    "   `account1`.\n",
    "3. Both threads are waiting for each other to release the locks, causing a\n",
    "   deadlock.\n",
    "\n",
    "Why do we need to know this? Because as we saw earlier, locks are useful for\n",
    "preventing race conditions. But using locks not so carefully can lead to\n",
    "deadlocks. GIL will aim to solve this as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Global Interpreter Lock (GIL) in Python\n",
    "\n",
    "The **Global Interpreter Lock (GIL)** is a **mutex** (lock) that protects access\n",
    "to Python objects, preventing multiple native threads from executing Python\n",
    "bytecodes simultaneously in the same process.\n",
    "\n",
    "-   To solve deadlocks, gil only has **one lock** for the entire process - thus\n",
    "    the scenario where two threads are waiting for each other to release a lock\n",
    "    is avoided. In more intuition, the gil allows only **one thread** to execute\n",
    "    bytecode at a time.\n",
    "-   With locks in place, race conditions are mostly resolved.\n",
    "\n",
    "With gil, it has its own trade-offs:\n",
    "\n",
    "-   **Limits Multi-threaded Performance:** Because the GIL allows only one\n",
    "    thread to execute Python code at a time, CPU-bound multi-threaded programs\n",
    "    don’t benefit from multiple cores. They run almost as if they were\n",
    "    single-threaded.\n",
    "-   **Inefficiency in Multi-core Systems:** In CPU-bound tasks, the GIL can\n",
    "    become a bottleneck, preventing Python programs from fully utilizing\n",
    "    multi-core processors.\n",
    "\n",
    "Let's see an example of how gil can limit multi-threaded performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU-bound task comparison:\n",
      "Single-threaded time: 1.71 seconds\n",
      "Multi-threaded time: 1.62 seconds\n",
      "Speed difference: 1.06x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import requests\n",
    "\n",
    "\n",
    "def cpu_bound_task():\n",
    "    \"\"\"CPU intensive task - calculating sum of numbers\"\"\"\n",
    "    count = 0\n",
    "    for _ in range(20_000_000):\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def run_tasks_single_thread(task, num_iterations):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        task()\n",
    "\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "\n",
    "def run_tasks_multi_thread(task, num_threads):\n",
    "    start_time = time.time()\n",
    "\n",
    "    threads: List[threading.Thread] = []\n",
    "    for _ in range(num_threads):\n",
    "        t = threading.Thread(target=task)\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# NOTE: CPU-bound tasks\n",
    "num_tasks = 4\n",
    "print(\"CPU-bound task comparison:\")\n",
    "single_thread_cpu = run_tasks_single_thread(cpu_bound_task, num_tasks)\n",
    "print(f\"Single-threaded time: {single_thread_cpu:.2f} seconds\")\n",
    "\n",
    "multi_thread_cpu = run_tasks_multi_thread(cpu_bound_task, num_tasks)\n",
    "print(f\"Multi-threaded time: {multi_thread_cpu:.2f} seconds\")\n",
    "print(f\"Speed difference: {single_thread_cpu/multi_thread_cpu:.2f}x\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU-bound task comparison:\n",
      "Single-threaded time: 1.88 seconds\n",
      "Multi-threaded time: 1.63 seconds\n",
      "Multi-process time: 0.06 seconds\n",
      "\n",
      "Speed comparison (relative to single-thread):\n",
      "Threading speedup: 1.15x\n",
      "Multiprocessing speedup: 30.59x\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/omniverse/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/omniverse/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/omniverse/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/omniverse/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/omniverse/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/omniverse/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/omniverse/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/omniverse/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'cpu_bound_task' on <module '__main__' (built-in)>\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'cpu_bound_task' on <module '__main__' (built-in)>\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'cpu_bound_task' on <module '__main__' (built-in)>\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'cpu_bound_task' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import requests\n",
    "from multiprocessing import Process\n",
    "\n",
    "def cpu_bound_task():\n",
    "    \"\"\"CPU intensive task - calculating sum of numbers\"\"\"\n",
    "    count = 0\n",
    "    for _ in range(20_000_000):\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def run_tasks_single_thread(task, num_iterations):\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        task()\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "def run_tasks_multi_thread(task, num_threads):\n",
    "    start_time = time.time()\n",
    "    threads = []\n",
    "    for _ in range(num_threads):\n",
    "        t = threading.Thread(target=task)\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "def run_tasks_multi_process(task, num_processes):\n",
    "    \"\"\"Run tasks using multiple processes\"\"\"\n",
    "    start_time = time.time()\n",
    "    processes = []\n",
    "    for _ in range(num_processes):\n",
    "        p = Process(target=task)\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "def main():\n",
    "    num_tasks = 4\n",
    "\n",
    "    print(\"CPU-bound task comparison:\")\n",
    "    single_thread_cpu = run_tasks_single_thread(cpu_bound_task, num_tasks)\n",
    "    print(f\"Single-threaded time: {single_thread_cpu:.2f} seconds\")\n",
    "\n",
    "    multi_thread_cpu = run_tasks_multi_thread(cpu_bound_task, num_tasks)\n",
    "    print(f\"Multi-threaded time: {multi_thread_cpu:.2f} seconds\")\n",
    "\n",
    "    multi_process_cpu = run_tasks_multi_process(cpu_bound_task, num_tasks)\n",
    "    print(f\"Multi-process time: {multi_process_cpu:.2f} seconds\")\n",
    "\n",
    "    print(f\"\\nSpeed comparison (relative to single-thread):\")\n",
    "    print(f\"Threading speedup: {single_thread_cpu/multi_thread_cpu:.2f}x\")\n",
    "    print(f\"Multiprocessing speedup: {single_thread_cpu/multi_process_cpu:.2f}x\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 10:22:37,712 - DEBUG - Starting new HTTPS connection (1): api.github.com:443\n",
      "2024-10-29 10:22:37,763 - DEBUG - https://api.github.com:443 \"GET / HTTP/1.1\" 200 510\n",
      "2024-10-29 10:22:37,767 - DEBUG - Starting new HTTPS connection (1): api.github.com:443\n",
      "2024-10-29 10:22:37,808 - DEBUG - https://api.github.com:443 \"GET / HTTP/1.1\" 200 510\n",
      "2024-10-29 10:22:37,811 - DEBUG - Starting new HTTPS connection (1): api.github.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO-bound task comparison:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 10:22:37,849 - DEBUG - https://api.github.com:443 \"GET / HTTP/1.1\" 200 510\n",
      "2024-10-29 10:22:37,852 - DEBUG - Starting new HTTPS connection (1): api.github.com:443\n",
      "2024-10-29 10:22:37,889 - DEBUG - https://api.github.com:443 \"GET / HTTP/1.1\" 200 510\n",
      "2024-10-29 10:22:37,893 - DEBUG - Starting new HTTPS connection (1): api.github.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-threaded time: 0.20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 10:22:37,895 - DEBUG - Starting new HTTPS connection (1): api.github.com:443\n",
      "2024-10-29 10:22:37,895 - DEBUG - Starting new HTTPS connection (1): api.github.com:443\n",
      "2024-10-29 10:22:37,895 - DEBUG - Starting new HTTPS connection (1): api.github.com:443\n",
      "2024-10-29 10:22:37,983 - DEBUG - https://api.github.com:443 \"GET / HTTP/1.1\" 200 510\n",
      "2024-10-29 10:22:37,984 - DEBUG - https://api.github.com:443 \"GET / HTTP/1.1\" 200 510\n",
      "2024-10-29 10:22:37,991 - DEBUG - https://api.github.com:443 \"GET / HTTP/1.1\" 200 510\n",
      "2024-10-29 10:22:37,998 - DEBUG - https://api.github.com:443 \"GET / HTTP/1.1\" 200 510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-threaded time: 0.11 seconds\n",
      "Speed difference: 1.82x\n"
     ]
    }
   ],
   "source": [
    "def io_bound_task():\n",
    "    \"\"\"IO intensive task - making HTTP requests\"\"\"\n",
    "    url = \"https://api.github.com\"\n",
    "    response = requests.get(url)\n",
    "    return response.status_code\n",
    "\n",
    "# NOTE: IO-bound tasks\n",
    "print(\"IO-bound task comparison:\")\n",
    "single_thread_io = run_tasks_single_thread(io_bound_task, num_tasks)\n",
    "print(f\"Single-threaded time: {single_thread_io:.2f} seconds\")\n",
    "\n",
    "multi_thread_io = run_tasks_multi_thread(io_bound_task, num_tasks)\n",
    "print(f\"Multi-threaded time: {multi_thread_io:.2f} seconds\")\n",
    "print(f\"Speed difference: {single_thread_io/multi_thread_io:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Further Readings\n",
    "\n",
    "-   [The Global Interpreter Lock (GIL) in Python](https://realpython.com/python-gil/)\n",
    "-   https://stackoverflow.com/questions/1294382/what-is-the-global-interpreter-lock-gil-in-cpython/55309364#55309364\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omniverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
