{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b1032c5-a99c-46c5-9879-74c2554c86e3",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\F}{\\mathbb{F}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\a}{\\mathbf{a}}\n",
    "\\newcommand{\\b}{\\mathbf{b}}\n",
    "\\newcommand{\\c}{\\mathbf{c}}\n",
    "\\newcommand{\\r}{\\mathbf{r}}\n",
    "\\newcommand{\\u}{\\mathbf{u}}\n",
    "\\newcommand{\\w}{\\mathbf{w}}\n",
    "\\newcommand{\\v}{\\mathbf{v}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\z}{\\mathbf{z}}\n",
    "\\newcommand{\\0}{\\mathbf{0}}\n",
    "\\newcommand{\\1}{\\mathbf{1}}\n",
    "\\newcommand{\\A}{\\mathbf{A}}\n",
    "\\newcommand{\\B}{\\mathbf{B}}\n",
    "\\newcommand{\\C}{\\mathbf{C}}\n",
    "\\newcommand{\\P}{\\mathbf{P}}\n",
    "\\newcommand{\\U}{\\mathbf{U}}\n",
    "\\newcommand{\\V}{\\mathbf{V}}\n",
    "\\newcommand{\\rank}{\\textbf{rank}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd356ec-9280-458a-bc34-30f7b3dedf75",
   "metadata": {},
   "source": [
    "## Gram-Schmidt\n",
    "\n",
    "The motivation of Gram-Schmidt is clear when we realize working with **orthogonal/orthonormal vectors** yield desirable properties. For example, a basis vector $\\B = \\{\\b_1, \\b_2, \\ldots, \\b_n\\}$ of a $\\R^n$ space can be transformed into a set of **orthogonal** vectors for easier processing. With this in mind, we go through a method to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c0bea-cf0b-4511-9053-649c5427cd3e",
   "metadata": {},
   "source": [
    "### Geometric Intuition (Gram-Schmidt)[^Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 477-480)] [^Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 89-90)]\n",
    "\n",
    "We leave the heavy lifting in the two references. But the intuition can be simply derived in $\\R^2$ space.\n",
    "\n",
    "Consider $2$ basis vectors $\\{\\u, \\v\\}$ of $\\R^2$, then fix the vector $\\u$, and find the projection of the vector $\\u$ on $\\v$. Recall this is found by:\n",
    "\n",
    "$$\n",
    "\\textbf{proj}_{\\u}(\\v) = \\dfrac{\\u \\cdot \\v}{\\u \\cdot \\u} \\u\n",
    "$$\n",
    "\n",
    "Then $\\v- \\textbf{proj}_{\\u}(\\v)$ is guaranteed to be **orthogonal** to $\\u$ by definition and this method holds for any $\\u, \\v$ in $\\R^n$ where $\\u \\neq \\0$. In $\\R^2$ space, we have already turned $\\u, \\v$ to $\\u, \\v- \\textbf{proj}_{\\u}(\\v)$ where the latter is a set of **orthogonal vectors** that is also a basis of $\\R^2$. Note one should be clear by now that **orthogonal vectors** like these are guanranteed to be **linearly independent** and since the cardinality is $2$, it spans the $R^2$ space. To further make them **orthonormal**, we further divide them by their length as a way of **normalization** and that is all.\n",
    "\n",
    "For higher dimensions, the process is iteratively applied.\n",
    "\n",
    "[^Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 477-480)]: Geometric Intuition of Gram-Schmidt: **Henry Ricardo: A Modern Introduction to Linear Algebra, 2009. (pp. 483-485)**\n",
    "[^Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 89-90)]: Geometric Intuition of Gram-Schmidt: **Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 89-90)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8071c-4a19-4549-b6f2-1ca023a7966b",
   "metadata": {},
   "source": [
    "## QR Decomposition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
