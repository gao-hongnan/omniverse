{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2297040-1e68-471d-85e2-90616bc7210b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\F}{\\mathbb{F}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\C}{\\mathbb{C}}\n",
    "\\newcommand{\\v}{\\mathbf{v}}\n",
    "\\newcommand{\\w}{\\mathbf{w}}\n",
    "\\newcommand{\\a}{\\mathbf{a}}\n",
    "\\newcommand{\\b}{\\mathbf{b}}\n",
    "\\newcommand{\\c}{\\mathbf{c}}\n",
    "\\newcommand{\\w}{\\mathbf{w}}\n",
    "\\newcommand{\\u}{\\mathbf{u}}\n",
    "\\newcommand{\\0}{\\mathbf{0}}\n",
    "\\newcommand{\\1}{\\mathbf{1}}\n",
    "\\newcommand{\\A}{\\mathbf{A}}\n",
    "\\newcommand{\\B}{\\mathbf{B}}\n",
    "\\newcommand{\\Q}{\\mathbf{Q}}\n",
    "\\newcommand{\\b}{\\mathbf{b}}\n",
    "\\newcommand{\\q}{\\mathbf{q}}\n",
    "\\newcommand{\\e}{\\mathbf{e}}\n",
    "\\newcommand{\\I}{\\mathbf{I}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75452b3-95c5-4bef-8465-ed0b2ea92f45",
   "metadata": {},
   "source": [
    "## Matrix Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6296b437-8335-43d8-974b-3ff2b0edce8b",
   "metadata": {},
   "source": [
    "### Matrix Addition and Subraction\n",
    "\n",
    "The sum of two matrices **of the same size** $m \\times n$, $\\A$ and $\\B$ are calculated elementwise:\n",
    "\n",
    "$$\n",
    "(\\A \\pm \\B)_{i, j} = \\A_{i, j} \\pm \\B_{i, j}\n",
    "$$\n",
    "\n",
    "where $1 \\leq i \\leq m , \\quad 1 \\leq j \\leq n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ae5bd-0c09-4a4b-975b-8bd94d0aba65",
   "metadata": {},
   "source": [
    "### Scalar-Matrix Multiplication\n",
    "\n",
    "For any scalar $\\lambda \\in \\F$, the **Matrix-Scalar Multiplication** $\\lambda \\A$ is given by:\n",
    "\n",
    "$$\n",
    "(\\lambda \\A)_{i, j} = \\lambda \\cdot \\A_{i, j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bba41b-5f78-4685-8b5c-c69b1489ad74",
   "metadata": {},
   "source": [
    "#### Commutative of Scalar-Matrix Multiplication\n",
    "\n",
    "Not surprisingly, the operation is commutative such that, given any scalar $\\lambda$, and any sequence of matrices $\\A, \\B$, we have:\n",
    "\n",
    "$$\n",
    "\\lambda \\A\\B = \\A\\lambda\\B = \\A\\B\\lambda\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10014bc3-8c77-4817-aa13-82f692c12ef6",
   "metadata": {},
   "source": [
    "### Matrix Operations Fulfill Field Properties\n",
    "\n",
    "In fact, matrix operations fulfill the properties of field properties. That is, for any matrix $\\A$ and $\\B$ of the same shape and size, we have[^courtesy_macro_analyst]:\n",
    "\n",
    "1. $\\A+ \\B= \\B+ \\A$\n",
    "2. $(\\A+\\B)+ C=\\A+(\\B+C)$\n",
    "3. $c(\\A+\\B)=c\\A+c\\B$\n",
    "4. $(c+d)\\A=c\\A+c{D}$\n",
    "5. $c(d\\A)=(cd)\\A$\n",
    "6. $\\A+=\\A$, where ${0}$ is the zero matrix\n",
    "7. For any $\\A$, there exists a $-\\A$, such that $ \\A+(- \\A)=0$.\n",
    "\n",
    "\n",
    "Although we have not learn **matrix multiplication**, their properties are:\n",
    "\n",
    "1. $ \\A({\\B\\mathbf{C}})=({\\A\\B}) \\mathbf{C}$\n",
    "2. $\\mathbf{C}({\\A\\B})=(\\mathbf{C}\\A)\\B=\\A(\\mathbf{C}\\B)$\n",
    "3. $\\A(\\B+ \\mathbf{C})={\\A\\B}+{\\A\\mathbf{C}}$\n",
    "4. $(\\B+\\mathbf{C})\\A={\\B\\A}+{\\mathbf{C}\\A}$\n",
    "\n",
    "[^courtesy_macro_analyst]: https://github.com/MacroAnalyst/Linear_Algebra_With_Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b1964-fa96-47ad-b41c-2be41c549a88",
   "metadata": {},
   "source": [
    "### Matrix Tranpose\n",
    "\n",
    "Given a matrix $\\A \\in \\R^{m \\times n}$, the **transpose of $\\A$** is denoted $\\A^\\top$ and formed by mapping the rows of $\\A$ to columns and columns of $\\A$ to rows, as illustrated:\n",
    "\n",
    "$$\n",
    "(\\A^\\top)_{i, j} = \\A_{j, i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9797e4a-6d4f-4704-afdd-cf3f73ac6203",
   "metadata": {},
   "source": [
    "#### Theorem (A Matrixs transpose is itself)\n",
    "\n",
    "Prove that the transpose of a matrix $\\mathbf{A}$'s transpose is $\\mathbf{A}$: $(\\mathbf{A}^\\top)^\\top = \\mathbf{A}$.\n",
    "\n",
    "##### Proof\n",
    "\n",
    "Consider a matrix $A_{n \\times k}$ as follows, \n",
    "$$\\mathbf{A}=\\begin{bmatrix}\n",
    " a_{11} & a_{12} & \\cdots & a_{1k} \\\\\n",
    " a_{21} & a_{22} & \\cdots & a_{2k} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " a_{n1} & a_{n2} & \\cdots & a_{nk} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "By definition of **Transpose**, all $(i,j)$ entries of $A$ is mapped to $(j,i)$, for example, $a_{1,2}$ becomes $a_{2,1}$ when transposed. Performing a transpose once more will then map all $(j,i)$ entries back to $(i,j)$. $A$ is unchanged and thus $(\\mathbf{A}^\\top)^\\top = \\mathbf{A}$. \n",
    "**Q.E.D**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97e680a-2849-4de0-94e6-1f0c65ac1cc4",
   "metadata": {},
   "source": [
    "#### Theorem (Sum of Transpose is Transpose of Sum)\n",
    "\n",
    "Given two matrices $\\mathbf{A}$ and $\\mathbf{B}$, show that the sum of transposes is equal to the transpose of a sum: $\\mathbf{A}^\\top + \\mathbf{B}^\\top = (\\mathbf{A} + \\mathbf{B})^\\top$.\n",
    "\n",
    "##### Proof\n",
    "\n",
    "Say that we have two matrices $\\mathbf{A} \\in \\mathbb{R}^{n \\times k}$ and $\\mathbf{B} \\in \\mathbb{R}^{k \\times m}$:\n",
    "\n",
    "$$\\mathbf{A}=\\begin{bmatrix}\n",
    " a_{11} & a_{12} & \\cdots & a_{1k} \\\\\n",
    " a_{21} & a_{22} & \\cdots & a_{2k} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " a_{n1} & a_{n2} & \\cdots & a_{nk} \\\\\n",
    "\\end{bmatrix},\\quad\n",
    "\\mathbf{B}=\\begin{bmatrix}\n",
    " b_{11} & b_{12} & \\cdots & b_{1m} \\\\\n",
    " b_{21} & b_{22} & \\cdots & b_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " b_{k1} & b_{k2} & \\cdots & b_{km} \\\\\n",
    "\\end{bmatrix},\\quad\n",
    "\\mathbf{A+B}=\\begin{bmatrix}\n",
    " a_{11}+b_{11} & a_{12}+b_{12} & \\cdots & a_{1m}+b_{1m} \\\\\n",
    " a_{21}+b_{21} & a_{22}+b_{22} & \\cdots & a_{2m}+b_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " a_{k1}+b_{k1} & a_{k2}+b_{k2} & \\cdots & a_{km}+b_{km} \\\\\n",
    "\\end{bmatrix}.$$\n",
    "\n",
    "Then we can prove it by simply computing the LHS and RHS respectively. Without loss of generality, we pick any pair of point $a_{i,j} \\in \\mathbf{A}, b_{i,j} \\in \\mathbf{B}$ and this pair of point corresponds to $a_{i,j}+b_{i,j} \\in \\mathbf{A}+\\mathbf{B}$. Note in particular that $a_{i,j}+b_{i,j} = (a+b)_{i,j}$.\n",
    "\n",
    "Then the transpose of the point $a_{i,j}$ and $b_{i,j}$ is $a_{j,i}$ and $b_{j,i}$, which sums to $a_{j,i}+b_{j,i} = (a+b)_{j,i}$, which is the transpose of the point $a_{i,j}+b_{i,j} = (a+b)_{i,j}$. **Q.E.D**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2646eb-998d-42e7-9b67-199fd568b409",
   "metadata": {
    "id": "dJDPbpI0DGI6"
   },
   "source": [
    "### Shifting a Matrix\n",
    "\n",
    "When we say we shift a matrix, we really mean the following:\n",
    "\n",
    "Given a **square matrix** $\\A \\in \\R^{n \\times n}$, then shifting a matrix by a constant $\\lambda$ is the following operation:\n",
    "\n",
    "$$\n",
    "\\widetilde{\\A} = \\A + \\lambda \\I_n \\quad \\A \\in \\R^{n \\times n}, \\lambda \\in \\R\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df39af-aeae-4ee9-980b-556c7ed3d187",
   "metadata": {
    "id": "xTS-sjOpEIoW"
   },
   "source": [
    "#### Example and Motivation\n",
    "\n",
    "The author Mike gave us an example with some motivation behind, with reference to **Linear Algebra: Theory, Intuition, Code, 2021. (pp. 127)**, we consider the matrix:\n",
    "\n",
    "$$\n",
    "\\widetilde{A} = \\A + 0.1 \\cdot \\I_3 = \\begin{bmatrix}1 & 3 & 0  \\\\ 1 & 3 & 0 \\\\ 2 & 2 & 7 \\end{bmatrix} + 0.1 \\cdot \\I_3 = \\begin{bmatrix}1.1 & 3 & 0  \\\\ 1 & 3.1 & 0 \\\\ 2 & 2 & 7.1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then we observed:\n",
    "\n",
    "- Diagonal Elements will be affected by shifting, but nothing else. This is obvious as off-diagonal elements of the scaled identity matrix are all zero entries.\n",
    "- Note that row 1 and 2 of $\\A$ are identical, and thus linearly dependent, but just by shifting a little, we will have distinct rows in $\\widetilde{A}$.\n",
    "- In practice, we choose $\\lambda$ to be small so that the shifted matrix is similar to the original matrix $\\A$, while still satisfying some constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee27856-092b-4ade-af40-a66bb461ec7f",
   "metadata": {
    "id": "DuVi639GGyP3"
   },
   "source": [
    "#### Applications in Machine Learning\n",
    "\n",
    "The well known regularization technique is shifting a matrix in disguise.\n",
    "\n",
    "One can read it more here[^Tikhonov_regularization].\n",
    "\n",
    "[^Tikhonov_regularization]: https://en.wikipedia.org/wiki/Tikhonov_regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3be434-0ff9-4a16-a594-5e0b6f33bacb",
   "metadata": {
    "id": "J0VObHa2HJZo"
   },
   "source": [
    "### Diagonal\n",
    "\n",
    "We can extract the diagonal of a matrix into a vector:\n",
    "\n",
    "$$\n",
    "\\v = \\text{diag}(\\A) \\quad \\A \\in \\R^{m, n}, v_i = \\A_{i, i}, i = \\{1, 2, ..., \\min{(m, n)}\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a280058-19db-4cf3-ac0c-08a61503a158",
   "metadata": {
    "id": "ypCfkdqyHbPR"
   },
   "source": [
    "#### Applications in Machine Learning\n",
    "\n",
    "The diagonal elements of a matrix can be extracted and placed into a vector. This is used, for example, in statistics: the diagonal elements of a covariance matrix contain the variance of each variable. **- Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 129)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6930df0-3a83-4bd0-a5ad-3710061b6a22",
   "metadata": {
    "id": "meBW6u6PI8nn"
   },
   "source": [
    "### Trace\n",
    "\n",
    "The trace of a matrix $\\A \\in \\R^{m \\times n}$ is:\n",
    "\n",
    "$$\n",
    "\\text{tr}(\\A) = \\sum_{i=1}^{m}a_{i, i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e11da34-4271-46b9-b69e-0b2c4337748e",
   "metadata": {
    "id": "Hft24QERJM-O"
   },
   "source": [
    "#### Applications in Machine Learning\n",
    "\n",
    "The trace operation has two applications in machine learning: It is used to compute the Frobenius norm of a matrix (a measure of the magnitude of a matrix) and it is used to measure the \"distance\" between two matrices. **- Mike X Cohen: Linear Algebra: Theory, Intuition, Code, 2021. (pp. 129)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
