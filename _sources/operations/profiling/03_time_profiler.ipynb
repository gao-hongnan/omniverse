{"cells":[{"cell_type":"markdown","metadata":{},"source":["# PyTorch's Event And Profiler \n","\n","[![Twitter Handle](https://img.shields.io/badge/Twitter-@gaohongnan-blue?style=social&logo=twitter)](https://twitter.com/gaohongnan)\n","[![LinkedIn Profile](https://img.shields.io/badge/@gaohongnan-blue?style=social&logo=linkedin)](https://linkedin.com/in/gao-hongnan)\n","[![GitHub Profile](https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&logo=github)](https://github.com/gao-hongnan)\n","![Tag](https://img.shields.io/badge/Tag-Brain_Dump-red)\n","![Tag](https://img.shields.io/badge/Level-Beginner-green)\n","\n","\n","```{contents}\n",":local:\n","```"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-12T04:03:10.356517Z","iopub.status.busy":"2024-08-12T04:03:10.356106Z","iopub.status.idle":"2024-08-12T04:03:58.689714Z","shell.execute_reply":"2024-08-12T04:03:58.688529Z","shell.execute_reply.started":"2024-08-12T04:03:10.356486Z"},"trusted":true},"outputs":[],"source":["# %pip install -q omniverse==0.0.63"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T04:44:15.080400Z","iopub.status.busy":"2024-08-12T04:44:15.079609Z","iopub.status.idle":"2024-08-12T04:44:15.085542Z","shell.execute_reply":"2024-08-12T04:44:15.084513Z","shell.execute_reply.started":"2024-08-12T04:44:15.080365Z"},"trusted":true},"outputs":[],"source":["from typing import Callable\n","import torch\n","import logging\n","import sys\n","from torch.profiler import profile, ProfilerActivity\n","\n","import pandas as pd"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T04:20:39.637739Z","iopub.status.busy":"2024-08-12T04:20:39.637322Z","iopub.status.idle":"2024-08-12T04:20:39.680720Z","shell.execute_reply":"2024-08-12T04:20:39.679761Z","shell.execute_reply.started":"2024-08-12T04:20:39.637712Z"},"trusted":true},"outputs":[],"source":["F = Callable[[torch.Tensor], torch.Tensor]\n","\n","assert torch.cuda.is_available()\n","device = torch.device(\"cuda\")\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n","    handlers=[logging.StreamHandler(sys.stdout)],\n","    force=True,\n",")\n","logger = logging.getLogger(__name__)"]},{"cell_type":"markdown","metadata":{},"source":["## Torch Cuda Event\n","\n","Recall in our earlier post that CUDA operations are asynchronous and therefore\n","using `timeit` naively without synchronization blocks would result in inaccurate\n","measurements. We could use `torch.cuda.Event` to have more a more precise timing\n","too."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T04:20:39.682732Z","iopub.status.busy":"2024-08-12T04:20:39.682373Z","iopub.status.idle":"2024-08-12T04:20:39.694853Z","shell.execute_reply":"2024-08-12T04:20:39.693876Z","shell.execute_reply.started":"2024-08-12T04:20:39.682706Z"},"trusted":true},"outputs":[],"source":["def square_by_multiplication(a: torch.Tensor) -> torch.Tensor:\n","    return a * a\n","\n","\n","def square_by_exponentiation(a: torch.Tensor) -> torch.Tensor:\n","    return a**2\n","\n","\n","def profile_with_event(func: F, input: torch.Tensor, warmup_steps: int = 5) -> float:\n","    start = torch.cuda.Event(enable_timing=True)  # Create a start event\n","    end = torch.cuda.Event(enable_timing=True)  # Create an end event\n","\n","    logger.info(f\"Warmup for {warmup_steps} steps to warm up the GPU\")\n","    for _ in range(warmup_steps):\n","        func(input)\n","\n","    start.record()\n","    func(input)\n","    end.record()\n","    torch.cuda.synchronize()  # Synchronize the GPU\n","\n","    time_spent: float = start.elapsed_time(end)\n","    return time_spent"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T04:20:41.392647Z","iopub.status.busy":"2024-08-12T04:20:41.392271Z","iopub.status.idle":"2024-08-12T04:20:42.778092Z","shell.execute_reply":"2024-08-12T04:20:42.777222Z","shell.execute_reply.started":"2024-08-12T04:20:41.392617Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-08-12 04:20:42,732 - __main__ - INFO - Warmup for 5 steps to warm up the GPU\n"]},{"data":{"text/plain":["1.480672001838684"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.randn(10000, 10000).to(device)\n","profile_with_event(square_by_multiplication, x)"]},{"cell_type":"markdown","metadata":{},"source":["## Torch Profiler"]},{"cell_type":"markdown","metadata":{},"source":["### Profiling Square Operation\n","\n","Below we refer to Christian Mill's\n","[lecture notes on CUDA MODE](https://christianjmills.com/posts/cuda-mode-notes/lecture-001/)."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T04:40:51.444414Z","iopub.status.busy":"2024-08-12T04:40:51.443899Z","iopub.status.idle":"2024-08-12T04:40:51.459231Z","shell.execute_reply":"2024-08-12T04:40:51.458052Z","shell.execute_reply.started":"2024-08-12T04:40:51.444382Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n","-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","                                           aten::square         0.19%      11.000us        76.81%       4.423ms       4.423ms       0.000us         0.00%       1.474ms       1.474ms             1  \n","                                              aten::pow        65.32%       3.761ms        76.62%       4.412ms       4.412ms       1.474ms       100.00%       1.474ms       1.474ms             1  \n","void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.474ms       100.00%       1.474ms       1.474ms             1  \n","                                      aten::result_type         0.03%       2.000us         0.03%       2.000us       2.000us       0.000us         0.00%       0.000us       0.000us             1  \n","                                               aten::to         0.02%       1.000us         0.02%       1.000us       1.000us       0.000us         0.00%       0.000us       0.000us             1  \n","                                       cudaLaunchKernel        11.25%     648.000us        11.25%     648.000us     648.000us       0.000us         0.00%       0.000us       0.000us             1  \n","                                  cudaDeviceSynchronize        23.19%       1.335ms        23.19%       1.335ms       1.335ms       0.000us         0.00%       0.000us       0.000us             1  \n","-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","Self CPU time total: 5.758ms\n","Self CUDA time total: 1.474ms\n","\n"]},{"name":"stderr","output_type":"stream","text":["STAGE:2024-08-12 04:40:51 34:34 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n","STAGE:2024-08-12 04:40:51 34:34 ActivityProfilerController.cpp:318] Completed Stage: Collection\n","STAGE:2024-08-12 04:40:51 34:34 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"]}],"source":["with torch.profiler.profile(\n","    activities=[\n","        torch.profiler.ProfilerActivity.CPU,\n","        torch.profiler.ProfilerActivity.CUDA,\n","    ]\n",") as prof:\n","    torch.square(x)\n","\n","print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"]},{"cell_type":"markdown","metadata":{},"source":["First [PyTorch C++ API](https://pytorch.org/cppdocs/) has a foundational tensor\n","and mathematical operation library called **ATen**, which all other operations\n","are built on top of. Later in the profiling you would see numerous prefixes like\n","`aten::` which indicates the operation is from the ATen library.\n","\n","The table have some key columns, for instance, the `aten::square` is an\n","operation that squares the input tensor element-wise. The `aten::pow` operation\n","is used to raise the input tensor to a power element-wise. The\n","`void at::native::vectorized_elementwise_kernel` operation is a C++ kernel used\n","in PyTorch for optimized elementwise operations on the tensor. And one should\n","also know that squaring can be done in two ways, say given an input $x$, then we\n","can either do $x^2$ or $x*x$.\n","\n","The `Self Cpu %` column shows the percentage of total CPU time spent\n","**exclusively** in this operation, not including time in any called subroutines.\n","What this means is that `aten::square` uses $0.17\\%$ of the total CPU time by\n","itself with an absolute amount of $9$ microseconds. Note that the column\n","`Self Cpu %` sums up to $100\\%$ across all operations in the table.\n","\n","Perhaps the term _exclusively_ would be clearer if we look at the `CPU total %`\n","column which represents the total percentage of CPU time spent in this operation\n","and any operations it calls. So `aten::square` takes up $74.27\\%$ of the CPU\n","time **including** itself and any functions it invokes. Granted that I am really\n","unsure of the exact operations that `aten::square` calls because I did not dig\n","further into the source code, it won't be surprising that it surely calls\n","`aten::pow` operation and probably the\n","`void at::native::vectorized_elementwise_kernel` operation. Something like below:\n","\n","```text\n","aten::square\n","└── aten::pow\n","    └── at::native::vectorized_elementwise_kernel...\n","```\n","\n","And the same concept can be applied to the `Self CUDA %` and `CUDA total %`, and\n","it is not surprising that the `aten::square` operation does not have any direct\n","GPU time recorded for it since the real cuda operation is done in the\n","`void at::native::vectorized_elementwise_kernel` operation (related to\n","`aten::pow`)."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T04:41:22.258965Z","iopub.status.busy":"2024-08-12T04:41:22.258571Z","iopub.status.idle":"2024-08-12T04:41:22.271853Z","shell.execute_reply":"2024-08-12T04:41:22.270726Z","shell.execute_reply.started":"2024-08-12T04:41:22.258935Z"},"trusted":true},"outputs":[],"source":["df = pd.DataFrame(map(vars, prof.key_averages()))"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T04:41:28.260097Z","iopub.status.busy":"2024-08-12T04:41:28.259142Z","iopub.status.idle":"2024-08-12T04:41:28.284606Z","shell.execute_reply":"2024-08-12T04:41:28.283221Z","shell.execute_reply.started":"2024-08-12T04:41:28.260062Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>key</th>\n","      <th>self_cpu_time_total</th>\n","      <th>cpu_time_total</th>\n","      <th>self_cuda_time_total</th>\n","      <th>cuda_time_total</th>\n","      <th>device_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>aten::square</td>\n","      <td>11</td>\n","      <td>4423</td>\n","      <td>0</td>\n","      <td>1474</td>\n","      <td>DeviceType.CPU</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>aten::pow</td>\n","      <td>3761</td>\n","      <td>4412</td>\n","      <td>1474</td>\n","      <td>1474</td>\n","      <td>DeviceType.CPU</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>aten::result_type</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>DeviceType.CPU</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>aten::to</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>DeviceType.CPU</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cudaLaunchKernel</td>\n","      <td>648</td>\n","      <td>648</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>DeviceType.CPU</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>void at::native::vectorized_elementwise_kernel...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1474</td>\n","      <td>1474</td>\n","      <td>DeviceType.CUDA</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>cudaDeviceSynchronize</td>\n","      <td>1335</td>\n","      <td>1335</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>DeviceType.CPU</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 key  self_cpu_time_total  \\\n","0                                       aten::square                   11   \n","1                                          aten::pow                 3761   \n","2                                  aten::result_type                    2   \n","3                                           aten::to                    1   \n","4                                   cudaLaunchKernel                  648   \n","5  void at::native::vectorized_elementwise_kernel...                    0   \n","6                              cudaDeviceSynchronize                 1335   \n","\n","   cpu_time_total  self_cuda_time_total  cuda_time_total      device_type  \n","0            4423                     0             1474   DeviceType.CPU  \n","1            4412                  1474             1474   DeviceType.CPU  \n","2               2                     0                0   DeviceType.CPU  \n","3               1                     0                0   DeviceType.CPU  \n","4             648                     0                0   DeviceType.CPU  \n","5               0                  1474             1474  DeviceType.CUDA  \n","6            1335                     0                0   DeviceType.CPU  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df[['key','self_cpu_time_total','cpu_time_total', 'self_cuda_time_total','cuda_time_total', 'device_type']]"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T03:07:15.852901Z","iopub.status.busy":"2024-08-12T03:07:15.852289Z","iopub.status.idle":"2024-08-12T03:07:15.877652Z","shell.execute_reply":"2024-08-12T03:07:15.876717Z","shell.execute_reply.started":"2024-08-12T03:07:15.852870Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>key</th>\n","      <th>count</th>\n","      <th>node_id</th>\n","      <th>is_async</th>\n","      <th>is_remote</th>\n","      <th>use_device</th>\n","      <th>cpu_time_total</th>\n","      <th>cuda_time_total</th>\n","      <th>privateuse1_time_total</th>\n","      <th>self_cpu_time_total</th>\n","      <th>...</th>\n","      <th>cuda_memory_usage</th>\n","      <th>privateuse1_memory_usage</th>\n","      <th>self_cpu_memory_usage</th>\n","      <th>self_cuda_memory_usage</th>\n","      <th>self_privateuse1_memory_usage</th>\n","      <th>cpu_children</th>\n","      <th>cpu_parent</th>\n","      <th>device_type</th>\n","      <th>is_legacy</th>\n","      <th>flops</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>aten::square</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>None</td>\n","      <td>3974</td>\n","      <td>1473</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[&lt;FunctionEvent id=2562 name=aten::pow device_...</td>\n","      <td>None</td>\n","      <td>DeviceType.CPU</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>aten::pow</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>None</td>\n","      <td>3965</td>\n","      <td>1473</td>\n","      <td>0</td>\n","      <td>3340</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[&lt;FunctionEvent id=2563 name=aten::result_type...</td>\n","      <td>&lt;FunctionEvent id=2561 name=aten::square devic...</td>\n","      <td>DeviceType.CPU</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>void at::native::vectorized_elementwise_kernel...</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>1473</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>None</td>\n","      <td>DeviceType.CUDA</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>aten::result_type</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>None</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>&lt;FunctionEvent id=2562 name=aten::pow device_t...</td>\n","      <td>DeviceType.CPU</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>aten::to</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>&lt;FunctionEvent id=2562 name=aten::pow device_t...</td>\n","      <td>DeviceType.CPU</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cudaLaunchKernel</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>None</td>\n","      <td>623</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>623</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>&lt;FunctionEvent id=2562 name=aten::pow device_t...</td>\n","      <td>DeviceType.CPU</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>cudaDeviceSynchronize</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>None</td>\n","      <td>1377</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1377</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>None</td>\n","      <td>DeviceType.CPU</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7 rows × 26 columns</p>\n","</div>"],"text/plain":["                                                 key  count  node_id  \\\n","0                                       aten::square      1       -1   \n","1                                          aten::pow      1       -1   \n","5  void at::native::vectorized_elementwise_kernel...      1       -1   \n","2                                  aten::result_type      1       -1   \n","3                                           aten::to      1       -1   \n","4                                   cudaLaunchKernel      1       -1   \n","6                              cudaDeviceSynchronize      1       -1   \n","\n","   is_async  is_remote use_device  cpu_time_total  cuda_time_total  \\\n","0     False      False       None            3974             1473   \n","1     False      False       None            3965             1473   \n","5     False      False       None               0             1473   \n","2     False      False       None               2                0   \n","3     False      False       None               0                0   \n","4     False      False       None             623                0   \n","6     False      False       None            1377                0   \n","\n","   privateuse1_time_total  self_cpu_time_total  ...  cuda_memory_usage  \\\n","0                       0                    9  ...                  0   \n","1                       0                 3340  ...                  0   \n","5                       0                    0  ...                  0   \n","2                       0                    2  ...                  0   \n","3                       0                    0  ...                  0   \n","4                       0                  623  ...                  0   \n","6                       0                 1377  ...                  0   \n","\n","   privateuse1_memory_usage self_cpu_memory_usage self_cuda_memory_usage  \\\n","0                         0                     0                      0   \n","1                         0                     0                      0   \n","5                         0                     0                      0   \n","2                         0                     0                      0   \n","3                         0                     0                      0   \n","4                         0                     0                      0   \n","6                         0                     0                      0   \n","\n","   self_privateuse1_memory_usage  \\\n","0                              0   \n","1                              0   \n","5                              0   \n","2                              0   \n","3                              0   \n","4                              0   \n","6                              0   \n","\n","                                        cpu_children  \\\n","0  [<FunctionEvent id=2562 name=aten::pow device_...   \n","1  [<FunctionEvent id=2563 name=aten::result_type...   \n","5                                                 []   \n","2                                                 []   \n","3                                                 []   \n","4                                                 []   \n","6                                                 []   \n","\n","                                          cpu_parent      device_type  \\\n","0                                               None   DeviceType.CPU   \n","1  <FunctionEvent id=2561 name=aten::square devic...   DeviceType.CPU   \n","5                                               None  DeviceType.CUDA   \n","2  <FunctionEvent id=2562 name=aten::pow device_t...   DeviceType.CPU   \n","3  <FunctionEvent id=2562 name=aten::pow device_t...   DeviceType.CPU   \n","4  <FunctionEvent id=2562 name=aten::pow device_t...   DeviceType.CPU   \n","6                                               None   DeviceType.CPU   \n","\n","   is_legacy  flops  \n","0      False      0  \n","1      False      0  \n","5      False      0  \n","2      False      0  \n","3      False      0  \n","4      False      0  \n","6      False      0  \n","\n","[7 rows x 26 columns]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df.sort_values(by=\"cuda_time_total\", ascending=False)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T04:43:12.744848Z","iopub.status.busy":"2024-08-12T04:43:12.744461Z","iopub.status.idle":"2024-08-12T04:43:12.758240Z","shell.execute_reply":"2024-08-12T04:43:12.756764Z","shell.execute_reply.started":"2024-08-12T04:43:12.744808Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n","-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","                                              aten::mul        49.96%       2.265ms        70.34%       3.189ms       3.189ms       1.477ms       100.00%       1.477ms       1.477ms             1  \n","void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.477ms       100.00%       1.477ms       1.477ms             1  \n","                                       cudaLaunchKernel        20.38%     924.000us        20.38%     924.000us     924.000us       0.000us         0.00%       0.000us       0.000us             1  \n","                                  cudaDeviceSynchronize        29.66%       1.345ms        29.66%       1.345ms       1.345ms       0.000us         0.00%       0.000us       0.000us             1  \n","-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","Self CPU time total: 4.534ms\n","Self CUDA time total: 1.477ms\n","\n"]},{"name":"stderr","output_type":"stream","text":["STAGE:2024-08-12 04:43:12 34:34 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n","STAGE:2024-08-12 04:43:12 34:34 ActivityProfilerController.cpp:318] Completed Stage: Collection\n","STAGE:2024-08-12 04:43:12 34:34 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"]}],"source":["with torch.profiler.profile(\n","    activities=[\n","        torch.profiler.ProfilerActivity.CPU,\n","        torch.profiler.ProfilerActivity.CUDA,\n","    ]\n",") as prof:\n","    square_by_multiplication(x)\n","\n","print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"]},{"cell_type":"markdown","metadata":{},"source":["### Trace"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T04:44:52.630681Z","iopub.status.busy":"2024-08-12T04:44:52.630337Z","iopub.status.idle":"2024-08-12T04:45:05.082014Z","shell.execute_reply":"2024-08-12T04:45:05.081102Z","shell.execute_reply.started":"2024-08-12T04:44:52.630655Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["STAGE:2024-08-12 04:44:52 34:34 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n","STAGE:2024-08-12 04:45:05 34:34 ActivityProfilerController.cpp:318] Completed Stage: Collection\n","STAGE:2024-08-12 04:45:05 34:34 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"]}],"source":["with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n","    for _ in range(10):\n","        a = torch.square(torch.randn(10000, 10000).cuda())\n","\n","prof.export_chrome_trace(\"default_square_trace.json\")"]},{"cell_type":"markdown","metadata":{},"source":["We can put this json file to chrome://tracing/ to see a flamegraph like visual.\n","\n","```{figure} ./assets/default_square_trace.png\n","---\n","name: default_square_trace\n","---\n","\n","Trace of the default square operation.\n","```"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T04:47:42.147135Z","iopub.status.busy":"2024-08-12T04:47:42.146379Z","iopub.status.idle":"2024-08-12T04:47:54.458626Z","shell.execute_reply":"2024-08-12T04:47:54.457776Z","shell.execute_reply.started":"2024-08-12T04:47:42.147101Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["STAGE:2024-08-12 04:47:44 34:34 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n","STAGE:2024-08-12 04:47:47 34:34 ActivityProfilerController.cpp:318] Completed Stage: Collection\n","STAGE:2024-08-12 04:47:47 34:34 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"]},{"name":"stdout","output_type":"stream","text":["-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n","-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","                                            aten::copy_         0.00%     111.000us         6.95%     171.340ms      85.670ms     170.696ms        98.30%     170.696ms      85.348ms             2  \n","                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     170.696ms        98.30%     170.696ms      85.348ms             2  \n","                                              aten::pow         0.01%     192.000us         0.01%     278.000us     139.000us       2.951ms         1.70%       2.951ms       1.476ms             2  \n","void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.951ms         1.70%       2.951ms       1.476ms             2  \n","                                          ProfilerStep*         2.01%      49.532ms        99.95%        2.464s        1.232s       0.000us         0.00%     173.647ms      86.823ms             2  \n","                                            aten::randn         0.00%      55.000us        90.97%        2.243s        1.121s       0.000us         0.00%       0.000us       0.000us             2  \n","                                            aten::empty         0.00%      77.000us         0.00%      77.000us      38.500us       0.000us         0.00%       0.000us       0.000us             2  \n","                                          aten::normal_        90.96%        2.242s        90.96%        2.242s        1.121s       0.000us         0.00%       0.000us       0.000us             2  \n","                                               aten::to         0.00%      53.000us         6.96%     171.507ms      42.877ms       0.000us         0.00%     170.696ms      42.674ms             4  \n","                                         aten::_to_copy         0.00%      60.000us         6.95%     171.454ms      85.727ms       0.000us         0.00%     170.696ms      85.348ms             2  \n","                                    aten::empty_strided         0.00%      54.000us         0.00%      54.000us      27.000us       0.000us         0.00%       0.000us       0.000us             2  \n","                                        cudaMemcpyAsync         6.94%     171.179ms         6.94%     171.179ms      85.590ms       0.000us         0.00%       0.000us       0.000us             2  \n","                                  cudaStreamSynchronize         0.00%      50.000us         0.00%      50.000us      25.000us       0.000us         0.00%       0.000us       0.000us             2  \n","                                           aten::square         0.00%       9.000us         0.01%     287.000us     143.500us       0.000us         0.00%       2.951ms       1.476ms             2  \n","                                      aten::result_type         0.00%       3.000us         0.00%       3.000us       1.500us       0.000us         0.00%       0.000us       0.000us             2  \n","                                       cudaLaunchKernel         0.00%      83.000us         0.00%      83.000us      41.500us       0.000us         0.00%       0.000us       0.000us             2  \n","                                  cudaDeviceSynchronize         0.05%       1.323ms         0.05%       1.323ms       1.323ms       0.000us         0.00%       0.000us       0.000us             1  \n","-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n","Self CPU time total: 2.465s\n","Self CUDA time total: 173.647ms\n","\n"]}],"source":["## With warmup and skip\n","# Non-default profiler schedule allows user to turn profiler on and off\n","# on different iterations of the training loop;\n","# trace_handler is called every time a new trace becomes available\n","def trace_handler(prof):\n","    print(prof.key_averages().table(\n","        sort_by=\"self_cuda_time_total\", row_limit=-1))\n","    prof.export_chrome_trace(\"non_default_trace_\" + str(prof.step_num) + \".json\")\n","\n","with torch.profiler.profile(\n","    activities=[\n","        torch.profiler.ProfilerActivity.CPU,\n","        torch.profiler.ProfilerActivity.CUDA,\n","    ],\n","\n","    # In this example with wait=1, warmup=1, active=2, repeat=1,\n","    # profiler will skip the first step/iteration,\n","    # start warming up on the second, record\n","    # the third and the forth iterations,\n","    # after which the trace will become available\n","    # and on_trace_ready (when set) is called;\n","    # the cycle repeats starting with the next step\n","\n","    schedule=torch.profiler.schedule(\n","        wait=1,\n","        warmup=1,\n","        active=2,\n","        repeat=1),\n","    on_trace_ready=trace_handler\n","    # on_trace_ready=torch.profiler.tensorboard_trace_handler('./log')\n","    # used when outputting for tensorboard\n","    ) as p:\n","        for iter in range(10):\n","            torch.square(torch.randn(10000, 10000).cuda())\n","            # send a signal to the profiler that the next iteration has started\n","            p.step()"]},{"cell_type":"markdown","metadata":{},"source":["## References And Further Readings\n","\n","-   [CUDA Mode Notes - Lecture 001 by Christian J. Mills](https://christianjmills.com/posts/cuda-mode-notes/lecture-001/)\n","-   [PyTorch Profiler Recipe](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
