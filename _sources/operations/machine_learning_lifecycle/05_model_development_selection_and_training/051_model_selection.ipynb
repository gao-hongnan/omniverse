{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "695a091a",
   "metadata": {},
   "source": [
    "# Stage 5.1. Model Selection\n",
    "\n",
    "[![Twitter Handle](https://img.shields.io/badge/Twitter-@gaohongnan-blue?style=social&logo=twitter)](https://twitter.com/gaohongnan)\n",
    "[![LinkedIn Profile](https://img.shields.io/badge/@gaohongnan-blue?style=social&logo=linkedin)](https://linkedin.com/in/gao-hongnan)\n",
    "[![GitHub Profile](https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&logo=github)](https://github.com/gao-hongnan)\n",
    "![Tag](https://img.shields.io/badge/Tag-Brain_Dump-red)\n",
    "![Tag](https://img.shields.io/badge/Level-Beginner-green)\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    "```\n",
    "\n",
    "\"Just use gradient boosting\", or \"Just use the biggest Transformer model\" are\n",
    "pretty much irresponsible advice for beginners. As a data scientist or machine\n",
    "learning engineer, you are not a gambler and hope to hit the jackpot with the\n",
    "biggest or SOTA model. Instead, you should understand the trade-offs between\n",
    "different models and choose the one that best fits your problem. On top of that,\n",
    "having a solid understanding of the assumptions and limitations of the model is\n",
    "crucial for making an informed decision.\n",
    "\n",
    "## Understanding Model And Data Assumptions\n",
    "\n",
    "Before selecting a model, it's important to understand the assumptions and\n",
    "limitations of the model. Different models make different assumptions about the\n",
    "data, and these assumptions can impact the model's performance. We would take\n",
    "examples from Chip Huyen's book _Designing Machine Learning Systems_ as she\n",
    "provided us with some useful points to consider when selecting a model for your\n",
    "problem[^chip-chapter6].\n",
    "\n",
    "### Independent and Identically Distributed (IID)\n",
    "\n",
    "Consider an underlying distribution $\\mathcal{D}$ from which the training and\n",
    "test data are drawn. The IID assumption states that the examples in the dataset\n",
    "are independently drawn from the same distribution without influence from each\n",
    "other.\n",
    "\n",
    "Consider the case of classification problem, a (sample) dataset\n",
    "$\\mathcal{S}=\\left\\{\\mathbf{z}^{(1)}, \\ldots, \\mathbf{z}^{(N)}\\right\\}$ is a\n",
    "list of individual data points $\\mathbf{z}^{(n)}$, for $n=1, \\ldots, N$.\n",
    "\n",
    "$$\n",
    "\\mathcal{S} \\overset{\\mathrm{iid}}{\\sim} \\mathcal{D} = \\left \\{ \\left(\\mathrm{X}^{(n)}, Y^{(n)} \\right) \\right \\}_{n=1}^N = \\left \\{ \\left(\\mathrm{x}^{(n)}, y^{(n)} \\right) \\right \\}_{n=1}^N \\in \\left(\\mathcal{X}, \\mathcal{Y} \\right)^N\n",
    "$$\n",
    "\n",
    "This means that $\\mathcal{S}$ is a collection of samples drawn $\\textbf{i.i.d.}$\n",
    "from an unknown distribution $\\mathcal{D}$ over the joint distribution of the\n",
    "input and the label space $\\mathcal{X} \\times \\mathcal{Y}$.\n",
    "\n",
    "-   The i.i.d. assumption is foundational in statistical modeling because it\n",
    "    simplifies the process significantly. For example, it allows us to\n",
    "    [**_express joint probability distributions_**](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)\n",
    "    as the product of marginal distributions.\n",
    "-   Furthermore, evaluation techniques such as **_resampling_** and\n",
    "    **_cross-validation_** with a holdout set rely on the assumption that the\n",
    "    training and test data are drawn from the same distribution.\n",
    "\n",
    "However one needs to understand that this assumption doesn't often hold in real\n",
    "world scenarios and assuming that the test set is drawn from the same\n",
    "distribution as the training set is a simplification that may not always be\n",
    "true.\n",
    "\n",
    "### Smoothness (Chaoticity)\n",
    "\n",
    "One of the goal of imposing smoothness constraints on a machine learning model\n",
    "is indeed to avoid chaotic behavior in the model's predictions. A chaotic\n",
    "system, in mathematical terms, is highly sensitive to initial conditions, where\n",
    "small changes can lead to drastically different outcomes. So to enable stability\n",
    "we often impose smoothness constraints on the model.\n",
    "\n",
    "The concept of smoothness in machine learning and mathematical contexts often\n",
    "pertains to the continuity and differentiability of functions. When talking\n",
    "about models in machine learning, the smoothness assumption suggests that the\n",
    "function mapping inputs to outputs should not have abrupt changes.\n",
    "\n",
    "1. **Lipschitz Continuity**: A function $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$\n",
    "   is said to be Lipschitz continuous if there exists a constant $L \\geq 0$ such\n",
    "   that for all $x, y \\in \\mathbb{R}^n$,\n",
    "\n",
    "    $$\n",
    "    |f(x) - f(y)| \\leq L \\|x - y\\|\n",
    "    $$\n",
    "\n",
    "    where $\\|x - y\\|$ is a norm (typically Euclidean) on $\\mathbb{R}^n$. The\n",
    "    constant $L$ is known as the Lipschitz constant. This definition ensures\n",
    "    that the function does not change more rapidly than a linear function scaled\n",
    "    by $L$, providing a bound on the rate of change of the function.\n",
    "\n",
    "2. **Hölder Continuity**: A generalization of Lipschitz continuity, a function\n",
    "   is Hölder continuous if there exists a constant $C \\geq 0$ and an exponent\n",
    "   $\\alpha$ (0 < $\\alpha$ ≤ 1) such that\n",
    "\n",
    "    $$\n",
    "    |f(x) - f(y)| \\leq C \\|x - y\\|^\\alpha\n",
    "    $$\n",
    "\n",
    "    for all $x, y$. When $\\alpha = 1$, Hölder continuity reduces to Lipschitz\n",
    "    continuity. Hölder continuity allows for functions that are less regular\n",
    "    than those required by Lipschitz continuity but still have controlled\n",
    "    variations.\n",
    "\n",
    "3. **Differentiability**: A function $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ is\n",
    "   differentiable at a point $x$ if there exists a linear map $J_f(x)$ (the\n",
    "   Jacobian matrix at $x$) such that\n",
    "\n",
    "    $$\n",
    "    \\lim_{h \\rightarrow 0} \\frac{|f(x+h) - f(x) - J_f(x)h|}{\\|h\\|} = 0\n",
    "    $$\n",
    "\n",
    "    This definition implies that the function can be locally approximated by a\n",
    "    linear map, ensuring smooth transitions between values. A function is\n",
    "    continuously differentiable (class $C^1$) if it is differentiable everywhere\n",
    "    and the derivative is continuous.\n",
    "\n",
    "4. **Twice Differentiability and Beyond**: Higher degrees of smoothness can be\n",
    "   defined by requiring higher derivatives to exist and be continuous. For\n",
    "   example, a function $f$ is of class $C^2$ if it is twice differentiable and\n",
    "   its second derivative is continuous.\n",
    "\n",
    "### Boundaries (Linearity)\n",
    "\n",
    "If your data isn't linearly separable or the relationship between features is\n",
    "non-linear, linear models like Linear Regression or Logistic Regression may not\n",
    "be the best choice. You may need non-linear models like Neural Networks, Support\n",
    "Vector Machines with non-linear kernels, or Tree-Based models.\n",
    "\n",
    "### Dimensionality\n",
    "\n",
    "If you have a high-dimensional dataset, some models may suffer from the curse of\n",
    "dimensionality, such as k-nearest neighbors (k-NN). In such scenarios,\n",
    "dimensionality reduction techniques or models less prone to this issue can be\n",
    "used.\n",
    "\n",
    "### Interpretability vs. Accuracy\n",
    "\n",
    "Depending on the use case, you may prioritize interpretability over prediction\n",
    "accuracy or vice versa. Models like Linear Regression, Logistic Regression, and\n",
    "Decision Trees are highly interpretable, while Neural Networks, SVMs, and\n",
    "Ensemble methods trade-off interpretability for higher accuracy.\n",
    "\n",
    "However, there are many cases where a more complex model is necessary to achieve\n",
    "the desired performance. For example, in image classification, a classical model\n",
    "might failed spectacularly, but a deep learning model like a Convolutional\n",
    "Neural Network (CNN) might be able to achieve much better performance. There are\n",
    "indeed tools such as Grad-CAM to help with the interpretability of deep learning\n",
    "models.\n",
    "\n",
    "### Tractability\n",
    "\n",
    "Let $X$ be the input and $Z$ be the latent representation of $X$. Every\n",
    "generative model makes the assumption that it’s tractable to compute the\n",
    "probability $P(Z \\mid X)$[^chip-chapter6].\n",
    "\n",
    "### Feature Characteristics\n",
    "\n",
    "The nature of your features also impacts model choice. For instance, decision\n",
    "trees and random forests are less affected by feature scaling and can handle\n",
    "mixtures of features (binary, categorical, numerical), whereas logistic\n",
    "regression or support vector machines usually require feature scaling for high\n",
    "performance.\n",
    "\n",
    "### Real-Time Prediction And Computational Resources\n",
    "\n",
    "If you need to make real-time predictions, consider models that are not only\n",
    "fast at prediction time but also have a smaller memory footprint. Simpler models\n",
    "like Logistic Regression, Decision Trees, or k-NNs (provided that the dataset is\n",
    "not too large) could be good choices here.\n",
    "\n",
    "Training models like deep learning or large ensembles can be resource-intensive.\n",
    "If you have computational resource constraints, you might prefer simpler or more\n",
    "efficient models.\n",
    "\n",
    "### No Free Lunch Theorem\n",
    "\n",
    "Remember, there's rarely a one-size-fits-all model for any given problem.\n",
    "Typically, you'll experiment with multiple models and choose the one that\n",
    "performs the best on your validation data and aligns with your project\n",
    "requirements. The\n",
    "[no free lunch theorem](https://en.wikipedia.org/wiki/No_free_lunch_theorem) in\n",
    "machine learning states that no single algorithm works best for every problem.\n",
    "Therefore, after knowing what limitations that the models may impose for your\n",
    "specific problem, you should then experiment with a few models to see which one\n",
    "is doing well.\n",
    "\n",
    "## Baseline\n",
    "\n",
    "Before proceeding with the selection of more complex models, it is beneficial to\n",
    "establish a baseline model. The baseline model is typically simple, or even\n",
    "naive, serving as the minimum benchmark for model performance.\n",
    "\n",
    "A common practice is to use a simple algorithm or heuristic that can quickly be\n",
    "implemented and run on your data. This baseline approach depends on the nature\n",
    "of the problem at hand. For instance:\n",
    "\n",
    "-   In regression tasks, you might predict the average of the target variable\n",
    "    for all instances.\n",
    "-   In classification tasks, a simple classifier such as predicting the most\n",
    "    common class can serve as a baseline.\n",
    "-   In time series forecasting, a persistence model that predicts the next step\n",
    "    to be the same as the last observed step can be used.\n",
    "\n",
    "> It is worth noting that scikit-learn's `Dummy` module provides a convenient\n",
    "> way to create baseline models for regression and classification tasks.\n",
    "\n",
    "The baseline model provides a point of comparison for future, more complex\n",
    "models. Any sophisticated model we train should perform significantly better\n",
    "than this baseline.\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "Following the baseline model, the next step is model selection. Here, you\n",
    "identify potential algorithms that could be used for solving the given problem.\n",
    "\n",
    "The difference here is you are actually running a few model classes from\n",
    "different hypothesis spaces $\\mathcal{H}$ based on the model selection process\n",
    "earlier.\n",
    "\n",
    "The choice of models usually depends on the problem type (regression,\n",
    "classification, clustering, etc.), the nature of your data, and practical\n",
    "considerations such as computational resources and time constraints.\n",
    "\n",
    "For example, if you have labeled data and a binary output, you may consider\n",
    "supervised learning algorithms such as logistic regression, decision trees, or\n",
    "support vector machines. If your dataset is large and complex, you might\n",
    "consider more powerful models like random forests or neural networks.\n",
    "\n",
    "In this step, it's also important to consider the interpretability of the model.\n",
    "In some cases, a simpler model might be preferred if it offers similar\n",
    "performance to a more complex model but is easier to interpret and explain.\n",
    "\n",
    "Remember, no one model fits all scenarios. A good practice is to try multiple\n",
    "models and see which one performs best on your specific dataset. Sometimes using\n",
    "the biggest model do yield the best results but if your latency is too high for\n",
    "inference and usable by the end-user, then it's not a good model - and that's\n",
    "why many current research directions emphasize on how to quantize large models,\n",
    "prune models, or even distill models to serve powerful models in a reasonable\n",
    "latency.\n",
    "\n",
    "## Ensembling\n",
    "\n",
    "Ensembling is a technique where multiple models are combined to improve\n",
    "performance. We can usually categorize this technique into three types, namely\n",
    "bagging, boosting, and stacking.\n",
    "\n",
    "It is a huge topic of its own and we will not cover it here as it is beyond the\n",
    "scope of this notebook. Have a read at Microsoft Rearch Blog\n",
    "[Three mysteries in deep learning: Ensemble, knowledge distillation, and self-distillation](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/)\n",
    "for some brief insights. Chip also mentioned in Chapter 6 of her book on this\n",
    "topic and provides intuition on how ensembling works and why it is effective.\n",
    "\n",
    "Notably, ensembling is used in many Kaggle competitions to achieve top scores,\n",
    "constrained by the inference time and memory usage.\n",
    "\n",
    "## References and Further Readings\n",
    "\n",
    "-   [Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning](https://sebastianraschka.com/pdf/manuscripts/model-eval.pdf)\n",
    "-   Huyen, Chip. \"Chapter 6. Model Development and Offline Evaluation.\" In\n",
    "    Designing Machine Learning Systems: An Iterative Process for\n",
    "    Production-Ready Applications, O'Reilly Media, Inc., 2022.\n",
    "\n",
    "[^chip-chapter6]:\n",
    "    Huyen, Chip. \"Chapter 6. Model Development and Offline Evaluation.\" In\n",
    "    Designing Machine Learning Systems: An Iterative Process for\n",
    "    Production-Ready Applications, O'Reilly Media, Inc., 2022."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "mystnb": {
   "number_source_lines": true
  },
  "source_map": [
   16
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}