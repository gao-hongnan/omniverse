{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9eab66b",
   "metadata": {},
   "source": [
    "# Stage 5.1. Model Selection\n",
    "\n",
    "[![Twitter Handle](https://img.shields.io/badge/Twitter-@gaohongnan-blue?style=social&logo=twitter)](https://twitter.com/gaohongnan)\n",
    "[![LinkedIn Profile](https://img.shields.io/badge/@gaohongnan-blue?style=social&logo=linkedin)](https://linkedin.com/in/gao-hongnan)\n",
    "[![GitHub Profile](https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&logo=github)](https://github.com/gao-hongnan)\n",
    "![Tag](https://img.shields.io/badge/Tag-Brain_Dump-red)\n",
    "![Tag](https://img.shields.io/badge/Level-Beginner-green)\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    "```\n",
    "\n",
    "\"Just use gradient boosting\", or \"Just use the biggest Transformer model\" are\n",
    "pretty much irresponsible advice for beginners. As a data scientist or machine\n",
    "learning engineer, you are not a gambler and hope to hit the jackpot with the\n",
    "biggest or SOTA model. Instead, you should understand the trade-offs between\n",
    "different models and choose the one that best fits your problem. On top of that,\n",
    "having a solid understanding of the assumptions and limitations of the model is\n",
    "crucial for making an informed decision.\n",
    "\n",
    "## Understanding Model And Data Assumptions\n",
    "\n",
    "Before selecting a model, it's important to understand the assumptions and\n",
    "limitations of the model. Different models make different assumptions about the\n",
    "data, and these assumptions can impact the model's performance. We would take\n",
    "examples from Chip Huyen's book _Designing Machine Learning Systems_ as she\n",
    "provided us with some useful points to consider when selecting a model for your\n",
    "problem.\n",
    "\n",
    "[^chip-chapter6]\n",
    "\n",
    "```{list-table} Factors to Consider in Model Selection\n",
    ":header-rows: 1\n",
    ":name: ml-lifecycle-model-selection-factors\n",
    "\n",
    "-   -   Consideration\n",
    "    -   Description\n",
    "-   -   Dataset size\n",
    "    -   Some algorithms, like deep learning models, perform better with a large\n",
    "        amount of data. Conversely, simpler models like linear regression or\n",
    "        decision trees may be more appropriate for smaller datasets.\n",
    "-   -   Feature characteristics\n",
    "    -   The nature of your features also impacts model choice. For instance,\n",
    "        decision trees and random forests are less affected by feature scaling\n",
    "        and can handle mixtures of features (binary, categorical, numerical),\n",
    "        whereas logistic regression or support vector machines usually require\n",
    "        feature scaling for high performance.\n",
    "-   -   Non-linearity\n",
    "    -   If your data isn't linearly separable or the relationship between\n",
    "        features is non-linear, linear models like Linear Regression or Logistic\n",
    "        Regression may not be the best choice. You may need non-linear models\n",
    "        like Neural Networks, Support Vector Machines with non-linear kernels,\n",
    "        or Tree-Based models.\n",
    "-   -   Dimensionality\n",
    "    -   If you have a high-dimensional dataset, some models may suffer from the\n",
    "        curse of dimensionality, such as k-nearest neighbors (k-NN). In such\n",
    "        scenarios, dimensionality reduction techniques or models less prone to\n",
    "        this issue like Random Forests or Gradient Boosting Machines could be\n",
    "        beneficial.\n",
    "-   -   Interpretability vs. Accuracy\n",
    "    -   Depending on the use case, you may prioritize interpretability over\n",
    "        prediction accuracy or vice versa. Models like Linear Regression,\n",
    "        Logistic Regression, and Decision Trees are highly interpretable, while\n",
    "        Neural Networks, SVMs, and Ensemble methods trade-off interpretability\n",
    "        for higher accuracy.\n",
    "\n",
    "        However, there are many cases where a more complex model is necessary to\n",
    "        achieve the desired performance. For example, in image classification, a\n",
    "        classical model might failed spectacularly, but a deep learning model\n",
    "        like a Convolutional Neural Network (CNN) might be able to achieve much\n",
    "        better performance. There are indeed tools such as Grad-CAM to help with\n",
    "        the interpretability of deep learning models.\n",
    "\n",
    "-   -   Real-time prediction\n",
    "    -   If you need to make real-time predictions, consider models that are not\n",
    "        only fast at prediction time but also have a smaller memory footprint.\n",
    "        Simpler models like Logistic Regression, Decision Trees, or k-NNs\n",
    "        (provided that the dataset is not too large) could be good choices here.\n",
    "-   -   Computation resources\n",
    "    -   Training models like deep learning or large ensembles can be\n",
    "        resource-intensive. If you have computational resource constraints, you\n",
    "        might prefer simpler or more efficient models.\n",
    "```\n",
    "\n",
    "Remember, there's rarely a one-size-fits-all model for any given problem.\n",
    "Typically, you'll experiment with multiple models and choose the one that\n",
    "performs the best on your validation data and aligns with your project\n",
    "requirements. The\n",
    "[no free lunch theorem](https://en.wikipedia.org/wiki/No_free_lunch_theorem) in\n",
    "machine learning states that no single algorithm works best for every problem.\n",
    "Therefore, after knowing what limitations that the models may impose for your\n",
    "specific problem, you should then experiment with a few models to see which one\n",
    "is doing well.\n",
    "\n",
    "## Baseline\n",
    "\n",
    "Before proceeding with the selection of more complex models, it is beneficial to\n",
    "establish a baseline model. The baseline model is typically simple, or even\n",
    "naive, serving as the minimum benchmark for model performance.\n",
    "\n",
    "A common practice is to use a simple algorithm or heuristic that can quickly be\n",
    "implemented and run on your data. This baseline approach depends on the nature\n",
    "of the problem at hand. For instance:\n",
    "\n",
    "-   In regression tasks, you might predict the average of the target variable\n",
    "    for all instances.\n",
    "-   In classification tasks, a simple classifier such as predicting the most\n",
    "    common class can serve as a baseline.\n",
    "-   In time series forecasting, a persistence model that predicts the next step\n",
    "    to be the same as the last observed step can be used.\n",
    "\n",
    "> It is worth noting that scikit-learn's `Dummy` module provides a convenient\n",
    "> way to create baseline models for regression and classification tasks.\n",
    "\n",
    "The baseline model provides a point of comparison for future, more complex\n",
    "models. Any sophisticated model we train should perform significantly better\n",
    "than this baseline.\n",
    "\n",
    "## Model Selection Revisited\n",
    "\n",
    "Following the baseline model, the next step is model selection. Here, you\n",
    "identify potential algorithms that could be used for solving the given problem.\n",
    "\n",
    "The difference here is you are actually running a few model classes from\n",
    "different hypothesis spaces $\\mathcal{H}$ based on the model selection process\n",
    "earlier.\n",
    "\n",
    "The choice of models usually depends on the problem type (regression,\n",
    "classification, clustering, etc.), the nature of your data, and practical\n",
    "considerations such as computational resources and time constraints.\n",
    "\n",
    "For example, if you have labeled data and a binary output, you may consider\n",
    "supervised learning algorithms such as logistic regression, decision trees, or\n",
    "support vector machines. If your dataset is large and complex, you might\n",
    "consider more powerful models like random forests or neural networks.\n",
    "\n",
    "In this step, it's also important to consider the interpretability of the model.\n",
    "In some cases, a simpler model might be preferred if it offers similar\n",
    "performance to a more complex model but is easier to interpret and explain.\n",
    "\n",
    "Remember, no one model fits all scenarios. A good practice is to try multiple\n",
    "models and see which one performs best on your specific dataset.\n",
    "\n",
    "---\n",
    "\n",
    "Sometimes using the biggest model do yield the best results but if your latency\n",
    "is too high for inference and usable by the end-user, then it's not a good\n",
    "model - and that's why many current research directions emphasize on how to\n",
    "quantize large models, prune models, or even distill models to serve powerful\n",
    "models in a reasonable latency.\n",
    "\n",
    "## References and Further Readings\n",
    "\n",
    "-   [Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning](https://sebastianraschka.com/pdf/manuscripts/model-eval.pdf)\n",
    "-   Huyen, Chip. \"Chapter 6. Model Development and Offline Evaluation.\" In\n",
    "    Designing Machine Learning Systems: An Iterative Process for\n",
    "    Production-Ready Applications, O'Reilly Media, Inc., 2022.\n",
    "\n",
    "[^chip-chapter6]:\n",
    "    Huyen, Chip. \"Chapter 6. Model Development and Offline Evaluation.\" In\n",
    "    Designing Machine Learning Systems: An Iterative Process for\n",
    "    Production-Ready Applications, O'Reilly Media, Inc., 2022."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "mystnb": {
   "number_source_lines": true
  },
  "source_map": [
   16
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}