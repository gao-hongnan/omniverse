{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "145eba38",
   "metadata": {},
   "source": [
    "# Stage 5.4. Model Testing\n",
    "\n",
    "[![Twitter Handle](https://img.shields.io/badge/Twitter-@gaohongnan-blue?style=social&logo=twitter)](https://twitter.com/gaohongnan)\n",
    "[![LinkedIn Profile](https://img.shields.io/badge/@gaohongnan-blue?style=social&logo=linkedin)](https://linkedin.com/in/gao-hongnan)\n",
    "[![GitHub Profile](https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&logo=github)](https://github.com/gao-hongnan)\n",
    "![Tag](https://img.shields.io/badge/Tag-Brain_Dump-red)\n",
    "![Tag](https://img.shields.io/badge/Level-Beginner-green)\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    "```\n",
    "\n",
    "Testing in machine learning is a bit different from traditional software\n",
    "testing. Here we just give an intuition on _how_ different it is.\n",
    "[Eugene Yan](https://eugeneyan.com/) has written a series of articles on testing\n",
    "in machine learning.\n",
    "\n",
    "Eugene highlighted that software involves having some _input data_ and some\n",
    "_handcrafted logic_ that processes the data to produce some _output data_, which\n",
    "is then compared against the expected output - a deterministic process. In\n",
    "contrast, machine learning involves having some _input data_ and _output data_\n",
    "and with a suitable learning algorithm $\\mathcal{A}$, we can learn a model\n",
    "$\\mathcal{G}$ that can predict the output data from the input data. The process\n",
    "involves a _learned logic_ and when we want to test the model with the learned\n",
    "logic, we would then actually need to load the model and run it on some input\n",
    "data to get the output data to compare against the expected output. And it is\n",
    "also common to compare loss for each epoch against a threshold to see if the\n",
    "model is learning.\n",
    "\n",
    "In my own experience, I always prepare a debug dataset, that is usually sampled\n",
    "(stratified, grouped if needed) from the training dataset. This dataset can be\n",
    "used as your fixture in testing. But more importantly, one should also use this\n",
    "debug dataset to test sanity of your training pipeline. For example, like what\n",
    "Eugene and Karpathy suggested, run your model for a certain number of steps and\n",
    "check if the loss is decreasing, and you can even craft it to be overfit on the\n",
    "debug dataset to see if your model $\\mathcal{G}$ has capacity to learn the data.\n",
    "Furthermore, during hyperparameter tuning, it is very expensive to run the model\n",
    "on the full dataset, so you can use the debug dataset to test if your model is\n",
    "reacting well to the hyperparameters (i.e. learning rate finder).\n",
    "\n",
    "## References and Further Readings\n",
    "\n",
    "-   [How to Test Machine Learning Code and Systems](https://eugeneyan.com/writing/testing-ml/)\n",
    "-   [Writing Robust Tests for Data & Machine Learning Pipelines](https://eugeneyan.com/writing/testing-pipelines/)\n",
    "-   [Don't Mock Machine Learning Models In Unit Tests](https://eugeneyan.com/writing/unit-testing-ml/)\n",
    "-   [A Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "mystnb": {
   "number_source_lines": true
  },
  "source_map": [
   16
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}