{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169ed81e",
   "metadata": {},
   "source": [
    "# Stage 10. Continuous Integration, Deployment, Learning and Training (DevOps, DataOps, MLOps)\n",
    "\n",
    "[![Twitter Handle](https://img.shields.io/badge/Twitter-@gaohongnan-blue?style=social&logo=twitter)](https://twitter.com/gaohongnan)\n",
    "[![LinkedIn Profile](https://img.shields.io/badge/@gaohongnan-blue?style=social&logo=linkedin)](https://linkedin.com/in/gao-hongnan)\n",
    "[![GitHub Profile](https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&logo=github)](https://github.com/gao-hongnan)\n",
    "![Tag](https://img.shields.io/badge/Tag-Brain_Dump-red)\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    "```\n",
    "\n",
    "```{figure} ./assets/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-4-ml-automation-ci-cd.svg\n",
    "---\n",
    "name: mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-4-ml-automation-ci-cd-stage-10\n",
    "---\n",
    "\n",
    "CI/CD and automated ML pipeline.\n",
    "\n",
    "Image Credits: [Google - MLOps: Continuous delivery and automation pipelines in machine learning](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)\n",
    "```\n",
    "\n",
    "## Continuous Integration (CI)\n",
    "\n",
    "Continuous Integration (CI) is a software development practice that focuses on\n",
    "frequently integrating code changes from multiple developers into a shared\n",
    "repository. CI aims to detect integration issues early and ensure that the\n",
    "software remains in a releasable state at all times.\n",
    "\n",
    "A CI workflow refers to the series of steps and automated processes involved in\n",
    "the continuous integration of code changes. It typically involves building and\n",
    "testing the software, often in an automated and reproducible manner.\n",
    "\n",
    "The primary goal of a CI workflow is to identify any issues or conflicts that\n",
    "may arise when integrating code changes. By continuously integrating code,\n",
    "developers can catch and fix problems early, reducing the chances of introducing\n",
    "bugs or breaking existing functionality.\n",
    "\n",
    "CI workflows usually include steps such as code compilation, running tests,\n",
    "generating documentation, and deploying the application to test environments.\n",
    "These steps are often automated, triggered by events such as code pushes or pull\n",
    "requests.\n",
    "\n",
    "Popular CI tools like Jenkins, Travis CI, and GitHub Actions provide mechanisms\n",
    "to define and execute CI workflows. These tools integrate with version control\n",
    "systems and offer a range of features, including customizable build and test\n",
    "environments, notifications, and integration with other development tools.\n",
    "\n",
    "## Technical Debt is Beyond Bad Code\n",
    "\n",
    "First of all, one should move away from the **_prior_** that _technical debt_ is\n",
    "_equivalent_ to _bad code_[^stop_saying_technical_debt]. While this may be often\n",
    "true, **equating** technical debt to bad code is a _simplification_ that, if not\n",
    "addressed, can lead to _misunderstanding_ and _miscommunication_. If one shows\n",
    "up and spurs out the contrapositive of the above statement, to derive to the\n",
    "conclusion that _if one writes good code, then there is no technical debt_, and\n",
    "in turn, there's no need to **revisit**, **document**, **lint**, and **test**\n",
    "the code[^stop_saying_technical_debt], and even though logically valid, he will\n",
    "be in for a _rude awakening_.\n",
    "\n",
    "Notwithstanding the slightly _philosophical_ introduction, the _practical\n",
    "situations_ are in fact, no one writes perfect code, and even just having a\n",
    "small amount of \"bad code\" will accumulate, some may not be even _immediately\n",
    "obvious_. If we do not have an _assurance policy_ (read: **Continuous\n",
    "Integration/Continuous Deployment**) in place, then what we end up is a\n",
    "_codebase_ full of _technical debt_, and trust me, no developer wants to inherit\n",
    "such a _codebase_.\n",
    "\n",
    "On a more _serious_ note, the **broader implication** of _technical debt_ is\n",
    "that the application sitting on top of it is _unreliable_, _unstable_, and\n",
    "_insecure_, leading to _bugs_, _security vulnerabilities_, and _performance\n",
    "issues_. What's worse is if one ships this code to _production_, then the _cost_\n",
    "of _fixing_ the _bugs_ is _exponentially higher_ than if it was _fixed_ in the\n",
    "_development_ phase. Fortunately, any _competent tech organization_ will have a\n",
    "_CI/CD_ pipeline in place, and will go through various stages of _testing_ and\n",
    "_validation_ before shipping to _production_.\n",
    "\n",
    "Before we move on, we need to be **_crystal clear_** that **CI/CD** is not a\n",
    "**silver bullet** that will **_eradicate_** all _bugs_ and _technical debt_.\n",
    "After all, we often see code breaking in _production_, and the _reason_ for this\n",
    "is two folds:\n",
    "\n",
    "-   How you implement your CI/CD pipeline matters. Skipping certain stages such\n",
    "    as _type safety checks_ will inevitably lead to _bugs_ in dynamic languages\n",
    "    like _Python_.\n",
    "-   How you write your code matters - consider the case where your unit tests\n",
    "    are **_not robust_**, then it obviously will not catch the bugs that it is\n",
    "    supposed to catch.\n",
    "\n",
    "Even if you think you fulfill the above two, we quote the well known saying\n",
    "**_To err is human_**, to play at the fact that _bugs_ are _inevitable_, and\n",
    "that means there is no such thing as a 100% bug free codebase. The argument here\n",
    "is not to **_eradicate_** bugs, but to **_reduce_** them - _a numbers game_.\n",
    "\n",
    "## Lifecycle\n",
    "\n",
    "Insert [image]?\n",
    "\n",
    "## Phase 1. Planning\n",
    "\n",
    "The Planning stage involves defining what needs to be built or developed. It's a\n",
    "crucial phase where project managers, developers, and stakeholders come together\n",
    "to identify requirements, set goals, establish timelines, and plan the resources\n",
    "needed for the project. This stage often involves using project tracking tools\n",
    "and Agile methodologies like scrum or kanban to organize tasks, sprints, and\n",
    "priorities.\n",
    "\n",
    "Common tech stack includes:\n",
    "\n",
    "-   [Jira](https://www.atlassian.com/software/jira): A popular project\n",
    "    management tool that helps teams plan, track, and manage agile software\n",
    "    development projects.\n",
    "-   [Confluence](https://www.atlassian.com/software/confluence): A team\n",
    "    collaboration tool that helps teams create, share, and collaborate on\n",
    "    projects.\n",
    "\n",
    "## Phase 2. Development\n",
    "\n",
    "Coding or development is where the actual software creation takes place.\n",
    "Developers write code to implement the planned features and functionalities,\n",
    "adhering to coding standards and practices. **Version control systems**, such as\n",
    "Git, play an important role in this stage, enabling developers to collaborate on\n",
    "code, manage changes, and maintain a history of the project's development.\n",
    "\n",
    "### Set Up Main Directory in Integrated Development Environment (IDE)\n",
    "\n",
    "Let us assume that we are residing in our root folder `~/` and we want to create\n",
    "a new project called **yolo** in Microsoft Visual Studio Code, we can do as\n",
    "follows:\n",
    "\n",
    "```bash title=\"creating main directory\" linenums=\"1\"\n",
    "~/      $ mkdir yolo && cd yolo\n",
    "~/yolo  $ code .                 # (1)\n",
    "```\n",
    "\n",
    "If you are cloning a repository to your local folder **yolo**, you can also do:\n",
    "\n",
    "```bash title=\"cloning repository\" linenums=\"1\"\n",
    "~/yolo $ git clone git@github.com:<username>/<repo-name>.git .\n",
    "```\n",
    "\n",
    "where `.` means cloning to the current directory.\n",
    "\n",
    "### README, LICENSE and CONTRIBUTING\n",
    "\n",
    "#### README\n",
    "\n",
    "The `README.md` file serves as the front page of your repository. It should\n",
    "provide all the necessary information about the project, including:\n",
    "\n",
    "-   **Project Name and Description**: Clearly state what your project does and\n",
    "    why it exists.\n",
    "-   **Installation Instructions**: Provide a step-by-step guide on how to get\n",
    "    your project running on a user's local environment.\n",
    "-   **Usage Guide**: Explain how to use your project, including examples of\n",
    "    common use cases.\n",
    "-   **Contributing**: Link to your `CONTRIBUTING.md` file and invite others to\n",
    "    contribute to the project.\n",
    "-   **License**: Mention the type of license the project is under, with a link\n",
    "    to the full `LICENSE` file.\n",
    "-   **Contact Information**: Offer a way for users to ask questions or get in\n",
    "    touch.\n",
    "\n",
    "We can create a `README.md` file to describe the project using the following\n",
    "command:\n",
    "\n",
    "```bash title=\"README.md\" linenums=\"1\"\n",
    "~/yolo $ touch README.md\n",
    "```\n",
    "\n",
    "#### LICENSE\n",
    "\n",
    "The `LICENSE` file is critical as it defines how others can legally use, modify,\n",
    "and distribute your project. If you’re unsure which license to use,\n",
    "[choosealicense.com](https://choosealicense.com/) can help you decide.\n",
    "\n",
    "```bash\n",
    "~/yolo $ touch LICENSE\n",
    "```\n",
    "\n",
    "After creating the file, you should fill it with the text of the license you've\n",
    "chosen. This could be the MIT License, GNU General Public License (GPL), Apache\n",
    "License 2.0, etc.\n",
    "\n",
    "#### CONTRIBUTING\n",
    "\n",
    "`CONTRIBUTING.md` outlines guidelines for contributing to your project. This\n",
    "might include:\n",
    "\n",
    "-   **How to File an Issue**: Instructions for reporting bugs or suggesting\n",
    "    enhancements.\n",
    "-   **How to Submit a Pull Request (PR)**: Guidelines on the process for\n",
    "    submitting a PR, including coding standards, test instructions, etc.\n",
    "-   **Community and Behavioral Expectations**: Information on the code of\n",
    "    conduct and the expectations for community interactions.\n",
    "\n",
    "```bash\n",
    "~/yolo $ touch CONTRIBUTING.md\n",
    "```\n",
    "\n",
    "### Version Control\n",
    "\n",
    "[**Version control**](https://en.wikipedia.org/wiki/Version_control), such as\n",
    "[**Git**](https://git-scm.com/), are foundational to modern software development\n",
    "practices, including Continuous Integration and Continuous Deployment/Delivery\n",
    "(CI/CD). The premise to CI/CD is to enable developers to work on the same code\n",
    "base simultaneously, track every change, and automate the CI/CD processes such\n",
    "as triggering builds, tests, and deployments based on code commits and merges.\n",
    "\n",
    "#### Initial Configuration\n",
    "\n",
    "Before you start using Git, you should configure your global username and email\n",
    "associated with your commits. This information identifies the author of the\n",
    "changes and is important for collaboration.\n",
    "\n",
    "```bash\n",
    "git config --global user.name <your-name>\n",
    "git config --global user.email <your-email>\n",
    "```\n",
    "\n",
    "You should necessarily replace `<your-name>` and `<your-email>` with your actual\n",
    "name and email address. In particular, having the correct email address is\n",
    "important as it is used to link your commits to your GitHub account.\n",
    "\n",
    "#### Setting Up a New Repository\n",
    "\n",
    "If you're starting a new project in a local directory (e.g., `~/yolo`), you'll\n",
    "follow these steps to initialize it as a Git repository, stage your files, and\n",
    "make your first commit.\n",
    "\n",
    "1. **Create a `.gitignore` File**: This file tells Git which files or\n",
    "   directories to ignore in your project, like build directories or system\n",
    "   files.\n",
    "\n",
    "    ```bash\n",
    "    ~/yolo $ touch .gitignore\n",
    "    ```\n",
    "\n",
    "    Populate `.gitignore` with patterns to ignore. For example:\n",
    "\n",
    "    ```text\n",
    "    .DS_Store\n",
    "    __pycache__/\n",
    "    env/\n",
    "    ```\n",
    "\n",
    "    which can be done using the following command:\n",
    "\n",
    "    ```bash\n",
    "    ~/yolo $ cat > .abc <<EOF\n",
    "    .DS_Store\n",
    "    __pycache__/\n",
    "    env/\n",
    "    EOF\n",
    "    ```\n",
    "\n",
    "2. **Initialize the Repository**:\n",
    "\n",
    "    ```bash\n",
    "    ~/yolo $ git init\n",
    "    ```\n",
    "\n",
    "    This command creates a new Git repository locally.\n",
    "\n",
    "3. **Add Files to the Repository**:\n",
    "\n",
    "    ```bash\n",
    "    ~/yolo $ git add .\n",
    "    ```\n",
    "\n",
    "    This adds all files in the directory (except those listed in `.gitignore`)\n",
    "    to the staging area, preparing them for commit.\n",
    "\n",
    "4. **Commit the Changes**:\n",
    "\n",
    "    ```bash\n",
    "    ~/yolo $ git commit -m \"Initial commit\"\n",
    "    ```\n",
    "\n",
    "    This captures a snapshot of the project's currently staged changes.\n",
    "\n",
    "#### Connecting to a Remote Repository\n",
    "\n",
    "After initializing your local repository, the next step is to link it with a\n",
    "remote repository. This allows you to push your changes to a server, making\n",
    "collaboration and backup easier.\n",
    "\n",
    "5. **Add a Remote Repository** (If you've just initialized a local repo or if\n",
    "   it's not yet connected to a remote):\n",
    "\n",
    "    ```bash\n",
    "    ~/yolo $ git remote add origin <repo-url>\n",
    "    ```\n",
    "\n",
    "    Replace `<repo-url>` with your repository's URL, which you can obtain from\n",
    "    GitHub or another Git service such as GitLab or Bitbucket.\n",
    "\n",
    "6. **Securely Push to the Remote Using a Token** (Optional but recommended for\n",
    "   enhanced security):\n",
    "\n",
    "    Before pushing changes, especially when 2FA (Two Factor Authentication) is\n",
    "    enabled, you might need to use a token instead of a password.\n",
    "\n",
    "    ```bash\n",
    "    ~/yolo $ git remote set-url origin https://<token>@github.com/<username>/<repository>\n",
    "    ```\n",
    "\n",
    "    Replace `<token>`, `<username>`, and `<repository>` with your personal\n",
    "    access token, your GitHub username, and your repository name, respectively.\n",
    "\n",
    "7. **Push Your Changes**:\n",
    "\n",
    "    ```bash\n",
    "    ~/yolo $ git push -u origin main\n",
    "    ```\n",
    "\n",
    "    This command pushes your commits to the `main` branch of the remote\n",
    "    repository. The `-u` flag sets the upstream, making `origin main` the\n",
    "    default target for future pushes.\n",
    "\n",
    "#### Cloning an Existing Repository\n",
    "\n",
    "If you've already cloned an existing repository, many of these steps\n",
    "(specifically from initializing the repo to the first commit) are unnecessary\n",
    "since the repository comes pre-initialized and connected to its remote\n",
    "counterpart. You'd typically start by pulling the latest changes with `git pull`\n",
    "and then proceed with your work.\n",
    "\n",
    "#### Git Workflow\n",
    "\n",
    "It is important to establish a consistent Git workflow to ensure that changes\n",
    "are managed effectively and that the project's history is kept clean.\n",
    "\n",
    "You can read more about git workflows here:\n",
    "\n",
    "-   [Feature Branch Workflow](https://www.atlassian.com/git/tutorials/comparing-workflows/feature-branch-workflow)\n",
    "-   [Gitflow workflow](https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow)\n",
    "-   [Forking Workflow](https://www.atlassian.com/git/tutorials/comparing-workflows/forking-workflow)\n",
    "\n",
    "### Virtual Environment\n",
    "\n",
    "We can follow python's official documentation on\n",
    "[installing packages in a virtual environment using pip and venv](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/).\n",
    "In what follows, we would give a brief overview of the steps to set up a virtual\n",
    "environment for your project.\n",
    "\n",
    "#### Create Virtual Environment\n",
    "\n",
    "```bash\n",
    "~/yolo $ python3 -m venv <venv-name>\n",
    "```\n",
    "\n",
    "#### Activate Virtual Environment\n",
    "\n",
    "````{tab} Unix/macOS\n",
    "```bash\n",
    "~/yolo $ source <venv-name>/bin/activate\n",
    "```\n",
    "````\n",
    "\n",
    "````{tab} Windows\n",
    "```bash\n",
    "~/yolo $ <venv-name>\\Scripts\\activate\n",
    "```\n",
    "````\n",
    "\n",
    "#### Upgrade pip, setuptools and wheel\n",
    "\n",
    "```bash\n",
    "(venv) ~/yolo $ python3 -m pip install --upgrade pip setuptools wheel\n",
    "```\n",
    "\n",
    "### Managing Project Dependencies\n",
    "\n",
    "Once you've established a virtual environment for your project, the next step is\n",
    "to install the necessary libraries and packages. This process ensures that your\n",
    "project has all the tools required for development and execution.\n",
    "\n",
    "#### Managing Dependencies with `requirements.txt`\n",
    "\n",
    "For project dependency management, the use of a `requirements.txt` file is a\n",
    "common and straightforward approach. This file lists all the packages your\n",
    "project needs, allowing for easy installation with a single command.\n",
    "\n",
    "For simpler or moderately complex projects, a `requirements.txt` file is often\n",
    "sufficient. Create this file and list each dependency on a separate line,\n",
    "specifying exact versions to ensure consistency across different environments.\n",
    "\n",
    "1. **Create a `requirements.txt` file**:\n",
    "\n",
    "    ```bash\n",
    "    touch requirements.txt\n",
    "    ```\n",
    "\n",
    "2. **Populate `requirements.txt` with your project's dependencies**. For\n",
    "   example:\n",
    "\n",
    "    ```text\n",
    "    torch==1.10.0+cu113\n",
    "    torchaudio==0.10.0+cu113\n",
    "    torchvision==0.11.1+cu113\n",
    "    albumentations==1.1.0\n",
    "    matplotlib==3.2.2\n",
    "    pandas==1.3.1\n",
    "    torchinfo==1.7.1\n",
    "    tqdm==4.64.1\n",
    "    wandb==0.12.6\n",
    "    ```\n",
    "\n",
    "    You can directly edit `requirements.txt` in your favorite text editor to\n",
    "    include the above dependencies.\n",
    "\n",
    "3. **Install the dependencies** from your `requirements.txt` file:\n",
    "\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "Certain libraries, like PyTorch with CUDA support, may require downloading\n",
    "binaries from a specific URL due to additional dependencies. In such cases, you\n",
    "can use the `-f` option with `pip` to specify a custom repository for dependency\n",
    "links:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt -f https://download.pytorch.org/whl/torch_stable.html\n",
    "```\n",
    "\n",
    "This command tells `pip` to also look at the given URL for any packages listed\n",
    "in your `requirements.txt`, which is particularly useful for installing versions\n",
    "of libraries that require CUDA for GPU acceleration.\n",
    "\n",
    "You can also have a `requirements-dev.txt` file for development dependencies.\n",
    "\n",
    "```bash\n",
    "touch requirements-dev.txt\n",
    "```\n",
    "\n",
    "These dependencies are often used for testing, documentation, and other\n",
    "development-related tasks.\n",
    "\n",
    "#### Managing Dependencies with `pyproject.toml`\n",
    "\n",
    "`pyproject.toml` is a configuration file introduced in\n",
    "[PEP 518](https://www.python.org/dev/peps/pep-0518/) as a standardized way for\n",
    "Python projects to manage project settings and dependencies. It aims to replace\n",
    "the traditional `setup.py` and `requirements.txt` files with a single, unified\n",
    "file that can handle a project's build system requirements, dependencies, and\n",
    "other configurations in a standardized format.\n",
    "\n",
    "-   **Unified Configuration**: `pyproject.toml` consolidates various tool\n",
    "    configurations into one file, making project setups more straightforward and\n",
    "    reducing the number of files at the project root.\n",
    "-   **Dependency Management**: It can specify both direct project dependencies\n",
    "    and development dependencies, similar to `requirements.txt` and\n",
    "    `requirements-dev.txt`. Tools like `pip` can read `pyproject.toml` to\n",
    "    install the necessary packages.\n",
    "-   **Build System Requirements**: It explicitly declares the build system\n",
    "    requirements, ensuring the correct tools are present before the build\n",
    "    process begins. This is particularly important for projects that need to\n",
    "    compile native extensions.\n",
    "-   **Tool Configuration**: Many Python tools (e.g., `black`, `flake8`,\n",
    "    `pytest`) now support reading configuration options from `pyproject.toml`,\n",
    "    allowing developers to centralize their configurations.\n",
    "\n",
    "```toml\n",
    "[build-system]\n",
    "requires = [\"setuptools\", \"wheel\"]\n",
    "build-backend = \"setuptools.build_meta\"\n",
    "\n",
    "[project]\n",
    "name = \"example_project\"\n",
    "version = \"0.1.0\"\n",
    "description = \"An example project\"\n",
    "authors = [{name = \"Your Name\", email = \"you@example.com\"}]\n",
    "dependencies = [\n",
    "    \"requests>=2.24\",\n",
    "    \"numpy>=1.19\"\n",
    "]\n",
    "optional-dependencies = {\n",
    "    \"dev\" = [\"pytest>=6.0\", \"black\", \"flake8\"]\n",
    "}\n",
    "\n",
    "[tool.black]\n",
    "line-length = 88\n",
    "target-version = ['py38']\n",
    "\n",
    "[tool.pytest]\n",
    "minversion = \"6.0\"\n",
    "addopts = \"-ra -q\"\n",
    "```\n",
    "\n",
    "Now if you want to install the dependencies, you can do so with:\n",
    "\n",
    "```bash\n",
    "pip install .\n",
    "```\n",
    "\n",
    "and for development dependencies:\n",
    "\n",
    "```bash\n",
    "pip install .[dev]\n",
    "```\n",
    "\n",
    "To this end, you should see the following directory structure:\n",
    "\n",
    "```text title=\"main directory tree\" linenums=\"1\" hl_lines=\"10 11 12 13 14 15\"\n",
    ".\n",
    "├── CONTRIBUTING.md\n",
    "├── LICENSE\n",
    "├── README.md\n",
    "├── pyproject.toml\n",
    "├── requirements.txt\n",
    "├── requirements-dev.txt\n",
    "└── venv\n",
    "    ├── bin\n",
    "    ├── include\n",
    "    ├── lib\n",
    "    ├── pyvenv.cfg\n",
    "    └── share\n",
    "```\n",
    "\n",
    "You can find more information on writing your\n",
    "[`pyproject.toml` file here](https://packaging.python.org/en/latest/guides/writing-pyproject-toml/).\n",
    "\n",
    "#### Pinning DevOps Tool Versions\n",
    "\n",
    "In DevOps, particularly in continuous integration (CI) environments, pinning\n",
    "exact versions of tools like `pytest`, `mypy`, and other linting tools is\n",
    "important. Here are the key reasons:\n",
    "\n",
    "1. **Reproducibility**: Pinning specific versions ensures that the development,\n",
    "   testing, and production environments are consistent. This means that code\n",
    "   will be tested against the same set of dependencies it was developed with,\n",
    "   reducing the \"it works on my machine\" problem.\n",
    "\n",
    "2. **Stability**: Updates in these tools can introduce changes in their behavior\n",
    "   or new rules that might break the build process. By pinning versions, you\n",
    "   control when to upgrade and prepare for any necessary changes in your\n",
    "   codebase, rather than being forced to deal with unexpected issues from\n",
    "   automatic updates.\n",
    "\n",
    "Tools like `black`, `isort`, `mypy`, and `pylint` are particularly important to\n",
    "pin because they directly affect code quality and consistency. Changes in their\n",
    "behavior due to updates can lead to new linting errors or formatting changes\n",
    "that could disrupt development workflows.\n",
    "\n",
    "```{prf:example} Pinning Pylint Version\n",
    ":label: cicd-concept-pinning-pylint\n",
    "\n",
    "Consider the Python linting tool`pylint`. It's known for its thoroughness in\n",
    "checking code quality and conformity to coding standards. However, `pylint` is\n",
    "also frequently updated, with new releases potentially introducing new checks or\n",
    "modifying existing ones.\n",
    "\n",
    "Suppose your project is using `pylint` version 2.6.0. In this version, your\n",
    "codebase passes all linting checks, ensuring a certain level of code quality and\n",
    "consistency. Now, imagine `pylint` releases a new version, 2.7.0, which includes\n",
    "a new check for a particular coding pattern (e.g., enforcing more stringent\n",
    "rules on string formatting or variable naming).\n",
    "\n",
    "Consequently, if you _don't_ pin the `pylint` version, the next time you run\n",
    "an installation (e.g., `pip install -r requirements.txt` in local or remote),\n",
    "`pylint` has a good chance of being updated to version 2.7.0. This update could\n",
    "trigger new linting errors in your codebase, even though the code itself hasn't\n",
    "changed. This situation can be particularly disruptive in a CI/CD environment,\n",
    "where a previously passing build now fails due to new linting errors.\n",
    "```\n",
    "\n",
    "### Local Pre-Commit Checks (Local Continuous Integration)\n",
    "\n",
    "Consider continuous integration (CI) as a practice of merging all developers'\n",
    "working copies to a shared mainline several times a day. Each integration is\n",
    "verified by an automated build (including linting, code smell, type checks, unit\n",
    "tests etc) to detect integration errors as quickly as possible. This build can\n",
    "be triggered easily by modern version control systems like Git through a simple\n",
    "push to the repository. Tools like GitHub Actions, a CI/CD feature within\n",
    "GitHub, play the role in facilitating these practices.\n",
    "\n",
    "As we will continuously emphasize, to maximize the effectiveness of tools like\n",
    "Jenkins and GitHub Actions, it's crucial to maintain **consistency** and\n",
    "**uniformity** between the local development environment and the CI/CD pipeline.\n",
    "This alignment ensures that the software builds, tests, and deploys in an\n",
    "identical manner, both locally and in the CI/CD environment. Achieving this\n",
    "uniformity often involves the use of containerization tools like Docker, which\n",
    "can encapsulate the application and its dependencies in a container that runs\n",
    "consistently across different computing environments. By doing so, developers\n",
    "can minimize the 'it works on my machine' syndrome, a common challenge in\n",
    "software development, and foster a more collaborative and productive development\n",
    "culture. Moreover, it is also common to see developers get a \"shock\" when their\n",
    "build failed in the remote CI/CD pipeline, which could have been easily detected\n",
    "locally _**if and only if**_ they had run the **same** checks locally. There are\n",
    "some commercial tools that may not be able to same checks locally, but for\n",
    "open-source tools, it is a good practice to run the same checks locally.\n",
    "\n",
    "Some developers will \"forget\" to run the same checks locally, and this is where\n",
    "[**pre-commit hooks**](https://pre-commit.com/) come into play. Pre-commit hooks\n",
    "are scripts that run before a commit is made to the version control system.\n",
    "\n",
    "#### Guard Rails\n",
    "\n",
    "As the name suggests, guard rails are a set of rules and guidelines that help\n",
    "developers stay on track and avoid common security, performance, and\n",
    "maintainability pitfalls. These guard rails can be implemented as pre-commit\n",
    "hooks, which are scripts that run before a commit is made to the version control\n",
    "system.\n",
    "\n",
    "-   [Bandit](https://bandit.readthedocs.io/en/latest/config.html) is a tool\n",
    "    designed to find common security issues in Python code. To install Bandit,\n",
    "    run:\n",
    "\n",
    "    ```bash\n",
    "    pip install -U bandit\n",
    "    ```\n",
    "\n",
    "    and you can place configurations of Bandit in a `.bandit` file. But more\n",
    "    commonly, we put in `pyproject.toml` file for unification.\n",
    "\n",
    "    ```toml\n",
    "    # FILE: pyproject.toml\n",
    "    [tool.bandit]\n",
    "    exclude_dirs = [\"tests\", \"path/to/file\"]\n",
    "    tests = [\"B201\", \"B301\"]\n",
    "    skips = [\"B101\", \"B601\"]\n",
    "    ```\n",
    "\n",
    "-   [`detect-secrets`](https://github.com/Yelp/detect-secrets/tree/master) is a\n",
    "    tool that can be used to prevent secrets from being committed to your\n",
    "    repository. It can be installed using pip:\n",
    "\n",
    "    ```bash\n",
    "    pip install -U detect-secrets\n",
    "    ```\n",
    "\n",
    "    You can find more information in the\n",
    "    [usage section](https://github.com/Yelp/detect-secrets/tree/master). People\n",
    "    commonly place this as a hook in the\n",
    "    [`.pre-commit-config.yaml`](https://github.com/Yelp/detect-secrets/blob/master/.pre-commit-hooks.yaml)\n",
    "    file.\n",
    "\n",
    "-   [Safety](https://github.com/pyupio/safety) is a tool that checks your\n",
    "    dependencies for known security vulnerabilities. You can draw parallels to\n",
    "    Nexus IQ, which is a commercial tool that does the same thing.\n",
    "\n",
    "There are many more guard rails that can be implemented as pre-commit hooks, we\n",
    "cite\n",
    "[Welcome to pre-commit heaven - Marvelous MLOps Substack](https://marvelousmlops.substack.com/i/130911126/guard-rails)\n",
    "as a good reference below:\n",
    "\n",
    "```yaml\n",
    "repos:\n",
    "    - repo: https://github.com/pre-commit/pre-commit-hooks\n",
    "      rev: v4.3.0\n",
    "      hooks:\n",
    "          - id: check-ast\n",
    "          - id: check-added-large-files\n",
    "          - id: check-json\n",
    "          - id: check-toml\n",
    "          - id: check-yaml\n",
    "          - id: check-shebang-scripts-are-executable\n",
    "          - id: detect-secrets\n",
    "    - repo: https://github.com/PyCQA/bandit\n",
    "      rev: 1.7.4\n",
    "      hooks:\n",
    "          - id: bandit\n",
    "```\n",
    "\n",
    "#### Styling, Formatting, and Linting\n",
    "\n",
    "Guido Van Rossum, the author of Python, aptly stated, \"Code is read more often\n",
    "than it is written.\" This principle underscores the necessity of both clear\n",
    "documentation and easy readability in coding. Adherence to style and formatting\n",
    "conventions, particularly those based on\n",
    "[PEP8](https://peps.python.org/pep-0008/), plays a vital role in achieving this\n",
    "goal. Different teams may adopt various conventions, but the key lies in\n",
    "consistent application and the use of automated pipelines to maintain this\n",
    "consistency. For instance, standardizing line lengths simplifies code review\n",
    "processes, making discussions about specific sections more straightforward. In\n",
    "this context, **linting** and **formating** emerge as critical tools for\n",
    "maintaining high code quality. Linting, the process of analyzing code for\n",
    "potential errors, and formatting, which ensures a uniform appearance,\n",
    "collectively boost **readability** and **maintainability**. A well-styled\n",
    "codebase not only looks professional but also reduces bugs and eases\n",
    "**integration** and **code reviews**. These practices, when ingrained as an\n",
    "**intuition** among developers, lead to more robust and efficient software\n",
    "development.\n",
    "\n",
    "This part is probably what most people are familiar with, we list some common\n",
    "tools for styling, formatting, and linting below (cited from\n",
    "[Welcome to pre-commit heaven - Marvelous MLOps Substack](https://marvelousmlops.substack.com/i/130911126)):\n",
    "\n",
    "```yaml\n",
    "repos:\n",
    "    - repo: https://github.com/pre-commit/pre-commit-hooks\n",
    "      rev: v4.3.0\n",
    "      hooks:\n",
    "          - id: end-of-file-fixer\n",
    "          - id: mixed-line-ending\n",
    "          - id: trailing-whitespace\n",
    "    - repo: https://github.com/psf/black\n",
    "      rev: 22.10.0\n",
    "      hooks:\n",
    "          - id: black\n",
    "            language_version: python3.11\n",
    "            args:\n",
    "                - --line-length=128\n",
    "          - id: black-jupyter\n",
    "            language_version: python3.11\n",
    "    - repo: https://github.com/pycqa/isort\n",
    "      rev: 5.11.5\n",
    "      hooks:\n",
    "          - id: isort\n",
    "            args: [\"--profile\", \"black\"]\n",
    "    - repo: https://github.com/pycqa/flake8\n",
    "      rev: 5.0.4\n",
    "      hooks:\n",
    "          - id: flake8\n",
    "            args:\n",
    "                - \"--max-line-length=128\"\n",
    "            additional_dependencies:\n",
    "                - flake8-bugbear\n",
    "                - flake8-comprehensions\n",
    "                - flake8-simplify\n",
    "    - repo: https://github.com/pre-commit/mirrors-mypy\n",
    "      rev: v0.991\n",
    "      hooks:\n",
    "          - id: mypy\n",
    "```\n",
    "\n",
    "#### Tests\n",
    "\n",
    "Testing is a critical part of the software development process. It helps ensure\n",
    "that the code behaves as expected and that changes don't introduce new bugs or\n",
    "break existing functionality. Unit tests, in particular, focus on testing\n",
    "individual components or units of code in isolation. They help catch bugs early\n",
    "and provide a safety net for refactoring and making changes with confidence.\n",
    "\n",
    "Usually, unit tests are run as part of _pre-merge checks_ to ensure that the\n",
    "changes being merged don't break existing functionality where as _post-merge\n",
    "checks_ can entail more comprehensive tests such as integration tests,\n",
    "end-to-end tests etc.\n",
    "\n",
    "Set up `pytest` for testing codes.\n",
    "\n",
    "```bash title=\"Install pytest\" linenums=\"1\"\n",
    "pytest==6.0.2\n",
    "pytest-cov==2.10.1\n",
    "```\n",
    "\n",
    "In general, **Pytest** expects our testing codes to be grouped under a folder\n",
    "called `tests`. We can configure in our `pyproject.toml` file to override this\n",
    "if we wish to ask `pytest` to check from a different directory. After specifying\n",
    "the folder holding the test codes, `pytest` will then look for python scripts\n",
    "starting with `tests_*.py`; we can also change the extensions accordingly if you\n",
    "want `pytest` to look for other kinds of files\n",
    "(extensions)[^testing_made_with_ml].\n",
    "\n",
    "```bash title=\"pyproject.toml\" linenums=\"1\"\n",
    "# Pytest\n",
    "[tool.pytest.ini_options]\n",
    "testpaths = [\"tests\"]\n",
    "python_files = \"test_*.py\"\n",
    "```\n",
    "\n",
    "```{admonition} References\n",
    ":class: seealso\n",
    "\n",
    "- [Chapter 5. Testing - Py-Pkgs](https://py-pkgs.org/05-testing)\n",
    "```\n",
    "\n",
    "#### Git Sanity Checks\n",
    "\n",
    "Git sanity checks are a set of rules and guidelines that help developers avoid\n",
    "common mistakes and pitfalls when working with Git. More specifically, we have\n",
    "the below:\n",
    "\n",
    "-   **commitizen**: This hook encourages developers to use the Commitizen tool\n",
    "    for formatting commit messages. Commitizen standardizes commit messages\n",
    "    based on predefined conventions, making the project's commit history more\n",
    "    readable and navigable. Standardized messages facilitate understanding the\n",
    "    purpose of each change, aiding in debugging and project management (though I\n",
    "    rarely need to sieve through commit messages) but this is good practice\n",
    "    (imagine all your commit message is \"111\" or \"fix bug\" or \"update\").\n",
    "\n",
    "-   **commitizen-branch**: A specific use of the Commitizen validation that can\n",
    "    be configured to work at different stages, such as during branch pushes.\n",
    "    This ensures that commits pushed to branches also follow the standardized\n",
    "    format, maintaining consistency not just locally but across the repository.\n",
    "\n",
    "-   **check-merge-conflict**: This hook checks for merge conflict markers (e.g.,\n",
    "    `<<<<<<<`, `=======`, `>>>>>>>`). These markers indicate unresolved merge\n",
    "    conflicts, which should not be committed to the repository as they can break\n",
    "    the codebase. Preventing such commits helps maintain the integrity and\n",
    "    operability of the project.\n",
    "\n",
    "-   **no-commit-to-branch**: It prevents direct commits to specific branches\n",
    "    (commonly the main or master branch). This practice encourages the use of\n",
    "    feature branches and pull requests, fostering code reviews and discussions\n",
    "    before changes are merged into the main codebase. It's a way to ensure that\n",
    "    changes are vetted and tested, reducing the risk of disruptions in the main\n",
    "    development line.\n",
    "\n",
    "Again, citing from\n",
    "[Welcome to pre-commit heaven - Marvelous MLOps Substack](https://marvelousmlops.substack.com/i/130911126):\n",
    "\n",
    "```yaml\n",
    "repos:\n",
    "  - repo: https://github.com/commitizen-tools/commitizen\n",
    "      rev: v2.35.0\n",
    "      hooks:\n",
    "        - id: commitizen\n",
    "        - id: commitizen-branch\n",
    "          stages: [push]\n",
    "  - repo: https://github.com/pre-commit/pre-commit-hooks\n",
    "      rev: v4.3.0\n",
    "      hooks:\n",
    "        - id: check-merge-conflict\n",
    "        - id: no-commit-to-branch\n",
    "```\n",
    "\n",
    "#### Code Correctors\n",
    "\n",
    "This is entering \"riskier\" territory, as code correctors can automatically\n",
    "correct your code.\n",
    "\n",
    "-   `pyupgrade` is a tool that automatically upgrades Python syntax to the\n",
    "    latest version that's supported by the Python interpreter specified. It\n",
    "    takes existing Python code and refactors it where possible to use newer\n",
    "    syntax features that are more efficient, readable, or otherwise preferred.\n",
    "    For instance, when targeting Python 3.9 and above, it might convert\n",
    "    old-style string formatting to f-strings, use newer Python 3.9 dictionary\n",
    "    merge operators, and more.\n",
    "\n",
    "-   `yesqa` automatically removes unnecessary `# noqa` comments from the code.\n",
    "    `# noqa` is used to tell linters to ignore specific lines of code that would\n",
    "    otherwise raise warnings or errors. However, over time, as the code evolves,\n",
    "    some of these `# noqa` comments might no longer be necessary because the\n",
    "    issues have been resolved or the code has changed.\n",
    "\n",
    "#### Setting Up Pre-Commit\n",
    "\n",
    "1.  **Install Pre-Commit**:\n",
    "\n",
    "    ```bash title=\"install pre-commit\" linenums=\"1\"\n",
    "    ~/yolo (venv) $ pip install -U pre-commit\n",
    "    ~/yolo (venv) $ pre-commit install\n",
    "    ```\n",
    "\n",
    "2.  **Create a `.pre-commit-config.yaml` File**:\n",
    "\n",
    "    ```bash title=\"create pre-commit-config.yaml\" linenums=\"1\"\n",
    "    ~/yolo (venv) $ touch .pre-commit-config.yaml\n",
    "    ```\n",
    "\n",
    "3.  **Populate `.pre-commit-config.yaml` with the desired hooks**:\n",
    "\n",
    "    Sample `.pre-commit-config.yaml` file:\n",
    "\n",
    "    ```yaml title=\".pre-commit-config.yaml\" linenums=\"1\"\n",
    "    repos:\n",
    "    - repo: https://github.com/pre-commit/pre-commit-hooks\n",
    "        rev: v4.5.0\n",
    "        hooks:\n",
    "        - id: check-added-large-files\n",
    "        - id: check-ast\n",
    "        - id: check-builtin-literals\n",
    "        - id: check-case-conflict\n",
    "        - id: check-docstring-first\n",
    "        - id: check-executables-have-shebangs\n",
    "        - id: check-json\n",
    "        - id: check-shebang-scripts-are-executable\n",
    "        - id: check-symlinks\n",
    "        - id: check-toml\n",
    "        - id: check-vcs-permalinks\n",
    "        - id: check-xml\n",
    "        - id: check-yaml\n",
    "        - id: debug-statements\n",
    "        - id: destroyed-symlinks\n",
    "        - id: mixed-line-ending\n",
    "        - id: trailing-whitespace\n",
    "    ```\n",
    "\n",
    "4.  **Run Pre-Commit**:\n",
    "\n",
    "    Sample command to run pre-commit on all files:\n",
    "\n",
    "    ```bash title=\"run pre-commit\" linenums=\"1\"\n",
    "    ~/yolo (venv) $ pre-commit run --all-files\n",
    "    ```\n",
    "\n",
    "    This command runs all the hooks specified in the `.pre-commit-config.yaml`\n",
    "    file on all files in the repository.\n",
    "\n",
    "### Documentation\n",
    "\n",
    "Documentation is severely underlooked in many organizations. However,\n",
    "documentation is a fundamental part of the development process as it provides\n",
    "guidance for users and developers through carefully crafted explanations,\n",
    "cookbooks, tutorials and API references.\n",
    "\n",
    "The documentation should necessarily be part of the CI/CD pipeline, and\n",
    "everytime you update the documentation, it should be automatically built and\n",
    "deployed to the documentation hosting platform.\n",
    "\n",
    "-   [Sphinx](https://www.sphinx-doc.org/en/master/): A tool that makes it easy\n",
    "    to create intelligent and beautiful documentation for Python projects. It is\n",
    "    commonly used to document Python libraries and applications, but it can also\n",
    "    be used to document other types of projects.\n",
    "-   [MkDocs](https://www.mkdocs.org/): A fast, simple, and downright gorgeous\n",
    "    static site generator that's geared towards building project documentation.\n",
    "-   [Sphinx API Documentation](https://www.sphinx-doc.org/en/master/man/sphinx-apidoc.html):\n",
    "    A tool that automatically generates API documentation from your source code.\n",
    "    It's commonly used in conjunction with Sphinx to create API references for\n",
    "    Python projects.\n",
    "\n",
    "```{admonition} References\n",
    ":class: seealso\n",
    "\n",
    "-   [Chapter 6. Documentation - Py-Pkgs](https://py-pkgs.org/06-documentation)\n",
    "-   [Hypermodern Python Chapter 5: Documentation - Claudio Jolowicz](https://cjolowicz.github.io/posts/hypermodern-python-05-documentation/)\n",
    "```\n",
    "\n",
    "### A Word on Type Safety Checks in Python\n",
    "\n",
    "#### Python is Strongly and Dynamically Typed\n",
    "\n",
    "First of all, one should be clear that Python is considered a _strongly_ and\n",
    "_dynamically_ typed language[^python_strongly_and_dynamic_typing].\n",
    "\n",
    "_Dynamic_ because runtime objects have a type, as opposed to the variable having\n",
    "a type in statically typed languages. For example, consider a variable\n",
    "`str_or_int` in python:\n",
    "\n",
    "```python\n",
    "str_or_int: str | int = \"hello\"\n",
    "```\n",
    "\n",
    "and later in the code, we can reassign it to an integer:\n",
    "\n",
    "```python\n",
    "str_or_int: str | int = 42\n",
    "```\n",
    "\n",
    "This is not possible in statically typed languages, where the type of a variable\n",
    "is fixed at compile time.\n",
    "\n",
    "_Strongly_ because Python does not allow unreasonable arbitrary type\n",
    "conversions/coercions. You are not allowed to concatenate a string with an\n",
    "integer, for example:\n",
    "\n",
    "```python\n",
    "\"hello\" + 42\n",
    "```\n",
    "\n",
    "will raise a `TypeError` exception.\n",
    "\n",
    "#### MyPy: Static Type Checking\n",
    "\n",
    "Static type checking is the process of verifying the type safety of a program\n",
    "based on analysis of some source code. `mypy` is probably the most recognized\n",
    "static type checker, in which it analyzes your code without executing it,\n",
    "identifying type mismatches based on the type hints you've provided. mypy is\n",
    "most valuable during the development phase, helping catch type-related errors\n",
    "before runtime.\n",
    "\n",
    "Consider the following very simply example:\n",
    "\n",
    "```python\n",
    "def concatenate(a: str, b: str) -> str:\n",
    "    return a + b\n",
    "```\n",
    "\n",
    "Here, we've used type hints to specify that `a` and `b` are strings, and that\n",
    "the function returns a string. A subtle bug can be introduced just for the sake\n",
    "of illustration:\n",
    "\n",
    "```python\n",
    "concatenate(\"hello\", 42) # mypy will catch this\n",
    "```\n",
    "\n",
    "This will raise a `TypeError` exception at runtime, but mypy will catch this\n",
    "before the code is executed. One would argue that this is a trivial example,\n",
    "since runtime will catch this error. However, in a larger codebase, you may not\n",
    "have the luxury of running the entire codebase to catch such errors.\n",
    "Furthermore, there are even more _silent_ errors that runtime may not catch due\n",
    "to a certain combination that does not immediately raise an exception.\n",
    "\n",
    "#### TypeGuard: Runtime Type Checking\n",
    "\n",
    "Unlike `mypy`, `typeguard` operates at runtime. In other words, `mypy` just tell\n",
    "you \"this is wrong\" but `typeguard` will actually raise an error at runtime.\n",
    "Consequently, we can view `typeguard` as a runtime type checker and\n",
    "complementary to `mypy`.\n",
    "\n",
    "`typeguard` is particularly useful in testing scenarios or in development\n",
    "environments where you want to ensure that type annotations are being respected\n",
    "at runtime. It can catch type errors that static analysis might not catch due to\n",
    "the dynamic nature of Python or when dealing with external systems that might\n",
    "not adhere to the expected types.\n",
    "\n",
    "To use TypeGuard, you typically employ it through decorators or with type\n",
    "checking in unit tests.\n",
    "\n",
    "```python\n",
    "from typeguard import typechecked\n",
    "\n",
    "@typechecked\n",
    "def greet(name: str) -> str:\n",
    "    return 'Hello ' + name\n",
    "\n",
    "try:\n",
    "    greet(42)\n",
    "except TypeError as e:\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "### Release and Versioning\n",
    "\n",
    "```{admonition} References\n",
    ":class: seealso\n",
    "\n",
    "-   [Chapter 7. Releasing and versioning - Py-Pkgs](https://py-pkgs.org/07-releasing-versioning)\n",
    "```\n",
    "\n",
    "## Phase 3. Build\n",
    "\n",
    "Considering we have came so far in the development phase, where we have set up\n",
    "our main directory, version control, virtual environment, project dependencies,\n",
    "local pre-commit checks, documentation, and release and versioning, we can now\n",
    "touch on the build phase - where _**automation**_ is the key. We need a way to\n",
    "automate whatever we have done in the development phase, and feedback whether\n",
    "the local build is actually \"really\" successful or not to every team member.\n",
    "\n",
    "1. Dockerize the application. Production identical environment.\n",
    "2. Infrastructure as Code (IaC) for cloud deployment.\n",
    "3. Container orchestration for scaling and managing containers.\n",
    "\n",
    "### Pre-Merge Checks\n",
    "\n",
    "Commit checks is to ensure the following:\n",
    "\n",
    "-   The requirements can be installed on various OS and python versions.\n",
    "-   Ensure code quality and adherence to PEP8 (or other coding standards).\n",
    "-   Ensure tests are passed.\n",
    "\n",
    "```yaml title=\"lint_test.yaml\" linenums=\"1\"\n",
    "name: Commit Checks # (1)\n",
    "on: [push, pull_request] # (2)\n",
    "\n",
    "jobs: # (3)\n",
    "    check_code: # (4)\n",
    "        runs-on: ${{ matrix.os }} # (5)\n",
    "        strategy: # (6)\n",
    "            fail-fast: false # (7)\n",
    "            matrix: # (8)\n",
    "                os: [ubuntu-latest, windows-latest] # (9)\n",
    "                python-version: [3.8, 3.9] # (10)\n",
    "        steps: # (11)\n",
    "            - name: Checkout code # (12)\n",
    "              uses: actions/checkout@v2 # (13)\n",
    "            - name: Setup Python # (14)\n",
    "              uses: actions/setup-python@v2 # (15)\n",
    "              with: # (16)\n",
    "                  python-version: ${{ matrix.python-version }} # (17)\n",
    "                  cache: \"pip\" # (18)\n",
    "            - name: Install dependencies # (19)\n",
    "              run: | # (20)\n",
    "                  python -m pip install --upgrade pip setuptools wheel\n",
    "                  pip install -e .\n",
    "            - name: Run Black Formatter # (21)\n",
    "              run: black --check . # (22)\n",
    "            # - name: Run flake8 Linter\n",
    "            #   run: flake8 . # look at my pyproject.toml file and see if there is a flake8 section, if so, run flake8 on the files in the flake8 section\n",
    "            - name: Run Pytest # (23)\n",
    "              run: python -m coverage run --source=custom_hn_exercise_counter -m\n",
    "                  pytest && python -m coverage report # (24)\n",
    "```\n",
    "\n",
    "1.  This is the name that will show up under the **Actions** tab in GitHub.\n",
    "    Typically, we should name it appropriately like how we indicate the subject\n",
    "    of an email.\n",
    "2.  The list here indicates the\n",
    "    [workflow will be triggered](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#pull_request)\n",
    "    whenever someone directly pushes or submits a PR to the main branch.\n",
    "3.  Once an event is triggered, a set of **jobs** will run on a\n",
    "    [runner](https://github.com/actions/runner). In our example, we will run a\n",
    "    job called `check_code` on a runner to check for formatting and linting\n",
    "    errors as well as run the `pytest` tests.\n",
    "4.  This is the name of the job that will run on the runner.\n",
    "5.  We specify which OS system we want the code to be run on. We can simply say\n",
    "    `ubuntu-latest` or `windows-latest` if we just want the code to be tested on\n",
    "    a single OS. However, here we want to check if it works on both Ubuntu and\n",
    "    Windows, and hence we define `${{ matrix.os }}` where `matrix.os` is\n",
    "    `[ubuntu-latest, windows-latest]`. A cartesian product is created for us and\n",
    "    the job will run on both OSs.\n",
    "6.  Strategy is a way to control how the jobs are run. In our example, we want\n",
    "    the job to run as fast as possible, so we set `strategy.fail-fast` to\n",
    "    `false`.\n",
    "7.  If one job fails, then the whole workflow will fail, this is not ideal if we\n",
    "    want to test multiple jobs, we can set `fail-fast` to `false` to allow the\n",
    "    workflow to continue running on the remaining jobs.\n",
    "8.  Matrix is a way to control how the jobs are run. In our example, we want to\n",
    "    run the job on both Python 3.8 and 3.9, so we set `matrix.python-version` to\n",
    "    `[3.8, 3.9]`.\n",
    "9.  This list consists of the OS that the job will run on in cartesian product.\n",
    "10. This is the python version that the job will run on in cartesian product. We\n",
    "    can simply say `3.8` or `3.9` if we just want the code to be tested on a\n",
    "    single python version. However, here we want to check if it works on both\n",
    "    python 3.8 and python 3.9, and hence we define\n",
    "    `${{ matrix.python-version }}` where `matrix.python-version` is\n",
    "    `[3.8, 3.9]`. A cartesian product is created for us and the job will run on\n",
    "    both python versions.\n",
    "11. This is a list of dictionaries that defines the steps that will be run.\n",
    "12. Name is the name of the step that will be run.\n",
    "13. It is important to specify `@v2` as if unspecified, then the workflow will\n",
    "    use the latest version from actions/checkout template, potentially causing\n",
    "    libraries to break. The idea here is like your `requirements.txt` idea, if\n",
    "    different versions then will break.\n",
    "14. Setup Python is a step that will be run before the job.\n",
    "15. Same as above, we specify `@v2` as if unspecified, then the workflow will\n",
    "    use the latest version from actions/setup-python template, potentially\n",
    "    causing libraries to break.\n",
    "16. With is a way to pass parameters to the step.\n",
    "17. This is the python version that the job will run on in cartesian product and\n",
    "    if run 1 python version then can define as just say 3.7\n",
    "18. Cache is a way to control how the libraries are installed.\n",
    "19. Install dependencies is a step that will be run before the job.\n",
    "20. `|` is multi-line string that runs the below code, which sets up the\n",
    "    libraries from `setup.py` file.\n",
    "21. Run Black Formatter is a step that will be run before the job.\n",
    "22. Runs `black` with configurations from `pyproject.toml` file.\n",
    "23. Run Pytest is a step that will be run before the job.\n",
    "24. Runs pytest, note that I specified `python -m` to resolve PATH issues.\n",
    "\n",
    "### Orchestration\n",
    "\n",
    "Here you would have many github actions/jenkins workflows that orchestrate the\n",
    "build, test, and release of your application. You might also have another\n",
    "workflow to deploy your data pipeline to say a container registry like AWS ECR\n",
    "or Google GCR.\n",
    "\n",
    "### Infrastructure as Code (IaC)\n",
    "\n",
    "You can also define templates for your infrastructure as code (IaC) in\n",
    "[Terraform](https://www.terraform.io/docs/language/index.html).\n",
    "\n",
    "## Phase 4. Scan and Test\n",
    "\n",
    "First and foremost, this piece of article is not to teach you **_how_** to write\n",
    "tests, because that would take a whole book to cover. Writing tests is \"easy\",\n",
    "but writing **_good tests_** is an art, and difficult to master. I want to set\n",
    "the stage for you to understand the importance of testing, and what types of\n",
    "testing are there, along with some intuition.\n",
    "\n",
    "### The Testing Pyramid\n",
    "\n",
    "The testing pyramid is a visual metaphor that illustrates the ideal distribution\n",
    "of testing methodologies from the base up: starting with unit tests, followed by\n",
    "integration tests, then system testing, and capped off with end-to-end (E2E)\n",
    "tests. This structure emphasizes the importance of a bottom-up approach to\n",
    "testing, where the majority of tests are low-level, quick, and automated unit\n",
    "tests, progressing to fewer, more comprehensive, and often manual tests at the\n",
    "top.\n",
    "\n",
    "-   Unit Tests\n",
    "-   Integration Tests\n",
    "-   System Tests\n",
    "-   End-to-End Tests\n",
    "\n",
    "```{figure} ./assets/pyramid-progression.jpg\n",
    "---\n",
    "name: devops-continuous-integration-testing-pyramid\n",
    "---\n",
    "\n",
    "The Testing Pyramid\n",
    "\n",
    "**Image Credit:**\n",
    "[Testing Pyramid](https://semaphoreci.com/blog/testing-pyramid)\n",
    "```\n",
    "\n",
    "### Unit Testing\n",
    "\n",
    "Unit testing is a fundamental tool in every developer's toolbox. Unit tests not\n",
    "only help us test our code, they encourage good design practices, reduce the\n",
    "chances of bugs reaching production, and can even serve as examples or\n",
    "documentation on how code functions. Properly written unit tests can also\n",
    "improve developer efficiency.\n",
    "\n",
    "#### Intuition\n",
    "\n",
    "Unit tests are the smallest and most granular tests in the testing pyramid. This\n",
    "can be explained through an analogy of a building. If you think of your\n",
    "application as a building, unit tests are the bricks. They are the smallest,\n",
    "most fundamental building blocks of your application. They test the smallest\n",
    "pieces of code, such as functions, methods, or classes, in isolation from the\n",
    "rest of the application.\n",
    "\n",
    "You need to ensure each brick is solid and reliable before you can build a\n",
    "sturdy, reliable building. Similarly, you need to ensure each unit of code is\n",
    "solid and reliable before you can build a sturdy, reliable application.\n",
    "\n",
    "#### Benefits of Unit Testing\n",
    "\n",
    "##### Early Bug Detection and Reduce Cost\n",
    "\n",
    "Why can't I catch a bug when the application is in production? Cost. It is\n",
    "expensive to revert back and fix the bug. It is much cheaper to fix the bug when\n",
    "it is caught early in the development cycle. Unit tests allow for the detection\n",
    "of problems early in the development cycle, saving time and effort by preventing\n",
    "bugs from propagating to later stages.\n",
    "\n",
    "A\n",
    "[2008 research study by IBM](https://www.researchgate.net/figure/IBM-System-Science-Institute-Relative-Cost-of-Fixing-Defects_fig1_255965523)\n",
    "estimates that a bug caught in production could cost 6 times as much as if it\n",
    "was caught during implementation[^unit-test-1].\n",
    "\n",
    "##### Refactoring with Confidence\n",
    "\n",
    "Development is an **_iterative process_**. You write code, test it, and then\n",
    "refactor it. You repeat this process until you are satisfied with the result.\n",
    "\n",
    "With a suite of unit tests, developers can make changes to the codebase\n",
    "confidently, knowing that they'll be alerted if a change inadvertently breaks\n",
    "something that used to work.\n",
    "\n",
    "##### Unit Test As Documentation\n",
    "\n",
    "Unit tests serve as a form of documentation that describes what the code is\n",
    "supposed to do, helping new developers understand the project's functionality\n",
    "more quickly.\n",
    "\n",
    "#### Dependency Injection\n",
    "\n",
    "Dependency Injection (DI) is a design pattern used to manage dependencies\n",
    "between objects in software development. It's a technique that allows a class's\n",
    "dependencies to be injected into it from the outside rather than being hardcoded\n",
    "within the class. This approach promotes loose coupling, enhances testability,\n",
    "and improves code maintainability.\n",
    "\n",
    "At its core, DI involves three key components:\n",
    "\n",
    "1. **The Client**: The object that depends on the service(s).\n",
    "2. **The Injector**: The mechanism that injects the service(s) into the client.\n",
    "3. **The Service**: The dependency or service being used by the client.\n",
    "\n",
    "Dependency Injection can be implemented in several ways, including constructor\n",
    "injection, setter injection, and interface injection. Each method has its\n",
    "context and use case, but they all serve the same purpose: to decouple the\n",
    "creation of a dependency from its usage.\n",
    "\n",
    "##### Link to Unit Testing\n",
    "\n",
    "The link between Dependency Injection and unit testing is fundamentally about\n",
    "making code easier to test. DI facilitates the testing process in several ways:\n",
    "\n",
    "-   **Isolation of Unit Tests**: By injecting dependencies into a class, you can\n",
    "    easily replace those dependencies with mocks or stubs during testing. This\n",
    "    allows you to isolate the unit of code being tested, ensuring that tests are\n",
    "    not affected by external factors such as databases, file systems, or network\n",
    "    calls.\n",
    "-   **Flexibility in Test Scenarios**: Dependency Injection makes it easier to\n",
    "    create different configurations of an object for testing. You can inject\n",
    "    different implementations of a dependency to test how the object behaves\n",
    "    under various conditions, enhancing test coverage and robustness.\n",
    "-   **Reduced Boilerplate Code**: Without DI, you might find yourself writing a\n",
    "    lot of boilerplate code to set up objects for testing, especially if they\n",
    "    have numerous and complex dependencies. DI frameworks can automate much of\n",
    "    this setup, keeping your test code cleaner and focused on the behavior\n",
    "    you're testing.\n",
    "\n",
    "##### No Dependency Injection vs Dependency Injection\n",
    "\n",
    "Consider a simple class that processes user data and requires a database\n",
    "connection to store this data. Without DI, the class might directly instantiate\n",
    "a connection to a specific database, making it difficult to test the class\n",
    "without accessing the actual database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9797d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "\n",
    "class DatasetLoader(Protocol):\n",
    "    def load_feature_and_label(self) -> Tuple[NDArray[np.float32], NDArray[np.int32]]:\n",
    "        ...\n",
    "\n",
    "\n",
    "class ImageDatasetLoader:\n",
    "    def load_feature_and_label(self) -> Tuple[NDArray[np.float32], NDArray[np.int32]]:\n",
    "        features = np.array([[0.1, 0.2, 0.3]])\n",
    "        labels = np.array([1])\n",
    "\n",
    "        return features, labels\n",
    "\n",
    "\n",
    "class TextDatasetLoader:\n",
    "    def load_feature_and_label(self) -> Tuple[NDArray[np.float32], NDArray[np.int32]]:\n",
    "        features = np.array([[0.4, 0.5, 0.6]])\n",
    "        labels = np.array([0])\n",
    "        return features, labels\n",
    "\n",
    "\n",
    "class TrainerWithoutDependencyInjection:\n",
    "    def __init__(self) -> None:\n",
    "        self.dataset_loader = ImageDatasetLoader()\n",
    "\n",
    "    def train(self) -> None:\n",
    "        features, labels = self.dataset_loader.load_feature_and_label()\n",
    "        print(f\"Training model on features: {features} and labels: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269889ba",
   "metadata": {},
   "source": [
    "This is a classic case of tight coupling, where the\n",
    "`TrainerWithoutDependencyInjection` class is tightly coupled to the\n",
    "`ImageDatasetLoader` class. This makes it difficult to test the\n",
    "`TrainerWithoutDependencyInjection` class in isolation, as it's dependent on the\n",
    "`ImageDatasetLoader` class and its behavior. If the `dataset_loader` is now an\n",
    "instance of `TextDatasetLoader`, the `TrainerWithoutDependencyInjection` class\n",
    "will fail to work as expected.\n",
    "\n",
    "To fix this, we can use Dependency Injection to decouple the `Trainer` class\n",
    "from the `DatasetLoader` class. This allows us to inject different\n",
    "implementations of the `DatasetLoader` interface into the `Trainer` class,\n",
    "making it easier to test and more flexible in terms of the data sources it can\n",
    "work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dcb6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, dataset_loader: DatasetLoader) -> None:\n",
    "        self.dataset_loader = dataset_loader\n",
    "\n",
    "    def train(self) -> None:\n",
    "        features, labels = self.dataset_loader.load_feature_and_label()\n",
    "        print(f\"Training model on features: {features} and labels: {labels}\")\n",
    "\n",
    "\n",
    "def test_train_model_using_image_dataset_loader() -> None:\n",
    "    dataset_loader = ImageDatasetLoader()\n",
    "    trainer = Trainer(dataset_loader)\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "def test_train_model_using_text_dataset_loader() -> None:\n",
    "    dataset_loader = TextDatasetLoader()\n",
    "    trainer = Trainer(dataset_loader)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee598624",
   "metadata": {},
   "source": [
    "#### Stubs and Mocks\n",
    "\n",
    "In unit testing, **mocks** and **stubs** are both types of test doubles used to\n",
    "simulate the behavior of real objects in a controlled way. They are essential\n",
    "tools for isolating the piece of code under test, ensuring that tests are fast,\n",
    "reliable, and independent of external factors or system states. However, mocks\n",
    "and stubs serve slightly different purposes and are used in different scenarios.\n",
    "\n",
    "##### Stubs\n",
    "\n",
    "**Stubs** provide predetermined responses to calls made during the test. They\n",
    "are typically used to represent dependencies of the unit under test, allowing\n",
    "you to bypass operations that are irrelevant to the test case, such as database\n",
    "access, network calls, or complex logic. Stubs are simple objects that return\n",
    "fixed data and are primarily used to:\n",
    "\n",
    "-   Provide indirect input to the system under test.\n",
    "-   Allow the test to control the test environment by simulating various\n",
    "    conditions.\n",
    "-   Avoid issues related to external dependencies, such as network latency or\n",
    "    database access errors.\n",
    "\n",
    "Stubs are passive and only return the specific responses they are programmed to\n",
    "return, without any assertion on how they were used by the unit under test.\n",
    "\n",
    "##### Mocks\n",
    "\n",
    "**Mocks** are more sophisticated than stubs. They are used to verify the\n",
    "interaction between the unit under test and its dependencies. Mocks can be\n",
    "programmed with expectations, which means they can assert if they were called\n",
    "correctly, how many times they were called, and with what arguments. They are\n",
    "particularly useful for:\n",
    "\n",
    "-   Verifying that the unit under test interacts correctly with its\n",
    "    dependencies.\n",
    "-   Ensuring that certain methods are called with the correct parameters.\n",
    "-   Checking the number of times a dependency is interacted with, to validate\n",
    "    the logic within the unit under test.\n",
    "\n",
    "Mocks actively participate in the test, and failing to meet their expectations\n",
    "will cause the test to fail. This makes them powerful for testing the behavior\n",
    "of the unit under test.\n",
    "\n",
    "#### Further Readings\n",
    "\n",
    "-   [Unit Testing - Microsoft](https://microsoft.github.io/code-with-engineering-playbook/automated-testing/unit-testing/)\n",
    "-   [Unit vs Integration vs System vs E2E Testing - Microsoft](https://microsoft.github.io/code-with-engineering-playbook/automated-testing/e2e-testing/testing-comparison/)\n",
    "\n",
    "### Integration Testing\n",
    "\n",
    "**Unlike unit testing**, which focuses on verifying the correctness of _isolated\n",
    "pieces of code_, **integration testing** focuses on testing the **connections\n",
    "and interactions between components** to identify any issues in the way they\n",
    "integrate and operate together.\n",
    "\n",
    "Verifying the **interactions between system components** is crucial, especially\n",
    "since these components might be developed **independently or in isolation**. A\n",
    "complex system typically encompasses **databases, APIs, interfaces**, and more,\n",
    "all of which interact with each other and possibly with **external systems**.\n",
    "**Integration testing** plays a key role in uncovering **system-wide issues**,\n",
    "such as _inconsistencies in database schemas_ or _problems with third-party API\n",
    "integrations_. It enhances overall **test coverage** and provides **vital\n",
    "feedback** throughout the development process, ensuring that components work\n",
    "together as intended[^unit-test-2].\n",
    "\n",
    "#### Intuition\n",
    "\n",
    "The analogy of a building can be extended to understand integration testing. If\n",
    "unit tests verify the integrity of each brick (component), integration testing\n",
    "checks the mortar between bricks (interactions). It ensures that not only are\n",
    "the individual components reliable, but they also come together to form a\n",
    "cohesive whole. Just as a wall relies on the strength of both the bricks and the\n",
    "mortar, a software system relies on both its individual components and their\n",
    "interactions.\n",
    "\n",
    "Integration testing is like verifying that the electrical and plumbing systems\n",
    "in a building work correctly once they are fitted together, despite each system\n",
    "working perfectly in isolation.\n",
    "\n",
    "#### Benefits of Integration Testing\n",
    "\n",
    "##### Exposes Interface Issues\n",
    "\n",
    "Integration testing is crucial for detecting problems that occur when different\n",
    "parts of a system interact. It can uncover issues with the interfaces between\n",
    "components, such as incorrect data being passed between modules, or problems\n",
    "with the way components use each other's APIs.\n",
    "\n",
    "##### Validates Functional Coherence\n",
    "\n",
    "By testing a group of components together, integration testing ensures that the\n",
    "software functions correctly as a whole. This is particularly important for\n",
    "critical paths in an application where the interaction between components is\n",
    "complex or involves external systems like databases or third-party services.\n",
    "\n",
    "##### Highlights Dependency Problems\n",
    "\n",
    "Complex systems often rely on external dependencies, and integration testing can\n",
    "reveal issues with these dependencies that might not be apparent during unit\n",
    "testing. This includes problems with network communications, database\n",
    "integrations, and interactions with external APIs.\n",
    "\n",
    "##### Improves Confidence in System Stability\n",
    "\n",
    "Successful integration tests provide confidence that the system will perform as\n",
    "expected under real-world conditions. This is especially important when changes\n",
    "are made to one part of the system, as it helps ensure that such changes do not\n",
    "adversely affect other parts.\n",
    "\n",
    "Given the provided overview of integration testing, let's construct a clear and\n",
    "practical guide to implementing integration testing, focusing on a hypothetical\n",
    "banking application as mentioned. This guide will outline key steps,\n",
    "considerations, and an example to illustrate how integration testing can be\n",
    "effectively applied.\n",
    "\n",
    "#### Understanding Integration Testing in Practice\n",
    "\n",
    "Let's adopt the example given in\n",
    "[Microsoft's Code with Engineering Playbook Integration Testing Design Blocks](https://microsoft.github.io/code-with-engineering-playbook/automated-testing/integration-testing/#integration-testing-design-blocks)\n",
    "to understand how integration testing can be applied in practice.\n",
    "\n",
    "**Objective**: To ensure that independently developed modules of a banking\n",
    "application—login, transfers, and current balance—work together as intended.\n",
    "\n",
    "##### Step 1: Identify Integration Points\n",
    "\n",
    "First, identify the key integration points within the application that require\n",
    "testing. For the banking application, these points include:\n",
    "\n",
    "-   **Login to Current Balance**: After a successful login, the application\n",
    "    redirects the user to their current balance page with the correct balance\n",
    "    displayed.\n",
    "-   **Transfers to Current Balance**: After a transfer is initiated, ensure that\n",
    "    the transfer completes successfully and the current balance is updated\n",
    "    accurately.\n",
    "\n",
    "##### Step 2: Design Integration Tests\n",
    "\n",
    "For each identified integration point, design a test scenario that mimics\n",
    "real-world usage:\n",
    "\n",
    "-   **Login Integration Test**:\n",
    "\n",
    "    -   **Objective**: Verify that upon login, the user is redirected to the\n",
    "        current balance page with the correct balance.\n",
    "    -   **Method**: Use a mock user with predefined credentials. After login,\n",
    "        assert that the redirection is correct and the displayed balance matches\n",
    "        the mock user's expected balance.\n",
    "\n",
    "-   **Transfers Integration Test**:\n",
    "    -   **Objective**: Confirm a transfer updates the sender's balance\n",
    "        correctly.\n",
    "    -   **Method**: Create a test scenario where a mock user transfers money to\n",
    "        another account. Verify pre-transfer and post-transfer balances to\n",
    "        ensure the transfer amount is correctly deducted.\n",
    "\n",
    "Note that it is generally the consensus that integration tests should be using\n",
    "real data and connections. So why did the example use the word \"mock\"? The\n",
    "example is using the word \"mock\" to refer to the user, not the data or\n",
    "connections. The user is a mock because it is not a real user, but a simulated\n",
    "user for the purpose of testing.\n",
    "\n",
    "#### Techniques for Integration Testing\n",
    "\n",
    "##### Big Bang Testing\n",
    "\n",
    "Big Bang Testing is a straightforward but high-risk approach to integration\n",
    "testing where all the components or modules of a software application are\n",
    "integrated simultaneously, and then tested as a whole. This method waits until\n",
    "all parts of the system are developed and then combines them to perform the\n",
    "integration test. The primary advantage of this approach is its simplicity, as\n",
    "it does not require complex planning or integration stages. However, it has\n",
    "significant drawbacks:\n",
    "\n",
    "-   Identifying the root cause of a failure can be challenging because all\n",
    "    components are integrated at once, making it difficult to isolate issues.\n",
    "-   It can lead to delays in testing until all components are ready.\n",
    "-   There's a higher risk of encountering multiple bugs or integration issues\n",
    "    simultaneously, which can be overwhelming to debug and fix.\n",
    "\n",
    "For example, if you want to test whether your `Trainer` class works correctly to\n",
    "train a large language model, you might need to integrate the `Trainer` class\n",
    "with the `LanguageModel` class, the `DatasetLoader` class, and the `Optimizer`\n",
    "class. So here you would integrate all these classes at once and test the\n",
    "`Trainer` class as a whole.\n",
    "\n",
    "##### Incremental Testing\n",
    "\n",
    "Incremental Testing is a more systematic and less risky approach compared to Big\n",
    "Bang Testing. It involves integrating and testing components or modules one at a\n",
    "time or in small groups. This method allows for early detection of defects\n",
    "related to interfaces and interactions between integrated components.\n",
    "Incremental Testing can be further divided into two main types: Top-Down Testing\n",
    "and Bottom-Up Testing.\n",
    "\n",
    "###### Top-Down Testing\n",
    "\n",
    "Top-Down Testing involves integrating and testing from the top levels of the\n",
    "software's control flow downwards. It starts with the highest-level modules and\n",
    "progressively integrates and tests lower-level modules using stubs (simplified\n",
    "implementations or placeholders) for modules that are not yet developed or\n",
    "integrated. This approach allows for early validation of high-level\n",
    "functionality and the overall system's architecture. However, it might delay\n",
    "testing of lower-level components and their interactions.\n",
    "\n",
    "Advantages include:\n",
    "\n",
    "-   Early testing of major functionalities and user interfaces.\n",
    "-   Facilitates early discovery of major defects.\n",
    "\n",
    "Disadvantages include:\n",
    "\n",
    "-   Lower-level modules are tested late in the cycle, which may delay the\n",
    "    discovery of some bugs.\n",
    "-   Requires the creation and maintenance of stubs, which can be\n",
    "    resource-intensive.\n",
    "\n",
    "###### Bottom-Up Testing\n",
    "\n",
    "Bottom-Up Testing, in contrast, starts with the lowest level modules and\n",
    "progressively moves up to higher-level modules, using drivers (temporary code\n",
    "that calls a module and provides it with the necessary input for testing) until\n",
    "the entire system is integrated and tested. This method is beneficial for\n",
    "testing the fundamental components of a system early in the development cycle.\n",
    "\n",
    "Advantages include:\n",
    "\n",
    "-   Early testing of the fundamental operations provided by lower-level modules.\n",
    "-   No need for stubs since testing begins with actual lower-level units.\n",
    "\n",
    "Disadvantages include:\n",
    "\n",
    "-   Higher-level functionalities and user interfaces are tested later in the\n",
    "    development cycle.\n",
    "-   Requires the development and maintenance of drivers, which can also be\n",
    "    resource-intensive.\n",
    "\n",
    "Both incremental approaches—Top-Down and Bottom-Up—offer more control and easier\n",
    "isolation of defects compared to Big Bang Testing. They also allow for parallel\n",
    "development and testing activities, potentially leading to more efficient use of\n",
    "project time and resources.\n",
    "\n",
    "#### Integration Test vs Acceptance Test\n",
    "\n",
    "As we understand the importance of integration testing, which focuses on testing\n",
    "the interactions between components, it is essential to distinguish integration\n",
    "testing from acceptance testing. While both are critical for ensuring the\n",
    "quality of a software system, they serve different purposes and operate at\n",
    "different levels of the testing pyramid.\n",
    "\n",
    "-   **Integration Testing**: Focuses on verifying the interactions between\n",
    "    components to identify any issues in the way they integrate and operate\n",
    "    together. It ensures that different parts of the system work together as\n",
    "    intended from a technical perspective.\n",
    "-   **Acceptance Testing**: Focuses on confirming a group of components work\n",
    "    together as intended from a business scenario. It is performed by end-users\n",
    "    or clients to validate the end-to-end business flow.\n",
    "\n",
    "#### Further Readings\n",
    "\n",
    "-   [Integration Testing - Microsoft](https://microsoft.github.io/code-with-engineering-playbook/automated-testing/integration-testing/)\n",
    "\n",
    "### System Testing\n",
    "\n",
    "#### Intuition\n",
    "\n",
    "System testing can be likened to the inspection of a completed building before\n",
    "it's opened for occupancy. After ensuring that all individual components\n",
    "(bricks, electrical systems, plumbing) are working correctly and are properly\n",
    "integrated, system testing examines the building as a whole to ensure it meets\n",
    "all the specified requirements. This involves checking not only the internal\n",
    "workings but also how the building interacts with external systems (such as\n",
    "electrical grids, water supply systems) and complies with all applicable codes\n",
    "and regulations. In software terms, system testing checks the complete and fully\n",
    "integrated software product to ensure it aligns with the specified requirements.\n",
    "It's about verifying that the entire system functions correctly in its intended\n",
    "environment and meets all user expectations.\n",
    "\n",
    "### End-to-End Testing\n",
    "\n",
    "#### Intuition\n",
    "\n",
    "End-to-end testing takes the building analogy a step further, comparing it to\n",
    "not only inspecting the building as a whole but also observing how it serves its\n",
    "occupants during actual use. Imagine a scenario where we follow residents as\n",
    "they move in, live in, and use the building's various facilities. This would\n",
    "include checking if the elevator efficiently transports people between floors,\n",
    "if the heating system provides adequate warmth during winter, and if the\n",
    "security systems ensure the residents' safety. In the context of software, E2E\n",
    "testing involves testing the application's workflow from beginning to end. This\n",
    "aims to replicate real user scenarios to ensure the system behaves as intended\n",
    "in real-world use. It's the ultimate test to see if the software can handle what\n",
    "users will throw at it, including interacting with other systems, databases, and\n",
    "networks, to fulfill end-user requirements comprehensively.\n",
    "\n",
    "Thus, while integration testing focuses on the connections and interactions\n",
    "between components, system testing evaluates the complete, integrated system\n",
    "against specified requirements, and end-to-end testing examines the system's\n",
    "functionality in real-world scenarios, from the user's perspective.\n",
    "\n",
    "### Unit vs Integration vs System vs E2E Testing\n",
    "\n",
    "The table below illustrates the most critical characteristics and differences\n",
    "among Unit, Integration, System, and End-to-End Testing, and when to apply each\n",
    "methodology in a project.\n",
    "\n",
    "|                         | Unit Test              | Integration Test                             | System Testing                                            | E2E Test                                                      |\n",
    "| ----------------------- | ---------------------- | -------------------------------------------- | --------------------------------------------------------- | ------------------------------------------------------------- |\n",
    "| **Scope**               | Modules, APIs          | Modules, interfaces                          | Application, system                                       | All sub-systems, network dependencies, services and databases |\n",
    "| **Size**                | Tiny                   | Small to medium                              | Large                                                     | X-Large                                                       |\n",
    "| **Environment**         | Development            | Integration test                             | QA test                                                   | Production like                                               |\n",
    "| **Data**                | Mock data              | Test data                                    | Test data                                                 | Copy of real production data                                  |\n",
    "| **System Under Test**   | Isolated unit test     | Interfaces and flow data between the modules | Particular system as a whole                              | Application flow from start to end                            |\n",
    "| **Scenarios**           | Developer perspectives | Developers and IT Pro tester perspectives    | Developer and QA tester perspectives                      | End-user perspectives                                         |\n",
    "| **When**                | After each build       | After Unit testing                           | Before E2E testing and after Unit and Integration testing | After System testing                                          |\n",
    "| **Automated or Manual** | Automated              | Manual or automated                          | Manual or automated                                       | Manual                                                        |\n",
    "\n",
    "1. **Unit Testing**:\n",
    "\n",
    "    - Tests individual units or components of the software in isolation (e.g.,\n",
    "      functions, methods).\n",
    "    - Ensures that each part works correctly on its own.\n",
    "\n",
    "2. **Integration Testing**:\n",
    "\n",
    "    - Tests the integration or interfaces between components or systems.\n",
    "    - Ensures that different parts of the system work together as expected.\n",
    "\n",
    "3. **System Testing**:\n",
    "\n",
    "    - Tests the complete and integrated software system.\n",
    "    - Verifies that the system meets its specified requirements.\n",
    "\n",
    "4. **Acceptance Testing**:\n",
    "\n",
    "    - Performed by end-users or clients to validate the end-to-end business\n",
    "      flow.\n",
    "    - Ensures that the software meets the business requirements and is ready for\n",
    "      delivery.\n",
    "\n",
    "5. **Regression Testing**:\n",
    "\n",
    "    - Conducted after changes (like enhancements or bug fixes) to ensure\n",
    "      existing functionalities work as before.\n",
    "    - Helps catch bugs introduced by recent changes.\n",
    "\n",
    "6. **Functional Testing**:\n",
    "\n",
    "    - Tests the software against functional specifications/requirements.\n",
    "    - Focuses on checking functionalities of the software.\n",
    "\n",
    "7. **Non-Functional Testing**:\n",
    "\n",
    "    - Includes testing of non-functional aspects like performance, usability,\n",
    "      reliability, etc.\n",
    "    - Examples include Performance Testing, Load Testing, Stress Testing,\n",
    "      Usability Testing, Security Testing, etc.\n",
    "\n",
    "8. **End-to-End Testing**:\n",
    "\n",
    "    - Tests the complete flow of the application from start to end.\n",
    "    - Ensures the system behaves as expected in real-world scenarios.\n",
    "\n",
    "9. **Smoke Testing**:\n",
    "\n",
    "    - Preliminary testing to check if the basic functions of the software work\n",
    "      correctly.\n",
    "    - Often done to ensure it's stable enough for further testing.\n",
    "\n",
    "10. **Exploratory Testing**:\n",
    "\n",
    "    - Unscripted testing to explore the application's capabilities.\n",
    "    - Helps to find unexpected issues that may not be covered in other tests.\n",
    "\n",
    "11. **Load Testing**:\n",
    "\n",
    "    - Evaluates system performance under a specific expected load.\n",
    "    - Identifies performance bottlenecks.\n",
    "\n",
    "12. **Stress Testing**:\n",
    "\n",
    "    - Tests the system under extreme conditions, often beyond its normal\n",
    "      operational capacity.\n",
    "    - Checks how the system handles overload.\n",
    "\n",
    "13. **Usability Testing**:\n",
    "\n",
    "    - Focuses on the user's ease of using the application, user interface, and\n",
    "      user satisfaction.\n",
    "    - Helps improve user experience and interface design.\n",
    "\n",
    "14. **Security Testing**:\n",
    "\n",
    "    - Identifies vulnerabilities in the software and ensures that the data and\n",
    "      resources are protected.\n",
    "    - Checks for potential exploits and security flaws.\n",
    "\n",
    "15. **Compatibility Testing**:\n",
    "\n",
    "    - Checks if the software is compatible with different environments like\n",
    "      operating systems, browsers, devices, etc.\n",
    "\n",
    "16. **Sanity Testing**:\n",
    "    - A subset of regression testing, focused on testing specific\n",
    "      functionalities after making changes.\n",
    "    - Usually quick and verifies whether a particular function of the\n",
    "      application is still working after a minor change.\n",
    "\n",
    "### References and Further Readings\n",
    "\n",
    "-   [Practical Test Pyramid - Martin Fowler](https://martinfowler.com/articles/practical-test-pyramid.html)\n",
    "-   [Unit Testing - Microsoft](https://microsoft.github.io/code-with-engineering-playbook/automated-testing/unit-testing/)\n",
    "-   [Integration Testing - Microsoft](https://microsoft.github.io/code-with-engineering-playbook/automated-testing/integration-testing/)\n",
    "-   [Unit vs Integration vs System vs E2E Testing](https://microsoft.github.io/code-with-engineering-playbook/automated-testing/e2e-testing/testing-comparison/)\n",
    "\n",
    "## Phase 5. Continuous Deployment\n",
    "\n",
    "Usually at this stage, we have a fully integrated and tested system that is\n",
    "ready to be deployed from staging environment to production. The deployment\n",
    "process is automated and follows a defined release process.\n",
    "\n",
    "### Release\n",
    "\n",
    "For example, we might have a `staging` environment that is a copy of the\n",
    "production environment. We deploy to the `staging` environment first, and after\n",
    "we have thoroughly tested the system, we deploy to the `production` environment.\n",
    "This is an example of a release and can be easily done via workflow automation\n",
    "like Github Actions, Gitlab CI, etc. If the deployed system is an application,\n",
    "we can also deploy to container orchestration platforms like Kubernetes etc.\n",
    "\n",
    "### Testing In Production\n",
    "\n",
    "Machine learning systems are often non-deterministic, and it is not uncommon to\n",
    "have good local evaluation results but poor production results. Consider a\n",
    "machine learning system that predicts the price of a stock. You might get good\n",
    "backtesting results, but when you deploy to production, you realize that the\n",
    "model is not performing as expected due to various drifts.\n",
    "\n",
    "We will follow Chip's book and mention a few techniques to test in production so\n",
    "that we can still \"rollback\" to a previous version of the system if the\n",
    "production results are not satisfactory.\n",
    "\n",
    "#### Shadow Deployment/Mirrored Deployment\n",
    "\n",
    "The mirrored deployment is a technique where we deploy both the existing model\n",
    "$\\mathcal{M}_1$ and the new model $\\mathcal{M}_2$ to production. We do the\n",
    "following:\n",
    "\n",
    "1. Deploy both $\\mathcal{M}_1$ and $\\mathcal{M}_2$ to production.\n",
    "2. For any incoming user requests, we will route to both $\\mathcal{M}_1$ and\n",
    "   $\\mathcal{M}_2$ to make predictions, however, we will only use the\n",
    "   predictions from the old model $\\mathcal{M}_1$ for the final output to the\n",
    "   users.\n",
    "3. The new predictions are logged and persisted so the developers can analyze\n",
    "   the results later.\n",
    "\n",
    "By doing this, we can compare the results from the old model $\\mathcal{M}_1$ and\n",
    "the new model $\\mathcal{M}_2$ to see if the new model is performing as expected.\n",
    "If the new model is performing better, we can continue to use it. If the new\n",
    "model is performing worse, we can rollback to the old model $\\mathcal{M}_1$.\n",
    "\n",
    "Of course one glaring issue is that this is expensive to run since we need to\n",
    "serve twice, and this means inference costs are likely doubled.\n",
    "\n",
    "#### A/B Testing\n",
    "\n",
    "A/B Testing, also known as **Split Testing**, involves deploying two or more\n",
    "versions of an application (Version A and Version B) simultaneously to different\n",
    "segments of users. The primary objective is to compare the performance, user\n",
    "engagement, and overall effectiveness of each version to inform data-driven\n",
    "decisions about which version to fully roll out.\n",
    "\n",
    "1. Deploy both the old model $\\mathcal{M}_1$ and the new model $\\mathcal{M}_2$\n",
    "   to production.\n",
    "2. Certain predictions are routed to $\\mathcal{M}_1$ and certain predictions are\n",
    "   routed to $\\mathcal{M}_2$.\n",
    "3. Based on predictions and user feedback, we can analyze the results and decide\n",
    "   which model to keep.\n",
    "\n",
    "##### 1. Randomized Traffic Allocation\n",
    "\n",
    "Randomly assigning users to different versions (A and B) is essential to\n",
    "eliminate bias and ensure that the test results are statistically valid.\n",
    "\n",
    "-   **Equal Opportunity:** Randomization ensures that each user has an equal\n",
    "    chance of being assigned to either version, which helps in controlling for\n",
    "    variables that could otherwise skew results.\n",
    "-   **Representative Sample:** This method creates a more representative sample\n",
    "    of the overall user population, which helps in generalizing the results\n",
    "    beyond the test group.\n",
    "-   **Minimizes Confounding Variables:** Random assignment reduces the risk of\n",
    "    confounding factors influencing the outcomes. For instance, if one version\n",
    "    is shown to a certain demographic, the results might be biased due to\n",
    "    inherent differences between that demographic and others.\n",
    "\n",
    "##### 2. Sufficient Sample Size\n",
    "\n",
    "Having a sufficiently large sample size is critical for obtaining statistically\n",
    "significant results.\n",
    "\n",
    "-   **Statistical Power:** A larger sample size increases the statistical power\n",
    "    of the test, making it more likely to detect a true effect if one exists.\n",
    "    This means you’re less likely to encounter Type II errors (failing to reject\n",
    "    a false null hypothesis).\n",
    "-   **Confidence Intervals:** Larger samples provide narrower confidence\n",
    "    intervals, which gives a clearer picture of the effect size and its\n",
    "    reliability. This helps in making informed decisions based on the results.\n",
    "-   **Minimizes Variability:** With a larger sample, random variability is\n",
    "    reduced, allowing the observed effects to be more accurately attributed to\n",
    "    the changes being tested rather than random chance.\n",
    "\n",
    "## Phase 6. Continuous Monitoring and Observability\n",
    "\n",
    "### Motivation\n",
    "\n",
    "Consider a financial institution that has a web-based banking application that\n",
    "allows customers to transfer money, pay bills, and manage their accounts. The\n",
    "motivation for implementing robust observing and monitoring practices is driven\n",
    "by the critical need for **security**, **reliability**, **performance**, and\n",
    "**regulatory compliance**.\n",
    "\n",
    "-   Financial transactions are prime targets for **fraudulent activities** and\n",
    "    **security breaches**. By **monitoring** system logs, network traffic, and\n",
    "    user activities, the bank can identify and respond to potential security\n",
    "    incidents in real time.\n",
    "-   Customers expect banking services to be available 24/7, without\n",
    "    interruptions. **Guaranteeing System Reliability and Availability** is\n",
    "    therefore paramount to establish trust and confidence in your services.\n",
    "    **Real-time health checks** and **performance metrics** can identify a\n",
    "    failing server or an overloaded network segment, allowing IT teams to\n",
    "    quickly reroute traffic or scale resources to prevent service disruption.\n",
    "\n",
    "    In other words, Murphy's law is always at play, and things will fail at a\n",
    "    certain point in time, and **you don't want to be oblivious to it**. If a\n",
    "    system fails, we need to know it immediately and take action (logging and\n",
    "    tracing are important to enable easy debugging).\n",
    "\n",
    "### The What and The Why\n",
    "\n",
    "We won't focus on the **how** to set up monitoring and observability, as there\n",
    "are many ways to do it. For example,\n",
    "[Grafana](https://grafana.com/blog/2023/11/20/ci-cd-observability-via-opentelemetry-at-grafana-labs/)\n",
    "is one of the most popular open-source observability platforms, and it is\n",
    "commonly used with\n",
    "[Prometheus](https://grafana.com/docs/grafana/latest/getting-started/get-started-grafana-prometheus/),\n",
    "a monitoring and alerting toolkit.\n",
    "\n",
    "Instead, we need to give intuition on the **what** and **why** of monitoring and\n",
    "observability.\n",
    "\n",
    "```{list-table} Symptom and Cause\n",
    ":header-rows: 1\n",
    ":name: devops-ci-concept-monitoring-observability\n",
    "\n",
    "*  - Symptom\n",
    "   - Cause\n",
    "*  - I’m serving HTTP 500s or 404s\n",
    "   - Database servers are refusing connections\n",
    "*  - My responses are slow\n",
    "   - CPUs are overloaded by a bogosort, or an Ethernet cable is crimped under a rack, visible as partial packet loss\n",
    "*  - Users in Antarctica aren’t receiving animated cat GIFs\n",
    "   - Your Content Distribution Network hates scientists and felines, and thus blacklisted some client IPs\n",
    "*  - Private content is world-readable\n",
    "   - A new software push caused ACLs to be forgotten and allowed all requests\n",
    "```\n",
    "\n",
    "### The Four Golden Signals\n",
    "\n",
    "```{admonition} Verbatim\n",
    ":class: attention\n",
    "\n",
    "The below section is verbatim from the\n",
    "[Google SRE Book](https://sre.google/sre-book/monitoring-distributed-systems/).\n",
    "```\n",
    "\n",
    "The four golden signals of monitoring are latency, traffic, errors, and\n",
    "saturation. If you can only measure four metrics of your user-facing system,\n",
    "focus on these four.\n",
    "\n",
    "#### Latency\n",
    "\n",
    "The time it takes to service a request. It’s important to distinguish between\n",
    "the latency of successful requests and the latency of failed requests. For\n",
    "example, an HTTP 500 error triggered due to loss of connection to a database or\n",
    "other critical backend might be served very quickly; however, as an HTTP 500\n",
    "error indicates a failed request, factoring 500s into your overall latency might\n",
    "result in misleading calculations. On the other hand, a slow error is even worse\n",
    "than a fast error! Therefore, it’s important to track error latency, as opposed\n",
    "to just filtering out errors.\n",
    "\n",
    "#### Traffic\n",
    "\n",
    "A measure of how much demand is being placed on your system, measured in a\n",
    "high-level system-specific metric. For a web service, this measurement is\n",
    "usually HTTP requests per second, perhaps broken out by the nature of the\n",
    "requests (e.g., static versus dynamic content). For an audio streaming system,\n",
    "this measurement might focus on network I/O rate or concurrent sessions. For a\n",
    "key-value storage system, this measurement might be transactions and retrievals\n",
    "per second.\n",
    "\n",
    "#### Errors\n",
    "\n",
    "The rate of requests that fail, either explicitly (e.g., HTTP 500s), implicitly\n",
    "(for example, an HTTP 200 success response, but coupled with the wrong content),\n",
    "or by policy (for example, \"If you committed to one-second response times, any\n",
    "request over one second is an error\"). Where protocol response codes are\n",
    "insufficient to express all failure conditions, secondary (internal) protocols\n",
    "may be necessary to track partial failure modes. Monitoring these cases can be\n",
    "drastically different: catching HTTP 500s at your load balancer can do a decent\n",
    "job of catching all completely failed requests, while only end-to-end system\n",
    "tests can detect that you’re serving the wrong content.\n",
    "\n",
    "#### Saturation\n",
    "\n",
    "How \"full\" your service is. A measure of your system fraction, emphasizing the\n",
    "resources that are most constrained (e.g., in a memory-constrained system, show\n",
    "memory; in an I/O-constrained system, show I/O). Note that many systems degrade\n",
    "in performance before they achieve 100% utilization, so having a utilization\n",
    "target is essential. In complex systems, saturation can be supplemented with\n",
    "higher-level load measurement: can your service properly handle double the\n",
    "traffic, handle only 10% more traffic, or handle even less traffic than it\n",
    "currently receives? For very simple services that have no parameters that alter\n",
    "the complexity of the request (e.g., \"Give me a nonce\" or \"I need a globally\n",
    "unique monotonic integer\") that rarely change configuration, a static value from\n",
    "a load test might be adequate. As discussed in the previous paragraph, however,\n",
    "most services need to use indirect signals like CPU utilization or network\n",
    "bandwidth that have a known upper bound. Latency increases are often a leading\n",
    "indicator of saturation. Measuring your 99th percentile response time over some\n",
    "small window (e.g., one minute) can give a very early signal of saturation.\n",
    "Finally, saturation is also concerned with predictions of impending saturation,\n",
    "such as \"It looks like your database will fill its hard drive in 4 hours.\" If\n",
    "you measure all four golden signals and page a human when one signal is\n",
    "problematic (or, in the case of saturation, nearly problematic), your service\n",
    "will be at least decently covered by monitoring.\n",
    "\n",
    "### A Word on Monitoring in Machine Learning Systems\n",
    "\n",
    "In the Machine Learning world, we may have to track things like model and data\n",
    "shitfts. For example, model monitoring is about continuously tracking the\n",
    "performance of models in production to ensure that they continue to provide\n",
    "accurate and reliable predictions.\n",
    "\n",
    "-   **Performance Monitoring**: Regularly evaluate the model's performance\n",
    "    metrics in production. This includes tracking metrics like accuracy,\n",
    "    precision, recall, F1 score for classification problems, or Mean Absolute\n",
    "    Error (MAE), Root Mean Squared Error (RMSE) for regression problems, etc.\n",
    "\n",
    "-   **Data Drift Monitoring**: Over time, the data that the model receives can\n",
    "    change. These changes can lead to a decrease in the model's performance.\n",
    "    Therefore, it's crucial to monitor the data the model is scoring on to\n",
    "    detect any drift from the data the model was trained on.\n",
    "\n",
    "-   **Model Retraining**: If the performance of the model drops or significant\n",
    "    data drift is detected, it might be necessary to retrain the model with new\n",
    "    data. The model monitoring should provide alerts or triggers for such\n",
    "    situations.\n",
    "\n",
    "-   **A/B Testing**: In case multiple models are in production, monitor their\n",
    "    performances comparatively through techniques like A/B testing to determine\n",
    "    which model performs better.\n",
    "\n",
    "In each of these stages, it's essential to keep in mind principles like\n",
    "reproducibility, automation, collaboration, and validation to ensure the\n",
    "developed models are reliable, efficient, and providing value to the\n",
    "organization.\n",
    "\n",
    "## Phase 7. Continuous Learning and Training\n",
    "\n",
    "As we consistently emphasized on monitoring and observing drifts in machine\n",
    "learning systems, what would you do if you detect a drift? One common approach\n",
    "is to re-train, or fine-tune the model on new data. So on top of _continuous\n",
    "integration_, _continuous deployment_, and _continuous monitoring_, we also have\n",
    "_continuous learning_ and _continuous training_.\n",
    "\n",
    "Consider your object detection model that detects whether a person is wearing\n",
    "safety helmets, masks and vests, but you notice that the model is performing\n",
    "super poorly. It turns out the colors and the shapes of the objects are slightly\n",
    "different now. So you likely need to collect more data, and retrain/fine-tune\n",
    "the model on the new data.\n",
    "\n",
    "```{admonition} See Also\n",
    ":class: seealso\n",
    "\n",
    "For more information on continuous learning and training, see Chapter 9.\n",
    "Continual Learning and Test in Production of Chip Huyen's book, _Designing\n",
    "Machine Learning Systems_.\n",
    "```\n",
    "\n",
    "## Appendix A. Styling, Formatting, and Linting\n",
    "\n",
    "### Intuition\n",
    "\n",
    "Guido Van Rossum, the author of Python, aptly stated, \"Code is read more often\n",
    "than it is written.\" This principle underscores the necessity of both clear\n",
    "documentation and easy readability in coding. Adherence to style and formatting\n",
    "conventions, particularly those based on\n",
    "[PEP8](https://peps.python.org/pep-0008/), plays a vital role in achieving this\n",
    "goal. Different teams may adopt various conventions, but the key lies in\n",
    "consistent application and the use of automated pipelines to maintain this\n",
    "consistency. For instance, standardizing line lengths simplifies code review\n",
    "processes, making discussions about specific sections more straightforward. In\n",
    "this context, **linting** and **formating** emerge as critical tools for\n",
    "maintaining high code quality. Linting, the process of analyzing code for\n",
    "potential errors, and formatting, which ensures a uniform appearance,\n",
    "collectively boost **readability** and **maintainability**. A well-styled\n",
    "codebase not only looks professional but also reduces bugs and eases\n",
    "**integration** and **code reviews**. These practices, when ingrained as an\n",
    "**intuition** among developers, lead to more robust and efficient software\n",
    "development.\n",
    "\n",
    "### Linting\n",
    "\n",
    "#### Benefits of Linting\n",
    "\n",
    "##### Code Quality Assurance\n",
    "\n",
    "Linting tools, like [Pylint](https://github.com/pylint-dev/pylint) for Python,\n",
    "automatically detect not just syntax errors but also a range of subtle issues\n",
    "that could lead to bugs. This preemptive detection ensures higher **code\n",
    "quality** and reliability.\n",
    "\n",
    "In other words, linting tools help in catching potential issues early, reducing\n",
    "the likelihood of bugs and errors in the codebase.\n",
    "\n",
    "##### Reducing Technical Debt\n",
    "\n",
    "In many big organizations, there is quality gate to pass if you were to deploy\n",
    "your code to production. Henceforth, by catching potential issues early, linting\n",
    "helps in reducing technical debt - the extra development work that arises from\n",
    "choosing an easy solution now over a better approach that would take longer.\n",
    "\n",
    "##### Maintainability and Scalability\n",
    "\n",
    "Linting enforces readability and uniformity, making the codebase easier to\n",
    "understand and modify. This is crucial for long-term **maintenance** and\n",
    "**scaling** of the project.\n",
    "\n",
    "#### The PEP8 Standard\n",
    "\n",
    "The [PEP8 guide](https://peps.python.org/pep-0008/) offers essential coding\n",
    "conventions.\n",
    "\n",
    "##### Simple Styling Practices\n",
    "\n",
    "1. **Indentation**: PEP8 recommends 4 spaces per indentation level. While Python\n",
    "   is flexible with indentation size (any consistent `k` spaces), adhering to\n",
    "   the 4-space convention promotes uniformity across the Python community.\n",
    "\n",
    "2. **Line Length**: A suggested maximum of 79 characters per line enhances\n",
    "   readability, especially in environments without dynamic wrapping. Different\n",
    "   organizations may vary, but consistency is key. This limit roots in\n",
    "   historical constraints and current practicality.\n",
    "\n",
    "3. **Variable Naming**: Readability is crucial. Variables should be descriptive,\n",
    "   making code understandable at a glance. For example, `name = \"John\"` is more\n",
    "   descriptive than `a = \"John\"`, as it clearly indicates the variable's\n",
    "   purpose.\n",
    "\n",
    "4. **Import Statements**: Avoid wildcard imports like `from .src.main import *`.\n",
    "   They obscure the origin of functions, complicating maintenance and\n",
    "   readability. A more complex issue arises with relative imports in a deeply\n",
    "   nested package structure, which can lead to confusion about the source file's\n",
    "   location and dependencies.\n",
    "\n",
    "##### A More Nuanced Example: Mutable Default Arguments\n",
    "\n",
    "The issue of mutable default arguments in Python demonstrates a subtle yet\n",
    "significant trap that we encounter. Consider a function `add_to_list` designed\n",
    "to append an item to a list. When using a default mutable argument like an empty\n",
    "list (`[]`), the list isn't reinitialized on each function call. This results in\n",
    "unexpected behavior, where subsequent calls to the function without specifying a\n",
    "list continue to add items to the same list.\n",
    "\n",
    "To address this, a better practice is to use `None` as the default argument.\n",
    "Inside the function, check if the argument is `None` and, if so, initialize a\n",
    "new list. This ensures that each function call operates on a fresh list unless\n",
    "otherwise specified.\n",
    "\n",
    "Let's see this in action.\n",
    "\n",
    "Consider the following code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9af124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import List, TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def add_to_list(item: T, some_list: List[T] = []) -> List[T]:\n",
    "    some_list.append(item)\n",
    "    return some_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487ad90",
   "metadata": {},
   "source": [
    "This looks harmless, but if you run the below code, you will see that the\n",
    "function does not behave as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ac282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_1: [0]\n",
      "list_2: [0, 1]\n",
      "list_1: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "list_1 = add_to_list(0)  # [0]\n",
    "print(f\"list_1: {list_1}\")\n",
    "\n",
    "list_2 = add_to_list(1)  # [0, 1]\n",
    "print(f\"list_2: {list_2}\")\n",
    "\n",
    "print(f\"list_1: {list_1}\") # [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b8491a",
   "metadata": {},
   "source": [
    "Why did `list_2` not return `[1]`? The issue lies in the default argument\n",
    "`some_list: List[T] = []`. This default argument is evaluated only once, when\n",
    "the function is defined, and not every time the function is called. This means\n",
    "that the same list is used every time the function is called without the\n",
    "`some_list` argument. This means that if you use a mutable default argument and\n",
    "mutate it, you will and have mutated that object for all future calls to the\n",
    "function as well. And if you print `list_1` again after `list_2`, you will see\n",
    "that `list_1` has also been mutated!\n",
    "\n",
    "To fix this, you can use `None` as the default argument and then initialize the\n",
    "list inside the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cc778d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_list(item: T, some_list: List[T] | None = None) -> List[T]:\n",
    "    if some_list is None:\n",
    "        some_list = []\n",
    "    some_list.append(item)\n",
    "    return some_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74ee4a",
   "metadata": {},
   "source": [
    "Then the function will behave as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a0296d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_1: [0]\n",
      "list_2: [1]\n"
     ]
    }
   ],
   "source": [
    "list_1 = add_to_list(0)  # [0]\n",
    "list_2 = add_to_list(1)  # [1]\n",
    "print(f\"list_1: {list_1}\")\n",
    "print(f\"list_2: {list_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b08b7",
   "metadata": {},
   "source": [
    "If this goes into **production**, it could lead to a **bug** that is _hard_ to\n",
    "catch.\n",
    "\n",
    "#### Tools\n",
    "\n",
    "In the industry, there are a few leading tools:\n",
    "\n",
    "-   [Pylint](https://pylint.pycqa.org/en/latest/index.html)\n",
    "-   [Flake8](https://flake8.pycqa.org/en/latest/)\n",
    "-   [Ruff](https://docs.astral.sh/ruff/)\n",
    "\n",
    "Ruff is a new entrant in the market and is gaining popularity due to its speed\n",
    "as it is written in Rust. Whichever the tool the team choose, the key is to\n",
    "ensure that it is integrated into the development workflow consistently.\n",
    "\n",
    "#### Best Practices for Linting and CI/CD Pipeline Integration\n",
    "\n",
    "##### Automate Linting and Integration with CI/CD Pipelines\n",
    "\n",
    "Integrating linting into a CI/CD pipeline typically involves the following\n",
    "steps:\n",
    "\n",
    "1. **Configuration**: Define linting rules in a configuration file. This file is\n",
    "   then placed in the project repository.\n",
    "\n",
    "2. **Pipeline Setup**: In the CI/CD system, create a job or stage specifically\n",
    "   for linting. This job will execute whenever a new commit is pushed to the\n",
    "   repository.\n",
    "\n",
    "3. **Running Linter**: During the linting stage, the CI/CD system runs the\n",
    "   linter against the codebase using the defined rules.\n",
    "\n",
    "4. **Handling Linting Results**: If the linter finds issues, it can fail the\n",
    "   build, preventing further stages (like testing or deployment) until the\n",
    "   issues are resolved.\n",
    "\n",
    "5. **Feedback to Developers**: The results of the linting process are reported\n",
    "   back to the developers, usually through the CI/CD system's interface or via\n",
    "   notifications.\n",
    "\n",
    "This integration ensures that code quality checks are an automated and\n",
    "consistent part of the development cycle.\n",
    "\n",
    "##### Local and CI Environment Consistency\n",
    "\n",
    "The remote Continuous Integration (CI) environment is a safety net and quality\n",
    "gate for the codebase. This does not mean you should wait for feedback from the\n",
    "CI environment to fix issues.\n",
    "\n",
    "Why? Imagine you committed a large piece of code without any regards to the\n",
    "linting rules. The CI environment will fail, and you will have to fix the issues\n",
    "and push the code again. Then again, there is no guarantee that the CI\n",
    "environment will pass. This is a waste of time and resources.\n",
    "\n",
    "What should you do? You should lint your code locally before pushing it to the\n",
    "remote repository. This will ensure that the CI environment will pass, and you\n",
    "will not have to wait for feedback from the CI environment.\n",
    "\n",
    "Consequently, it is essential to maintain consistency between the local\n",
    "development environment and the CI environment. This consistency ensures that\n",
    "the code behaves consistently across different setups. In other words, the lint\n",
    "rules defined locally should be the same as those defined in the CI environment.\n",
    "One source of truth is the mantra that should be followed, if not, a rule\n",
    "defined in CI which is not defined locally may fail the build. Conversely, a\n",
    "locally defined rule A might not be defined in the CI environment, leading to a\n",
    "false sense of security.\n",
    "\n",
    "##### Pre-Commit Hooks\n",
    "\n",
    "Pre-commit hooks are scripts that run before a commit is made. They are a\n",
    "powerful tool for ensuring that code quality checks are performed before\n",
    "commits. This can include linting, formatting, and other checks such as testing.\n",
    "This is a good to have as it injects some sort of discipline and automation into\n",
    "the local development environment.\n",
    "\n",
    "##### Order in Pipeline\n",
    "\n",
    "In a CI/CD pipeline, the typical sequence is to lint first, then format, and\n",
    "finally run unit tests. Linting first helps catch syntax errors and code smells\n",
    "early, reducing the likelihood of these issues causing test failures. Formatting\n",
    "next ensures code consistency, and finally, unit tests validate the\n",
    "functionality. This order optimizes the build process, catching errors\n",
    "efficiently and maintaining code quality.\n",
    "\n",
    "### Formatting\n",
    "\n",
    "What is formatting? Formatting is the process of ensuring that the codebase\n",
    "adheres to a consistent style/format. This includes indentation, line length and\n",
    "spacing, among other things. The goal is to make the codebase more readable and\n",
    "maintainable. This will reduce friction in code reviews. Imagine the frustration\n",
    "if developer A uses a 120 character line length and developer B uses 80\n",
    "characters. They will not be in sync with each other.\n",
    "\n",
    "#### What is the Difference between Linting and Formatting?\n",
    "\n",
    "The difference might be nuanced and isn't clear. The tagline, **linters for\n",
    "catching errors and quality, formatters to fix code formatting style** can be\n",
    "demonstrated with an example:\n",
    "\n",
    "```python\n",
    "from typing import List, TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def add_to_list_and_purposely_make_the_list_very_very_very_long(item: T, some_list: List[T] = []) -> List[T]:\n",
    "    some_list.append(item)\n",
    "    return some_list\n",
    "```\n",
    "\n",
    "-   Our linter will complain something like \"Mutable default argument\" as this\n",
    "    is a potential bug. This is where our linter such as `ruff` or `pylint` will\n",
    "    come into play. The linter will suggest to you to take action but won't take\n",
    "    action for you. Furthermore, a formatter such as `black` won't catch this\n",
    "    issue because they are not designed to catch such issues.\n",
    "\n",
    "-   Our linter and formatter will also see another glaring issue, that is the\n",
    "    `if` line is too long, exceeding the `PEP8` standard of $79$ length. Both\n",
    "    `black` and `ruff` will tell us this, but `black` will perform an\n",
    "    **in-place** treatment, formatting the code on the go for you, whereas\n",
    "    `ruff` will just tell you.\n",
    "\n",
    "Therefore, the coding world generally uses a formatter (`black`) and a linter\n",
    "(`ruff`) in tandem.\n",
    "\n",
    "#### Tools\n",
    "\n",
    "In the industry, there are a few leading tools:\n",
    "\n",
    "-   [Black](https://black.readthedocs.io/en/stable/)\n",
    "-   [Ruff](https://docs.astral.sh/ruff/)\n",
    "\n",
    "Interestingly, `ruff` serves as both a linter and a formatter, so we can have an\n",
    "all in one package. However, `black` seems to be the most popular formatter in\n",
    "the Python and generally, more matured.\n",
    "\n",
    "Many teams also add in `isort` to sort the imports. This is a good practice as\n",
    "it makes the imports more readable.\n",
    "\n",
    "#### Best Practices for Formatting and CI/CD Pipeline Integration\n",
    "\n",
    "In general, the best practices for formatting are similar to those for linting.\n",
    "The key is to ensure that the formatting tool is integrated into the development\n",
    "workflow consistently.\n",
    "\n",
    "### Where to Start?\n",
    "\n",
    "-   [PyTorch](https://github.com/pytorch/pytorch/blob/main/pyproject.toml)\n",
    "-   [OpenAI](https://github.com/openai/openai-python/blob/main/pyproject.toml)\n",
    "-   [FastAPI](https://github.com/tiangolo/fastapi/blob/master/pyproject.toml)\n",
    "\n",
    "### References and Further Readings\n",
    "\n",
    "-   [Code Style Checks - Microsoft](https://microsoft.github.io/code-with-engineering-playbook/continuous-integration/#code-style-checks)\n",
    "-   [Code Analysis Linting - Microsoft](https://microsoft.github.io/code-with-engineering-playbook/code-reviews/recipes/python/#code-analysis-linting)\n",
    "-   [Differences between code linters and formatters](https://taiyr.me/what-is-the-difference-between-code-linters-and-formatters)\n",
    "-   [Format Code vs Lint Code](https://medium.com/@awesomecode/format-code-vs-and-lint-code-95613798dcb3)\n",
    "-   [PEP8 guide](https://peps.python.org/pep-0008/)\n",
    "-   [Pre-commits Styling](https://ljvmiranda921.github.io/notebook/2018/06/21/precommits-using-black-and-flake8/)\n",
    "\n",
    "## References and Further Readings\n",
    "\n",
    "-   [Welcome to pre-commit heaven - Marvelous MLOps Substack](https://marvelousmlops.substack.com/i/130911126)\n",
    "-   [MLOps Basics [Week 6]: CI/CD - GitHub Actions](https://www.ravirajag.dev/blog/mlops-github-actions)\n",
    "-   [CI/CD for Machine Learning](https://madewithml.com/courses/mlops/cicd/)\n",
    "-   [Stop saying \"technical debt\" - Stack Overflow](https://stackoverflow.blog/2023/12/27/stop-saying-technical-debt/)\n",
    "-   [Is Python strongly typed? - Stack Overflow](https://stackoverflow.com/questions/11328920/is-python-strongly-typed)\n",
    "-   [Chapter 6. Monitoring Distributed Systems - Google SRE](https://sre.google/sre-book/monitoring-distributed-systems/)\n",
    "-   \"Chapter 9. Continual Learning and Test in Production.\" In Designing Machine\n",
    "    Learning Systems: An Iterative Process for Production-Ready Applications,\n",
    "    O'Reilly Media, Inc., 2022.\n",
    "\n",
    "[^stop_saying_technical_debt]:\n",
    "    [Stop saying \"technical debt\" - Stack Overflow](https://stackoverflow.blog/2023/12/27/stop-saying-technical-debt/)\n",
    "\n",
    "[^python_strongly_and_dynamic_typing]:\n",
    "    [Is Python strongly typed? - Stack Overflow](https://stackoverflow.com/questions/11328920/is-python-strongly-typed)\n",
    "\n",
    "[^google-sre-monitoring]:\n",
    "    [Chapter 6. Monitoring Distributed Systems - Google SRE](https://sre.google/sre-book/monitoring-distributed-systems/)\n",
    "\n",
    "[^1]:\n",
    "    [Deliver Quickly and Daily - Microsoft](https://microsoft.github.io/code-with-engineering-playbook/continuous-integration/#deliver-quickly-and-daily)\n",
    "\n",
    "[^2]: [Common Gotchas](https://docs.python-guide.org/writing/gotchas/)\n",
    "[^unit-test-1]:\n",
    "    [Why Unit Tests - Microsoft](https://microsoft.github.io/code-with-engineering-playbook/automated-testing/unit-testing/why-unit-tests/)\n",
    "\n",
    "[^unit-test-2]:\n",
    "    [Why Integration Testing - Microsoft](https://microsoft.github.io/code-with-engineering-playbook/automated-testing/integration-testing/#why-integration-testing)\n",
    "\n",
    "[^unit-test-3]:\n",
    "    [Unit vs Integration vs System vs E2E Testing](https://microsoft.github.io/code-with-engineering-playbook/automated-testing/e2e-testing/testing-comparison/)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "mystnb": {
   "number_source_lines": true
  },
  "source_map": [
   16,
   1293,
   1327,
   1343,
   1363,
   2147,
   2157,
   2162,
   2170,
   2184,
   2190,
   2194,
   2199
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}