{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c414de",
   "metadata": {},
   "source": [
    "# Stage 9. Model Monitoring (MLOps)\n",
    "\n",
    "[![Twitter Handle](https://img.shields.io/badge/Twitter-@gaohongnan-blue?style=social&logo=twitter)](https://twitter.com/gaohongnan)\n",
    "[![LinkedIn Profile](https://img.shields.io/badge/@gaohongnan-blue?style=social&logo=linkedin)](https://linkedin.com/in/gao-hongnan)\n",
    "[![GitHub Profile](https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&logo=github)](https://github.com/gao-hongnan)\n",
    "![Tag](https://img.shields.io/badge/Tag-Brain_Dump-red)\n",
    "![Tag](https://img.shields.io/badge/Level-Beginner-green)\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    "```\n",
    "\n",
    "Model monitoring is about continuously tracking the performance of models in\n",
    "production to ensure that they continue to provide accurate and reliable\n",
    "predictions.\n",
    "\n",
    "-   **Performance Monitoring**: Regularly evaluate the model's performance\n",
    "    metrics in production. This includes tracking metrics like accuracy,\n",
    "    precision, recall, F1 score for classification problems, or Mean Absolute\n",
    "    Error (MAE), Root Mean Squared Error (RMSE) for regression problems, etc.\n",
    "\n",
    "-   **Data Drift Monitoring**: Over time, the data that the model receives can\n",
    "    change. These changes can lead to a decrease in the model's performance.\n",
    "    Therefore, it's crucial to monitor the data the model is scoring on to\n",
    "    detect any drift from the data the model was trained on.\n",
    "\n",
    "-   **Model Retraining**: If the performance of the model drops or significant\n",
    "    data drift is detected, it might be necessary to retrain the model with new\n",
    "    data. The model monitoring should provide alerts or triggers for such\n",
    "    situations.\n",
    "\n",
    "-   **A/B Testing**: In case multiple models are in production, monitor their\n",
    "    performances comparatively through techniques like A/B testing to determine\n",
    "    which model performs better.\n",
    "\n",
    "In each of these stages, it's essential to keep in mind principles like\n",
    "reproducibility, automation, collaboration, and validation to ensure the\n",
    "developed models are reliable, efficient, and providing value to the\n",
    "organization.\n",
    "\n",
    "## Intuition\n",
    "\n",
    "Even though we've trained and thoroughly evaluated our model, the real work\n",
    "begins once we deploy to production. This is one of the fundamental differences\n",
    "between traditional software engineering and ML development. Traditionally, with\n",
    "rule-based, deterministic software, the majority of the work occurs at the\n",
    "initial stage and once deployed, our system works as we've defined it. But with\n",
    "machine learning, we haven't explicitly defined how something works but used\n",
    "data to architect a probabilistic solution. This approach is subject to natural\n",
    "performance degradation over time, as well as unintended behavior, since the\n",
    "data exposed to the model will be different from what it has been trained on.\n",
    "This isn't something we should be trying to avoid but rather understand and\n",
    "mitigate as much as possible. In this lesson, we'll understand the shortcomings\n",
    "from attempting to capture performance degradation in order to motivate the need\n",
    "for **drift detection**.\n",
    "\n",
    "## System Health\n",
    "\n",
    "The first step to ensure that our model is performing well is to ensure that the\n",
    "actual system is up and running as it should. This can include metrics specific\n",
    "to service requests such as latency, throughput, error rates, etc. as well as\n",
    "infrastructure utilization such as CPU/GPU utilization, memory, etc.\n",
    "\n",
    "## System Health Dashboard\n",
    "\n",
    "Fortunately, most cloud providers and even orchestration layers will provide\n",
    "this insight into our system's health for free through a dashboard. In the event\n",
    "we don't, we can easily use [Grafana](https://grafana.com/),\n",
    "[Datadog](https://www.datadoghq.com/), etc. to ingest system performance metrics\n",
    "from logs to create a customized dashboard and set alerts.\n",
    "\n",
    "## Examples\n",
    "\n",
    "The plot shows both the cumulative mean squared error (MSE) and the sliding MSE\n",
    "over time.\n",
    "\n",
    "The x-axis represents the hour since the model has been deployed, and the y-axis\n",
    "represents the MSE. The \"Threshold\" line is a hypothetical threshold that we set\n",
    "for the MSE; we could say that any MSE above this threshold would indicate that\n",
    "the model's performance is not satisfactory.\n",
    "\n",
    "We can see that both the cumulative and sliding MSE start reasonably low, but\n",
    "after some time, they start to increase, indicating that the model's performance\n",
    "is degrading. The sliding MSE is more responsive to recent changes in the\n",
    "model's performance and hence it rises above the threshold before the cumulative\n",
    "MSE. This is why it's beneficial to monitor both cumulative and sliding\n",
    "metrics - they give us different insights into the model's performance over\n",
    "time.\n",
    "\n",
    "## MY OLD EXAMPLE TO REFINE\n",
    "\n",
    "Model monitoring and data drift monitoring are key components in maintaining the\n",
    "performance of any predictive model over time. Here are the key aspects to\n",
    "consider for your Bitcoin price prediction model:\n",
    "\n",
    "1. **Model Performance Monitoring**: Regularly evaluate your model's performance\n",
    "   metrics such as accuracy, precision, recall, F1-score, AUC-ROC, etc.,\n",
    "   depending on the nature of your problem (classification, regression, etc.).\n",
    "   Track these metrics over time. If there's a substantial decrease, your model\n",
    "   might need retraining or updating.\n",
    "\n",
    "2. **Data Drift Monitoring**: This involves checking if the distribution of the\n",
    "   model's input data is changing over time. You want to make sure that the data\n",
    "   your model was trained on is representative of the data it is making\n",
    "   predictions on. If the data drifts too much, the model’s performance might\n",
    "   decrease.\n",
    "\n",
    "    To monitor data drift, you can use a two-sample t-test, which compares the\n",
    "    means of two groups to determine if they're significantly different. Here's\n",
    "    how to do it:\n",
    "\n",
    "    - Consider one feature at a time. For instance, start with 'Volume'.\n",
    "    - From your current data, take a sample. Compute its mean (let's call it\n",
    "      mean1) and standard deviation (std1).\n",
    "    - Take a sample of the same size from the data your model was trained on.\n",
    "      Compute its mean (mean2) and standard deviation (std2).\n",
    "    - Use the t-test formula to calculate the t-score. The formula is\n",
    "      `t = (mean1 - mean2) / sqrt((std1^2/n1) + (std2^2/n2))`, where n1 and n2\n",
    "      are the sizes of your samples.\n",
    "    - If the absolute t-score is large (greater than the critical t-value for\n",
    "      your desired confidence level), then the means are significantly\n",
    "      different, indicating data drift.\n",
    "\n",
    "    The resulting `t` value (t-score) is a measure of the size of the difference\n",
    "    relative to the variation in your data. A large absolute t-score means that\n",
    "    the difference in means is large relative to the variability of the data,\n",
    "    which suggests that the means are significantly different. This would be an\n",
    "    indication of data drift.\n",
    "\n",
    "    Remember to conduct this test for all relevant features ('Open', 'Close',\n",
    "    'Volume', etc.) and over regular intervals (daily, weekly, etc.) to ensure\n",
    "    continuous monitoring.\n",
    "\n",
    "3. **Concept Drift Monitoring**: Sometimes, even if the data distribution stays\n",
    "   the same, the underlying relationship between the input features and the\n",
    "   target variable might change. This is called concept drift. To monitor this,\n",
    "   you can look for a decrease in your model's performance over time, even when\n",
    "   there's no significant data drift.\n",
    "\n",
    "Lastly, while t-tests can help in identifying drifts, they are just one part of\n",
    "the puzzle. Monitoring residuals (the differences between your model’s\n",
    "predictions and the actual values) can also provide insights into whether the\n",
    "model is continuing to perform well.\n",
    "\n",
    "## Monitor 2\n",
    "\n",
    "When monitoring your model and data for drifts in the context of predicting\n",
    "Bitcoin price increase or decrease, there are a few techniques you can consider,\n",
    "including statistical tests such as t-tests. Here's a general overview:\n",
    "\n",
    "1. Model Monitoring: It involves monitoring the performance of your predictive\n",
    "   model over time to ensure its accuracy and reliability. Some techniques for\n",
    "   model monitoring include:\n",
    "\n",
    "    - Tracking key performance metrics like accuracy, precision, recall, or mean\n",
    "      absolute error.\n",
    "    - Monitoring model output distributions to detect significant changes or\n",
    "      shifts.\n",
    "    - Comparing model predictions with actual outcomes to identify\n",
    "      discrepancies.\n",
    "\n",
    "2. Data Monitoring: It involves monitoring the input data used by your model to\n",
    "   detect any changes or drifts that may impact the model's performance. Here\n",
    "   are a few methods for data monitoring:\n",
    "    - Statistical tests: T-tests can be used to compare statistical properties\n",
    "      (e.g., means) of different data subsets or time periods. For example, you\n",
    "      can compare Bitcoin price increase predictions for different time\n",
    "      intervals to identify significant differences.\n",
    "    - Control charts: These graphical tools help detect shifts or anomalies in\n",
    "      data distribution, allowing you to identify potential drifts.\n",
    "    - Concept drift detection: Techniques like change point detection algorithms\n",
    "      or sliding window approaches can be employed to detect significant changes\n",
    "      in the underlying data distribution.\n",
    "\n",
    "Remember, model and data monitoring should be an ongoing process to ensure the\n",
    "reliability of your predictions. Regularly evaluating and updating your model\n",
    "can help account for evolving market dynamics and improve its performance.\n",
    "\n",
    "## Drift _madewithml_\n",
    "\n",
    "$$\n",
    "\\begin{array}{|lll|}\n",
    "\\hline \\text { Entity } & \\text { Description } & \\text { Drift } \\\\\n",
    "\\hline X & \\text { inputs (features) } & \\text { data drift } \\rightarrow P(X) \\neq P_{\\text {ref }}(X) \\\\\n",
    "\\hline y & \\text { outputs (ground-truth) } & \\text { target drift } \\rightarrow P(y) \\neq P_{\\text {ref }}(y) \\\\\n",
    "\\hline P(y \\mid X) & \\text { actual relationship between } X \\text { and } y & \\text { concept drift } \\rightarrow P(y \\mid X) \\neq P_{r e f}(y \\mid X) \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "## Concept Drift\n",
    "\n",
    "Sometimes, even if the data distribution stays the same, the underlying\n",
    "relationship between the input features and the target variable might change.\n",
    "This is called concept drift. To monitor this, you can look for a decrease in\n",
    "your model's performance over time, even when there's no significant data drif\n",
    "\n",
    "Let's consider a concrete example of concept drift in the context of a movie\n",
    "recommendation system.\n",
    "\n",
    "Suppose you have a movie recommendation algorithm that takes into account\n",
    "factors like user's age, genre preferences, and ratings of previously watched\n",
    "movies to recommend new movies. The model is trained on a dataset and works well\n",
    "initially, giving good recommendations and having a high click-through rate.\n",
    "\n",
    "Over time, however, you notice that even though the distribution of the user's\n",
    "age, genre preferences, and ratings of previously watched movies (your input\n",
    "features) stays the same, the click-through rate of the recommended movies (your\n",
    "target variable) starts to decrease. This indicates that the relationship\n",
    "between the input features and the target variable has changed.\n",
    "\n",
    "Why might this happen? One possible reason is a change in movie trends. Perhaps\n",
    "when the model was initially trained, action movies were very popular. But over\n",
    "time, the popularity of action movies has decreased and documentaries have\n",
    "become more popular. The model, however, is still biased towards recommending\n",
    "action movies because that's what worked when it was initially trained. This is\n",
    "an example of concept drift: the underlying concept – what kind of movies are\n",
    "likely to be clicked on – has changed, even though the distribution of the input\n",
    "features has not.\n",
    "\n",
    "To monitor this, you would track the performance of your model over time. If you\n",
    "see a decrease in performance – in this case, a decrease in the click-through\n",
    "rate – that could be an indication of concept drift. You might then decide to\n",
    "retrain your model on more recent data, or to revise it to take into account\n",
    "more recent trends in movie popularity."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "mystnb": {
   "number_source_lines": true
  },
  "source_map": [
   16
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}