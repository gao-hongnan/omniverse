{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f62095",
   "metadata": {},
   "source": [
    "# Overview Of Concurrency, Parallelism, and Asynchronous Execution\n",
    "\n",
    "[![Twitter Handle](https://img.shields.io/badge/Twitter-@gaohongnan-blue?style=social&logo=twitter)](https://twitter.com/gaohongnan)\n",
    "[![LinkedIn Profile](https://img.shields.io/badge/@gaohongnan-blue?style=social&logo=linkedin)](https://linkedin.com/in/gao-hongnan)\n",
    "[![GitHub Profile](https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&logo=github)](https://github.com/gao-hongnan)\n",
    "![Tag](https://img.shields.io/badge/Tag-Brain_Dump-red)\n",
    "![Tag](https://img.shields.io/badge/Level-Beginner-green)\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    "```\n",
    "\n",
    "## The Problem: Synchronous Execution In Single Process And Single Thread\n",
    "\n",
    "In general, and by default, a normal Python program runs as a single process\n",
    "with a single thread. This is known as the \"main thread\" within the \"main\n",
    "process\".\n",
    "\n",
    "1. Single Process: When you run a Python script, the Python interpreter starts a\n",
    "   single process to execute that script. This process is assigned by the\n",
    "   operating system and has its own memory space.\n",
    "\n",
    "2. Single Thread: Within this process, Python starts with a single thread of\n",
    "   execution, often referred to as the \"main thread\". This thread is responsible\n",
    "   for executing your code sequentially from top to bottom.\n",
    "\n",
    "3. Global Interpreter Lock (GIL): It's worth noting that CPython (the standard\n",
    "   Python implementation) uses a Global Interpreter Lock (GIL), which allows\n",
    "   only one thread to execute Python bytecode at a time, even on multi-core\n",
    "   processors. We will see later to circumvent this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8005cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main thread with PID: 4005, TID: 139914812608640\n",
      "Worker thread started with PID: 4005, TID: 139914812608640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker thread finished.\n",
      "Main thread completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def worker() -> None:\n",
    "    print(f\"Worker thread started with PID: {os.getpid()}, TID: {threading.get_ident()}\")\n",
    "    time.sleep(1)\n",
    "    print(\"Worker thread finished.\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    print(f\"Main thread with PID: {os.getpid()}, TID: {threading.get_ident()}\")\n",
    "    worker()\n",
    "    print(\"Main thread completed.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241407c8",
   "metadata": {},
   "source": [
    "And if we want to say, run 3 workers to do some tasks independently, we can do\n",
    "it sequentially like below:\n",
    "\n",
    "```python\n",
    "workers = [worker, worker, worker]\n",
    "\n",
    "for worker in workers:\n",
    "    worker()\n",
    "```\n",
    "\n",
    "This would take 3 seconds to run, as each worker runs sequentially. This is\n",
    "uncalled for since each worker is doing an independent task. If we can somehow\n",
    "run each workers concurrently or in parallel, we can reduce the execution time\n",
    "to 1 second. This is where concurrency or parallelism comes in.\n",
    "\n",
    "## CPU Bound\n",
    "\n",
    "### Definition: What is CPU-Bound?\n",
    "\n",
    "A **CPU-bound operation** refers to a type of task that primarily utilizes the\n",
    "Central Processing Unit (CPU) for its execution. These operations are limited by\n",
    "the CPU's processing power rather than by input/output (I/O) activities such as\n",
    "disk reads/writes or network communication. In other words, the speed at which a\n",
    "CPU-bound task runs is determined by how fast the CPU can perform computations,\n",
    "making efficient CPU usage crucial for performance.\n",
    "\n",
    "-   Single Core CPU means that a CPU-bound task will be executed by a single\n",
    "    core without any parallelism.\n",
    "-   Multi Core CPU means that a CPU-bound task can be executed by multiple cores\n",
    "    with parallelism.\n",
    "\n",
    "### Example: Calculating Prime Numbers\n",
    "\n",
    "Consider the task of finding all prime numbers up to a large number _n_. This\n",
    "task involves intensive computations—checking each number for primality—which\n",
    "requires significant CPU resources. The operation doesn't depend on waiting for\n",
    "data from external sources but relies entirely on the CPU's ability to perform\n",
    "calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f52e17f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of primes up to 100000: 9592\n"
     ]
    }
   ],
   "source": [
    "from math import isqrt\n",
    "from typing import List\n",
    "\n",
    "def is_prime(number: int) -> bool:\n",
    "    if number < 2:\n",
    "        return False\n",
    "    for divisor in range(2, isqrt(number) + 1):\n",
    "        if number % divisor == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_primes(limit: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Find all prime numbers up to a given limit.\n",
    "    \"\"\"\n",
    "    primes: List[int] = []\n",
    "    for num in range(2, limit + 1):\n",
    "        if is_prime(num):\n",
    "            primes.append(num)\n",
    "    return primes\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main function to execute the prime number search.\n",
    "    \"\"\"\n",
    "    limit: int = 100000\n",
    "    primes: List[int] = find_primes(limit)\n",
    "    print(f\"Number of primes up to {limit}: {len(primes)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb92a27c",
   "metadata": {},
   "source": [
    "#### Why It's CPU-Bound\n",
    "\n",
    "| Aspect                    | Description                                                                                                                                  |\n",
    "| ------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| Computational Intensity   | The process involves numerous calculations, especially for large limits, making the CPU the bottleneck.                                      |\n",
    "| Lack of I/O Wait          | The operations do not involve waiting for external resources like disk I/O or network responses; the CPU continuously works on computations. |\n",
    "| Impact of CPU Performance | Faster CPUs or more efficient algorithms can significantly reduce the computation time for CPU-bound tasks.                                  |\n",
    "\n",
    "## I/O Bound\n",
    "\n",
    "### Definition: What is I/O-Bound?\n",
    "\n",
    "An **I/O-bound operation** refers to a type of task that is limited by the\n",
    "system's input/output (I/O) capabilities rather than its CPU processing power.\n",
    "These operations spend more time waiting for I/O activities, such as reading\n",
    "from or writing to disk, network communication, or user input, than performing\n",
    "computations. As a result, the overall performance of I/O-bound tasks is\n",
    "primarily constrained by the speed and efficiency of the I/O subsystem.\n",
    "\n",
    "### Example: Reading A Website\n",
    "\n",
    "Consider the task of fetching data from multiple web APIs. Each HTTP request\n",
    "involves network communication, where the program waits for the server to\n",
    "respond. The performance of this task is limited by the network latency and the\n",
    "response time of the servers, making it an I/O-bound operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578f46c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 102975 from https://www.gaohongnan.com/intro.html\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "def download_site(url: str, session: requests.Session) -> None:\n",
    "    with session.get(url) as response:\n",
    "        print(f\"Read {len(response.content)} from {url}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.gaohongnan.com/intro.html\"\n",
    "    session = requests.Session()\n",
    "    download_site(url, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099307e9",
   "metadata": {},
   "source": [
    "#### Why It's I/O-Bound\n",
    "\n",
    "| Aspect                     | Description                                                                                                                                |\n",
    "| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| Waiting for I/O Operations | The task spends a significant amount of time waiting for the network response from the website.                                            |\n",
    "| Limited by Network Latency | The speed of data transfer over the internet and the responsiveness of the server affect performance.                                      |\n",
    "| Minimal CPU Usage          | The CPU remains largely idle while waiting for the I/O operations to complete, as the primary activity is data retrieval over the network. |\n",
    "\n",
    "## Comparison of CPU-Bound and I/O-Bound Operations\n",
    "\n",
    "| Aspect                  | CPU-Bound Operations                             | I/O-Bound Operations                            |\n",
    "| ----------------------- | ------------------------------------------------ | ----------------------------------------------- |\n",
    "| Primary Limitation      | CPU processing power                             | I/O subsystem speed (network, devices, etc.)    |\n",
    "| Example Tasks           | Calculating prime numbers, data encryption       | Making HTTP requests, database queries          |\n",
    "| Performance Factors     | CPU speed, number of cores, algorithm efficiency | Network latency, I/O bandwidth, device speed    |\n",
    "| Optimization Strategies | Efficient algorithms, parallel processing        | Asynchronous I/O, caching, faster I/O solutions |\n",
    "\n",
    "```{admonition} See Also\n",
    ":class: seealso\n",
    "\n",
    "-   [When Is Concurrency Useful?](https://realpython.com/python-concurrency/#when-is-concurrency-useful)\n",
    "```\n",
    "\n",
    "## Visualization of Process and Thread\n",
    "\n",
    "Here's a simple diagram to visualize the relationship:\n",
    "\n",
    "```text\n",
    "+--------------------------------------------------+\n",
    "|                 Operating System                 |\n",
    "|  +--------------------+  +--------------------+  |\n",
    "|  |      Process A     |  |      Process B     |  |\n",
    "|  |  +---------------+ |  |  +---------------+ |  |\n",
    "|  |  |    Thread 1   | |  |  |    Thread 1   | |  |\n",
    "|  |  +---------------+ |  |  +---------------+ |  |\n",
    "|  |  +---------------+ |  |  +---------------+ |  |\n",
    "|  |  |    Thread 2   | |  |  |    Thread 2   | |  |\n",
    "|  |  +---------------+ |  |  +---------------+ |  |\n",
    "|  |        ...         |  |        ...         |  |\n",
    "|  +--------------------+  +--------------------+  |\n",
    "|                                                  |\n",
    "+--------------------------------------------------+\n",
    "```\n",
    "\n",
    "-   The **Operating System (OS)** manages multiple independent **processes**.\n",
    "-   Each **process** can have one or more **threads**.\n",
    "-   **Threads** within the same **process** share the same memory space, whereas\n",
    "    **processes** are isolated from one another.\n",
    "\n",
    "## Process\n",
    "\n",
    "### Definition: What is a Process?\n",
    "\n",
    "A **process** is an independent program in execution, with its own memory space\n",
    "and system resources. are isolated from each other, meaning one process cannot\n",
    "directly access the memory of another process.\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "-   **Isolation:** Each process operates in its own memory space. This isolation\n",
    "    ensures that one process cannot directly interfere with the memory of\n",
    "    another, enhancing stability and security.\n",
    "-   **Resource Allocation:** Processes have their own set of resources,\n",
    "    including memory, file handles, and system resources.\n",
    "-   **Inter-Process Communication (IPC):** Since processes are isolated,\n",
    "    communication between them requires explicit mechanisms like pipes, sockets,\n",
    "    shared memory, or message queues.\n",
    "-   **Overhead:** Creating and managing processes typically incurs more overhead\n",
    "    compared to threads due to the isolation and resource allocation involved.\n",
    "\n",
    "-   **In Python:**\n",
    "    -   The `multiprocessing` module allows the creation of separate processes,\n",
    "        each with its own Python interpreter and memory space.\n",
    "    -   This bypasses the **Global Interpreter Lock (GIL)**, enabling true\n",
    "        parallelism for CPU-bound tasks.\n",
    "\n",
    "### Example: Two Scripts Running Simultaneously\n",
    "\n",
    "Say we have two scripts, `script1.py` and `script2.py`.\n",
    "\n",
    "````{tab} Script 1\n",
    "```python\n",
    "import time\n",
    "\n",
    "def main() -> None:\n",
    "    print(\"Script 1 started\")\n",
    "    time.sleep(20)\n",
    "    print(\"Script 1 completed\")\n",
    "```\n",
    "````\n",
    "\n",
    "````{tab} Script 2\n",
    "```python\n",
    "import time\n",
    "\n",
    "def main() -> None:\n",
    "    print(\"Script 2 started\")\n",
    "    time.sleep(20)\n",
    "    print(\"Script 2 completed\")\n",
    "```\n",
    "````\n",
    "\n",
    "During the execution of `script1.py`, the OS will create a new process to run\n",
    "the script. At the same time, another new process will be created to run\n",
    "`script2.py`. The scripts will print their process ID, like below:\n",
    "\n",
    "````{tab} Script 1 Output\n",
    "```bash\n",
    "Script 1 started with PID: 12345\n",
    "```\n",
    "````\n",
    "\n",
    "````{tab} Script 2 Output\n",
    "```bash\n",
    "Script 2 started with PID: 12346\n",
    "```\n",
    "````\n",
    "\n",
    "We can see they are two processes by using the `ps` command in the terminal.\n",
    "\n",
    "```bash\n",
    "ps aux | grep -E \"script1.py|script2.py\" | grep -v grep\n",
    "```\n",
    "\n",
    "This will yield something like:\n",
    "\n",
    "```bash\n",
    "gaohn      12345  0.0  0.0  111111  1111  ??  S    11:11AM   0:00.00 /usr/bin/python3 /Users/gaohn/gaohn/omniverse/sandbox.py\n",
    "gaohn      12346  0.0  0.0  111111  1111  ??  S    11:11AM   0:00.00 /usr/bin/python3 /Users/gaohn/gaohn/omniverse/sandbox.py\n",
    "```\n",
    "\n",
    "Also note that your applications are also processes. Google Chrome is a process,\n",
    "slack is a process, discord is a process, etc.\n",
    "\n",
    "### Process ID\n",
    "\n",
    "To get the process ID of the current process, we can use the `os.getpid()`\n",
    "function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d1d89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current process ID: 4005\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(f\"Current process ID: {os.getpid()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643b853",
   "metadata": {},
   "source": [
    "To list all processes, we can use the `psutil` library.\n",
    "\n",
    "```python\n",
    "import psutil\n",
    "import contextlib\n",
    "\n",
    "total_processes = len(psutil.pids())\n",
    "print(f\"Total Processes: {total_processes}\")\n",
    "\n",
    "for proc in psutil.process_iter([\"pid\", \"name\", \"num_threads\"]):\n",
    "    with contextlib.suppress(psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
    "        print(f\"PID: {proc.info['pid']}, Name: {proc.info['name']}, Threads: {proc.info['num_threads']}\")\n",
    "```\n",
    "\n",
    "## Thread\n",
    "\n",
    "### Definition: What is a Thread?\n",
    "\n",
    "A **thread** is the smallest sequence of programmed instructions that can be\n",
    "managed independently by a scheduler. Threads exist within a process and share\n",
    "the same memory and resources of that process.\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "-   **Shared Memory Space:** Threads within the same process share the same\n",
    "    memory, allowing for efficient communication and data sharing.\n",
    "-   **Lightweight:** Creating and managing threads generally incurs less\n",
    "    overhead compared to processes because they share the same memory space.\n",
    "-   **Concurrency:** Multiple threads can execute concurrently within the same\n",
    "    process, which is beneficial for I/O-bound tasks.\n",
    "-   **Synchronization:** Shared memory necessitates synchronization mechanisms\n",
    "    (like locks, semaphores) to prevent race conditions and ensure data\n",
    "    integrity.\n",
    "\n",
    "-   **In Python:**\n",
    "    -   The `threading` module facilitates the creation of threads within a\n",
    "        process.\n",
    "    -   However, due to the **Global Interpreter Lock (GIL)** in CPython,\n",
    "        threads cannot execute Python bytecodes in true parallelism for\n",
    "        CPU-bound tasks. They are, however, effective for I/O-bound operations.\n",
    "\n",
    "### Example: Python Program On Single Process And Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39fbbc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main thread with PID: 4005, TID: 139914812608640\n",
      "Worker thread started with PID: 4005, TID: 139914812608640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker thread finished.\n",
      "Main thread completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def worker() -> None:\n",
    "    print(f\"Worker thread started with PID: {os.getpid()}, TID: {threading.get_ident()}\")\n",
    "    time.sleep(2)\n",
    "    print(\"Worker thread finished.\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    print(f\"Main thread with PID: {os.getpid()}, TID: {threading.get_ident()}\")\n",
    "    worker()\n",
    "    print(\"Main thread completed.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a08f6db",
   "metadata": {},
   "source": [
    "### Thread ID\n",
    "\n",
    "To get the thread ID of the current thread, we can use the\n",
    "`threading.get_ident()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae9ce13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current thread ID: 139914812608640\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "print(f\"Current thread ID: {threading.get_ident()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8757e29e",
   "metadata": {},
   "source": [
    "### Memory Sharing and Synchronization\n",
    "\n",
    "-   **Shared Memory:**\n",
    "\n",
    "    -   **Threads** within the same process can easily share data by accessing\n",
    "        shared variables in memory (i.e. global variables).\n",
    "    -   **Processes**, being isolated, require explicit IPC mechanisms to share\n",
    "        data.\n",
    "\n",
    "-   **Synchronization Mechanisms:**\n",
    "    -   **Locks:** Prevent multiple threads from accessing shared resources\n",
    "        simultaneously.\n",
    "    -   **Semaphores:** Control access to a common resource by multiple threads.\n",
    "    -   **Events and Conditions:** Allow threads to wait for certain conditions\n",
    "        or events before proceeding.\n",
    "\n",
    "## Process vs Thread\n",
    "\n",
    "| Aspect                | Processes                                         | Threads                                             |\n",
    "| --------------------- | ------------------------------------------------- | --------------------------------------------------- |\n",
    "| **Memory Space**      | Separate for each process                         | Shared within the same process                      |\n",
    "| **Creation Overhead** | Higher overhead                                   | Lower overhead                                      |\n",
    "| **Communication**     | Requires IPC mechanisms                           | Direct access to shared memory                      |\n",
    "| **Isolation**         | High isolation enhances security and stability    | Lower isolation can lead to race conditions         |\n",
    "| **Concurrency**       | True parallelism in multi-core systems            | Limited by GIL in CPython for CPU-bound tasks       |\n",
    "| **Use Cases**         | CPU-bound tasks, applications requiring isolation | I/O-bound tasks, applications requiring shared data |\n",
    "\n",
    "## MultiThreading\n",
    "\n",
    "To illustrate the difference between processes and threads, let's consider a\n",
    "Python example where we perform a CPU-bound task: calculating the factorial of a\n",
    "large number.\n",
    "\n",
    "### Join == Barrier\n",
    "\n",
    "So the join is like PyTorch's `torch.distributed.barrier()` idea.\n",
    "\n",
    "### Using Threads\n",
    "\n",
    "```python\n",
    "import threading\n",
    "from typing import List\n",
    "import math\n",
    "import time\n",
    "\n",
    "def compute_factorial(n: int, results: List[int], index: int) -> None:\n",
    "    \"\"\"\n",
    "    Compute the factorial of a number and store the result.\n",
    "\n",
    "    Args:\n",
    "        n (int): The number to compute the factorial of.\n",
    "        results (List[int]): Shared list to store results.\n",
    "        index (int): Index to store the result in the list.\n",
    "    \"\"\"\n",
    "    results[index] = math.factorial(n)\n",
    "\n",
    "def main_threads() -> None:\n",
    "    numbers = [100000] * 4  # List of numbers to compute factorial\n",
    "    threads = []\n",
    "    results = [0] * len(numbers)\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, number in enumerate(numbers):\n",
    "        thread = threading.Thread(target=compute_factorial, args=(number, results, i))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Threads Result: Computed {len(results)} factorials in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_threads()\n",
    "```\n",
    "\n",
    "### Using Processes\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "from typing import List\n",
    "import math\n",
    "import time\n",
    "\n",
    "def compute_factorial_process(n: int, queue: multiprocessing.Queue) -> None:\n",
    "    \"\"\"\n",
    "    Compute the factorial of a number and put the result in a queue.\n",
    "\n",
    "    Args:\n",
    "        n (int): The number to compute the factorial of.\n",
    "        queue (multiprocessing.Queue): Queue to store the result.\n",
    "    \"\"\"\n",
    "    queue.put(math.factorial(n))\n",
    "\n",
    "def main_processes() -> None:\n",
    "    numbers = [100000] * 4  # List of numbers to compute factorial\n",
    "    processes = []\n",
    "    queue = multiprocessing.Queue()\n",
    "    start_time = time.time()\n",
    "\n",
    "    for number in numbers:\n",
    "        process = multiprocessing.Process(target=compute_factorial_process, args=(number, queue))\n",
    "        processes.append(process)\n",
    "        process.start()\n",
    "\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "\n",
    "    results = [queue.get() for _ in processes]\n",
    "    end_time = time.time()\n",
    "    print(f\"Processes Result: Computed {len(results)} factorials in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_processes()\n",
    "```\n",
    "\n",
    "### Expected Outcome\n",
    "\n",
    "When running both scripts, you will typically observe that the\n",
    "**multi-threaded** version does not significantly reduce the computation time\n",
    "compared to a single-threaded approach due to the GIL. Conversely, the\n",
    "**multi-processing** version can leverage multiple CPU cores to achieve true\n",
    "parallelism, resulting in a noticeable decrease in computation time.\n",
    "\n",
    "**Sample Output:**\n",
    "\n",
    "```\n",
    "Threads Result: Computed 4 factorials in 12.34 seconds\n",
    "Processes Result: Computed 4 factorials in 3.21 seconds\n",
    "```\n",
    "\n",
    "_Note: Actual times may vary based on system specifications._\n",
    "\n",
    "### Global Interpreter Lock (GIL) in Python\n",
    "\n",
    "-   **Definition:** The **GIL** is a mutex that prevents multiple native threads\n",
    "    from executing Python bytecodes simultaneously in CPython, the standard\n",
    "    Python implementation.\n",
    "\n",
    "-   **Implications:**\n",
    "\n",
    "    -   **CPU-Bound Tasks:** Threads are limited by the GIL, preventing true\n",
    "        parallel execution on multiple cores. This means that multi-threading\n",
    "        does not provide performance benefits for CPU-intensive tasks.\n",
    "    -   **I/O-Bound Tasks:** Threads can be beneficial as they can handle I/O\n",
    "        operations concurrently, allowing one thread to run while others are\n",
    "        waiting for I/O operations to complete.\n",
    "\n",
    "-   **Workarounds:**\n",
    "    -   **Multi-Processing:** Using separate processes can achieve parallelism\n",
    "        as each process has its own Python interpreter and GIL.\n",
    "    -   **Alternative Python Implementations:** Some implementations like Jython\n",
    "        or IronPython do not have a GIL, allowing true multi-threading.\n",
    "\n",
    "## Multiprocessing\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "\n",
    "def worker(name: str, sleep_time: int) -> None:\n",
    "    \"\"\"\n",
    "    Worker function that simulates a task by sleeping.\n",
    "    \"\"\"\n",
    "    pid = os.getpid()\n",
    "    print(f\"{name} started with PID: {pid}\")\n",
    "    for i in range(3):\n",
    "        print(f\"{name} is working... ({i+1}/3)\")\n",
    "        time.sleep(sleep_time)\n",
    "    print(f\"{name} with PID: {pid} completed.\")\n",
    "\n",
    "\n",
    "def spawn_processes(workers: List[Dict[str, Any]]) -> List[multiprocessing.Process]:\n",
    "    \"\"\"\n",
    "    Function to spawn worker processes.\n",
    "    \"\"\"\n",
    "    process_list: List[multiprocessing.Process] = []\n",
    "    for worker_info in workers:\n",
    "        process = multiprocessing.Process(target=worker, args=(worker_info[\"name\"], worker_info[\"sleep_time\"]))\n",
    "        process_list.append(process)\n",
    "    return process_list\n",
    "\n",
    "\n",
    "def monitor_processes(process_list: List[multiprocessing.Process]) -> None:\n",
    "    \"\"\"\n",
    "    Function to monitor and join child processes.\n",
    "    \"\"\"\n",
    "    parent_pid = os.getpid()\n",
    "    print(f\"\\nParent Process PID: {parent_pid}\")\n",
    "    print(\"Monitoring Child Processes:\\n\")\n",
    "\n",
    "    for process in process_list:\n",
    "        print(f\"Process Name: {process.name}, PID: {process.pid}, Alive: {process.is_alive()}\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main function to manage the process workflow.\n",
    "    \"\"\"\n",
    "    workers = [{\"name\": \"Process A\", \"sleep_time\": 2}, {\"name\": \"Process B\", \"sleep_time\": 3}]\n",
    "\n",
    "    process_list = spawn_processes(workers)\n",
    "\n",
    "    for process in process_list:\n",
    "        process.start()\n",
    "\n",
    "    time.sleep(1)  # Allow some time for processes to start\n",
    "\n",
    "    monitor_processes(process_list)\n",
    "\n",
    "    for process in process_list:\n",
    "        process.join()\n",
    "\n",
    "    print(\"\\nAll child processes have completed.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "-   join == dist.barrier() idea\n",
    "-   start ?\n",
    "\n",
    "| **Aspect**            | **Default Synchronous Python Code** | **Multi-Threaded Python Code (`threading.Thread`)**  | **Multi-Processed Python Code (`multiprocessing.Process`)** |\n",
    "| --------------------- | ----------------------------------- | ---------------------------------------------------- | ----------------------------------------------------------- |\n",
    "| **Execution Units**   | Single Process, Single Thread       | Single Process, Multiple Threads                     | Multiple Processes, Each with Single Thread                 |\n",
    "| **Process ID (PID)**  | One PID                             | One PID                                              | Multiple PIDs                                               |\n",
    "| **Thread ID (TID)**   | One TID                             | Multiple TIDs                                        | Each process has its own TID                                |\n",
    "| **Memory Space**      | Shared (single process)             | Shared within the same process                       | Isolated between processes                                  |\n",
    "| **Concurrency Model** | Sequential execution                | Concurrent execution within the same process         | True parallel execution across multiple processes           |\n",
    "| **Best Suited For**   | Simple, linear tasks                | I/O-bound tasks (e.g., network requests, file I/O)   | CPU-bound tasks (e.g., data processing, computations)       |\n",
    "| **Overhead**          | Minimal                             | Low                                                  | Higher                                                      |\n",
    "| **Impact of GIL**     | Not applicable                      | Limited for CPU-bound tasks; efficient for I/O-bound | Bypasses GIL; allows true parallelism for CPU-bound tasks   |\n",
    "\n",
    "## **1. Understanding Threading and Asyncio**\n",
    "\n",
    "### **Threading**\n",
    "\n",
    "-   **Threading** involves running multiple threads (lightweight processes)\n",
    "    concurrently within a single process.\n",
    "-   **Pre-emptive Multitasking:** The operating system (OS) manages thread\n",
    "    scheduling and can interrupt any thread at virtually any point to switch\n",
    "    execution to another thread. This means threads don't need to explicitly\n",
    "    yield control.\n",
    "\n",
    "### **Asyncio**\n",
    "\n",
    "-   **Asyncio** is a library for writing concurrent code using the\n",
    "    `async`/`await` syntax.\n",
    "-   **Cooperative Multitasking:** Tasks voluntarily yield control (e.g., when\n",
    "    awaiting I/O operations). The scheduler switches tasks only at these yield\n",
    "    points.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Pre-emptive Multitasking in Threading**\n",
    "\n",
    "With pre-emptive multitasking, the OS can interrupt a thread at any time, even\n",
    "in the middle of executing a single Python statement. This can lead to issues\n",
    "like **race conditions**, where the program's behavior depends on the\n",
    "unpredictable timing of threads.\n",
    "\n",
    "### **Illustrative Example: Race Condition in Threading**\n",
    "\n",
    "Consider a simple counter that's incremented by multiple threads:\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Shared resource\n",
    "counter = 0\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        counter += 1  # Not an atomic operation\n",
    "\n",
    "# Create multiple threads\n",
    "threads = []\n",
    "for _ in range(2):\n",
    "    thread = threading.Thread(target=increment)\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(f\"Final counter value: {counter}\")\n",
    "```\n",
    "\n",
    "### **Preventing Race Conditions with Locks**\n",
    "\n",
    "To ensure that only one thread modifies the `counter` at a time, use a **lock**:\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "counter = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def safe_increment():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        with lock:\n",
    "            counter += 1\n",
    "\n",
    "threads = []\n",
    "for _ in range(2):\n",
    "    thread = threading.Thread(target=safe_increment)\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(f\"Final counter value: {counter}\")\n",
    "```\n",
    "\n",
    "**Output:** `Final counter value: 200000`\n",
    "\n",
    "**Explanation:** The `with lock:` statement ensures that the block of code\n",
    "modifying `counter` is executed by only one thread at a time, preventing race\n",
    "conditions.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Cooperative Multitasking in Asyncio**\n",
    "\n",
    "In contrast to threading, **asyncio** requires tasks to **explicitly yield\n",
    "control**, typically when awaiting I/O operations. This eliminates the risk of a\n",
    "task being interrupted in the middle of a statement, thus avoiding race\n",
    "conditions without the need for locks in many cases.\n",
    "\n",
    "### **Example Using Asyncio**\n",
    "\n",
    "Let's implement a similar counter increment using asyncio:\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "counter = 0\n",
    "\n",
    "async def increment():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        counter += 1  # Safe in asyncio as no pre-emptive switches\n",
    "        if _ % 10000 == 0:\n",
    "            await asyncio.sleep(0)  # Yield control\n",
    "\n",
    "async def main():\n",
    "    await asyncio.gather(increment(), increment())\n",
    "\n",
    "    print(f\"Final counter value: {counter}\")\n",
    "\n",
    "# Run the asyncio program\n",
    "asyncio.run(main())\n",
    "```\n",
    "\n",
    "**Output:** `Final counter value: 200000`\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "-   **No Pre-emptive Interruptions:** Since asyncio uses cooperative\n",
    "    multitasking, `counter += 1` executes atomically between `await` points.\n",
    "-   **Yielding Control:** The `await asyncio.sleep(0)` statement allows other\n",
    "    tasks to run, ensuring that tasks take turns but only at defined points.\n",
    "\n",
    "### **Why Is This Safer?**\n",
    "\n",
    "-   **Atomic Operations:** Operations between `await` points are executed\n",
    "    without interruption, reducing the risk of race conditions.\n",
    "-   **No Need for Locks:** Since tasks yield control explicitly, shared\n",
    "    resources can be managed more predictably.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Summary of Key Differences**\n",
    "\n",
    "| Feature             | Threading (Pre-emptive)                          | Asyncio (Cooperative)                                     |\n",
    "| ------------------- | ------------------------------------------------ | --------------------------------------------------------- |\n",
    "| **Task Switching**  | OS can interrupt at any time                     | Tasks yield control explicitly                            |\n",
    "| **Synchronization** | Requires locks to prevent race conditions        | Often safer due to controlled yielding                    |\n",
    "| **Complexity**      | More complex due to potential for race issues    | Simpler in scenarios with I/O-bound tasks                 |\n",
    "| **Performance**     | Suitable for CPU-bound tasks with multiple cores | Best for I/O-bound and high-level structured network code |\n",
    "| **Overhead**        | Higher due to OS thread management               | Lower, managed within the program                         |\n",
    "\n",
    "---\n",
    "\n",
    "## **5. When to Use Threading vs Asyncio**\n",
    "\n",
    "-   **Use Threading When:**\n",
    "\n",
    "    -   You need to perform CPU-bound operations.\n",
    "    -   You're working with libraries that are not asynchronous.\n",
    "    -   You require true parallelism on multi-core processors.\n",
    "\n",
    "-   **Use Asyncio When:**\n",
    "    -   You're handling I/O-bound tasks (e.g., network requests, file I/O).\n",
    "    -   You want to manage concurrency with lower overhead.\n",
    "    -   Your codebase can be structured around `async`/`await`.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "Understanding the fundamental differences between threading and asyncio,\n",
    "especially regarding how they handle task switching, is crucial for writing\n",
    "efficient and bug-free concurrent Python programs. **Pre-emptive multitasking**\n",
    "in threading offers flexibility but introduces complexity due to potential race\n",
    "conditions. **Cooperative multitasking** in asyncio provides a safer and often\n",
    "simpler model for managing concurrency, particularly for I/O-bound applications.\n",
    "\n",
    "By choosing the appropriate concurrency model and employing synchronization\n",
    "mechanisms like locks when necessary, you can harness the full power of Python's\n",
    "concurrency capabilities effectively.\n",
    "\n",
    "## Concurrency vs Parallelism\n",
    "\n",
    "![Concurrency vs Parallelism](./assets/concurrency_parallelism.jpeg)\n",
    "\n",
    "Here are the three parallelization mechanisms in Python:\n",
    "\n",
    "### ⇢ **AsyncIO**\n",
    "\n",
    "-   **Type:** Single-threaded\n",
    "-   **Best for:** I/O-bound tasks\n",
    "-   **Limitations:** Not suitable for CPU-bound tasks like image or video\n",
    "    processing\n",
    "-   **How it works:** Uses a single event loop with coroutines managed by\n",
    "    async/await, which struggles with CPU-heavy operations.\n",
    "-   **Conclusion:** Not ideal for CPU-intensive tasks.\n",
    "\n",
    "### ⇢ **Threading**\n",
    "\n",
    "-   **Type:** Multi-threaded with shared memory\n",
    "-   **Best for:** I/O-bound tasks\n",
    "-   **Limitations:** Limited by the Global Interpreter Lock (GIL), which allows\n",
    "    only one thread to execute Python bytecode at a time, adding overhead for\n",
    "    CPU-bound tasks.\n",
    "-   **Analogy:** Think of the GIL as a mediator in a debate, letting only one\n",
    "    person speak at a time.\n",
    "-   **Conclusion:** Effective for I/O tasks but inefficient for CPU-heavy\n",
    "    processing.\n",
    "\n",
    "### ⇢ **Multiprocessing**\n",
    "\n",
    "-   **Type:** Multiple processes with separate memory spaces\n",
    "-   **Best for:** CPU-bound tasks\n",
    "-   **How it works:**\n",
    "    -   **Linux/macOS:** Uses \"Fork\" to create child processes that copy the\n",
    "        parent’s memory.\n",
    "    -   **Windows:** Uses \"Spawn\" to start fresh interpreter instances with\n",
    "        necessary resources.\n",
    "-   **Advantages:** Achieves true parallelism, allows control over processing\n",
    "    workflows, and enables efficient data sharing through Queues or raw ctypes\n",
    "    arrays.\n",
    "-   **Conclusion:** The preferred choice for CPU-intensive operations.\n",
    "\n",
    "### **Summary:**\n",
    "\n",
    "-   **AsyncIO:** Single-threaded, ideal for I/O, not for CPU-bound tasks.\n",
    "-   **Threading:** Shared memory, constrained by GIL.\n",
    "-   **Multiprocessing:** Separate memory spaces, offers true parallelism.\n",
    "\n",
    "## References And Further Readings\n",
    "\n",
    "-   https://realpython.com/python-concurrency/#when-is-concurrency-useful\n",
    "-   https://realpython.com/intro-to-python-threading/\n",
    "-   https://docs.python.org/3/library/multiprocessing.html\n",
    "-   https://realpython.com/async-io-python/\n",
    "-   Chapter 7 Concurrency And Parallelism From Effective Python"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "mystnb": {
   "number_source_lines": true
  },
  "source_map": [
   16,
   49,
   69,
   110,
   142,
   170,
   183,
   324,
   328,
   373,
   393,
   400,
   404
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}