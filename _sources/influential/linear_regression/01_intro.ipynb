{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35674a2",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "[![Twitter Handle](https://img.shields.io/badge/Twitter-@gaohongnan-blue?style=social&logo=twitter)](https://twitter.com/gaohongnan)\n",
    "[![LinkedIn Profile](https://img.shields.io/badge/@gaohongnan-blue?style=social&logo=linkedin)](https://linkedin.com/in/gao-hongnan)\n",
    "[![GitHub Profile](https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&logo=github)](https://github.com/gao-hongnan)\n",
    "![Tag](https://img.shields.io/badge/Tag-Organized_Chaos-orange)\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    "```\n",
    "\n",
    "In this chapter, we discuss linear regression, which is a very widely used\n",
    "method for predicting a real-valued output (also called the dependent variable\n",
    "or target) $y \\in \\mathbb{R}$, given a vector of real-valued inputs (also called\n",
    "independent variables, explanatory variables, or covariates)\n",
    "$\\boldsymbol{x} \\in \\mathbb{R}^D$. The key property of the model is that the\n",
    "expected value of the output is assumed to be a linear function of the input,\n",
    "$\\mathbb{E}[y \\mid \\boldsymbol{x}]=\\boldsymbol{w}^{\\top} \\boldsymbol{x}$, which\n",
    "makes the model easy to interpret, and easy to fit to data {cite}`pml1Book`.\n",
    "\n",
    "There are two views to solving Linear Regression, we will focus on the\n",
    "probabilistic aspect of it and leave the geometry/linear algebra interpretation\n",
    "for further readings.\n",
    "\n",
    "Regression in itself is a very broad topic, the analysis in itself can be made\n",
    "as a course/book. Therefore, I will just touch and go on the important parts of\n",
    "it.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "```{tableofcontents}\n",
    "\n",
    "```\n",
    "\n",
    "## References and Further Readings\n",
    "\n",
    "-   https://d2l.ai/\n",
    "-   Murphy, Kevin P. \"Chapter .\" In Probabilistic Machine Learning: An\n",
    "    Introduction. MIT Press, 2022.\n",
    "-   James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n",
    "    \"Chapter .\" In An Introduction to Statistical Learning: With Applications in\n",
    "    R. Boston: Springer, 2022.\n",
    "-   Jung, Alexander. \"Chapter \" In Machine Learning: The Basics. Singapore:\n",
    "    Springer Nature Singapore, 2023.\n",
    "-   Bishop, Christopher M. \"Chapter .\" In Pattern Recognition and Machine\n",
    "    Learning. New York: Springer-Verlag, 2016.\n",
    "-   Hal Daum√© III. \"Chapter .\" In A Course in Machine Learning, January 2017.\n",
    "-   [Machine Learning from Scratch](https://dafriedman97.github.io/mlbook/content/introduction.html)\n",
    "-   **GOOD**: https://github.com/NathanielDake/intuitiveml\n",
    "-   https://github.com/goodboychan/goodboychan.github.io/tree/main/_notebooks"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "mystnb": {
   "number_source_lines": true
  },
  "source_map": [
   16
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}