
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>The Concept of Generative Pre-trained Transformers (GPT) &#8212; Omniverse</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=bb35926c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../../_static/tabs.js?v=3ee01567"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-MYW5YKC2WF"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-MYW5YKC2WF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-MYW5YKC2WF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"defeq": "\\overset{\\text{def}}{=}", "defa": "\\overset{\\text{(a)}}{=}", "defb": "\\overset{\\text{(b)}}{=}", "defc": "\\overset{\\text{(c)}}{=}", "defd": "\\overset{\\text{(d)}}{=}", "st": "\\mid", "mod": "\\mid", "S": "\\Omega", "s": "\\omega", "e": "\\exp", "P": "\\mathbb{P}", "R": "\\mathbb{R}", "expectation": "\\mathbb{E}", "v": "\\mathbf{v}", "a": "\\mathbf{a}", "b": "\\mathbf{b}", "c": "\\mathbf{c}", "u": "\\mathbf{u}", "w": "\\mathbf{w}", "x": "\\mathbf{x}", "y": "\\mathbf{y}", "z": "\\mathbf{z}", "0": "\\mathbf{0}", "1": "\\mathbf{1}", "A": "\\mathbf{A}", "B": "\\mathbf{B}", "C": "\\mathbf{C}", "E": "\\mathcal{F}", "eventA": "\\mathcal{A}", "lset": "\\left\\{", "rset": "\\right\\}", "lsq": "\\left[", "rsq": "\\right]", "lpar": "\\left(", "rpar": "\\right)", "lcurl": "\\left\\{", "rcurl": "\\right\\}", "pmf": "p_X", "pdf": "f_X", "pdftwo": "f_{X,Y}", "pdfjoint": "f_{\\mathbf{X}}", "pmfjointxy": "p_{X, Y}", "pdfjointxy": "f_{X, Y}", "cdf": "F_X", "pspace": "(\\Omega, \\mathcal{F}, \\mathbb{P})", "var": "\\operatorname{Var}", "std": "\\operatorname{Std}", "bern": "\\operatorname{Bernoulli}", "binomial": "\\operatorname{Binomial}", "geometric": "\\operatorname{Geometric}", "poisson": "\\operatorname{Poisson}", "uniform": "\\operatorname{Uniform}", "normal": "\\operatorname{Normal}", "gaussian": "\\operatorname{Gaussian}", "gaussiansymbol": "\\mathcal{N}", "exponential": "\\operatorname{Exponential}", "iid": "\\textbf{i.i.d.}", "and": "\\text{and}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'influential/generative_pretrained_transformer/03_concept';</script>
    <link rel="canonical" href="https://www.gaohongnan.com/influential/generative_pretrained_transformer/03_concept.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="The Implementation of Generative Pre-trained Transformers (GPT)" href="04_implementation.html" />
    <link rel="prev" title="Notations" href="02_notations.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Omniverse - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Omniverse - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    🌌 Omniverse: A Journey Through Knowledge
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Notations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notations/machine_learning.html">Machine Learning Notations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Influential Ideas and Papers</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="01_intro.html">Generative Pre-trained Transformers</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="02_notations.html">Notations</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">The Concept of Generative Pre-trained Transformers (GPT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_implementation.html">The Implementation of Generative Pre-trained Transformers (GPT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_adder.html">Training a Mini-GPT to Learn Two-Digit Addition</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../low_rank_adaptation/01_intro.html">Low-Rank Adaptation Of Large Language Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../low_rank_adaptation/02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../low_rank_adaptation/03_implementation.html">Implementation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../kmeans_clustering/01_intro.html">K-Means</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/02_concept.html">Concept: K-Means Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/03_implementation.html">Implementation: K-Means (Lloyd)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/04_image_segmentation.html">Application: Image Compression and Segmentation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../empirical_risk_minimization/01_intro.html">Empirical Risk Minimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../empirical_risk_minimization/02_concept.html">Concept: Empirical Risk Minimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../empirical_risk_minimization/03_bayes_optimal_classifier.html">Bayes Optimal Classifier</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../learning_theory/01_intro.html">Is The Learning Problem Solvable?</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../learning_theory/02_concept.html">Concept: Learning Theory</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Playbook</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../playbook/how_to_calculate_flops_in_transformer_based_models.html">How to Calculate the Number of FLOPs in Transformer Based Models?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/how_to_inspect_function_and_class_signatures.html">How to Inspect Function and Class Signatures in Python?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/why_cosine_annealing_warmup_stabilize_training.html">Why Does Cosine Annealing With Warmup Stabilize Training?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/why_softmax_preserves_order_translation_invariant_not_invariant_scaling.html">Softmax Preserves Order, Is Translation Invariant But Not Invariant Under Scaling.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/how_to_finetune_decoder_with_last_token_pooling.html">How To Fine-Tune Decoder-Only Models For Sequence Classification Using Last Token Pooling?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/how_to_finetune_decoder_with_cross_attention.html">How To Fine-Tune Decoder-Only Models For Sequence Classification With Cross-Attention?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/how_to_teacher_student_knowledge_distillation.html">How To Do Teacher-Student Knowledge Distillation?</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Operations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/distributed/intro.html">Distributed Systems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/01_notations.html">Notations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/02_basics.html">Basics Of Distributed Data Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/03_how_to_setup_slurm_in_aws.html">How to Setup SLURM and ParallelCluster in AWS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/04_ablation.html">Ablations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/profiling/intro.html">Profiling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/01_synchronize.html">Synchronize CUDA To Time CUDA Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/02_timeit.html">Profiling Code With Timeit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/03_time_profiler.html">PyTorch’s Event And Profiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/04_small_gpt_profile.html">Profile GPT Small Time And Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/05_memory_leak.html">CUDA Memory Allocations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/00_intro.html">The Lifecycle of an AIOps System</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/01_problem_formulation.html">Stage 1. Problem Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/02_project_scoping.html">Stage 2. Project Scoping And Framing The Problem</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/03_dataops_pipeline.html">Stage 3. Data Pipeline (Data Engineering and DataOps)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/031_data_source_and_format.html">Stage 3.1. Data Source and Formats</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/032_data_model_and_storage.html">Stage 3.2. Data Model and Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/033_etl.html">Stage 3.3. Extract, Transform, Load (ETL)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/04_mlops_data_pipeline.html">Stage 4. Data Extraction (MLOps), Data Analysis (Data Science), Data Preparation (Data Science)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline.html">Stage 5. Model Development and Training (MLOps)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/051_model_selection.html">Stage 5.1. Model Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/052_metric_selection.html">Stage 5.2. Metric Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/053_experiment_tracking.html">Stage 5.3. Experiment Tracking And Versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/054_model_testing.html">Stage 5.4. Model Testing</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/06_model_evaluation.html">Stage 6. Model Evaluation (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/07_model_validation_registry_and_pushing_model_to_production.html">Stage 7. Model Validation, Registry and Pushing Model to Production (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/08_model_deployment_and_serving.html">Stage 8. Model Serving (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/09_model_monitoring.html">Stage 9. Model Monitoring (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/010_continuous_integration_deployment_learning_and_training.html">Stage 10. Continuous Integration, Deployment, Learning and Training (DevOps, DataOps, MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/011_infrastructure_and_tooling_for_mlops.html">Stage 11. Infrastructure and Tooling for MLOps</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Software Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/config_management/concept.html">Configuration Management</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/config_management/01-pydra.html">Pydantic And Hydra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/config_management/02-state.html">State And Metadata Management</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/design_patterns/intro.html">Design Patterns</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/dependency-inversion-principle.html">Dependency Inversion Principle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/strategy.html">Strategy Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/registry.html">Registry Design Pattern</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/intro.html">Concurrency, Parallelism and Asynchronous Programming</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/generator_yield.html">A Rudimentary Introduction to Generator and Yield in Python</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Computer Science</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../computer_science/type_theory/intro.html">Type Theory, A Very Rudimentary Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/01-subtypes.html">Subtypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/02-type-safety.html">Type Safety</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/03-subsumption.html">Subsumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/04-generics.html">Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/05-typevar-bound-constraints.html">Bound and Constraint in Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/06-invariance-covariance-contravariance.html">Invariance, Covariance and Contravariance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/07-pep-3124-overloading.html">Function Overloading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/08-pep-661-sentinel-values.html">Sentinel Types</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Structures and Algorithms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/complexity_analysis/intro.html">Complexity Analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/complexity_analysis/master_theorem.html">Master Theorem </a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/stack/intro.html">Stack</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/stack/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/searching_algorithms/linear_search/intro.html">Linear Search</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/linear_search/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/intro.html">Binary Search</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/problems/875-koko-eating-bananas.html">Koko Eating Bananas</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Algebra</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linear_algebra/01_preliminaries/intro.html">Preliminaries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/01_preliminaries/01-fields.html">Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/01_preliminaries/02-systems-of-linear-equations.html">Systems of Linear Equations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linear_algebra/02_vectors/intro.html">Vectors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/01-vector-definition.html">Vector and Its Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/02-vector-operation.html">Vector and Its Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/03-vector-norm.html">Vector Norm and Distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/04-vector-products.html">A First Look at Vector Products</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Probability Theory</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/intro.html">Chapter 1. Mathematical Preliminaries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/01_combinatorics.html">Permutations and Combinations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/02_calculus.html">Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/03_contours.html">Contour Maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/02_probability/intro.html">Chapter 2. Probability</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0202_probability_space.html">Probability Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0203_probability_axioms.html">Probability Axioms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0204_conditional_probability.html">Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0205_independence.html">Independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0206_bayes_theorem.html">Baye’s Theorem and the Law of Total Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/summary.html">Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/intro.html">Chapter 3. Discrete Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0301_random_variables.html">Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0302_discrete_random_variables.html">Discrete Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0303_probability_mass_function.html">Probability Mass Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0304_cumulative_distribution_function.html">Cumulative Distribution Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0305_expectation.html">Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0306_moments_and_variance.html">Moments and Variance</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/intro.html">Discrete Uniform Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/0307_discrete_uniform_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/0307_discrete_uniform_distribution_application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/intro.html">Bernoulli Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/0308_bernoulli_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/0308_bernoulli_distribution_application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/iid.html">Independent and Identically Distributed (IID)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/intro.html">Binomial Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_implementation.html">Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_application.html">Real World Examples</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/geometric/intro.html">Geometric Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/geometric/0310_geometric_distribution_concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/intro.html">Poisson Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/0311_poisson_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/0311_poisson_distribution_implementation.html">Implementation</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/summary.html">Important</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/intro.html">Chapter 4. Continuous Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/from_discrete_to_continuous.html">From Discrete to Continuous</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0401_continuous_random_variables.html">Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0402_probability_density_function.html">Probability Density Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0403_expectation.html">Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0404_moments_and_variance.html">Moments and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0405_cumulative_distribution_function.html">Cumulative Distribution Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0406_mean_median_mode.html">Mean, Median and Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0407_continuous_uniform_distribution.html">Continuous Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0408_exponential_distribution.html">Exponential Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0409_gaussian_distribution.html">Gaussian Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0410_skewness_and_kurtosis.html">Skewness and Kurtosis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0411_convolve_and_sum_of_random_variables.html">Convolution and Sum of Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0412_functions_of_random_variables.html">Functions of Random Variables</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/intro.html">Chapter 5. Joint Distributions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/05_joint_distributions/from_single_variable_to_joint_distributions.html">From Single Variable to Joint Distributions</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0501_joint_pmf_pdf/intro.html">Joint PMF and PDF</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0501_joint_pmf_pdf/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0502_joint_expectation_and_correlation/intro.html">Joint Expectation and Correlation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0502_joint_expectation_and_correlation/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/intro.html">Conditional PMF and PDF</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/intro.html">Conditional Expectation and Variance</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0505_sum_of_random_variables/intro.html">Sum of Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0505_sum_of_random_variables/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0506_random_vectors/intro.html">Random Vectors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0506_random_vectors/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/intro.html">Multivariate Gaussian Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/application_transformation.html">Application: Plots and Transformations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/psd.html">Covariance Matrix is Positive Semi-Definite</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/eigendecomposition.html">Eigendecomposition and Covariance Matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/geometry_of_multivariate_gaussian.html">The Geometry of Multivariate Gaussians</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/intro.html">Chapter 6. Sample Statistics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/intro.html">Moment Generating and Characteristic Functions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/moment_generating_function.html">Moment Generating Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/moment_generating_function_application_sum_of_rv.html">Application: Moment Generating Function and the Sum of Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/characteristic_function.html">Characteristic Function</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/intro.html">Probability Inequalities</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/concept.html">Probability Inequalities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/application.html">Application: Learning Theory</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/intro.html">Law of Large Numbers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/convergence.html">Convergence of Sample Average</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/application.html">Application: Learning Theory</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/08_estimation_theory/intro.html">Chapter 8. Estimation Theory</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/08_estimation_theory/maximum_likelihood_estimation/intro.html">Maximum Likelihood Estimation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/08_estimation_theory/maximum_likelihood_estimation/concept.html">Concept</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References, Resources and Roadmap</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../citations.html">IEEE (Style) Citations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../api/reproducibility.html">API Reference</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/gao-hongnan/omniverse/blob/main/omniverse/influential/generative_pretrained_transformer/03_concept.md" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gao-hongnan/omniverse" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gao-hongnan/omniverse/issues/new?title=Issue%20on%20page%20%2Finfluential/generative_pretrained_transformer/03_concept.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/influential/generative_pretrained_transformer/03_concept.ipynb" target="_blank"
   class="btn btn-sm btn-download-notebook-button dropdown-item"
   title="Download notebook file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li><a href="../../_sources/influential/generative_pretrained_transformer/03_concept.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The Concept of Generative Pre-trained Transformers (GPT)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-gpt-1-to-gpt-2">From GPT-1 to GPT-2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-2-paper-key-ideas">GPT-2 Paper Key Ideas</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract-overview">Abstract Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-competent-generalists-over-narrow-experts-1">Key 1. Competent Generalists over Narrow Experts (1)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-iid-assumption-fails-in-real-world-2-3">Key 2. IID Assumption Fails in Real World (2, 3)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-3-multi-task-learning-is-nacent-4">Key 3. Multi-Task Learning is Nacent (4)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-4-from-word-embeddings-to-contextual-embeddings-5-6">Key 4. From Word Embeddings to Contextual Embeddings (5,6)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-5-zero-shot-learning-and-zero-shot-transfer-7">Key 5. Zero Shot Learning and Zero Shot Transfer (7)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#section-2-approach">Section 2. Approach</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-modeling-language-models-over-joint-probability-distributions-1">Key 1. Modeling Language Models over Joint Probability Distributions (1)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-decompose-joint-distributions-as-conditional-distributions-via-chain-rule-2">Key 2. Decompose Joint Distributions as Conditional Distributions via Chain Rule (2)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-3-conditional-on-task-3">Key 3. Conditional on Task (3)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-4-optimizing-unsupervised-is-the-same-as-optimizing-supervised-4">Key 4. Optimizing Unsupervised is the same as Optimizing Supervised (4)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-5-large-language-models-has-capacity-to-infer-and-generalize-5">Key 5. Large Language Models has Capacity to Infer and Generalize (5)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-dataset">2.1. Training Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-rejection-of-commoncrawl-1-2">Key 1. Rejection of CommonCrawl (1,2)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-construction-of-webtext-dataset">Key 2. Construction of WebText Dataset</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#input-representation">2.2. Input Representation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-byte-pair-encoding-bpe-1-2-3">Key 1. Byte Pair Encoding (BPE) (1,2,3)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model">2.3. Model</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-gpt-2-is-a-continuation-of-gpt-1-with-self-attention-mechanisms-1">Key 1. GPT-2 is a Continuation of GPT-1 with Self-Attention Mechanisms (1)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-modifications-from-gpt-1-and-model-stability-1">Key 2. Modifications from GPT-1 and Model Stability (1)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-2-variants">GPT-2 Variants</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-autoregressive-self-supervised-learning-paradigm">The Autoregressive Self-Supervised Learning Paradigm</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#autoregressive-self-supervised-learning">Autoregressive Self-Supervised Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation-of-the-conditional-probability-distribution">Estimation of the Conditional Probability Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initial-condition-of-conditional-probability-distribution">Initial Condition of Conditional Probability Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-assumption">Markov Assumption</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-estimator-function-is-smooth-with-respect-to-the-parameters">The Estimator Function is Smooth with Respect to the Parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#context-length-and-token-context-window">Context Length and Token Context Window</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-entropy-and-perplexity-as-loss-function">Conditional Entropy and Perplexity as Loss Function</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-entropy">Conditional Entropy</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#perplexity">Perplexity</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function">Loss Function</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence">Convergence</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-is-a-autoregressive-self-supervised-learning-model">GPT is a Autoregressive Self-Supervised Learning Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-on-task">Conditional on Task</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-fine-tuning">Supervised Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#objective-function-for-fine-tuning">Objective Function for Fine-Tuning</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#auxiliary-loss-function">Auxiliary Loss Function</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizing-unsupervised-is-the-same-as-optimizing-supervised">Optimizing Unsupervised is the same as Optimizing Supervised</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references-and-further-readings">References and Further Readings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#citations">Citations</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="the-concept-of-generative-pre-trained-transformers-gpt">
<h1>The Concept of Generative Pre-trained Transformers (GPT)<a class="headerlink" href="#the-concept-of-generative-pre-trained-transformers-gpt" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="https://twitter.com/gaohongnan"><img alt="Twitter Handle" src="https://img.shields.io/badge/Twitter-&#64;gaohongnan-blue?style=social&amp;logo=twitter" /></a>
<a class="reference external" href="https://linkedin.com/in/gao-hongnan"><img alt="LinkedIn Profile" src="https://img.shields.io/badge/&#64;gaohongnan-blue?style=social&amp;logo=linkedin" /></a>
<a class="reference external" href="https://github.com/gao-hongnan"><img alt="GitHub Profile" src="https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&amp;logo=github" /></a>
<img alt="Tag" src="https://img.shields.io/badge/Tag-Organized_Chaos-orange" /></p>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#motivation" id="id32">Motivation</a></p></li>
<li><p><a class="reference internal" href="#from-gpt-1-to-gpt-2" id="id33">From GPT-1 to GPT-2</a></p></li>
<li><p><a class="reference internal" href="#gpt-2-paper-key-ideas" id="id34">GPT-2 Paper Key Ideas</a></p>
<ul>
<li><p><a class="reference internal" href="#abstract-overview" id="id35">Abstract Overview</a></p></li>
<li><p><a class="reference internal" href="#introduction" id="id36">Introduction</a></p>
<ul>
<li><p><a class="reference internal" href="#key-1-competent-generalists-over-narrow-experts-1" id="id37">Key 1. Competent Generalists over Narrow Experts (1)</a></p></li>
<li><p><a class="reference internal" href="#key-2-iid-assumption-fails-in-real-world-2-3" id="id38">Key 2. IID Assumption Fails in Real World (2, 3)</a></p></li>
<li><p><a class="reference internal" href="#key-3-multi-task-learning-is-nacent-4" id="id39">Key 3. Multi-Task Learning is Nacent (4)</a></p></li>
<li><p><a class="reference internal" href="#key-4-from-word-embeddings-to-contextual-embeddings-5-6" id="id40">Key 4. From Word Embeddings to Contextual Embeddings (5,6)</a></p></li>
<li><p><a class="reference internal" href="#key-5-zero-shot-learning-and-zero-shot-transfer-7" id="id41">Key 5. Zero Shot Learning and Zero Shot Transfer (7)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#section-2-approach" id="id42">Section 2. Approach</a></p>
<ul>
<li><p><a class="reference internal" href="#key-1-modeling-language-models-over-joint-probability-distributions-1" id="id43">Key 1. Modeling Language Models over Joint Probability Distributions (1)</a></p></li>
<li><p><a class="reference internal" href="#key-2-decompose-joint-distributions-as-conditional-distributions-via-chain-rule-2" id="id44">Key 2. Decompose Joint Distributions as Conditional Distributions via Chain Rule (2)</a></p></li>
<li><p><a class="reference internal" href="#key-3-conditional-on-task-3" id="id45">Key 3. Conditional on Task (3)</a></p></li>
<li><p><a class="reference internal" href="#key-4-optimizing-unsupervised-is-the-same-as-optimizing-supervised-4" id="id46">Key 4. Optimizing Unsupervised is the same as Optimizing Supervised (4)</a></p></li>
<li><p><a class="reference internal" href="#key-5-large-language-models-has-capacity-to-infer-and-generalize-5" id="id47">Key 5. Large Language Models has Capacity to Infer and Generalize (5)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#training-dataset" id="id48">2.1. Training Dataset</a></p>
<ul>
<li><p><a class="reference internal" href="#key-1-rejection-of-commoncrawl-1-2" id="id49">Key 1. Rejection of CommonCrawl (1,2)</a></p></li>
<li><p><a class="reference internal" href="#key-2-construction-of-webtext-dataset" id="id50">Key 2. Construction of WebText Dataset</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#input-representation" id="id51">2.2. Input Representation</a></p>
<ul>
<li><p><a class="reference internal" href="#key-1-byte-pair-encoding-bpe-1-2-3" id="id52">Key 1. Byte Pair Encoding (BPE) (1,2,3)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#model" id="id53">2.3. Model</a></p>
<ul>
<li><p><a class="reference internal" href="#key-1-gpt-2-is-a-continuation-of-gpt-1-with-self-attention-mechanisms-1" id="id54">Key 1. GPT-2 is a Continuation of GPT-1 with Self-Attention Mechanisms (1)</a></p></li>
<li><p><a class="reference internal" href="#key-2-modifications-from-gpt-1-and-model-stability-1" id="id55">Key 2. Modifications from GPT-1 and Model Stability (1)</a></p></li>
<li><p><a class="reference internal" href="#gpt-2-variants" id="id56">GPT-2 Variants</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#the-autoregressive-self-supervised-learning-paradigm" id="id57">The Autoregressive Self-Supervised Learning Paradigm</a></p>
<ul>
<li><p><a class="reference internal" href="#autoregressive-self-supervised-learning" id="id58">Autoregressive Self-Supervised Learning</a></p></li>
<li><p><a class="reference internal" href="#estimation-of-the-conditional-probability-distribution" id="id59">Estimation of the Conditional Probability Distribution</a></p></li>
<li><p><a class="reference internal" href="#initial-condition-of-conditional-probability-distribution" id="id60">Initial Condition of Conditional Probability Distribution</a></p></li>
<li><p><a class="reference internal" href="#markov-assumption" id="id61">Markov Assumption</a></p></li>
<li><p><a class="reference internal" href="#the-estimator-function-is-smooth-with-respect-to-the-parameters" id="id62">The Estimator Function is Smooth with Respect to the Parameters</a></p></li>
<li><p><a class="reference internal" href="#context-length-and-token-context-window" id="id63">Context Length and Token Context Window</a></p></li>
<li><p><a class="reference internal" href="#conditional-entropy-and-perplexity-as-loss-function" id="id64">Conditional Entropy and Perplexity as Loss Function</a></p>
<ul>
<li><p><a class="reference internal" href="#conditional-entropy" id="id65">Conditional Entropy</a></p></li>
<li><p><a class="reference internal" href="#perplexity" id="id66">Perplexity</a></p></li>
<li><p><a class="reference internal" href="#loss-function" id="id67">Loss Function</a></p></li>
<li><p><a class="reference internal" href="#convergence" id="id68">Convergence</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#gpt-is-a-autoregressive-self-supervised-learning-model" id="id69">GPT is a Autoregressive Self-Supervised Learning Model</a></p></li>
<li><p><a class="reference internal" href="#conditional-on-task" id="id70">Conditional on Task</a></p></li>
<li><p><a class="reference internal" href="#supervised-fine-tuning" id="id71">Supervised Fine-Tuning</a></p>
<ul>
<li><p><a class="reference internal" href="#objective-function-for-fine-tuning" id="id72">Objective Function for Fine-Tuning</a></p></li>
<li><p><a class="reference internal" href="#auxiliary-loss-function" id="id73">Auxiliary Loss Function</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#optimizing-unsupervised-is-the-same-as-optimizing-supervised" id="id74">Optimizing Unsupervised is the same as Optimizing Supervised</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#references-and-further-readings" id="id75">References and Further Readings</a></p></li>
<li><p><a class="reference internal" href="#citations" id="id76">Citations</a></p></li>
</ul>
</nav>
<section id="motivation">
<h2><a class="toc-backref" href="#id32" role="doc-backlink">Motivation</a><a class="headerlink" href="#motivation" title="Link to this heading">#</a></h2>
<p>The problem that GPT-2 aims to solve is to demonstrate that language models,
given <strong><em>large</em></strong> enough capacity in terms of parameters, and <strong><em>large</em></strong> enough
<strong><em>unlabeled and high-quality</em></strong> text data, can solve specialized natural
language processing tasks such as question answering, translation, and
summarization, in a
<a class="reference external" href="https://en.wikipedia.org/wiki/Zero-shot_learning"><strong><em>zero-shot</em></strong></a> manner -
without the need for task-specific architectures or supervised fine-tuning.</p>
<p>The emphasis on the <em>large and high-quality</em> text data cannot be understated as
the authors are hinging on the fact that the dataset is so <strong><em>diverse</em></strong>, and
therefore <em>bound</em> to have examples of the <em>specialized</em> tasks that the model can
learn from.</p>
<p>For example, if we are looking at translation tasks, then the data is bound to
have somewhat <strong>sequential</strong> and <strong>natural occuring translation text</strong> such as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">translation</span> <span class="n">of</span> <span class="n">the</span> <span class="n">french</span> <span class="n">sentence</span> <span class="s1">&#39;As-tu aller au cine ́ma?&#39;</span> <span class="n">to</span> <span class="n">english</span> <span class="ow">is</span> <span class="s1">&#39;Did you go to the cinema?&#39;</span><span class="o">.</span>
</pre></div>
</div>
<p>The model can learn from such examples and generalize to perform well on the
translation task via the
<a class="reference external" href="https://en.wikipedia.org/wiki/Autoregressive_model"><strong><em>autoregressive</em></strong></a>,
<a class="reference external" href="https://en.wikipedia.org/wiki/Self-supervised_learning"><strong><em>self-supervised</em></strong></a>
learning paradigm without the need for supervised fine-tuning.</p>
</section>
<section id="from-gpt-1-to-gpt-2">
<h2><a class="toc-backref" href="#id33" role="doc-backlink">From GPT-1 to GPT-2</a><a class="headerlink" href="#from-gpt-1-to-gpt-2" title="Link to this heading">#</a></h2>
<p>In
<a class="reference external" href="https://en.wikipedia.org/wiki/Natural-language_understanding"><strong>Natural Language Understanding</strong></a>
(NLU), there are a wide range of tasks, such as textual entailment, question
answering, semantic similarity assessment, and document classification. These
tasks are inherently labeled, but given the scarcity of such data, it makes
<a class="reference external" href="https://en.wikipedia.org/wiki/Discriminative_model">discriminative</a> models such
as Bidirectional Long Short-Term Memory (Bi-LSTM) underperform
<span id="id1">[<a class="reference internal" href="../../bibliography.html#id21" title="Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. 2018.">Radford <em>et al.</em>, 2018</a>]</span>, leading to poor performance on these tasks.</p>
<p>In the GPT-1 paper
<a class="reference external" href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf"><em>Improving Language Understanding by Generative Pre-Training</em></a>,
the authors demonstrated that <em>generative pre-training</em> of a language model on a
diverse corpus of <em>unlabeled</em> text, followed by <em>discriminative fine-tuning</em> on
each specific task, can overcome the constraints of the small amount of
annotated data for these specific tasks. The process is collectively termed as
<a class="reference external" href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised learning</a>
and the goal is to learn an <strong><em>universal representation</em></strong> of the natural
language space that can be used across a wide range of tasks.</p>
<p>The pretraining objective is to predict the next token in a sequence, in an
<strong><em>autoregressive</em></strong> manner, given the previous tokens. The pretrained model,
often known as the <strong><em>foundational model</em></strong> (or <em>backbone</em>), serves as a base
from which specialized capabilities can be added through <em>fine-tuning</em> on
specific tasks. In the fine-tuning phase, task-specific adaptations are
necessary: the input format must be adjusted to align with the particular
requirements of the task at hand, and the model’s final layer—or “head”—needs to
be replaced to accommodate the task’s specific class structure. The author
showed that this approach yielded state-of-the-art results on a wide range of
NLU tasks.</p>
<p>Notwithstanding the success of this approach, the same set of authors came up
with a new paper in the following year, titled
<a class="reference external" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"><em>Language Models are Unsupervised Multitask Learners</em></a>,
where they introduced a new model, <em>GPT-2</em>, that was larger in model capacity,
and trained on a much larger unlabeled corpus, <strong>WebText</strong>. However, the key
innovation was to void the supervised fine-tuning step, and instead, they
demonstrated that GPT-2 could be used directly on a wide range of NLU tasks
directly, with what they termed as the <em>zero-shot transfer</em>. The motivation is
that the authors think that foundational language models should be competent
generalists, rather than narrowly experts <span id="id2">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>. They call
for the need to shift the language model paradigm to one that is generic enough
to handle NLU tasks without the need to curate specific training data for each
specific task.</p>
<p>In what follows, we would first review the key concepts and ideas of the GPT-2
paper, formalize the autoregressive self-supervised learning paradigm, and then
take a look at the implementation of the GPT-2 model.</p>
</section>
<section id="gpt-2-paper-key-ideas">
<h2><a class="toc-backref" href="#id34" role="doc-backlink">GPT-2 Paper Key Ideas</a><a class="headerlink" href="#gpt-2-paper-key-ideas" title="Link to this heading">#</a></h2>
<p>In this section, we would review the key ideas from the GPT-2 paper.</p>
<section id="abstract-overview">
<h3><a class="toc-backref" href="#id35" role="doc-backlink">Abstract Overview</a><a class="headerlink" href="#abstract-overview" title="Link to this heading">#</a></h3>
<p>Below are the key ideas from the abstract of the GPT-2 paper:</p>
<ul class="simple">
<li><p>All <strong>previous pretrained language models</strong> necessitated a secondary stage
of <strong><em>supervised fine-tuning</em></strong> to tailor them to specific downstream tasks.</p></li>
<li><p>The authors showcased that, given sufficient <strong><em>model capacity</em></strong> and
<strong><em>data</em></strong>, language models can be adeptly adjusted to a broad spectrum of
tasks <strong><em>without the need for task-specific architectural modifications</em></strong>.</p></li>
<li><p>When tasked with a question-answering challenge, specifically conditioned on
a document and questions using the
<a class="reference external" href="https://huggingface.co/datasets/stanfordnlp/coqa">CoQA dataset</a> — comprised
of over 127,700 training examples — the model demonstrates the capability to
<strong><em>match or surpass the performance of three baseline models</em></strong>.</p></li>
<li><p>An emphasis is placed on the <strong><em>model’s capacity</em></strong> as being integral to the
success of <strong><em>zero-shot transfer</em></strong>. It’s highlighted that the model’s
performance escalates in a <strong><em>log-linear fashion</em></strong> relative to the number
of parameters, signifying that as the model’s capacity increases
<em>logarithmically</em>, its <strong>performance</strong> improves <em>linearly</em>.</p></li>
</ul>
</section>
<section id="introduction">
<h3><a class="toc-backref" href="#id36" role="doc-backlink">Introduction</a><a class="headerlink" href="#introduction" title="Link to this heading">#</a></h3>
<p>In this section, we would discuss the key ideas from the introduction of the
GPT-2 paper.</p>
<section id="key-1-competent-generalists-over-narrow-experts-1">
<h4><a class="toc-backref" href="#id37" role="doc-backlink">Key 1. Competent Generalists over Narrow Experts (1)</a><a class="headerlink" href="#key-1-competent-generalists-over-narrow-experts-1" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>The authors cited other works that have demonstrated significant success of
machine learning systems through a <strong><em>combination</em></strong> of <strong><em>large-scale
data</em></strong>, <strong><em>high model capacity</em></strong>, along with <strong><em>supervised fine-tuning</em></strong>.</p></li>
<li><p>However, such systems, termed as “<strong><em>narrow experts</em></strong>,” are fragile, as
they are highly dependent on the specific training regime and task. A slight
<strong><em>perturbation</em></strong> to the input distribution can cause the model to perform
poorly.</p></li>
<li><p>The authors then expressed the desire for “<strong><em>competent generalists</em></strong>” that
can perform well across a wide range of tasks <strong><em>without</em></strong> the need for
task-specific architectures or supervised fine-tuning.</p></li>
</ul>
</section>
<section id="key-2-iid-assumption-fails-in-real-world-2-3">
<h4><a class="toc-backref" href="#id38" role="doc-backlink">Key 2. IID Assumption Fails in Real World (2, 3)</a><a class="headerlink" href="#key-2-iid-assumption-fails-in-real-world-2-3" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>The overarching goal in machine learning is to <strong><em>generalize to unseen data
points</em></strong>. To streamline the modeling of machine learning objectives, it’s
commonly assumed that the training and test data are drawn from the same
distribution, a concept known as the
<a class="reference external" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables"><strong><em>Independent and Identically Distributed (i.i.d.)</em></strong></a>
assumption.</p>
<ul>
<li><p>As an aside, the i.i.d. assumption is foundational in statistical
modeling because it simplifies the process significantly. For example,
it allows us to
<a class="reference external" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables"><strong><em>express joint probability distributions</em></strong></a>
as the product of marginal distributions.</p></li>
<li><p>Furthermore, evaluation techniques such as <strong><em>resampling</em></strong> and
<strong><em>cross-validation</em></strong> with a holdout set rely on the assumption that
the training and test data are drawn from the same distribution.</p></li>
</ul>
</li>
<li><p>However, as the authors highlighted, the i.i.d. assumption fails in the real
world. The distribution of the test data is often different from the
training data, and the model’s performance degrades significantly when the
test data distribution is different from the training data distribution.</p></li>
<li><p>They attribute this to the prevalence of <strong>single</strong> task training on
<strong>single</strong> domain datasets, which limits the model’s ability to generalize
across diverse conditions and tasks.</p></li>
</ul>
<div class="seealso admonition">
<p class="admonition-title">References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/213464/on-the-importance-of-the-i-i-d-assumption-in-statistical-learning">On the importance of the i.i.d. assumption in statistical learning</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">Independent and identically distributed random variables - Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://gao-hongnan.github.io/gaohn-galaxy/probability_theory/08_estimation_theory/maximum_likelihood_estimation/concept.html#independence-and-identically-distributed-iid">Independence and Identically Distributed (IID) - GAO Hongnan</a></p></li>
</ul>
</div>
</section>
<section id="key-3-multi-task-learning-is-nacent-4">
<h4><a class="toc-backref" href="#id39" role="doc-backlink">Key 3. Multi-Task Learning is Nacent (4)</a><a class="headerlink" href="#key-3-multi-task-learning-is-nacent-4" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>The author then underscored that <strong><em>multi-task learning</em></strong> represents a
<strong><em>promising framework</em></strong>. By training a single model on <strong><em>multiple tasks
simultaneously</em></strong>, the model is enabled to leverage <strong><em>generalizable latent
space embeddings and representations</em></strong> to excel across various tasks.</p></li>
<li><p>It was further pointed out that recent work in the field utilizes, for
example, <strong><em>10 (dataset, objective) pairs</em></strong> <span id="id3">[<a class="reference internal" href="../../bibliography.html#id24" title="Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. The natural language decathlon: multitask learning as question answering. 2018. arXiv:1806.08730.">McCann <em>et al.</em>, 2018</a>]</span> to
train a singular model (an approach known as
<a class="reference external" href="https://en.wikipedia.org/wiki/Meta-learning_(computer_science)"><strong><em>meta-learning</em></strong></a>).
This implies that:</p>
<ul>
<li><p>Each dataset and its corresponding objective are unique.</p></li>
<li><p>For instance, one dataset might focus on <strong><em>sentiment data</em></strong>, with the
goal of <strong><em>predicting sentence sentiment</em></strong>, whereas another dataset
might concentrate on <strong><em>named entity recognition</em></strong>, aiming to
<strong><em>identify named entities within a sentence</em></strong>.</p></li>
</ul>
</li>
<li><p>The <strong><em>challenge</em></strong> then circles back to the <strong><em>compilation, curation, and
annotation</em></strong> of these datasets and objectives to ensure the model’s
generalizability. Essentially, this dilemma mirrors the initial issue of
<strong><em>single-task training on single-domain datasets</em></strong>. The implication is
that training a <strong><em>multi-task model</em></strong> might require an equivalent volume of
curated data as training several <strong><em>single-task models</em></strong>. Furthermore,
scalability becomes a concern when the focus is limited to merely <strong><em>10
(dataset, objective) pairs</em></strong>.</p></li>
</ul>
</section>
<section id="key-4-from-word-embeddings-to-contextual-embeddings-5-6">
<h4><a class="toc-backref" href="#id40" role="doc-backlink">Key 4. From Word Embeddings to Contextual Embeddings (5,6)</a><a class="headerlink" href="#key-4-from-word-embeddings-to-contextual-embeddings-5-6" title="Link to this heading">#</a></h4>
<ul>
<li><p>Initially, <strong><em>word embeddings</em></strong> such as <strong>Word2Vec</strong> and <strong>GloVe</strong>
revolutionized the representation of words by mapping them into dense,
fixed-dimensional vectors within a continuous <span class="math notranslate nohighlight">\(D\)</span> dimensional space, hinging
on the fact that words occuring in similar contexts/documents are similar
semantically. These vectors were then used as input to a model to perform a
specific task.</p></li>
<li><p>The next advancement is capturing more <em>contextual information</em> by using
<strong><em>contextual embeddings</em></strong>, where the word embeddings are <strong>conditioned</strong>
on the entire context of the sentence.
<a class="reference external" href="https://en.wikipedia.org/wiki/Recurrent_neural_network"><strong>Recurrent Neural Networks</strong></a>
(RNNs) is one example and the context embeddings can be “transferred” to
other downstream tasks.</p>
<p>Specifically, <strong>unidirectional RNNs</strong> are adept at assimilating context from
preceding elements, whereas <strong>bidirectional RNNs</strong> excel in integrating
context from both preceding and succeeding elements. Nonetheless, both
strategies grapple with challenges in encoding long-range dependencies.</p>
<p>Moreover, RNNs are notoriously plagued by the
<a class="reference external" href="https://ai.stackexchange.com/questions/20075/why-does-the-transformer-do-better-than-rnn-and-lstm-in-long-range-context-depen"><strong><em>gradient vanishing problem</em></strong></a>,
which means that the model is <strong>biased</strong> by the most <em>recent</em> tokens in the
sequence, and the model’s performance <strong>degrades</strong> as the <em>sequence length</em>
<strong>increases</strong>.</p>
</li>
<li><p><strong><em>Self-attention mechanisms</em></strong>, foundational to the <strong>Transformer
architecture</strong>, mark a paradigm shift by enabling each token to “attend” to
every other token within a sequence concurrently.</p>
<ul class="simple">
<li><p>This allows the model to capture long-range dependencies and is the
basis for the Transformer architecture. Consequently, self-attention is
non-sequential by design and operates over a <em>set</em> of tokens, and not a
<em>sequence</em> of tokens. This calls for the need to introduce positional
encodings to the input embeddings to capture the sequential nature of
the tokens.</p></li>
<li><p>This advancement transcends the limitations of static word embeddings.
Now, given two sentences, <em>I went to the river bank</em> versus <em>i went to
the bank to withdraw money</em>, the word “bank” in the first sentence is
semantically different from the word “bank” in the second sentence. The
contextual embeddings can capture this difference.</p></li>
</ul>
</li>
<li><p>The authors then went on to mention that the above methods would still
require supervised fine-tuning to adapt to a specific task.</p>
<p>If there are minimal or no supervised data is available, there are other
lines of work using language model to handle it - commonsense reasoning
(Schwartz et al., 2017) and sentiment analysis (Radford et al., 2017).</p>
</li>
</ul>
<div class="seealso admonition">
<p class="admonition-title">References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://ai.stackexchange.com/questions/20075/why-does-the-transformer-do-better-than-rnn-and-lstm-in-long-range-context-depen">Why does the transformer do better than RNN and LSTM in long-range context dependencies?</a></p></li>
<li><p><a class="reference external" href="https://stackoverflow.com/questions/55158554/how-transformer-is-bidirectional-machine-learning">How Transformer is Bidirectional - Machine Learning</a></p></li>
</ul>
</div>
</section>
<section id="key-5-zero-shot-learning-and-zero-shot-transfer-7">
<h4><a class="toc-backref" href="#id41" role="doc-backlink">Key 5. Zero Shot Learning and Zero Shot Transfer (7)</a><a class="headerlink" href="#key-5-zero-shot-learning-and-zero-shot-transfer-7" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Building upon the foundational concepts introduced previously, the authors
explore the utilization of <strong><em>general methods of transfer</em></strong> to illustrate
how language models can adeptly execute downstream tasks in a <strong><em>zero-shot
manner</em></strong>, without necessitating any modifications to parameters or
architecture.</p></li>
<li><p><strong><em>Zero-shot learning (ZSL)</em></strong> is characterized by a model’s capability to
accurately execute tasks or recognize categories that it was not explicitly
trained to handle. The crux of ZSL lies in its ability to <strong><em>generalize from
known to unknown</em></strong> classes or tasks by harnessing side information or
semantic relationships.</p>
<ul>
<li><p>For example, a model trained to recognize on a set of animals (including
horses) but not on zebra, should be able to recognize a zebra as
something close to horse, given the semantic relationship between the
two animals.</p></li>
</ul>
</li>
<li><p><strong><em>Zero-shot transfer</em></strong>, often discussed within the context of <strong>transfer
learning</strong>, involves applying a model trained on one set of tasks or domains
to a completely new task or domain without any additional training. Here,
the focus is on the transferability of learned features or knowledge across
different but related tasks or domains. Zero-shot transfer extends the
concept of transfer learning by not requiring any examples from the target
domain during training, relying instead on the model’s ability to generalize
across different contexts based on its pre-existing knowledge.</p></li>
</ul>
<div class="seealso admonition">
<p class="admonition-title">References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Zero-shot_learning">Zero-shot learning - Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://ai.stackexchange.com/questions/21719/what-is-the-difference-between-one-shot-learning-transfer-learning-and-fine-tun">What is the difference between one-shot learning, transfer learning, and fine-tuning? - AI Stack Exchange</a></p></li>
<li><p><a class="reference external" href="https://joeddav.github.io/blog/2020/05/29/ZSL.html">Zero-Shot Learning in Modern NLP - Joe Davison</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1301.3666">Zero-Shot Learning Through Cross-Modal Transfer - arXiv</a></p></li>
<li><p><a class="reference external" href="https://ai.stackexchange.com/questions/23527/zero-shot-learning-available-labels-in-testing-set">Zero shot learning available labels in testing set - AI Stack Exchange</a></p></li>
<li><p><a class="reference external" href="https://www.theaidream.com/post/zero-shot-learning-can-you-classify-an-object-without-seeing-it-before">Zero-Shot Learning: Can You Classify an Object Without Seeing It Before?</a></p></li>
<li><p><a class="reference external" href="https://dl.acm.org/doi/10.1145/3293318">A Survey of Zero-Shot Learning: Settings, Methods, and Applications</a></p></li>
</ul>
</div>
</section>
</section>
<section id="section-2-approach">
<h3><a class="toc-backref" href="#id42" role="doc-backlink">Section 2. Approach</a><a class="headerlink" href="#section-2-approach" title="Link to this heading">#</a></h3>
<p>In this section, we would discuss the key ideas from the approach section of the
GPT-2 paper.</p>
<section id="key-1-modeling-language-models-over-joint-probability-distributions-1">
<h4><a class="toc-backref" href="#id43" role="doc-backlink">Key 1. Modeling Language Models over Joint Probability Distributions (1)</a><a class="headerlink" href="#key-1-modeling-language-models-over-joint-probability-distributions-1" title="Link to this heading">#</a></h4>
<p>Language models strive to approximate the complex and inherently unknown
distribution of the natural language space, denoted as <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. In
contrast to supervised learning, which explicitly separates inputs
(<span class="math notranslate nohighlight">\(\mathcal{X}\)</span>) from labels (<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>), unsupervised learning —
particularly when employing self-supervision as seen in language modeling —
blurs this distinction. Here, <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> is conceptually a shifted
counterpart of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, facilitating a unified approach where
<span class="math notranslate nohighlight">\(\mathcal{D}\)</span> can be modeled exclusively over the space of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. This
scenario allows us to frame <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> as a probability distribution across
sequences of tokens within <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, parameterized by
<span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span>.</p>
<p>In this context, the essence of language modeling is to characterize the
<strong><em>joint probability distribution</em></strong> of sequences
<span class="math notranslate nohighlight">\(\mathbf{x} = (x_1, x_2, \ldots, x_T)\)</span> within <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. The goal is to
maximize the likelihood of observing these sequences in a corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>,
denoted as <span class="math notranslate nohighlight">\(\hat{\mathcal{L}}(\mathcal{S} ; \hat{\boldsymbol{\Theta}})\)</span>, where
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> represents the estimated parameter space that
approximates the true parameter space <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span>.</p>
</section>
<section id="key-2-decompose-joint-distributions-as-conditional-distributions-via-chain-rule-2">
<h4><a class="toc-backref" href="#id44" role="doc-backlink">Key 2. Decompose Joint Distributions as Conditional Distributions via Chain Rule (2)</a><a class="headerlink" href="#key-2-decompose-joint-distributions-as-conditional-distributions-via-chain-rule-2" title="Link to this heading">#</a></h4>
<p>The joint probability of a sequence in natural language, <strong>inherently ordered</strong>
<span id="id4">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>, can be factorized into the product of conditional
probabilities of each token in the sequence using the
<a class="reference external" href="https://en.wikipedia.org/wiki/Chain_rule_(probability)"><strong>chain rule of probability</strong></a>.
This approach not only enables <strong><em>tractable sampling</em></strong> from and
<strong><em>estimation</em></strong> of the distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{x} ; \boldsymbol{\Theta})\)</span> but also facilitates modeling
conditionals in forms such as
<span class="math notranslate nohighlight">\(\mathbb{P}(x_{t-k} \ldots x_t \mid x_1 \ldots x_{t-k-1} ; \boldsymbol{\Theta})\)</span>
<span id="id5">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>. Given a corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> with <span class="math notranslate nohighlight">\(N\)</span> sequences,
the likelihood function
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}(\mathcal{S} ; \hat{\boldsymbol{\Theta}})\)</span> represents the
likelihood of observing these sequences. The ultimate objective is to maximize
this likelihood, effectively <em>approximating</em> the joint probability distribution
through conditional probability distributions.</p>
</section>
<section id="key-3-conditional-on-task-3">
<h4><a class="toc-backref" href="#id45" role="doc-backlink">Key 3. Conditional on Task (3)</a><a class="headerlink" href="#key-3-conditional-on-task-3" title="Link to this heading">#</a></h4>
<p>In the GPT-2 paper, <em>Language Models are Unsupervised Multitask Learners</em>, the
authors introduced the concept of <em>conditional on task</em> where the GPT model
<span class="math notranslate nohighlight">\(\mathcal{G}\)</span> theoretically should not only learn the conditional probability
distribution <span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span> but also learn
the conditional probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}, \mathcal{T})\)</span> where
<span class="math notranslate nohighlight">\(\mathcal{T}\)</span> is the task that the model should implicitly learn
<span id="id6">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>. This is a powerful concept because if such a
hypothesis is correct, then the GPT model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> can indeed be a
multi-task learner, and can be used directly on a wide range of NLU tasks
without the need for supervised fine-tuning for downstream domain-specific
tasks.</p>
<p>In practice, the authors mentioned that task conditioning is often implemented
at an architectural level, via task specific encoder and decoder in the paper
<a class="reference external" href="https://arxiv.org/abs/1706.05137"><em>One Model To Learn Them All</em></a>
<span id="id7">[<a class="reference internal" href="../../bibliography.html#id23" title="Lukasz Kaiser, Aidan N. Gomez, Noam Shazeer, Ashish Vaswani, Niki Parmar, Llion Jones, and Jakob Uszkoreit. One model to learn them all. 2017. arXiv:1706.05137.">Kaiser <em>et al.</em>, 2017</a>]</span>, for instance, or at an algorithmic level, such as the
inner and outer loop optimization framework, as seen in the paper
<a class="reference external" href="https://arxiv.org/abs/1703.03400"><em>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</em></a>
<span id="id8">[<a class="reference internal" href="../../bibliography.html#id22" title="Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 2017. arXiv:1703.03400.">Finn <em>et al.</em>, 2017</a>]</span>.</p>
<p>However, the authors further mentioned that without task-specific architectural
changes, one can leverage the sequential nature of the natural language space
where we can construct a tasks, inputs and outputs all as a sequence of symbols
<span id="id9">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>. For example, a translation task can be formulated
as a sequence of symbols via
<code class="docutils literal notranslate"><span class="pre">(translate</span> <span class="pre">to</span> <span class="pre">french,</span> <span class="pre">english</span> <span class="pre">sequence,</span> <span class="pre">french</span> <span class="pre">sequence)</span></code>, where the model can
now learn to also condition on the task <code class="docutils literal notranslate"><span class="pre">(translate</span> <span class="pre">to</span> <span class="pre">french)</span></code> in addition to
the sequence of tokens. The paper <em>The Natural Language Decathlon: Multitask
Learning as Question Answering</em> exemplifies this concept with their model
<strong>Multitask Question Answering Network (MQAN)</strong>, where a single model is trained
to perform many diverse natural language processing tasks simultaneously.</p>
</section>
<section id="key-4-optimizing-unsupervised-is-the-same-as-optimizing-supervised-4">
<h4><a class="toc-backref" href="#id46" role="doc-backlink">Key 4. Optimizing Unsupervised is the same as Optimizing Supervised (4)</a><a class="headerlink" href="#key-4-optimizing-unsupervised-is-the-same-as-optimizing-supervised-4" title="Link to this heading">#</a></h4>
<p>The GPT-2 paper <em>Language Models are Unsupervised Multitask Learners</em>
demonstrated that they want to do away with the supervised fine-tuning phase via
an interesting hypothesis, that <strong>optimizing the unsupervised objective is the
same as optimizing the supervised objective</strong> because the <em>global minimum</em> of
the unsupervised objective is the same as the <em>global minimum</em> of the supervised
objective <span id="id10">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>.</p>
</section>
<section id="key-5-large-language-models-has-capacity-to-infer-and-generalize-5">
<h4><a class="toc-backref" href="#id47" role="doc-backlink">Key 5. Large Language Models has Capacity to Infer and Generalize (5)</a><a class="headerlink" href="#key-5-large-language-models-has-capacity-to-infer-and-generalize-5" title="Link to this heading">#</a></h4>
<p>In what follows, the author added that the internet contains a vast amount of
information that is passively available without the need for interactive
communication. The example that I provided on the french-to-english translation
would bound to exist naturally in the internet. They speculate that if the
language model is <strong>large</strong> enough in terms of <strong>capacity</strong>, then it should be
able to learn to perform the tasks demonstrated in natural language sequences in
order to better predict them, regardless of their method of procurement
<span id="id11">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>.</p>
<p>In the figure below, we can see examples of naturally occurring demonstrations
of English to French and French to English translation found throughout the
WebText training set.</p>
<figure class="align-default" id="decoder-concept-gpt-2-table-1">
<img alt="../../_images/gpt-2-table-1.png" src="../../_images/gpt-2-table-1.png" />
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Examples of naturally occurring demonstrations of English to French and French
to English translation found throughout the WebText training set.</span><a class="headerlink" href="#decoder-concept-gpt-2-table-1" title="Link to this image">#</a></p>
<div class="legend">
<p><strong>Image Credit:</strong>
<a class="reference external" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</a></p>
</div>
</figcaption>
</figure>
</section>
</section>
<section id="training-dataset">
<h3><a class="toc-backref" href="#id48" role="doc-backlink">2.1. Training Dataset</a><a class="headerlink" href="#training-dataset" title="Link to this heading">#</a></h3>
<section id="key-1-rejection-of-commoncrawl-1-2">
<h4><a class="toc-backref" href="#id49" role="doc-backlink">Key 1. Rejection of CommonCrawl (1,2)</a><a class="headerlink" href="#key-1-rejection-of-commoncrawl-1-2" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Prior research often focused on training language models on <strong><em>single-domain
datasets</em></strong>, which relates to the concept of models becoming <strong><em>narrow
experts</em></strong>.</p></li>
<li><p>To cultivate <strong><em>competent generalists</em></strong>, the authors contend that models
need exposure to a <strong><em>diverse array</em></strong> of tasks and domains.</p></li>
<li><p><strong><em>CommonCrawl</em></strong>, housing an expansive collection of web scrapes
(essentially capturing the entirety of the internet), is recognized for its
diversity.</p></li>
<li><p>Nevertheless, CommonCrawl was ultimately <strong><em>rejected</em></strong> by the authors due
to <strong><em>significant data quality issues</em></strong>.</p></li>
</ul>
</section>
<section id="key-2-construction-of-webtext-dataset">
<h4><a class="toc-backref" href="#id50" role="doc-backlink">Key 2. Construction of WebText Dataset</a><a class="headerlink" href="#key-2-construction-of-webtext-dataset" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>The authors sought to compile a web scrape prioritizing <strong><em>document quality
over quantity</em></strong>.</p></li>
<li><p>To attain a certain level of document quality without the exorbitant costs
of manual curation, the authors employed a strategy of <strong><em>indirect human
curation</em></strong>. This involved scraping all <strong><em>outbound links from Reddit</em></strong>
that garnered a minimum of <strong><em>3 karma</em></strong>. Karma, in this scenario, acts as a
heuristic for content deemed interesting, educational, or entertaining by
the Reddit community.</p>
<ul>
<li><p><strong><em>Outbound links</em></strong> refer to instances where a Reddit post links out to
external websites; the authors included the content from these external
sites in their dataset, contingent on the originating post receiving at
least 3 karma.</p></li>
</ul>
</li>
<li><p>The resulting dataset, dubbed <strong><em>WebText</em></strong>, comprises text from
approximately <strong><em>45 million links</em></strong>.</p></li>
<li><p>Subsequent preprocessing efforts, including <strong><em>de-duplication,
heuristic-based cleaning</em></strong>, and the <strong><em>exclusion of Wikipedia links</em></strong>,
resulted in a dataset spanning about <strong><em>40GB of text (8 million
documents)</em></strong>.</p></li>
<li><p>The snapshot of the dataset is <strong><em>December 2017</em></strong>.</p></li>
<li><p>Wikipedia’s exclusion was deliberate, stemming from the authors’ intention
to minimize overlap with training sources prevalent in other studies. This
decision aimed to facilitate more “authentic” <strong><em>evaluation/testing</em></strong>
scenarios for their model by reducing data leakage.</p></li>
</ul>
</section>
</section>
<section id="input-representation">
<h3><a class="toc-backref" href="#id51" role="doc-backlink">2.2. Input Representation</a><a class="headerlink" href="#input-representation" title="Link to this heading">#</a></h3>
<section id="key-1-byte-pair-encoding-bpe-1-2-3">
<h4><a class="toc-backref" href="#id52" role="doc-backlink">Key 1. Byte Pair Encoding (BPE) (1,2,3)</a><a class="headerlink" href="#key-1-byte-pair-encoding-bpe-1-2-3" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Traditional tokenization methods often involve steps such as
<strong><em>lower-casing</em></strong>, <strong><em>punctuation stripping</em></strong>, and <strong><em>splitting on
whitespace</em></strong>. Additionally, these methods might encode out-of-vocabulary
words using a special token to enable the model to handle unseen words
during evaluation or testing phases. For instance, language models (LMs) may
struggle with interpreting emojis due to such constraints.</p></li>
<li><p>These conventional approaches can inadvertently restrict the natural
language input space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, consequently limiting the model space
<span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. This limitation stems from the fact that the scope of
<span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is inherently dependent on the comprehensiveness of
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> as we can see
<span class="math notranslate nohighlight">\(\mathcal{H} = \mathcal{H}(\mathcal{X} ; \boldsymbol{\Theta})\)</span>, which means
that the model space <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is a function of the input space
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and the parameter space <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span>.</p></li>
<li><p>To resolve this, the idea of <strong><em>byte-level encoding</em></strong> can be used - since
you theoretically can encode any character in the world in <strong><em>UTF-8
encoding</em></strong>.</p></li>
<li><p>However, the limitation is current byte-level language models tend to
perform poorly on word level tasks.</p></li>
<li><p>The authors then introduced the BPE algorithm (is “byte-level” because it
operates on UTF-8 encoded strings) where they striked a balance between
character-level and word-level tokenization.</p></li>
<li><p>So in summary, BPE is the <strong>tokenizer</strong> used to encode the input text into a
sequence of tokens - which form the input representation to the model.</p></li>
</ul>
<div class="seealso admonition">
<p class="admonition-title">References</p>
<ul class="simple">
<li><p><a class="github reference external" href="https://github.com/karpathy/minbpe">karpathy/minbpe</a></p></li>
<li><p><a class="github reference external" href="https://github.com/openai/tiktoken">openai/tiktoken</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/learn/nlp-course/en/chapter6/5">Byte Pair Encoding on Hugging Face’s NLP Course</a></p></li>
</ul>
</div>
</section>
</section>
<section id="model">
<h3><a class="toc-backref" href="#id53" role="doc-backlink">2.3. Model</a><a class="headerlink" href="#model" title="Link to this heading">#</a></h3>
<p>The GPT-2 architecture is a <strong><em>transformer</em></strong>-based model, and as the name
suggests, it is a continuation of the GPT-1 model with some minor modifications.</p>
<section id="key-1-gpt-2-is-a-continuation-of-gpt-1-with-self-attention-mechanisms-1">
<h4><a class="toc-backref" href="#id54" role="doc-backlink">Key 1. GPT-2 is a Continuation of GPT-1 with Self-Attention Mechanisms (1)</a><a class="headerlink" href="#key-1-gpt-2-is-a-continuation-of-gpt-1-with-self-attention-mechanisms-1" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>GPT-2 utilizes a <strong>Transformer</strong> architecture <span id="id12">[<a class="reference internal" href="../../bibliography.html#id18" title="Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. 2017. arXiv:1706.03762.">Vaswani <em>et al.</em>, 2017</a>]</span>
as its backbone, which is distinguished by <strong><em>self-attention mechanisms</em></strong>.
This architecture empowers the model to capture complex dependencies and
relationships within the data.</p></li>
</ul>
</section>
<section id="key-2-modifications-from-gpt-1-and-model-stability-1">
<h4><a class="toc-backref" href="#id55" role="doc-backlink">Key 2. Modifications from GPT-1 and Model Stability (1)</a><a class="headerlink" href="#key-2-modifications-from-gpt-1-and-model-stability-1" title="Link to this heading">#</a></h4>
<ul>
<li><p>Modifications from GPT-1 include:</p>
<ul>
<li><p><strong>Layer normalization</strong> is repositioned to the <strong><em>input</em></strong> of each
sub-block, mirroring a <strong><em>pre-activation residual network</em></strong>. This
modification is believed to offer training stability and model
performance. By normalizing the inputs to each sub-block, it is
conjectured to alleviate issues tied to <strong><em>internal covariate shift</em></strong>,
thus aiding in smoother and potentially faster training.</p></li>
<li><p>GPT-2 introduces an <strong><em>additional layer normalization step</em></strong> that is
executed <strong><em>after the final self-attention block</em></strong> within the model.
This additional normalization step can help ensure that the outputs of
the transformer layers are normalized before being passed to subsequent
layers or used in further processing, further contributing to model
stability.</p></li>
<li><p>The GPT-2 paper introduces a modification to the standard weight
initialization for the model’s residual layers. Specifically, the
weights are scaled by a factor of
<span class="math notranslate nohighlight">\(\frac{1}{\sqrt{N_{\text{decoder_blocks}}}}\)</span>, where
<span class="math notranslate nohighlight">\(N_{\text{decoder_blocks}}\)</span> represents the number of blocks (or layers)
in the Transformer’s decoder.</p>
<p>The rationale, as quoted from the paper: <em>“A modified initialization
which accounts for the accumulation on the residual path with model
depth is used”</em> <span id="id13">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>, is to ensure that the
variance of the input to the block is the same as the variance of the
block’s output. This is to ensure that the signal is neither amplified
nor diminished as it passes through the block. As the model depth
increases, the activations get added/acculumated, and hence the scaling
factor is <span class="math notranslate nohighlight">\(\frac{1}{\sqrt{N_{\text{decoder_blocks}}}}\)</span>, to scale it
down.</p>
</li>
<li><p>Clearly, we can see the empahsis on model stability. In training large
language models, <strong>numerical stability</strong> is paramount; the cost of
training is significantly high, with every loss and gradient spike that
fails to recover necessitating a return to a previous checkpoint,
resulting in substantial GPU hours and potentially tens of thousands of
dollars wasted.</p></li>
<li><p>The model’s <strong>vocabulary</strong> is expanded to 50,257 tokens.</p></li>
<li><p>The context window size is increased from 512 to 1024 tokens, enhancing
the model’s ability to maintain coherence over longer text spans.</p></li>
<li><p>A larger batch size of 512, GPT-2 benefits from more stable and
effective gradient estimates during training, contributing to improved
learning outcomes.</p></li>
</ul>
</li>
</ul>
</section>
<section id="gpt-2-variants">
<h4><a class="toc-backref" href="#id56" role="doc-backlink">GPT-2 Variants</a><a class="headerlink" href="#gpt-2-variants" title="Link to this heading">#</a></h4>
<p>To this end, we encapsulate some key parameters in
<a class="reference internal" href="#decoder-concept-gpt-2-family"><span class="std std-numref">Table 3</span></a> below, which provides specifications for
several GPT-2 variants, distinguished by their scale.</p>
<div class="pst-scrollable-table-container"><table class="table" id="decoder-concept-gpt-2-family">
<caption><span class="caption-number">Table 3 </span><span class="caption-text">GPT-2 Family</span><a class="headerlink" href="#decoder-concept-gpt-2-family" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Parameters</p></th>
<th class="head"><p>Layers</p></th>
<th class="head"><p>d_model</p></th>
<th class="head"><p>H</p></th>
<th class="head"><p>d_ff</p></th>
<th class="head"><p>Activation</p></th>
<th class="head"><p>Vocabulary Size</p></th>
<th class="head"><p>Context Window</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>117M</p></td>
<td><p>12</p></td>
<td><p>768</p></td>
<td><p>12</p></td>
<td><p>3072</p></td>
<td><p>GELU</p></td>
<td><p>50,257</p></td>
<td><p>1024</p></td>
</tr>
<tr class="row-odd"><td><p>345M</p></td>
<td><p>24</p></td>
<td><p>1024</p></td>
<td><p>16</p></td>
<td><p>4096</p></td>
<td><p>GELU</p></td>
<td><p>50,257</p></td>
<td><p>1024</p></td>
</tr>
<tr class="row-even"><td><p>762M</p></td>
<td><p>36</p></td>
<td><p>1280</p></td>
<td><p>20</p></td>
<td><p>5120</p></td>
<td><p>GELU</p></td>
<td><p>50,257</p></td>
<td><p>1024</p></td>
</tr>
<tr class="row-odd"><td><p>1542M</p></td>
<td><p>48</p></td>
<td><p>1600</p></td>
<td><p>25</p></td>
<td><p>6400</p></td>
<td><p>GELU</p></td>
<td><p>50,257</p></td>
<td><p>1024</p></td>
</tr>
</tbody>
</table>
</div>
<div class="seealso admonition">
<p class="admonition-title">Implementation</p>
<p>See
<a class="reference external" href="https://www.gaohongnan.com/transformer/decoder/implementation.html">The Implementation of Generative Pre-trained Transformers (GPT)</a>
for a more comprehensive walkthrough of the GPT-2 model architecture, annotated
with code.</p>
</div>
</section>
</section>
</section>
<section id="the-autoregressive-self-supervised-learning-paradigm">
<h2><a class="toc-backref" href="#id57" role="doc-backlink">The Autoregressive Self-Supervised Learning Paradigm</a><a class="headerlink" href="#the-autoregressive-self-supervised-learning-paradigm" title="Link to this heading">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> be the true but unknown distribution of the natural language
space. In the context of unsupervised learning with self-supervision, such as
language modeling, we consider both the inputs and the implicit labels derived
from the same data sequence. Thus, while traditionally we might decompose the
distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> of a supervised learning task into input space
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and label space <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, in this scenario, <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> are intrinsically linked, because <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> is a shifted
version of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, and so we can consider <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> as a distribution
over <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> only.</p>
<p>Since <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> is a distribution, we also define it as a probability
distribution over <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, and we can write it as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{D} &amp;= \mathbb{P}(\mathcal{X} ; \boldsymbol{\Theta}) \\
            &amp;= \mathbb{P}_{\{\mathcal{X} ; \boldsymbol{\Theta}\}}(\mathbf{x})
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span> is the parameter space that defines the distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(\mathcal{X} ; \boldsymbol{\Theta})\)</span> and <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is a sample
from <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> generated by the distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. It is common to
treat <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> as a sequence of tokens (i.e. a sentence is a sequence of
tokens), and we can write <span class="math notranslate nohighlight">\(\mathbf{x} = \left(x_1, x_2, \ldots, x_T\right)\)</span>,
where <span class="math notranslate nohighlight">\(T\)</span> is the length of the sequence.</p>
<p>Given such a sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, the joint probability of the sequence can be
factorized into the product of the conditional probabilities of each token in
the sequence via the
<a class="reference external" href="https://en.wikipedia.org/wiki/Chain_rule_(probability)">chain rule of probability</a>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(\mathbf{x} ; \boldsymbol{\Theta}) = \prod_{t=1}^T \mathbb{P}(x_t \mid x_1, x_2, \ldots, x_{t-1} ; \boldsymbol{\Theta})
\]</div>
<p>We can do this because natural language are <em>inherently ordered</em>. Such
decomposition allows for <em>tractable sampling</em> from and <em>estimation</em> of the
distribution <span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{x} ; \boldsymbol{\Theta})\)</span> as well as any
conditionals in the form of
<span class="math notranslate nohighlight">\(\mathbb{P}(x_{t-k}, x_{t-k+1}, \ldots, x_{t} \mid x_{1}, x_{2}, \ldots, x_{t-k-1} ; \boldsymbol{\Theta})\)</span>
<span id="id14">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>.</p>
<p>To this end, consider a corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> with <span class="math notranslate nohighlight">\(N\)</span> sequences
<span class="math notranslate nohighlight">\(\left\{\mathbf{x}_{1}, \mathbf{x}_{2}, \ldots, \mathbf{x}_{N}\right\}\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\mathcal{S} = \left\{\mathbf{x}_{1}, \mathbf{x}_{2}, \ldots, \mathbf{x}_{N}\right\} \underset{\text{i.i.d.}}{\sim} \mathcal{D}
\]</div>
<p>where each sequence <span class="math notranslate nohighlight">\(\mathbf{x}_{n}\)</span> is a sequence of tokens that are sampled
<span class="math notranslate nohighlight">\(\text{i.i.d.}\)</span> from the distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<p>Then, we can frame the
<a class="reference external" href="https://gao-hongnan.github.io/gaohn-galaxy/probability_theory/08_estimation_theory/maximum_likelihood_estimation/concept.html">likelihood function</a>
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}(\cdot)\)</span> as the likelihood of observing the sequences in the
corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right) = \prod_{n=1}^N \mathbb{P}(\mathbf{x}_{n} ; \hat{\boldsymbol{\Theta}})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> is the estimated parameter space that
approximates the true parameter space <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span>.</p>
<p>Subsequently, the objective function is now well-defined, to be the maximization
of the likelihood of the sequences in the corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmax}} \hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right) \\
                              &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmax}} \prod_{n=1}^N \mathbb{P}(\mathbf{x}_{n} ; \hat{\boldsymbol{\Theta}}) \\
                              &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmax}} \prod_{n=1}^N \prod_{t=1}^{T_n} \mathbb{P}(x_{n, t} \mid x_{n, 1}, x_{n, 2}, \ldots, x_{n, t-1} ; \hat{\boldsymbol{\Theta}}) \\
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(T_n\)</span> is the length of the sequence <span class="math notranslate nohighlight">\(\mathbf{x}_{n}\)</span>.</p>
<p>Owing to the fact that multiplying many probabilities together can lead to
<a class="reference external" href="https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html#numerical-optimization-and-the-negative-log-likelihood">numerical instability</a>
because the product of many probabilities can be very small, it is common and
necessary to use the log-likelihood as the objective function, because it can be
proven that maximizing the log-likelihood is equivalent to maximizing the
likelihood itself.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmax}} \log\left(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\right) \\
&amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmax}} \sum_{n=1}^N \sum_{t=1}^{T_n} \log \mathbb{P}(x_{n, t} \mid x_{n, 1}, x_{n, 2}, \ldots, x_{n, t-1} ; \hat{\boldsymbol{\Theta}}) \\
\end{aligned}
\end{split}\]</div>
<p>Furthermore, since we are treating the the loss function as a form of
minimization, we can simply negate the log-likelihood to obtain the negative
log-likelihood as the objective function to be minimized,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmin}} \left(-\log\left(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\right)\right) \\
&amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmin}} \left(-\sum_{n=1}^N \sum_{t=1}^{T_n} \log \mathbb{P}(x_{n, t} \mid x_{n, 1}, x_{n, 2}, \ldots, x_{n, t-1} ; \hat{\boldsymbol{\Theta}})\right) \\
\end{aligned}
\end{split}\]</div>
<p>It is worth noting that the objective function is a function of the parameter
space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span>, and not the data <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, so all
analysis such as convergence and consistency will be with respect to the
parameter space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span>.</p>
<p>To this end, we denote the GPT model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> to be an <em>autoregressive</em> and
<em>self-supervised learning</em> model that is trained to maximize the likelihood of
observing all data points <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{S}\)</span> via the objective
function <span class="math notranslate nohighlight">\(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\)</span>
by learning the conditional probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \hat{\boldsymbol{\Theta}})\)</span> over the vocabulary
<span class="math notranslate nohighlight">\(\mathcal{V}\)</span> of tokens, conditioned on the contextual preciding tokens
<span class="math notranslate nohighlight">\(x_{&lt;t} = \left(x_1, x_2, \ldots, x_{t-1}\right)\)</span>. We are clear that although
the goal is to model the joint probability distribution of the token sequences,
we can do so by estimating the joint probability distribution via the
conditional probability distributions.</p>
<div class="proof remark admonition" id="decoder-simplified-objective-function">
<p class="admonition-title"><span class="caption-number">Remark 2 </span> (Simplification of the Objective Function)</p>
<section class="remark-content" id="proof-content">
<p>In what follows, we will mostly focus on the inner summand of the objective
function, namely, we will look at the loss function for a single sequence
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. And in particular the conditional probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \hat{\boldsymbol{\Theta}})\)</span>. It should be clear
that the objective function is over all <span class="math notranslate nohighlight">\(N\)</span> sequences in the corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>,
where each sequence <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span> can be decomposed into the product of the
conditional probabilities of each token in the sequence.</p>
</section>
</div><section id="autoregressive-self-supervised-learning">
<h3><a class="toc-backref" href="#id58" role="doc-backlink">Autoregressive Self-Supervised Learning</a><a class="headerlink" href="#autoregressive-self-supervised-learning" title="Link to this heading">#</a></h3>
<p>The learning paradigm of an autoregressive self-supervised learning framework
can be formalized as a learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> that is trained to
predict the next token <span class="math notranslate nohighlight">\(x_t\)</span> in a sequence given the previous tokens
<span class="math notranslate nohighlight">\(x_{&lt;t} = \left(x_1, x_2, \ldots, x_{t-1}\right)\)</span> in the sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>
(<em>autoregressive</em>), where <span class="math notranslate nohighlight">\(t \in \{1, 2, \ldots, T\}\)</span> is the position of the
token in the sequence, and <em>self-supervised</em> because the “label” <span class="math notranslate nohighlight">\(x_t\)</span> is
derived from the input sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> itself. The model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span>
then uses <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> to learn a <strong><em>conditional probability distribution</em></strong>
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span> over the vocabulary
<span class="math notranslate nohighlight">\(\mathcal{V}\)</span> of tokens, conditioned on the contextual preciding tokens
<span class="math notranslate nohighlight">\(x_{&lt;t} = \left(x_1, x_2, \ldots, x_{t-1}\right)\)</span>, where <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span>
is the parameter space that defines the distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span>.</p>
<p>The distinction between <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is that <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> is
the vocabulary of tokens, which is a discrete space, and <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is the
natural language space, which is a combinatorial discrete space. We can think of
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> as the natural language space of <em><strong>all possible sequences</strong></em>
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span> that can be formed from the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> (an
enumeration over <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>). Consequently, there is no confusion that a
<em>sequence</em> <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is a member of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, and a <em>token</em> <span class="math notranslate nohighlight">\(x_t\)</span> is a
member of <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>.</p>
<p>Through this learning algorithm, we can recover all chained conditional
probabilities of the form <span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span>,
which implicitly defines the joint probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{x}
; \boldsymbol{\Theta})\)</span> over the natural language space
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span><a class="footnote-reference brackets" href="#id31" id="id15" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>.</p>
</section>
<section id="estimation-of-the-conditional-probability-distribution">
<h3><a class="toc-backref" href="#id59" role="doc-backlink">Estimation of the Conditional Probability Distribution</a><a class="headerlink" href="#estimation-of-the-conditional-probability-distribution" title="Link to this heading">#</a></h3>
<p>In practice, we can only <em><strong>estimate</strong></em> the conditional probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span> from the corpus
<span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, and we can write the process of estimating as:</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathbb{P}}(x_t \mid x_{&lt;t} ; \hat{\boldsymbol{\Theta}}) \approx \mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> is the estimated parameter space that
approximates the true parameter space <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span>.</p>
<p>To facilitate the notational burden, we denote the estimated conditional
probability distribution
<span class="math notranslate nohighlight">\(\hat{\mathbb{P}}(x_t \mid x_{&lt;t} ; \hat{\boldsymbol{\Theta}})\)</span> as a function
<span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span>, and equate them as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{\hat{\boldsymbol{\Theta}}}(x_t \mid x_{&lt;t}) &amp;:= \mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}) \\
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(x_t \mid x_{&lt;t})\)</span> can be realised as our
GPT model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span>.</p>
<p>To this end, we should be clear that this learning process is to approximate the
true distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> of the natural language space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, but
instead of modeling over the entire space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, consisting of all
sequences <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, we model over the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> of tokens,
which is to generate the next token in a sequence given the previous tokens in
the sequence.</p>
</section>
<section id="initial-condition-of-conditional-probability-distribution">
<h3><a class="toc-backref" href="#id60" role="doc-backlink">Initial Condition of Conditional Probability Distribution</a><a class="headerlink" href="#initial-condition-of-conditional-probability-distribution" title="Link to this heading">#</a></h3>
<p>While the earlier conditional distribution seems correct by definition of the
<a class="reference external" href="https://en.wikipedia.org/wiki/Chain_rule_(probability)">chain rule of probability</a>,
it is worth noting that we are being a bit loose when <span class="math notranslate nohighlight">\(t=1\)</span>. Firstly, when
<span class="math notranslate nohighlight">\(t=1\)</span>, we are actually conditioning on nothing, and so it is the case that we
are estimating <span class="math notranslate nohighlight">\(\mathbb{P}(x_1 ; \boldsymbol{\Theta})\)</span>. But this is not part of
the learning process because we would need something to condition on. For the
sake of completeness, we can treat the initial token <span class="math notranslate nohighlight">\(x_1\)</span> as the initial
condition, and we can write the chain rule as:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(\mathbf{x} ; \boldsymbol{\Theta}) = \mathbb{P}(x_1 ; \boldsymbol{\Theta}) \prod_{t=2}^T \mathbb{P}(x_t \mid x_1, x_2, \ldots, x_{t-1} ; \boldsymbol{\Theta})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{P}(x_1 ; \boldsymbol{\Theta})\)</span> can be thought of the “initial
prompt” or “initial condition” of the sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p>
<div class="seealso admonition">
<p class="admonition-title">References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://d2l.ai/chapter_recurrent-neural-networks/sequence">Working with Sequences - Dive Into Deep Learning</a></p></li>
<li><p><a class="reference external" href="https://github.com/huggingface/transformers/issues/28860">How do LLMs learn to be “Generative”, as we often describe them?</a></p></li>
</ul>
</div>
</section>
<section id="markov-assumption">
<h3><a class="toc-backref" href="#id61" role="doc-backlink">Markov Assumption</a><a class="headerlink" href="#markov-assumption" title="Link to this heading">#</a></h3>
<p>Now suppose that we wish to employ the strategy mentioned above, where we
condition only on the <span class="math notranslate nohighlight">\(\tau\)</span> previous time steps, i.e.,
<span class="math notranslate nohighlight">\(x_{t-1}, \ldots, x_{t-\tau}\)</span>, rather than the entire sequence history
<span class="math notranslate nohighlight">\(x_{t-1}, \ldots, x_1\)</span>. Whenever we can throw away the history beyond the
previous <span class="math notranslate nohighlight">\(\tau\)</span> steps without any loss in predictive power, we say that the
sequence satisfies a Markov condition, i.e., that the future is conditionally
independent of the past, given the recent history. When <span class="math notranslate nohighlight">\(\tau=1\)</span>, we say that
the data is characterized by a first-order Markov model, and when <span class="math notranslate nohighlight">\(\tau=k\)</span>, we
say that the data is characterized by a <span class="math notranslate nohighlight">\(k^{\text {th }}\)</span>-order Markov model
<span id="id16">[<a class="reference internal" href="../../bibliography.html#id5" title="Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. Cambridge University Press, 2023. URL: https://D2L.ai.">Zhang <em>et al.</em>, 2023</a>]</span>.</p>
<p>More formally, a discrete-time Markov chain is a sequence of
<a class="reference external" href="https://en.wikipedia.org/wiki/Random_variable">random variables</a>
<span class="math notranslate nohighlight">\(X_1, X_2, X_3, \ldots\)</span> with the
<a class="reference external" href="https://en.wikipedia.org/wiki/Markov_property">Markov property</a>, namely that
the probability of moving to the next state depends only on the present state
and not on the previous states:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left(X_{t+1} \mid X_{1}, X_{2}, \ldots, X_{t}\right) = \mathbb{P}\left(X_{t+1} \mid X_{t-k+1}, X_{t-k+2}, \ldots, X_{t}\right)
\]</div>
<p>for all <span class="math notranslate nohighlight">\(t \in \mathbb{N}\)</span> and all states
<span class="math notranslate nohighlight">\(X_{t+1}, X_{t}, X_{1}, X_{2}, \ldots\)</span>.</p>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Markov_property">Markov assumption</a> is more
of an implicit assumption in the autoregressive self-supervised learning
framework where we can draw parallels to. We often find it useful to work with
models that proceed as though a Markov condition were satisfied, even when we
know that this is only approximately true. With real text documents we continue
to gain information as we include more and more leftwards context. But these
gains diminish rapidly. Thus, sometimes we compromise, obviating computational
and statistical difficulties by training models whose validity depends on a
<span class="math notranslate nohighlight">\(k^{\text {th }}\)</span>-order Markov condition. Even today’s massive RNN- and
Transformer based language models seldom incorporate more than thousands of
words of context <span id="id17">[<a class="reference internal" href="../../bibliography.html#id5" title="Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. Cambridge University Press, 2023. URL: https://D2L.ai.">Zhang <em>et al.</em>, 2023</a>]</span>. In short, the Markov assumption is a
convenient assumption to simplify the modeling of the joint probability
distribution of the token sequences.</p>
<div class="seealso admonition">
<p class="admonition-title">References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://news.ycombinator.com/item?id=35551452">GPT-4 absolutely isn’t a Markov chain</a></p></li>
<li><p><a class="reference external" href="https://twitter.com/karpathy/status/1645115622517542913">GPT is a Finite State Markov Chain - Andrej Karpathy</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_recurrent-neural-networks/sequence.html">Working with Sequences - Dive Into Deep Learning</a></p></li>
<li><p><a class="reference external" href="https://cs.stackexchange.com/questions/160891/why-gpt-model-is-a-higher-order-hidden-markov-model">Why GPT model is a higher order hidden markov model</a></p></li>
</ul>
</div>
</section>
<section id="the-estimator-function-is-smooth-with-respect-to-the-parameters">
<h3><a class="toc-backref" href="#id62" role="doc-backlink">The Estimator Function is Smooth with Respect to the Parameters</a><a class="headerlink" href="#the-estimator-function-is-smooth-with-respect-to-the-parameters" title="Link to this heading">#</a></h3>
<p>This assumption is a common one in the context of deep learning, because for
when we say that the estimator function <span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span>
is <em>smooth</em> with respect to the parameter space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span>, it
means that the estimator function <span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span> is
<em>smooth</em> with respect to the parameter space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> if the
function is continuous and differentiable with respect to the parameter space
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> up to a certain order (usually the first for SGD
variants and second order for Newton).</p>
<p>What this implies is that the derivative of the function with respect to the
parameter space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span>, denoted as
<span class="math notranslate nohighlight">\(\nabla_{\hat{\boldsymbol{\Theta}}} f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span> is
continuous. Loosely, you can think of that a small perturbation in the parameter
space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> will result in a small change in the output of
the function <span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span> - enabling gradient-based
optimization algorithms to work effectively as if not, then taking a step in the
direction of the gradient would not guarantee a decrease in the loss function,
slowing down convergence.</p>
<p>However, this is also not a strict assumption as in practice, piece-wise linear
activation functions are not smooth because the derivative is not continuous at
<span class="math notranslate nohighlight">\(0\)</span>, and consequently, <span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span> is
<a class="reference external" href="https://stats.stackexchange.com/questions/473643/why-are-neural-networks-smooth-functions">not smooth with respect to the parameter space</a>
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span>.</p>
</section>
<section id="context-length-and-token-context-window">
<h3><a class="toc-backref" href="#id63" role="doc-backlink">Context Length and Token Context Window</a><a class="headerlink" href="#context-length-and-token-context-window" title="Link to this heading">#</a></h3>
<p>Given a coherent sequence of tokens <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, say, <em>the tabby cat walks by
the river bank</em>, we may not always pass the full sequence to the model. Based on
a <em>context length</em> <span class="math notranslate nohighlight">\(\tau\)</span>, we can pass a <em>token context window</em> of length <span class="math notranslate nohighlight">\(\tau\)</span>
to the model. For instance, if <span class="math notranslate nohighlight">\(\tau=4\)</span>, then the token context window would be
<span class="math notranslate nohighlight">\(\left(x_{t-3}, x_{t-2}, x_{t-1}, x_{t}\right)\)</span>, and the model would be trained
to predict the next token <span class="math notranslate nohighlight">\(x_{t+1}\)</span> given the token context window. In other
words, the sentence above would be broken down into the following token context
windows:</p>
<ul class="simple">
<li><p><em>the tabby cat walks</em></p></li>
<li><p><em>by the river bank</em></p></li>
</ul>
<p>And the longer the context length, the model would be able to capture
longer-range dependenciees in the sequence, but also may increase the
computational complexity of the model <span id="id18">[<a class="reference internal" href="../../bibliography.html#id17" title="Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 2023. URL: https://www.mdpi.com/2227-7390/11/11/2451, doi:10.3390/math11112451.">Lee, 2023</a>]</span>.</p>
<p>More formally, we can define the token context window as a function
<span class="math notranslate nohighlight">\(C_{\tau}(\mathbf{x}, t)\)</span> that maps a sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and a position <span class="math notranslate nohighlight">\(t\)</span>
to a token context window of length <span class="math notranslate nohighlight">\(\tau\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
C_{\tau} : \mathcal{X} \times \mathbb{N} &amp;\rightarrow \mathcal{X}^{\tau} \\
(\mathbf{x}, t) &amp;\mapsto \left(x_{t-\tau+1}, x_{t-\tau+2}, \ldots, x_{t}\right)
\end{aligned}
\end{split}\]</div>
</section>
<section id="conditional-entropy-and-perplexity-as-loss-function">
<h3><a class="toc-backref" href="#id64" role="doc-backlink">Conditional Entropy and Perplexity as Loss Function</a><a class="headerlink" href="#conditional-entropy-and-perplexity-as-loss-function" title="Link to this heading">#</a></h3>
<p>Having defined the basis of the autoregressive self-supervised learning
framework, we can now define the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> that is used to
train the model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> to maximize the likelihood of the sequences in the
corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. In order to transit towards the final objective/loss
function, we would need to define the notion of
<a class="reference external" href="https://en.wikipedia.org/wiki/Conditional_entropy"><em><strong>conditional entropy</strong></em></a>.</p>
<section id="conditional-entropy">
<h4><a class="toc-backref" href="#id65" role="doc-backlink">Conditional Entropy</a><a class="headerlink" href="#conditional-entropy" title="Link to this heading">#</a></h4>
<p>Define <span class="math notranslate nohighlight">\(X_t\)</span> as a random variable representing the token at position <span class="math notranslate nohighlight">\(t\)</span> in the
sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and <span class="math notranslate nohighlight">\(X_{&lt;t} = \left(X_1, X_2, \ldots, X_{t-1}\right)\)</span> as
random variables representing the tokens at positions <span class="math notranslate nohighlight">\(1, 2, \ldots, t-1\)</span> in the
sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. Then the conditional
<a class="reference external" href="https://en.wikipedia.org/wiki/Shannon_Entropy">entropy</a> of the token <span class="math notranslate nohighlight">\(X_t\)</span>
given a specific realization of <span class="math notranslate nohighlight">\(X_{&lt;t}\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
H\left(X_t \mid X_{&lt;t} = x_{&lt;t} \right) &amp;= -\sum_{x_t \in \mathcal{V}} \mathbb{P}\left(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}\right) \log \mathbb{P}\left(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}\right) \\
\end{aligned}
\end{split}\]</div>
<p>This calculates the conditional entropy given a specific realization of the
context <span class="math notranslate nohighlight">\(X_{&lt;t} = x_{&lt;t}\)</span>, where we see that summation sums over all
possibilities of the token <span class="math notranslate nohighlight">\(x_t\)</span> in the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>, considering
the probability of the token <span class="math notranslate nohighlight">\(x_t\)</span> given <em>a particular preceding</em> sequence of
tokens.</p>
<p>To account for all possible realizations of the context <span class="math notranslate nohighlight">\(X_{&lt;t}\)</span>, we simply sum
over all possible realizations of the context <span class="math notranslate nohighlight">\(X_{&lt;t}\)</span>, and we can write the
conditional entropy as:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
H\left(X_t \mid X_{&lt;t}\right) = -\sum_{x_{t} \in \mathcal{V}} \sum_{x_{&lt;t} \in \mathcal{V}^{&lt;t}} \mathbb{P}\left(x_t, x_{&lt;t} ; \boldsymbol{\Theta}\right) \log \mathbb{P}\left(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}\right)
\end{aligned}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{P}\left(x_t, x_{&lt;t} ; \boldsymbol{\Theta}\right)\)</span> is the joint
probability distribution of observing the sequence <span class="math notranslate nohighlight">\((x_{&lt;t}, x_t)\)</span>,
<span class="math notranslate nohighlight">\(\mathbb{P}\left(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}\right)\)</span> is the
conditional probability distribution of observing the token <span class="math notranslate nohighlight">\(x_t\)</span> given the
context <span class="math notranslate nohighlight">\(x_{&lt;t}\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{V}^{&lt;t}\)</span> is the set of all possible realizations
of the context <span class="math notranslate nohighlight">\(X_{&lt;t}\)</span>.</p>
<p>It is worth noting that the conditional entropy <span class="math notranslate nohighlight">\(H\left(X_t \mid X_{&lt;t}\right)\)</span>
is also the conditional expectation of the negative log-likelihood of the token
<span class="math notranslate nohighlight">\(X_t\)</span> given the context <span class="math notranslate nohighlight">\(X_{&lt;t}\)</span>, and we can write it as:</p>
<div class="math notranslate nohighlight">
\[
H\left(X_t \mid X_{&lt;t}\right) = -\mathbb{E}_{\mathcal{D}}\left[\log \mathbb{P}\left(X_t \mid X_{&lt;t} ; \boldsymbol{\Theta}\right)\right]
\]</div>
<div class="seealso admonition">
<p class="admonition-title">References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Conditional_entropy">Conditional Entropy - Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Conditional_expectation">Conditional Expectation - Wikipedia</a></p></li>
</ul>
</div>
</section>
<section id="perplexity">
<h4><a class="toc-backref" href="#id66" role="doc-backlink">Perplexity</a><a class="headerlink" href="#perplexity" title="Link to this heading">#</a></h4>
<p>Language model has a standing history of using
<a class="reference external" href="https://en.wikipedia.org/wiki/Perplexity"><strong>Perplexity</strong></a> as a measure of the
quality of a language model. It is a measure of how well a probability
distribution or probability model predicts a sample. Without going into the
details, we define the perplexity of a probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span> as the exponential of the
conditional entropy of the distribution, and we can write it as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\operatorname{Perplexity}\left(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\right) &amp;= \exp\left(H\left(X_t \mid X_{&lt;t}\right)\right) \\
\end{aligned}
\end{split}\]</div>
<div class="seealso admonition">
<p class="admonition-title">References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Perplexity">Perplexity - Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/docs/transformers/en/perplexity">Perplexity of fixed-length models</a></p></li>
</ul>
</div>
</section>
<section id="loss-function">
<h4><a class="toc-backref" href="#id67" role="doc-backlink">Loss Function</a><a class="headerlink" href="#loss-function" title="Link to this heading">#</a></h4>
<p>Given the definitions of the conditional entropy and perplexity, we can
formalize the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{L}\left(\mathcal{D} ; \boldsymbol{\Theta}\right) &amp;= -\sum_{\mathbf{x} \in \mathcal{D}} \sum_{t=1}^T \log \mathbb{P}\left(x_t \mid C_{\tau}(\mathbf{x}, t) ; \boldsymbol{\Theta}\right) \\
\end{aligned}
\end{split}\]</div>
<p>and the objective function is to minimize the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\boldsymbol{\theta}^{*} &amp;= \underset{\boldsymbol{\theta} \in \boldsymbol{\Theta}}{\text{argmin}} \mathcal{L}\left(\mathcal{D} ; \boldsymbol{\Theta}\right) \\
                        &amp;= \underset{\boldsymbol{\theta} \in \boldsymbol{\Theta}}{\text{argmin}} -\sum_{\mathbf{x} \in \mathcal{D}} \sum_{t=1}^T \log \mathbb{P}\left(x_t \mid C_{\tau}(\mathbf{x}, t) ; \boldsymbol{\Theta}\right) \\
\end{aligned}
\end{split}\]</div>
<p>However, we do not know the true distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>, and so we can only
estimate the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> from the corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, and we
can write the process of estimating via the negative log-likelihood as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right) &amp;= -\sum_{\mathbf{x} \in \mathcal{S}} \sum_{t=1}^T \log \mathbb{P}\left(x_t \mid C_{\tau}(\mathbf{x}, t) ; \hat{\boldsymbol{\Theta}}\right) \\
    &amp;= -\sum_{n=1}^N \sum_{t=1}^{T_n} \log \mathbb{P}\left(x_{n, t} \mid C_{\tau}(\mathbf{x}_{n}, t) ; \hat{\boldsymbol{\Theta}}\right) \\
\end{aligned}
\end{split}\]</div>
<p>and consequently, the objective function is to minimize the estimated loss
function
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmin}} \hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right) \\
                              &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmin}} -\sum_{n=1}^N \sum_{t=1}^{T_n} \log \mathbb{P}\left(x_{n, t} \mid C_{\tau}(\mathbf{x}_{n}, t) ; \hat{\boldsymbol{\Theta}}\right) \\
\end{aligned}
\end{split}\]</div>
</section>
<section id="convergence">
<h4><a class="toc-backref" href="#id68" role="doc-backlink">Convergence</a><a class="headerlink" href="#convergence" title="Link to this heading">#</a></h4>
<p>It can be shown that the given the Markov assumption and a token context window
size of <span class="math notranslate nohighlight">\(\tau\)</span>, the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is a
<a class="reference external" href="https://en.wikipedia.org/wiki/Consistent_estimator">consistent estimator</a> of
the true distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>, and the the objective
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\)</span>
converges to the true conditional probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span> over <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> as the
size of the corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> goes to infinity, if the model has sufficient
capacity and the optimization algorithm is appropriate <span id="id19">[<a class="reference internal" href="../../bibliography.html#id17" title="Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 2023. URL: https://www.mdpi.com/2227-7390/11/11/2451, doi:10.3390/math11112451.">Lee, 2023</a>]</span>.</p>
<p>Furthermore, the proposition that the conditional entropy
<span class="math notranslate nohighlight">\(H\left(X_t \mid X_{&lt;t}\right)\)</span> of the true data-generating process is upper
bounded by the logarithm of the size of the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>, i.e.,
<span class="math notranslate nohighlight">\(H\left(X_t \mid X_{&lt;t}\right) \leq \log |\mathcal{V}|\)</span> <span id="id20">[<a class="reference internal" href="../../bibliography.html#id17" title="Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 2023. URL: https://www.mdpi.com/2227-7390/11/11/2451, doi:10.3390/math11112451.">Lee, 2023</a>]</span>.</p>
<p>The proposition that the conditional entropy has an upper limit, carries
significant implications for optimizing autoregressive self-supervised learning
models. Specifically, because the conditional entropy cannot exceed the
logarithm of the vocabulary size <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>, we infer a similar upper limit
on perplexity. This cap on perplexity offers a valuable benchmark for evaluating
and comparing different models, establishing a theoretical maximum for model
performance based on the size of the vocabulary <span id="id21">[<a class="reference internal" href="../../bibliography.html#id17" title="Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 2023. URL: https://www.mdpi.com/2227-7390/11/11/2451, doi:10.3390/math11112451.">Lee, 2023</a>]</span>.</p>
</section>
</section>
<section id="gpt-is-a-autoregressive-self-supervised-learning-model">
<h3><a class="toc-backref" href="#id69" role="doc-backlink">GPT is a Autoregressive Self-Supervised Learning Model</a><a class="headerlink" href="#gpt-is-a-autoregressive-self-supervised-learning-model" title="Link to this heading">#</a></h3>
<p>Finally, we can piece together the autoregressive self-supervised learning
framework to define the GPT model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> as a model that is trained to
maximize the likelihood of the sequences in the corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> via the
objective function
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\)</span> where
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> is the estimated parameter space that approximates
the true parameter space <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is the corpus
of sequences that are sampled <span class="math notranslate nohighlight">\(\text{i.i.d.}\)</span> from the distribution
<span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<p>In pseudo-code, the GPT model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> consists of decoder blocks, each
block consisting of a multi-head self-attention mechanism and a position-wise
feed-forward neural network, with a head layer to produce a probability
distribution over the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> of tokens.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
h_0 &amp;= \mathcal{S} \cdot \mathbf{W}_{e}+ \mathbf{W}_{p} \\
h_{\ell} &amp;= \text{DecoderBlock}(h_{\ell-1}) \quad \text{for} \quad \ell = 1, 2, \ldots, L \\
\mathbb{P}(x_t \mid C_{\tau}(\mathbf{x}, t) ; \boldsymbol{\Theta}) &amp;= \text{softmax}(h_{L} \cdot \mathbf{W}_{e}^{\top})
\end{aligned}
\end{split}\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{W}_{e}\)</span> is the embedding matrix that maps the token to a vector
representation in a continuous vector space,</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{W}_{p}\)</span> is the positional encoding matrix that encodes the position
of the token in the sequence,</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{DecoderBlock}\)</span> is a function that applies a multi-head self-attention
mechanism and a position-wise feed-forward neural network to the input
sequence,</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{W}_{e}^{\top}\)</span> is the transpose of the embedding matrix that maps
the vector representation of the token back to the vocabulary space.</p></li>
</ul>
<p>Note that it is only a pseudo-code because notations like <span class="math notranslate nohighlight">\(\mathbf{W}_{e}\)</span> are
used to denote both the token embedding matrix in <span class="math notranslate nohighlight">\(h_0\)</span> and the transformed
contextual embedding matrix in the head/linear/last layer. The actual
implementation of the GPT model is more complex, and we will take a look at it
in later sections.</p>
</section>
<section id="conditional-on-task">
<h3><a class="toc-backref" href="#id70" role="doc-backlink">Conditional on Task</a><a class="headerlink" href="#conditional-on-task" title="Link to this heading">#</a></h3>
<p>In the GPT-2 paper, <em>Language Models are Unsupervised Multitask Learners</em>, the
authors introduced the concept of <em>conditional on task</em> where the GPT model
<span class="math notranslate nohighlight">\(\mathcal{G}\)</span> theoretically should not only learn the conditional probability
distribution <span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span> but also learn
the conditional probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}, \mathcal{T})\)</span> where
<span class="math notranslate nohighlight">\(\mathcal{T}\)</span> is the task that the model should implicitly learn
<span id="id22">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>. This is a powerful concept because if such a
hypothesis is correct, then the GPT model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> can indeed be a
multi-task learner, and can be used directly on a wide range of NLU tasks
without the need for supervised fine-tuning for downstream domain-specific
tasks.</p>
<p>In practice, the authors mentioned that task conditioning is often implemented
at an architectural level, via task specific encoder and decoder in the paper
<a class="reference external" href="https://arxiv.org/abs/1706.05137"><em>One Model To Learn Them All</em></a>
<span id="id23">[<a class="reference internal" href="../../bibliography.html#id23" title="Lukasz Kaiser, Aidan N. Gomez, Noam Shazeer, Ashish Vaswani, Niki Parmar, Llion Jones, and Jakob Uszkoreit. One model to learn them all. 2017. arXiv:1706.05137.">Kaiser <em>et al.</em>, 2017</a>]</span>, for instance, or at an algorithmic level, such as the
inner and outer loop optimization framework, as seen in the paper
<a class="reference external" href="https://arxiv.org/abs/1703.03400"><em>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</em></a>
<span id="id24">[<a class="reference internal" href="../../bibliography.html#id22" title="Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 2017. arXiv:1703.03400.">Finn <em>et al.</em>, 2017</a>]</span>.</p>
<p>However, the authors further mentioned that without task-specific architectural
changes, one can leverage the sequential nature of the natural language space
where we can construct a tasks, inputs and outputs all as a sequence of symbols
<span id="id25">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>. For example, a translation task can be formulated
as a sequence of symbols via
<code class="docutils literal notranslate"><span class="pre">(translate</span> <span class="pre">to</span> <span class="pre">french,</span> <span class="pre">english</span> <span class="pre">sequence,</span> <span class="pre">french</span> <span class="pre">sequence)</span></code>, where the model can
now learn to also condition on the task <code class="docutils literal notranslate"><span class="pre">(translate</span> <span class="pre">to</span> <span class="pre">french)</span></code> in addition to
the sequence of tokens. The paper <em>The Natural Language Decathlon: Multitask
Learning as Question Answering</em> exemplifies this concept with their model
<strong>Multitask Question Answering Network (MQAN)</strong>, where a single model is trained
to perform many diverse natural language processing tasks simultaneously.</p>
</section>
<section id="supervised-fine-tuning">
<h3><a class="toc-backref" href="#id71" role="doc-backlink">Supervised Fine-Tuning</a><a class="headerlink" href="#supervised-fine-tuning" title="Link to this heading">#</a></h3>
<p>Though GPT-2 has demonstrated that it can be used directly on a wide range of
NLU without the need for supervised fine-tuning, it is worth taking a detour
back to how GPT-1 was fine-tuned immediately after the pretraining phase.</p>
<p>In the paper <em>Improving Language Understanding by Generative Pre-Training</em>,
after the pretrained (foundational) model was trained with the objective
function
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\)</span>, we
would then fine-tune the model on a specific task by replacing the final layer
of the model with a task-specific layer, and then train the model on the
specific task with the task-specific layer <span id="id26">[<a class="reference internal" href="../../bibliography.html#id21" title="Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. 2018.">Radford <em>et al.</em>, 2018</a>]</span>.</p>
<section id="objective-function-for-fine-tuning">
<h4><a class="toc-backref" href="#id72" role="doc-backlink">Objective Function for Fine-Tuning</a><a class="headerlink" href="#objective-function-for-fine-tuning" title="Link to this heading">#</a></h4>
<p>More concretely, now our dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is a dataset of labeled examples
<span class="math notranslate nohighlight">\(\mathcal{S} = \left\{\left(\mathbf{x}_n, y_n\right)\right\}_{n=1}^N\)</span>, where it
may be sampled together from a new underlying distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>,
usually a cartesian product <span class="math notranslate nohighlight">\(\mathcal{X} \times \mathcal{Y}\)</span> where <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>
is the label space. Each input sequence <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span> is a sequence of tokens,
and each output label <span class="math notranslate nohighlight">\(y_n\)</span> is a label from the set of labels <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>.</p>
<p>A task specific layer is often used to replace the original head layer, for
instance, if we are training the model on a text classification task with
<span class="math notranslate nohighlight">\(\mathcal{C}\)</span> number of classes, then the task specific layer would be a linear
layer with <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> number of output units. Of course, the output of this
layer, being the logits, will usually pass into appropriate loss functions such
as the cross-entropy loss with a softmax layer on top of the logits to induce a
<em>not so well-calibrated</em> probability distribution over the classes
<span class="math notranslate nohighlight">\(\mathcal{C}\)</span>.</p>
<p>If we denote the loss function (or the negative log-likelihood) of the
pre-training phase as
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}_{1}\left(\mathcal{S}_{1} ; \hat{\boldsymbol{\Theta}}_{1}\right)\)</span>,
then the objective in this second phase is simply to maximize the likelihood of
the labeled examples <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> via the objective function
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}_{2}\left(\mathcal{S}_{2} ; \hat{\boldsymbol{\Theta}}_{2}\right)\)</span>
where <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}_{1}\)</span> is the estimated parameter space for the
pre-training phase, and <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}_{2}\)</span> is the estimated
parameter space for the fine-tuning phase. Note that the
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}_{2}\)</span> is initialized with partial weights from the
pre-trained model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span>, so it naturally should overlap with the
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}_{1}\)</span> up to the number of <em>frozen</em> layers.</p>
<p>We denote the maximization as a minimization of the negative log-likelihood:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}_{2}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}}_{2} \in \boldsymbol{\Theta}_{2}}{\text{argmin}} \hat{\mathcal{L}}_{2}\left(\mathcal{S}_{2} ; \hat{\boldsymbol{\Theta}}_{2}\right) \\
                                    &amp;= \underset{\hat{\boldsymbol{\theta}}_{2} \in \boldsymbol{\Theta}_{2}}{\text{argmin}} -\sum_{n=1}^N \log \mathbb{P}\left(y_n \mid \mathbf{x}_n ; \hat{\boldsymbol{\Theta}}_{2}\right) \\
\end{aligned}
\end{split}\]</div>
<p>It is also customary to find the expected loss over the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}_{2}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}}_{2} \in \boldsymbol{\Theta}_{2}}{\text{argmin}} \mathbb{E}_{\mathcal{S}}\left[\hat{\mathcal{L}}_{2}\left(\mathcal{S}_{2} ; \hat{\boldsymbol{\Theta}}_{2}\right)\right] \\
                                    &amp;= \underset{\hat{\boldsymbol{\theta}}_{2} \in \boldsymbol{\Theta}_{2}}{\text{argmin}} -\mathbb{E}_{\mathcal{S}}\left[\sum_{n=1}^N \log \mathbb{P}\left(y_n \mid \mathbf{x}_n ; \hat{\boldsymbol{\Theta}}_{2}\right)\right] \\
                                    &amp;= -\frac{1}{N} \sum_{n=1}^N \log \mathbb{P}\left(y_n \mid \mathbf{x}_n ; \hat{\boldsymbol{\Theta}}_{2}\right) \\
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the number of samples in the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
</section>
<section id="auxiliary-loss-function">
<h4><a class="toc-backref" href="#id73" role="doc-backlink">Auxiliary Loss Function</a><a class="headerlink" href="#auxiliary-loss-function" title="Link to this heading">#</a></h4>
<p>In the context of fine-tuning GPT-1 or similar models for specific tasks, the
term “auxiliary (supplementary) loss” refers to additional objectives or loss
functions that are incorporated into the fine-tuning process alongside the
primary loss function. This approach is based on the idea that including
auxiliary tasks or losses can help improve the model’s performance on the main
task by leveraging the knowledge gained during pre-training. The author also
mentioned that this method (a) improving generalization of the supervised model,
and (b) accelerating convergence <span id="id27">[<a class="reference internal" href="../../bibliography.html#id21" title="Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. 2018.">Radford <em>et al.</em>, 2018</a>]</span>.</p>
<p>During pre-training, models like GPT-1 learn to predict the next token in a
sequence, which is a form of auxiliary task. When fine-tuning these models on
downstream tasks, the authors of the GPT-1 paper found it beneficial to include
the pre-training loss (the auxiliary loss) in the fine-tuning loss function.
This is done by calculating the primary loss for the specific task (e.g.,
classification, named-entity recognition) and then combining it with the
auxiliary loss, often with a weighting factor to balance their contributions.
The weighting factor, denoted as <span class="math notranslate nohighlight">\(\alpha\)</span> in the fine-tuning loss function,
allows for adjusting the relative importance of the primary and auxiliary losses
during the fine-tuning process.</p>
<p>To this end, the final loss function for fine-tuning the GPT-1 model on a
specific task is a combination of the primary loss and the auxiliary loss, and
we can write it as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\mathcal{L}}_{3}\left(\mathcal{S}_{2} ; \hat{\boldsymbol{\Theta}}_{3}\right) &amp;= \alpha \hat{\mathcal{L}}_{2}\left(\mathcal{S}_{2} ; \hat{\boldsymbol{\Theta}}_{2}\right) + (1 - \alpha) \hat{\mathcal{L}}_{1}\left(\mathcal{S}_{1} ; \hat{\boldsymbol{\Theta}}_{1}\right) \\
\end{aligned}
\end{split}\]</div>
<p>and we can minimize the new auxiliary loss function in the same way.</p>
</section>
</section>
<section id="optimizing-unsupervised-is-the-same-as-optimizing-supervised">
<h3><a class="toc-backref" href="#id74" role="doc-backlink">Optimizing Unsupervised is the same as Optimizing Supervised</a><a class="headerlink" href="#optimizing-unsupervised-is-the-same-as-optimizing-supervised" title="Link to this heading">#</a></h3>
<p>The GPT-2 paper <em>Language Models are Unsupervised Multitask Learners</em>
demonstrated that they want to do away with the supervised fine-tuning phase via
an interesting hypothesis, that <strong>optimizing the unsupervised objective is the
same as optimizing the supervised objective</strong> because the <em>global minimum</em> of
the unsupervised objective is the same as the <em>global minimum</em> of the supervised
objective <span id="id28">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>.</p>
<p>Indeed, the unsupervised objective in language modeling is to maximize the
likelihood of observing the entire sequence of tokens over the dataset
<span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. This is an unsupervised task because it does not rely on labeled
input-output pairs but rather on the sequence itself. For simplicity, we state
the unsupervised objective as simply the argmax of the log-likelihood of the
sequence of tokens over the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}^{*}_{\text{unsupervised}} &amp;= \underset{\hat{\boldsymbol{\theta}}_{\text{unsupervised}} \in \boldsymbol{\Theta}}{\text{argmax}} \log\left(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\right) \\
&amp;= \underset{\hat{\boldsymbol{\theta}}_{\text{unsupervised}} \in \boldsymbol{\Theta}}{\text{argmax}} \sum_{n=1}^N \sum_{t=1}^{T_n} \log \mathbb{P}(x_{n, t} \mid x_{n, 1}, x_{n, 2}, \ldots, x_{n, t-1} ; \hat{\boldsymbol{\Theta}}) \\
\end{aligned}
\end{split}\]</div>
<p>In a supervised setting, such as sequence-to-sequence tasks (e.g., translation,
summarization), the objective is often to predict a target sequence
<span class="math notranslate nohighlight">\(\mathbf{y} = (y_1, y_2, \ldots, y_{T^{\prime}})\)</span> given an input sequence
<span class="math notranslate nohighlight">\(\mathbf{x} = (x_1, x_2, \ldots, x_T)\)</span>, and we can write the objective as the
argmax of the log-likelihood of the target sequence over the dataset
<span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. And if we define the sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> in the unsupervised
objective as a union of the input sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and the target sequence
<span class="math notranslate nohighlight">\(\mathbf{y}\)</span>, then the supervised objective is the same as the unsupervised
objective:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}^{*}_{\text{supervised}} &amp;= \underset{\hat{\boldsymbol{\theta}}_{\text{supervised}} \in \boldsymbol{\Theta}}{\text{argmax}} \log\left(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\right) \\
&amp;= \underset{\hat{\boldsymbol{\theta}}_{\text{supervised}} \in \boldsymbol{\Theta}}{\text{argmax}} \sum_{n=1}^N \sum_{t=1}^{T + T^{\prime}} \log \mathbb{P}(x_{n, t} \mid x_{n, 1}, x_{n, 2}, \ldots, x_{n, t-1} ; \hat{\boldsymbol{\Theta}}) \\
\end{aligned}
\end{split}\]</div>
<p>where
<span class="math notranslate nohighlight">\(\mathbf{x} = (x_1, x_2, \ldots, x_T) \cup (y_1, y_2, \ldots, y_{T^{\prime}})\)</span>.</p>
<p>The key insight here is that if we can construct the input sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>
such that the task-specific labels, are somehow encoded into the input sequence
as well, then the supervised task is indeed a subset of the unsupervised task.
For example, in the case of a translation task, the input sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>
can be something like
<code class="docutils literal notranslate"><span class="pre">The</span> <span class="pre">translation</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">french</span> <span class="pre">sentence</span> <span class="pre">'As-tu</span> <span class="pre">aller</span> <span class="pre">au</span> <span class="pre">cine</span> <span class="pre">́ma?'</span> <span class="pre">to</span> <span class="pre">english</span> <span class="pre">is</span></code>,
and the target sequence <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> can be the english translation
<code class="docutils literal notranslate"><span class="pre">Did</span> <span class="pre">you</span> <span class="pre">go</span> <span class="pre">to</span> <span class="pre">the</span> <span class="pre">movies?</span></code>.</p>
<p>However, the authors mention that such learning is much slower than the case
where the model is directly trained on the supervised task
<span id="id29">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>.</p>
<p>In what follows, the author added that the internet contains a vast amount of
information that is passively available without the need for interactive
communication. The example that I provided on the french-to-english translation
would bound to exist naturally in the internet. They speculate that if the
language model is <em>large</em> enough in terms of capacity, then it should be able to
learn to perform the tasks demonstrated in natural language sequences in order
to better predict them, regardless of their method of procurement
<span id="id30">[<a class="reference internal" href="../../bibliography.html#id16" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>.</p>
</section>
</section>
<section id="references-and-further-readings">
<h2><a class="toc-backref" href="#id75" role="doc-backlink">References and Further Readings</a><a class="headerlink" href="#references-and-further-readings" title="Link to this heading">#</a></h2>
<div class="seealso admonition">
<p class="admonition-title">References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/213464/on-the-importance-of-the-i-i-d-assumption-in-statistical-learning">On the importance of the i.i.d. assumption in statistical learning</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">Independent and identically distributed random variables - Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://gao-hongnan.github.io/gaohn-galaxy/probability_theory/08_estimation_theory/maximum_likelihood_estimation/concept.html#independence-and-identically-distributed-iid">Independence and Identically Distributed (IID) - GAO Hongnan</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Zero-shot_learning">Zero-shot learning - Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://ai.stackexchange.com/questions/21719/what-is-the-difference-between-one-shot-learning-transfer-learning-and-fine-tun">What is the difference between one-shot learning, transfer learning, and fine-tuning? - AI Stack Exchange</a></p></li>
<li><p><a class="reference external" href="https://joeddav.github.io/blog/2020/05/29/ZSL.html">Zero-Shot Learning in Modern NLP - Joe Davison</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1301.3666">Zero-Shot Learning Through Cross-Modal Transfer - arXiv</a></p></li>
<li><p><a class="reference external" href="https://ai.stackexchange.com/questions/23527/zero-shot-learning-available-labels-in-testing-set">Zero shot learning available labels in testing set - AI Stack Exchange</a></p></li>
<li><p><a class="reference external" href="https://www.theaidream.com/post/zero-shot-learning-can-you-classify-an-object-without-seeing-it-before">Zero-Shot Learning: Can You Classify an Object Without Seeing It Before?</a></p></li>
<li><p><a class="reference external" href="https://dl.acm.org/doi/10.1145/3293318">A Survey of Zero-Shot Learning: Settings, Methods, and Applications</a></p></li>
<li><p><a class="reference external" href="https://stackoverflow.com/questions/66451430/changes-in-gpt2-gpt3-model-during-few-shot-learning">Changes in GPT-2/GPT-3 Model During Few-Shot Learning - Stack Overflow</a></p></li>
<li><p><a class="github reference external" href="https://github.com/karpathy/minbpe">karpathy/minbpe</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/learn/nlp-course/en/chapter6/5">Byte Pair Encoding on Hugging Face’s NLP Course</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Perplexity">Perplexity - Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/docs/transformers/en/perplexity">Perplexity of fixed-length models</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_recurrent-neural-networks/language-model.html#perplexity">9.3.2. Perplexity - Dive Into Deep Learning</a></p></li>
<li><p><a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/3.pdf">3.3 Evaluating Language Models: Perplexity - Speech and Language Processing</a></p></li>
<li><p><a class="reference external" href="https://e2eml.school/transformers.html">Transformers from Scratch - Brandon Rohrer</a></p></li>
<li><p><a class="reference external" href="https://aman.ai/primers/ai/transformers/#positional-encoding">Primers • Transformers - Aman Chadha</a></p></li>
<li><p><a class="reference external" href="https://jalammar.github.io/illustrated-gpt2/">The Illustrated GPT-2 (Visualizing Transformer Language Models) - Jay Alammar</a></p></li>
<li><p><a class="reference external" href="https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2">The Transformer Family Version 2.0 - Lilian Weng</a></p></li>
<li><p><a class="reference external" href="https://osanseviero.github.io/hackerllama/blog/posts/random_transformer">The Random Transformer - hackerllama</a></p></li>
<li><p><a class="reference external" href="https://blog.matdmiller.com/posts/2023-06-10_transformers/notebook.html">Transformers From Scratch - Mat Miller</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing#scrollTo=JB82yzt44REI">Andrej Karpathy GPT Implementation Google Colab</a></p></li>
<li><p><a class="reference external" href="http://www.columbia.edu/~jsl2239/transformers.html">Transformers: a Primer - Justin Seonyong Lee</a></p></li>
<li><p><a class="reference external" href="https://leimao.github.io/article/OpenAI-GPT-Models/">OpenAI GPT Models - Lei Mao</a></p></li>
<li><p><a class="reference external" href="https://leimao.github.io/blog/Transformer-Explained/">Transformer Explained in One Single Page - Lei Mao</a></p></li>
<li><p><a class="reference external" href="https://deepgenerativemodels.github.io/notes/autoregressive/">Autoregressive models</a></p></li>
<li><p><a class="reference external" href="https://nlp.seas.harvard.edu/annotated-transformer/">The Annotated Transformer - Harvard NLP</a></p></li>
<li><p><a class="reference external" href="https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html">Tutorial 6: Transformers and Multi-Head Attention - UvA</a></p></li>
<li><p><a class="reference external" href="https://eugeneyan.com/writing/attention/">Some Intuition on Attention and the Transformer - Eugene Yan</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=kCc8FmEb1nY">Let’s build GPT: from scratch, in code, spelled out - Andrej Karpathy</a></p></li>
<li><p><a class="reference external" href="https://ai.stackexchange.com/questions/20075/why-does-the-transformer-do-better-than-rnn-and-lstm-in-long-range-context-depen">Why does the transformer do better than RNN and LSTM in long-range context dependencies?</a></p></li>
<li><p><a class="reference external" href="https://stackoverflow.com/questions/55158554/how-transformer-is-bidirectional-machine-learning">How Transformer is Bidirectional - Machine Learning</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate - arXiv</a></p></li>
<li><p><a class="reference external" href="https://github.com/rasbt/LLMs-from-scratch">Building Language Models from Scratch - Sebastian Raschka</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_multilayer-perceptrons/numerical-stability-and-init.html#breaking-the-symmetry">Numerical Stability and Initialization - Dive into Deep Learning</a></p></li>
<li><p><a class="reference external" href="https://developers.google.com/machine-learning/gan/generative">Background: What is a Generative Model? - Google Developers</a> -
Google Developers</p></li>
<li><p><a class="reference external" href="https://ai.stackexchange.com/questions/12579/why-can-we-approximate-the-joint-probability-distribution-using-the-output-vecto">Why can we approximate the joint probability distribution using the output vector of the GPT model?</a></p></li>
<li><p><a class="reference external" href="https://datascience.stackexchange.com/questions/65806/why-joint-probability-in-generative-models">Why Joint Probability in Generative Models? - Data Science Stack Exchange</a></p></li>
<li><p><a class="reference external" href="https://probmlcourse.github.io/csc412/lectures/week_2/">CSC412 Winter 2020: Probabilsitic Machine Learning - University of Toronto</a></p></li>
<li><p><a class="reference external" href="https://stanford-cs324.github.io/winter2022/lectures/introduction/">CS324 - Large Language Models - Stanford University</a></p></li>
<li><p><a class="reference external" href="https://www.probabilitycourse.com/chapter5/5_1_1_joint_pmf.php">Joint Probability Mass Function (PMF)</a></p></li>
<li><p><a class="reference external" href="https://math.stackexchange.com/questions/1566215/difference-between-joint-probability-distribution-and-conditional-probability-di">Difference Between Joint Probability Distribution and Conditional Probability Distribution - Math Stack Exchange</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_convolutional-modern/resnet.html">Residual Networks (ResNets) - Dive into Deep Learning</a></p></li>
<li><p><a class="reference external" href="https://songhuiming.github.io/pages/2023/05/28/gpt-1-gpt-2-gpt-3-instructgpt-chatgpt-and-gpt-4-summary/">GPT-1, GPT-2, GPT-3, InstructGPT, ChatGPT, and GPT-4 Summary</a></p></li>
<li><p><a class="reference external" href="https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/">How to Optimize Data Transfers in CUDA C/C++ - NVIDIA Developer Blogs</a></p></li>
<li><p><a class="reference external" href="https://developer.nvidia.com/blog/how-overlap-data-transfers-cuda-cc/">How to Overlap Data Transfers in CUDA C/C++ - NVIDIA Developer Blogs</a></p></li>
</ul>
</div>
</section>
<section id="citations">
<h2><a class="toc-backref" href="#id76" role="doc-backlink">Citations</a><a class="headerlink" href="#citations" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>[1] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
Ł. Kaiser, and I. Polosukhin.
<a class="reference external" href="https://arxiv.org/abs/1706.03762">“Attention is all you need”</a>. In Advances
in Neural Information Processing Systems, pp. 5998–6008, 2017.</p></li>
<li><p>[2] I. Loshchilov and F. Hutter,
<a class="reference external" href="https://arxiv.org/abs/1711.05101">“Decoupled weight decay regularization”</a>,
arXiv preprint arXiv:1711.05101, [Submitted on 14 Nov 2017 (v1), last
revised 4 Jan 2019 (this version, v3)].</p></li>
<li><p>[3] D. P. Kingma and J. Ba,
<a class="reference external" href="https://arxiv.org/abs/1412.6980">“Adam: A Method for Stochastic Optimization”</a>,
arXiv preprint arXiv:1412.6980, [Submitted on 22 Dec 2014 (v1), last revised
30 Jan 2017 (this version, v9)].</p></li>
<li><p>[4] L. Liu, H. Jiang, P. He, W. Chen, X. Liu, J. Gao, and J. Han,
<a class="reference external" href="https://arxiv.org/abs/1908.03265">“On the Variance of the Adaptive Learning Rate and Beyond”</a>,
arXiv preprint arXiv:1908.03265, [Submitted on 8 Aug 2019 (v1), last revised
26 Oct 2021 (this version, v4)].</p></li>
<li><p>[5] A. Zhang, Z. C. Lipton, M. Li, and A. J. Smola,
<a class="reference external" href="https://d2l.ai/chapter_recurrent-neural-networks/index.html">“Chapter 9. Recurrent Neural Networks”</a>
in Dive into Deep Learning, Cambridge University Press, 2023.</p></li>
<li><p>[6] A. Zhang, Z. C. Lipton, M. Li, and A. J. Smola,
<a class="reference external" href="https://d2l.ai/chapter_attention-mechanisms-and-transformers/index.html">“Chapter 11. Attention Mechanisms and Transformers”</a>
in Dive into Deep Learning, Cambridge University Press, 2023.</p></li>
<li><p>[7] D. Jurafsky and J. H. Martin,
<a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/3.pdf">“Chapter 3. N-gram Language Models”</a>
in Speech and Language Processing, 3rd ed., Pearson, 2023. pp. 32-59.</p></li>
<li><p>[8] D. Jurafsky and J. H. Martin,
<a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/10.pdf">“Chapter 10. Transformers and Large Language Models”</a>
in Speech and Language Processing, 3rd ed., Pearson, 2023. pp. 213-241.</p></li>
<li><p>[9] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever,
<a class="reference external" href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">“Improving Language Understanding by Generative Pre-Training”</a>.</p></li>
<li><p>[10] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever,
<a class="reference external" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">“Language Models are Unsupervised Multitask Learners”</a>.</p></li>
</ul>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id31" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">1</a><span class="fn-bracket">]</span></span>
<p>This part is not concrete as the formalization is not rigorous in the
statistical learning framework, but the general idea is there.</p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./influential/generative_pretrained_transformer"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="02_notations.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Notations</p>
      </div>
    </a>
    <a class="right-next"
       href="04_implementation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">The Implementation of Generative Pre-trained Transformers (GPT)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-gpt-1-to-gpt-2">From GPT-1 to GPT-2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-2-paper-key-ideas">GPT-2 Paper Key Ideas</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract-overview">Abstract Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-competent-generalists-over-narrow-experts-1">Key 1. Competent Generalists over Narrow Experts (1)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-iid-assumption-fails-in-real-world-2-3">Key 2. IID Assumption Fails in Real World (2, 3)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-3-multi-task-learning-is-nacent-4">Key 3. Multi-Task Learning is Nacent (4)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-4-from-word-embeddings-to-contextual-embeddings-5-6">Key 4. From Word Embeddings to Contextual Embeddings (5,6)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-5-zero-shot-learning-and-zero-shot-transfer-7">Key 5. Zero Shot Learning and Zero Shot Transfer (7)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#section-2-approach">Section 2. Approach</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-modeling-language-models-over-joint-probability-distributions-1">Key 1. Modeling Language Models over Joint Probability Distributions (1)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-decompose-joint-distributions-as-conditional-distributions-via-chain-rule-2">Key 2. Decompose Joint Distributions as Conditional Distributions via Chain Rule (2)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-3-conditional-on-task-3">Key 3. Conditional on Task (3)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-4-optimizing-unsupervised-is-the-same-as-optimizing-supervised-4">Key 4. Optimizing Unsupervised is the same as Optimizing Supervised (4)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-5-large-language-models-has-capacity-to-infer-and-generalize-5">Key 5. Large Language Models has Capacity to Infer and Generalize (5)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-dataset">2.1. Training Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-rejection-of-commoncrawl-1-2">Key 1. Rejection of CommonCrawl (1,2)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-construction-of-webtext-dataset">Key 2. Construction of WebText Dataset</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#input-representation">2.2. Input Representation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-byte-pair-encoding-bpe-1-2-3">Key 1. Byte Pair Encoding (BPE) (1,2,3)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model">2.3. Model</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-gpt-2-is-a-continuation-of-gpt-1-with-self-attention-mechanisms-1">Key 1. GPT-2 is a Continuation of GPT-1 with Self-Attention Mechanisms (1)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-modifications-from-gpt-1-and-model-stability-1">Key 2. Modifications from GPT-1 and Model Stability (1)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-2-variants">GPT-2 Variants</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-autoregressive-self-supervised-learning-paradigm">The Autoregressive Self-Supervised Learning Paradigm</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#autoregressive-self-supervised-learning">Autoregressive Self-Supervised Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation-of-the-conditional-probability-distribution">Estimation of the Conditional Probability Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initial-condition-of-conditional-probability-distribution">Initial Condition of Conditional Probability Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-assumption">Markov Assumption</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-estimator-function-is-smooth-with-respect-to-the-parameters">The Estimator Function is Smooth with Respect to the Parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#context-length-and-token-context-window">Context Length and Token Context Window</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-entropy-and-perplexity-as-loss-function">Conditional Entropy and Perplexity as Loss Function</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-entropy">Conditional Entropy</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#perplexity">Perplexity</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function">Loss Function</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence">Convergence</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-is-a-autoregressive-self-supervised-learning-model">GPT is a Autoregressive Self-Supervised Learning Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-on-task">Conditional on Task</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-fine-tuning">Supervised Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#objective-function-for-fine-tuning">Objective Function for Fine-Tuning</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#auxiliary-loss-function">Auxiliary Loss Function</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizing-unsupervised-is-the-same-as-optimizing-supervised">Optimizing Unsupervised is the same as Optimizing Supervised</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references-and-further-readings">References and Further Readings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#citations">Citations</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gao Hongnan
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>