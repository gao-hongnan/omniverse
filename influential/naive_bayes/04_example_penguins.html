
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Naive Bayes Application: Penguins &#8212; Omniverse</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=bb35926c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../../_static/tabs.js?v=3ee01567"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-MYW5YKC2WF"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-MYW5YKC2WF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-MYW5YKC2WF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"defeq": "\\overset{\\text{def}}{=}", "defa": "\\overset{\\text{(a)}}{=}", "defb": "\\overset{\\text{(b)}}{=}", "defc": "\\overset{\\text{(c)}}{=}", "defd": "\\overset{\\text{(d)}}{=}", "st": "\\mid", "mod": "\\mid", "S": "\\Omega", "s": "\\omega", "e": "\\exp", "P": "\\mathbb{P}", "R": "\\mathbb{R}", "expectation": "\\mathbb{E}", "v": "\\mathbf{v}", "a": "\\mathbf{a}", "b": "\\mathbf{b}", "c": "\\mathbf{c}", "u": "\\mathbf{u}", "w": "\\mathbf{w}", "x": "\\mathbf{x}", "y": "\\mathbf{y}", "z": "\\mathbf{z}", "0": "\\mathbf{0}", "1": "\\mathbf{1}", "A": "\\mathbf{A}", "B": "\\mathbf{B}", "C": "\\mathbf{C}", "E": "\\mathcal{F}", "eventA": "\\mathcal{A}", "lset": "\\left\\{", "rset": "\\right\\}", "lsq": "\\left[", "rsq": "\\right]", "lpar": "\\left(", "rpar": "\\right)", "lcurl": "\\left\\{", "rcurl": "\\right\\}", "pmf": "p_X", "pdf": "f_X", "pdftwo": "f_{X,Y}", "pdfjoint": "f_{\\mathbf{X}}", "pmfjointxy": "p_{X, Y}", "pdfjointxy": "f_{X, Y}", "cdf": "F_X", "pspace": "(\\Omega, \\mathcal{F}, \\mathbb{P})", "var": "\\operatorname{Var}", "std": "\\operatorname{Std}", "bern": "\\operatorname{Bernoulli}", "binomial": "\\operatorname{Binomial}", "geometric": "\\operatorname{Geometric}", "poisson": "\\operatorname{Poisson}", "uniform": "\\operatorname{Uniform}", "normal": "\\operatorname{Normal}", "gaussian": "\\operatorname{Gaussian}", "gaussiansymbol": "\\mathcal{N}", "exponential": "\\operatorname{Exponential}", "iid": "\\textbf{i.i.d.}", "and": "\\text{and}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'influential/naive_bayes/04_example_penguins';</script>
    <link rel="canonical" href="https://www.gaohongnan.com/influential/naive_bayes/04_example_penguins.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Naive Bayes Application (MNIST)" href="05_application_mnist.html" />
    <link rel="prev" title="Naives Bayes Implementation" href="03_implementation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Omniverse - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Omniverse - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Omniverse
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Notations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notations/machine_learning.html">Machine Learning Notations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Influential Ideas and Papers</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../generative_pretrained_transformer/01_intro.html">Generative Pre-trained Transformers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/02_notations.html">Notations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/03_concept.html">The Concept of Generative Pre-trained Transformers (GPT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/04_implementation.html">The Implementation of Generative Pre-trained Transformers (GPT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/05_adder.html">Training a Mini-GPT to Learn Two-Digit Addition</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../low_rank_adaptation/01_intro.html">Low-Rank Adaptation Of Large Language Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../low_rank_adaptation/02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../low_rank_adaptation/03_implementation.html">Implementation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../empirical_risk_minimization/01_intro.html">Empirical Risk Minimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../empirical_risk_minimization/02_concept.html">Concept: Empirical Risk Minimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../empirical_risk_minimization/03_bayes_optimal_classifier.html">Bayes Optimal Classifier</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../learning_theory/01_intro.html">Is The Learning Problem Solvable?</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../learning_theory/02_concept.html">Concept: Learning Theory</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../kmeans_clustering/01_intro.html">Lloyd’s K-Means Clustering Algorithm</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/02_concept.html">Concept: K-Means Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/03_implementation.html">Implementation: K-Means (Lloyd)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/04_image_segmentation.html">Application: Image Compression and Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/05_conceptual_questions.html">Conceptual Questions</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="01_intro.html">Naive Bayes</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_implementation.html">Naives Bayes Implementation</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Naive Bayes Application: Penguins</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_application_mnist.html">Naive Bayes Application (MNIST)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../gaussian_mixture_models/01_intro.html">Mixture Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_mixture_models/02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_mixture_models/03_implementation.html">Gaussian Mixture Models Implementation</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Playbook</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../playbook/training/intro.html">Training Dynamics And Tricks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_calculate_flops_in_transformer_based_models.html">How to Calculate the Number of FLOPs in Transformer Based Models?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/why_cosine_annealing_warmup_stabilize_training.html">Why Does Cosine Annealing With Warmup Stabilize Training?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_finetune_decoder_with_last_token_pooling.html">How To Fine-Tune Decoder-Only Models For Sequence Classification Using Last Token Pooling?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_finetune_decoder_with_cross_attention.html">How To Fine-Tune Decoder-Only Models For Sequence Classification With Cross-Attention?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_teacher_student_knowledge_distillation.html">How To Do Teacher-Student Knowledge Distillation?</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/why_softmax_preserves_order_translation_invariant_not_invariant_scaling.html">Softmax Preserves Order, Is Translation Invariant But Not Invariant Under Scaling.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/how_to_inspect_function_and_class_signatures.html">How to Inspect Function and Class Signatures in Python?</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Probability Theory</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/intro.html">Chapter 1. Mathematical Preliminaries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/01_combinatorics.html">Permutations and Combinations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/02_calculus.html">Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/03_contours.html">Contour Maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/02_probability/intro.html">Chapter 2. Probability</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0202_probability_space.html">Probability Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0203_probability_axioms.html">Probability Axioms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0204_conditional_probability.html">Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0205_independence.html">Independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0206_bayes_theorem.html">Baye’s Theorem and the Law of Total Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/summary.html">Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/intro.html">Chapter 3. Discrete Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0301_random_variables.html">Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0302_discrete_random_variables.html">Discrete Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0303_probability_mass_function.html">Probability Mass Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0304_cumulative_distribution_function.html">Cumulative Distribution Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0305_expectation.html">Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0306_moments_and_variance.html">Moments and Variance</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/intro.html">Discrete Uniform Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/0307_discrete_uniform_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/0307_discrete_uniform_distribution_application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/intro.html">Bernoulli Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/0308_bernoulli_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/0308_bernoulli_distribution_application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/iid.html">Independent and Identically Distributed (IID)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/intro.html">Binomial Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_implementation.html">Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_application.html">Real World Examples</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/geometric/intro.html">Geometric Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/geometric/0310_geometric_distribution_concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/intro.html">Poisson Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/0311_poisson_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/0311_poisson_distribution_implementation.html">Implementation</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/summary.html">Important</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/intro.html">Chapter 4. Continuous Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/from_discrete_to_continuous.html">From Discrete to Continuous</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0401_continuous_random_variables.html">Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0402_probability_density_function.html">Probability Density Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0403_expectation.html">Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0404_moments_and_variance.html">Moments and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0405_cumulative_distribution_function.html">Cumulative Distribution Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0406_mean_median_mode.html">Mean, Median and Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0407_continuous_uniform_distribution.html">Continuous Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0408_exponential_distribution.html">Exponential Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0409_gaussian_distribution.html">Gaussian Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0410_skewness_and_kurtosis.html">Skewness and Kurtosis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0411_convolve_and_sum_of_random_variables.html">Convolution and Sum of Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0412_functions_of_random_variables.html">Functions of Random Variables</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/intro.html">Chapter 5. Joint Distributions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/05_joint_distributions/from_single_variable_to_joint_distributions.html">From Single Variable to Joint Distributions</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0501_joint_pmf_pdf/intro.html">Joint PMF and PDF</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0501_joint_pmf_pdf/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0502_joint_expectation_and_correlation/intro.html">Joint Expectation and Correlation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0502_joint_expectation_and_correlation/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/intro.html">Conditional PMF and PDF</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/intro.html">Conditional Expectation and Variance</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0505_sum_of_random_variables/intro.html">Sum of Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0505_sum_of_random_variables/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0506_random_vectors/intro.html">Random Vectors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0506_random_vectors/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/intro.html">Multivariate Gaussian Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/application_transformation.html">Application: Plots and Transformations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/psd.html">Covariance Matrix is Positive Semi-Definite</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/eigendecomposition.html">Eigendecomposition and Covariance Matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/geometry_of_multivariate_gaussian.html">The Geometry of Multivariate Gaussians</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/intro.html">Chapter 6. Sample Statistics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/intro.html">Moment Generating and Characteristic Functions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/moment_generating_function.html">Moment Generating Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/moment_generating_function_application_sum_of_rv.html">Application: Moment Generating Function and the Sum of Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/characteristic_function.html">Characteristic Function</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/intro.html">Probability Inequalities</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/concept.html">Probability Inequalities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/application.html">Application: Learning Theory</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/intro.html">Law of Large Numbers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/convergence.html">Convergence of Sample Average</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/application.html">Application: Learning Theory</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/08_estimation_theory/intro.html">Chapter 8. Estimation Theory</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/08_estimation_theory/maximum_likelihood_estimation/intro.html">Maximum Likelihood Estimation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/08_estimation_theory/maximum_likelihood_estimation/concept.html">Concept</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Operations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/distributed/intro.html">Distributed Systems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/01_notations.html">Notations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/02_basics.html">Basics Of Distributed Data Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/03_how_to_setup_slurm_in_aws.html">How to Setup SLURM and ParallelCluster in AWS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/04_ablation.html">Ablations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/profiling/intro.html">Profiling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/01_synchronize.html">Synchronize CUDA To Time CUDA Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/02_timeit.html">Profiling Code With Timeit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/03_time_profiler.html">PyTorch’s Event And Profiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/04_small_gpt_profile.html">Profile GPT Small Time And Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/05_memory_leak.html">CUDA Memory Allocations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/00_intro.html">The Lifecycle of an AIOps System</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/01_problem_formulation.html">Stage 1. Problem Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/02_project_scoping.html">Stage 2. Project Scoping And Framing The Problem</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/03_dataops_pipeline.html">Stage 3. Data Pipeline (Data Engineering and DataOps)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/031_data_source_and_format.html">Stage 3.1. Data Source and Formats</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/032_data_model_and_storage.html">Stage 3.2. Data Model and Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/033_etl.html">Stage 3.3. Extract, Transform, Load (ETL)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/04_mlops_data_pipeline.html">Stage 4. Data Extraction (MLOps), Data Analysis (Data Science), Data Preparation (Data Science)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline.html">Stage 5. Model Development and Training (MLOps)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/051_model_selection.html">Stage 5.1. Model Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/052_metric_selection.html">Stage 5.2. Metric Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/053_experiment_tracking.html">Stage 5.3. Experiment Tracking And Versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/054_model_testing.html">Stage 5.4. Model Testing</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/06_model_evaluation.html">Stage 6. Model Evaluation (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/07_model_validation_registry_and_pushing_model_to_production.html">Stage 7. Model Validation, Registry and Pushing Model to Production (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/08_model_deployment_and_serving.html">Stage 8. Model Serving (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/09_model_monitoring.html">Stage 9. Model Monitoring (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/010_continuous_integration_deployment_learning_and_training.html">Stage 10. Continuous Integration, Deployment, Learning and Training (DevOps, DataOps, MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/011_infrastructure_and_tooling_for_mlops.html">Stage 11. Infrastructure and Tooling for MLOps</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Software Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/config_management/intro.html">Config, State, Metadata Management</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/config_management/concept.html">Configuration Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/config_management/01-pydra.html">Pydantic And Hydra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/config_management/02-state.html">State And Metadata Management</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/design_patterns/intro.html">Design Patterns</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/dependency_inversion_principle.html">Dependency Inversion Principle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/named_constructor.html">Named Constructor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/strategy.html">Strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/registry.html">Registry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/god_object_pattern.html">Context Object Pattern (God Object)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/factory_method.html">Factory Method</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/python/intro.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/iterator_protocol.html">The Iterator Protocol</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/decorator.html">Decorator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/generators_over_lists.html">Generators Over Lists For Memory Efficiency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/pydantic.html">Pydantic Is All You Need - Jason Liu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/mutable_default.html">Do Not Use Mutable Default Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/set_vs_list.html">Set Over List For Frequent Membership Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/late_binding_closures.html">Late Binding Closures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/is_vs_equality.html">Is vs Equality</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/intro.html">Concurrency, Parallelism and Asynchronous Programming</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/overview.html">Overview Of Concurrency, Parallelism, and Asynchronous Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/generator_yield.html">A Rudimentary Introduction to Generator and Yield in Python</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Computer Science</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../computer_science/type_theory/intro.html">Type Theory, A Very Rudimentary Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/01-subtypes.html">Subtypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/02-type-safety.html">Type Safety</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/03-subsumption.html">Subsumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/04-generics.html">Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/05-typevar-bound-constraints.html">Bound and Constraint in Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/06-invariance-covariance-contravariance.html">Invariance, Covariance and Contravariance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/07-pep-3124-overloading.html">Function Overloading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/08-pep-661-sentinel-values.html">Sentinel Types</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Structures and Algorithms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/complexity_analysis/intro.html">Complexity Analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/complexity_analysis/master_theorem.html">Master Theorem </a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/stack/intro.html">Stack</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/stack/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/searching_algorithms/linear_search/intro.html">Linear Search</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/linear_search/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/intro.html">Binary Search</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/problems/875-koko-eating-bananas.html">Koko Eating Bananas</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Algebra</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linear_algebra/01_preliminaries/intro.html">Preliminaries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/01_preliminaries/01-fields.html">Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/01_preliminaries/02-systems-of-linear-equations.html">Systems of Linear Equations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linear_algebra/02_vectors/intro.html">Vectors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/01-vector-definition.html">Vector and Its Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/02-vector-operation.html">Vector and Its Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/03-vector-norm.html">Vector Norm and Distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/04-vector-products.html">A First Look at Vector Products</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References, Resources and Roadmap</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../citations.html">IEEE (Style) Citations</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/gao-hongnan/omniverse/blob/main/omniverse/influential/naive_bayes/04_example_penguins.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gao-hongnan/omniverse" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gao-hongnan/omniverse/issues/new?title=Issue%20on%20page%20%2Finfluential/naive_bayes/04_example_penguins.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/influential/naive_bayes/04_example_penguins.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Naive Bayes Application: Penguins</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dependencies">Dependencies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">Problem Statement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-prior">The Prior</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classifying-one-penguin">Classifying one penguin</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-categorical-feature">One Categorical Feature</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-quantitative-predictor">One Quantitative Predictor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#two-continuous-predictors">Two (Continuous) Predictors</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-independence">Conditional Independence</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#three-predictors">Three Predictors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch">PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-readings">Further Readings</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="naive-bayes-application-penguins">
<h1>Naive Bayes Application: Penguins<a class="headerlink" href="#naive-bayes-application-penguins" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="https://twitter.com/gaohongnan"><img alt="Twitter Handle" src="https://img.shields.io/badge/Twitter-&#64;gaohongnan-blue?style=social&amp;logo=twitter" /></a>
<a class="reference external" href="https://linkedin.com/in/gao-hongnan"><img alt="LinkedIn Profile" src="https://img.shields.io/badge/&#64;gaohongnan-blue?style=social&amp;logo=linkedin" /></a>
<a class="reference external" href="https://github.com/gao-hongnan"><img alt="GitHub Profile" src="https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&amp;logo=github" /></a>
<img alt="Tag" src="https://img.shields.io/badge/Tag-Organized_Chaos-orange" /></p>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#dependencies" id="id5">Dependencies</a></p></li>
<li><p><a class="reference internal" href="#problem-statement" id="id6">Problem Statement</a></p></li>
<li><p><a class="reference internal" href="#the-prior" id="id7">The Prior</a></p></li>
<li><p><a class="reference internal" href="#classifying-one-penguin" id="id8">Classifying one penguin</a></p>
<ul>
<li><p><a class="reference internal" href="#one-categorical-feature" id="id9">One Categorical Feature</a></p></li>
<li><p><a class="reference internal" href="#one-quantitative-predictor" id="id10">One Quantitative Predictor</a></p></li>
<li><p><a class="reference internal" href="#two-continuous-predictors" id="id11">Two (Continuous) Predictors</a></p>
<ul>
<li><p><a class="reference internal" href="#conditional-independence" id="id12">Conditional Independence</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#three-predictors" id="id13">Three Predictors</a></p></li>
<li><p><a class="reference internal" href="#summary" id="id14">Summary</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#pytorch" id="id15">PyTorch</a></p></li>
<li><p><a class="reference internal" href="#further-readings" id="id16">Further Readings</a></p></li>
</ul>
</nav>
<p>References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.bayesrulesbook.com/chapter-2.html#building-a-bayesian-model-for-events">The Bayes Rules Book</a>.</p></li>
<li><p>Reference: <a class="reference external" href="https://www.bayesrulesbook.com/chapter-2.html#building-a-bayesian-model-for-events">The Bayes Rules Book</a>.</p></li>
<li><p>prior reading of concept before this.</p></li>
</ul>
<section id="dependencies">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Dependencies</a><a class="headerlink" href="#dependencies" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">mpatches</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">model_selection</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span> <span class="nn">rich</span> <span class="kn">import</span> <span class="nb">print</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="n">parent_dir</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">()</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">parent_dir</span><span class="p">)</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parent_dir</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">omnivault.utils.probability_theory.plot</span> <span class="kn">import</span> <span class="n">plot_scatter</span><span class="p">,</span> <span class="n">plot_contour</span><span class="p">,</span> <span class="n">plot_surface</span><span class="p">,</span> <span class="n">plot_bar</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080">/home/runner/work/omniverse/</span><span style="color: #ff00ff; text-decoration-color: #ff00ff">omniverse</span>
</pre>
</div></div>
</div>
</section>
<section id="problem-statement">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">Problem Statement</a><a class="headerlink" href="#problem-statement" title="Link to this heading">#</a></h2>
<p>There exist multiple penguin species throughout Antarctica, including the Adelie, Chinstrap, and Gentoo. When encountering one of these penguins on an Antarctic trip, we might classify its species</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Y= \begin{cases}A &amp; \text { Adelie } \\ C &amp; \text { Chinstrap } \\ G &amp; \text { Gentoo }\end{cases}
\end{split}\]</div>
<p>by examining various physical characteristics, such as whether the penguin weighs more than the average <span class="math notranslate nohighlight">\(4200 \mathrm{~g}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
X_1= \begin{cases}1 &amp; \text { above-average weight } \\ 0 &amp; \text { below-average weight }\end{cases}
\end{split}\]</div>
<p>as well as measurements of the penguin’s bill</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp; X_2=\text { bill length }(\text { in } \mathrm{mm}) \\
&amp; X_3=\text { flipper length }(\text { in } \mathrm{mm})
\end{aligned}
\end{split}\]</div>
<p>The penguins_bayes data, originally made available by Gorman, Williams, and Fraser (2014) and distributed by Horst, Hill, and Gorman (2020), contains the above species and feature information for a sample of 344 Antarctic penguins:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;penguins&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="c1"># penguins.head().style.set_table_attributes(&#39;style=&quot;font-size: 13px&quot;&#39;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>species</th>
      <th>island</th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>sex</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.1</td>
      <td>18.7</td>
      <td>181.0</td>
      <td>3750.0</td>
      <td>Male</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.5</td>
      <td>17.4</td>
      <td>186.0</td>
      <td>3800.0</td>
      <td>Female</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>40.3</td>
      <td>18.0</td>
      <td>195.0</td>
      <td>3250.0</td>
      <td>Female</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>36.7</td>
      <td>19.3</td>
      <td>193.0</td>
      <td>3450.0</td>
      <td>Female</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 344 entries, 0 to 343
Data columns (total 7 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   species            344 non-null    object 
 1   island             344 non-null    object 
 2   bill_length_mm     342 non-null    float64
 3   bill_depth_mm      342 non-null    float64
 4   flipper_length_mm  342 non-null    float64
 5   body_mass_g        342 non-null    float64
 6   sex                333 non-null    object 
dtypes: float64(4), object(3)
memory usage: 18.9+ KB
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>None
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>342.000000</td>
      <td>342.000000</td>
      <td>342.000000</td>
      <td>342.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>43.921930</td>
      <td>17.151170</td>
      <td>200.915205</td>
      <td>4201.754386</td>
    </tr>
    <tr>
      <th>std</th>
      <td>5.459584</td>
      <td>1.974793</td>
      <td>14.061714</td>
      <td>801.954536</td>
    </tr>
    <tr>
      <th>min</th>
      <td>32.100000</td>
      <td>13.100000</td>
      <td>172.000000</td>
      <td>2700.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>39.225000</td>
      <td>15.600000</td>
      <td>190.000000</td>
      <td>3550.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>44.450000</td>
      <td>17.300000</td>
      <td>197.000000</td>
      <td>4050.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>48.500000</td>
      <td>18.700000</td>
      <td>213.000000</td>
      <td>4750.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>59.600000</td>
      <td>21.500000</td>
      <td>231.000000</td>
      <td>6300.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Among these penguins, 152 are Adelies, 68 are Chinstraps, and 124 are Gentoos. We’ll assume throughout that the proportional breakdown of these species in our dataset reflects the species breakdown in the wild. That is, our prior assumption about any new penguin is that it’s most likely an Adelie and least likely a Chinstrap:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>species
Adelie       152
Gentoo       124
Chinstrap     68
Name: count, dtype: int64
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>species
Adelie       0.441860
Gentoo       0.360465
Chinstrap    0.197674
Name: proportion, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">missing_values_table</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function to calculate missing values by column.</span>

<span class="sd">    credit: https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Total missing values per column</span>
    <span class="n">missing_values_per_column</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># Percentage of missing values</span>
    <span class="n">missing_values_per_column_percent</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

    <span class="n">missing_value_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">missing_values_per_column</span><span class="p">,</span> <span class="n">missing_values_per_column_percent</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>
    <span class="n">missing_value_table_renamed</span> <span class="o">=</span> <span class="n">missing_value_table</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
        <span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;Missing Values&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">% o</span><span class="s2">f Total Values&quot;</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># Sort the table by percentage of missing descending</span>
    <span class="n">missing_value_table_renamed</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">missing_value_table_renamed</span><span class="p">[</span><span class="n">missing_value_table_renamed</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
        <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">% o</span><span class="s2">f Total Values&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Your selected dataframe has </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="si">}</span><span class="s2"> columns.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">missing_value_table_renamed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="s2">&quot; columns that have missing values.&quot;</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">missing_value_table_renamed</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">missing_values_table</span><span class="p">(</span><span class="n">penguins</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Your selected dataframe has <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">7</span> columns.
There are <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5</span> columns that have missing values.
</pre>
</div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Missing Values</th>
      <th>% of Total Values</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>sex</th>
      <td>11</td>
      <td>3.2</td>
    </tr>
    <tr>
      <th>bill_length_mm</th>
      <td>2</td>
      <td>0.6</td>
    </tr>
    <tr>
      <th>bill_depth_mm</th>
      <td>2</td>
      <td>0.6</td>
    </tr>
    <tr>
      <th>flipper_length_mm</th>
      <td>2</td>
      <td>0.6</td>
    </tr>
    <tr>
      <th>body_mass_g</th>
      <td>2</td>
      <td>0.6</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We drop <code class="docutils literal notranslate"><span class="pre">sex</span></code> column for simplicity as there are quite a few missing values in it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;sex&quot;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We also drop the other NA rows for simplicity, there are only 2 of them
and they turn out to be the same row.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># drop rows with NAs, only 2 rows</span>
<span class="n">penguins</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>species</th>
      <th>island</th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.1</td>
      <td>18.7</td>
      <td>181.0</td>
      <td>3750.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.5</td>
      <td>17.4</td>
      <td>186.0</td>
      <td>3800.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>40.3</td>
      <td>18.0</td>
      <td>195.0</td>
      <td>3250.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>36.7</td>
      <td>19.3</td>
      <td>193.0</td>
      <td>3450.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.3</td>
      <td>20.6</td>
      <td>190.0</td>
      <td>3650.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>337</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>47.2</td>
      <td>13.7</td>
      <td>214.0</td>
      <td>4925.0</td>
    </tr>
    <tr>
      <th>338</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>46.8</td>
      <td>14.3</td>
      <td>215.0</td>
      <td>4850.0</td>
    </tr>
    <tr>
      <th>339</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>50.4</td>
      <td>15.7</td>
      <td>222.0</td>
      <td>5750.0</td>
    </tr>
    <tr>
      <th>340</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>45.2</td>
      <td>14.8</td>
      <td>212.0</td>
      <td>5200.0</td>
    </tr>
    <tr>
      <th>341</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>49.9</td>
      <td>16.1</td>
      <td>213.0</td>
      <td>5400.0</td>
    </tr>
  </tbody>
</table>
<p>342 rows × 6 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>species
Adelie       151
Gentoo       123
Chinstrap     68
Name: count, dtype: int64
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>species
Adelie       0.441520
Gentoo       0.359649
Chinstrap    0.198830
Name: proportion, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_body_mass_g</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s1">&#39;body_mass_g&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The mean body mass of penguins is </span><span class="si">{</span><span class="n">mean_body_mass_g</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> grams.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">The mean body mass of penguins is <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4201.75</span> grams.
</pre>
</div></div>
</div>
<p>We create a new categorical feature <code class="docutils literal notranslate"><span class="pre">overweight</span></code> which is 1 if the <code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code> is over the
mean, and 0 otherwise. This feature corresponds to our earlier defined random variable <span class="math notranslate nohighlight">\(X_1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;overweight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;body_mass_g&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;body_mass_g&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;overweight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>overweight
0    193
1    149
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-prior">
<span id="naive-bayes-penguin-the-prior"></span><h2><a class="toc-backref" href="#id7" role="doc-backlink">The Prior</a><a class="headerlink" href="#the-prior" title="Link to this heading">#</a></h2>
<p>The prior distribution for <span class="math notranslate nohighlight">\(Y\)</span> is a <a class="reference external" href="https://en.wikipedia.org/wiki/Categorical_distribution">categorical distribution</a> with three categories, one for each species. The prior probabilities are given by the relative frequencies of each species in the dataset:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp; \text { A } \sim \text { Categorical }(\pi_A=0.44) \\
&amp; \text { C } \sim \text { Categorical }(\pi_C=0.20) \\
&amp; \text { G } \sim \text { Categorical }(\pi_G=0.36)
\end{aligned}
\end{split}\]</div>
<p>which implies</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}(Y=A) &amp;= 0.44 \\
\mathbb{P}(Y=C) &amp;= 0.20 \\
\mathbb{P}(Y=G) &amp;= 0.36
\end{aligned}
\end{split}\]</div>
<p>Given a new penguin not in the dataset, the <strong>prior assumption</strong> says that the probability
of it being an Adelie is <span class="math notranslate nohighlight">\(0.44\)</span>, the probability of it being a Chinstrap is <span class="math notranslate nohighlight">\(0.20\)</span>, and the probability of it being a Gentoo is <span class="math notranslate nohighlight">\(0.36\)</span>.</p>
<p>We then map <span class="math notranslate nohighlight">\(A \rightarrow 0\)</span>, <span class="math notranslate nohighlight">\(C \rightarrow 1\)</span>, and <span class="math notranslate nohighlight">\(G \rightarrow 2\)</span> for convenience, as well as
to allow us to plug these values for training.</p>
<p>Let us create a new column <code class="docutils literal notranslate"><span class="pre">class_id</span></code> which is 0 for Adelie, 1 for Chinstrap, and 2 for Gentoo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;class_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s2">&quot;Adelie&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Chinstrap&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Gentoo&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
<span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;class_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>class_id
0    151
2    123
1     68
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;class_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_prior</span><span class="p">(</span><span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">distribution</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">probs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">distribution</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">get_prior</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The prior distribution is </span><span class="si">{</span><span class="n">prior</span><span class="o">.</span><span class="n">probs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">The prior distribution is <span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.4415</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.1988</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.3596</span><span style="font-weight: bold">])</span>
</pre>
</div></div>
</div>
<p>This indeed matches the prior probabilities (i.e. the relative frequencies of each species in the dataset).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Adelie&quot;</span><span class="p">,</span> <span class="s2">&quot;Chinstrap&quot;</span><span class="p">,</span> <span class="s2">&quot;Gentoo&quot;</span><span class="p">]</span>
<span class="n">class_colours</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">bar</span> <span class="o">=</span> <span class="n">plot_bar</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">prior</span><span class="o">.</span><span class="n">probs</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="n">class_colours</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Class&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Prior probability&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prior distribution of penguin species&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/0efe76cc3843ed5f04d80b9594cabe54ded65c41fb5dd05a4d107021970c1d5c.png" src="../../_images/0efe76cc3843ed5f04d80b9594cabe54ded65c41fb5dd05a4d107021970c1d5c.png" />
</div>
</div>
</section>
<section id="classifying-one-penguin">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">Classifying one penguin</a><a class="headerlink" href="#classifying-one-penguin" title="Link to this heading">#</a></h2>
<p>Consider a <strong>new</strong> penguin with the following features:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code>: <span class="math notranslate nohighlight">\(&lt; 4200 \mathrm{~g}\)</span> (<code class="docutils literal notranslate"><span class="pre">overweight</span></code> = 0 if <code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code> <span class="math notranslate nohighlight">\(&lt; 4200 \mathrm{~g}\)</span>, 1 otherwise)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>: <span class="math notranslate nohighlight">\(50 \mathrm{~mm}\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>: <span class="math notranslate nohighlight">\(195 \mathrm{~mm}\)</span></p></li>
</ul>
<p>Then we want to find out the <strong>posterior</strong> distribution of the species of this penguin, given the <strong>features</strong>.
In other words, what is the probability of this penguin being an Adelie, Chinstrap, or Gentoo, given the features mentioned above.</p>
<section id="one-categorical-feature">
<h3><a class="toc-backref" href="#id9" role="doc-backlink">One Categorical Feature</a><a class="headerlink" href="#one-categorical-feature" title="Link to this heading">#</a></h3>
<p>Let us assume that we are building our Naive Bayes based off one categorical feature, <code class="docutils literal notranslate"><span class="pre">overweight</span></code>.
Then, since this penguin has a <code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code> of <span class="math notranslate nohighlight">\(&lt; 4200 \mathrm{~g}\)</span>, it belongs to the category <span class="math notranslate nohighlight">\(0\)</span> of the feature <code class="docutils literal notranslate"><span class="pre">overweight</span></code>.</p>
<p>Let us call this feature <span class="math notranslate nohighlight">\(X_1\)</span>, and the species <span class="math notranslate nohighlight">\(Y\)</span>. Then we want to find out the posterior distribution of <span class="math notranslate nohighlight">\(Y\)</span>, given <span class="math notranslate nohighlight">\(X_1=0\)</span>.</p>
<p>Let’s reproduce the figure 14.1 from the <a class="reference external" href="https://www.bayesrulesbook.com/chapter-14.html">book</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">total</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;species&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;counts&quot;</span><span class="p">)</span>
<span class="n">overweight</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">penguins</span><span class="p">[</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;overweight&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
    <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;species&quot;</span><span class="p">)[</span><span class="s2">&quot;overweight&quot;</span><span class="p">]</span>
    <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">overweight</span><span class="p">[</span><span class="s2">&quot;overweight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">i</span> <span class="o">/</span> <span class="n">j</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">overweight</span><span class="p">[</span><span class="s2">&quot;overweight&quot;</span><span class="p">],</span> <span class="n">total</span><span class="p">[</span><span class="s2">&quot;counts&quot;</span><span class="p">])</span>
<span class="p">]</span>
<span class="n">total</span><span class="p">[</span><span class="s2">&quot;counts&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">/</span> <span class="n">j</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">total</span><span class="p">[</span><span class="s2">&quot;counts&quot;</span><span class="p">],</span> <span class="n">total</span><span class="p">[</span><span class="s2">&quot;counts&quot;</span><span class="p">])]</span>

<span class="n">display</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">overweight</span><span class="p">)</span>  <span class="c1"># percentage of overweight penguins for each species</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>species</th>
      <th>counts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adelie</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Chinstrap</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Gentoo</td>
      <td>100.0</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>species</th>
      <th>overweight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adelie</td>
      <td>16.556291</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Chinstrap</td>
      <td>10.294118</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Gentoo</td>
      <td>95.121951</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># bar chart 1 -&gt; top bars (group of &#39;overweight=No&#39;)</span>
<span class="n">bar1</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;counts&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">total</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;darkblue&quot;</span><span class="p">)</span>

<span class="c1"># bar chart 2 -&gt; bottom bars (group of &#39;overweight=Yes&#39;)</span>
<span class="n">bar2</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;overweight&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">overweight</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightblue&quot;</span><span class="p">)</span>

<span class="c1"># add legend</span>
<span class="n">top_bar</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;darkblue&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;overweight = No&quot;</span><span class="p">)</span>
<span class="n">bottom_bar</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightblue&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;overweight = Yes&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="p">[</span><span class="n">top_bar</span><span class="p">,</span> <span class="n">bottom_bar</span><span class="p">])</span>

<span class="c1"># show the graph</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/1059a86c3cfa1274260fc3581ce06ce148373e57a1d679a9077e955fac13cb0a.png" src="../../_images/1059a86c3cfa1274260fc3581ce06ce148373e57a1d679a9077e955fac13cb0a.png" />
</div>
</div>
<p>From the conditionals below, the Chinstrap species have the highest probability of underweight penguins by
the relative freqeuncy table. That is, for each species, we compute the relative frequency within each species as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[X_1=0|Y=A] &amp;= \frac{126}{151} \approx 0.8344 \\
\mathbb{P}[X_1=0|Y=C] &amp;= \frac{61}{68} \approx 0.8971 \\
\mathbb{P}[X_1=0|Y=G] &amp;= \frac{6}{123} \approx 0.0488
\end{aligned}
\end{split}\]</div>
<p>Note that we are abusing the notation <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> here,
since we are not talking about the <strong>true probability distribution</strong>,
but rather the <strong>(empirical) relative frequency</strong> of feature <span class="math notranslate nohighlight">\(X_1\)</span> within
each species <span class="math notranslate nohighlight">\(Y=k \in \{A, C, G\}\)</span>.</p>
<p>The expressions above are the conditional probability of <span class="math notranslate nohighlight">\(X_1=0\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> is a certain species,
also termed as the <strong>likelihood</strong> of <span class="math notranslate nohighlight">\(Y\)</span> being a certain species given <span class="math notranslate nohighlight">\(X_1=0\)</span>. Again, we are being loose with notation here as everything here is empirical!</p>
<p>So one might say that the Chinstrap species is the least likely to be overweight, and the Gentoo species is the most likely to be overweight. Well, this makes intuitive sense since we are talking
about “likelihood” here: of all <span class="math notranslate nohighlight">\(P(X_1=0|Y=A)\)</span>, <span class="math notranslate nohighlight">\(P(X_1=0|Y=C)\)</span>, and <span class="math notranslate nohighlight">\(P(X_1=0|Y=G)\)</span>, the Chinstrap species is the least likely to be overweight. This is because within the Chinstrap species, <span class="math notranslate nohighlight">\(P(X_1=0|Y=C)\)</span> is the highest,
and therefore the complement <span class="math notranslate nohighlight">\(P(X_1=1|Y=C)\)</span> is the lowest.</p>
<p>Yet before we can make any conclusions, we need to take into account the prior probabilities of each species. We should weight the relative frequencies by the prior probabilities of each species. Intuitively, since Chinstrap is also the <em><strong>rarest</strong></em> species, it diminishes the likelihood of the penguin being a Chinstrap.</p>
<p>We need to use both the prior and the likelihood to compute the <strong>posterior distribution</strong> of the species of the penguin.
The posterior distribution is the probability of the species of the penguin given the features.</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\mathbb{P}[Y=y|X_1=x_1] = \frac{\mathbb{P}[X_1=x_1|Y=y] \mathbb{P}[Y=y]}{\mathbb{P}[X_1=x_1]}
\end{aligned}
\]</div>
<p>For example, if our given feature of the test penguin is <span class="math notranslate nohighlight">\(X_1=0\)</span>, then we need
to find the posterior distribution of <strong>all</strong> species given <span class="math notranslate nohighlight">\(X_1=0\)</span>. That is, we need to compute</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[Y=A|X_1=0] &amp;= \frac{\mathbb{P}[X_1=0|Y=A] \mathbb{P}[Y=A]}{\mathbb{P}[X_1=0]} \\
\mathbb{P}[Y=C|X_1=0] &amp;= \frac{\mathbb{P}[X_1=0|Y=C] \mathbb{P}[Y=C]}{\mathbb{P}[X_1=0]} \\
\mathbb{P}[Y=G|X_1=0] &amp;= \frac{\mathbb{P}[X_1=0|Y=G] \mathbb{P}[Y=G]}{\mathbb{P}[X_1=0]}
\end{aligned}
\end{split}\]</div>
<p>and get the <strong>argmax</strong> of the above three expressions. The argmax is the species with the highest probability.
Note this makes sense because <span class="math notranslate nohighlight">\(\mathbb{P}[Y=y|X_1=x_1]\)</span> is a legitimate probability measure
over the sample space <span class="math notranslate nohighlight">\(\Omega_Y = \{A, C, G\} = \{0, 1, 2\}\)</span>. Therefore, the argmax is the species with the highest probability in this sample space.</p>
<p>The <strong>argmax</strong> expression is as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\underbrace{\underset{y \in \{A, C, G\}}{\text{argmax}}}_{\text{species}} \underbrace{\mathbb{P}[Y=y|X_1=0]}_{\text{posterior}} &amp;= \underbrace{\underset{y \in \{A, C, G\}}{\text{argmax}}}_{\text{species}} \dfrac{\overbrace{\mathbb{P}[X_1=0|Y=y]}^{\text{likelihood}} \overbrace{\mathbb{P}[Y=y]}^{\text{prior}}}{\underbrace{\mathbb{P}[X_1=0]}_{\text{marginal}}} \\
&amp;= \underset{y \in \{A, C, G\}}{\text{argmax}} \frac{\mathbb{P}[X_1=0|Y=y] \mathbb{P}[Y=y]}{\sum_{y' \in \{A, C, G\}} \mathbb{P}[X_1=0|Y=y'] \mathbb{P}[Y=y']}
\end{aligned}
\end{split}\]</div>
<p>Note in the Bayes Rules Book, the authors used the notation <span class="math notranslate nohighlight">\(f\)</span> instead of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>,
they are the same thing in this context since both <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are discrete random variables.
Consequently, the right hand side of the equation <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=x_1|Y=y]\)</span>
gives us a concrete value (the probability). However, if <span class="math notranslate nohighlight">\(X_1\)</span> were a continuous random variable, as we will see in the
next section, then the expression <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=x_1|Y=y]\)</span> would not make much sense since
we the conditional probability of a continuous random variable at a point <span class="math notranslate nohighlight">\(x_1\)</span> is <span class="math notranslate nohighlight">\(0\)</span> by definition.</p>
<p>Let’s digress slightly:</p>
<p>We reconcile this by expressing Bayes Rule in terms of the probability density function (PDF) of the posterior distribution, see <a class="reference external" href="https://en.wikipedia.org/wiki/Bayes%27_theorem#Simple_form">Bayes’ Rule forms</a>.</p>
<p>The conditional PDF of the posterior distribution is</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
f_{Y|X_1}(y|x_1) = \frac{f_{X_1|Y}(x_1|y) f_{Y}(y)}{f_{X_1}(x_1)}
\end{aligned}
\]</div>
<p>We make a bold statement (not proved here but true) now that the <span class="math notranslate nohighlight">\(\hat{Y}\)</span> that maximizes
the posterior distribution in terms of Bayes Rules is the same as the <span class="math notranslate nohighlight">\(\hat{Y}\)</span> that maximizes
the posterior distribution in terms of the conditional PDF.</p>
<p>If this statement is true, then finding the argmax of the posterior PDF is the same as finding the argmax of the posterior distribution in terms of Bayes Rule.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\underset{y \in \{A, C, G\}}{\text{argmax}} f_{Y|X_1}(y|x_1) &amp;= \underset{y \in \{A, C, G\}}{\text{argmax}} \frac{f_{X_1|Y}(x_1|y) f_{Y}(y)}{f_{X_1}(x_1)} \\
&amp;= \underset{y \in \{A, C, G\}}{\text{argmax}} \frac{f_{X_1|Y}(x_1|y) f_{Y}(y)}{\sum_{y' \in \{A, C, G\}} f_{X_1|Y}(x_1|y') f_{Y}(y')}
\end{aligned}
\end{split}\]</div>
<p>Let’s go back to where we left off.</p>
<p>The table below breaks down the joint distribution table of <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X_1\)</span>, since
both are categorical, it is easy to compute the joint distribution table.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(Y\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(X_1 = 0\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(X_1 = 1\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\sum\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>126</p></td>
<td><p>25</p></td>
<td><p>151</p></td>
</tr>
<tr class="row-odd"><td><p>C</p></td>
<td><p>61</p></td>
<td><p>7</p></td>
<td><p>68</p></td>
</tr>
<tr class="row-even"><td><p>G</p></td>
<td><p>6</p></td>
<td><p>117</p></td>
<td><p>123</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\sum\)</span></p></td>
<td><p>193</p></td>
<td><p>149</p></td>
<td><p>342</p></td>
</tr>
</tbody>
</table>
</div>
<p>The below table represents the marginal distribution table of <span class="math notranslate nohighlight">\(X_1\)</span> in terms
of the relative frequency.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(Y\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(X_1 = 0\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(X_1 = 1\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\sum\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>0.365</p></td>
<td><p>0.072</p></td>
<td><p>0.437</p></td>
</tr>
<tr class="row-odd"><td><p>C</p></td>
<td><p>0.178</p></td>
<td><p>0.020</p></td>
<td><p>0.198</p></td>
</tr>
<tr class="row-even"><td><p>G</p></td>
<td><p>0.017</p></td>
<td><p>0.342</p></td>
<td><p>0.359</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\sum\)</span></p></td>
<td><p>0.560</p></td>
<td><p>0.434</p></td>
<td><p>1.000</p></td>
</tr>
</tbody>
</table>
</div>
<p>The image is a sketch of the joint distribution table of <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X_1\)</span>.</p>
<figure class="align-default" id="penguin-overweight-joint">
<a class="reference internal image-reference" href="../../_images/penguin_overweight_joint_sketch.jpg"><img alt="../../_images/penguin_overweight_joint_sketch.jpg" src="../../_images/penguin_overweight_joint_sketch.jpg" style="height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">Joint distribution diagram of <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X_1\)</span>.</span><a class="headerlink" href="#penguin-overweight-joint" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>We can also use seaborns <code class="docutils literal notranslate"><span class="pre">jointgrid</span></code> to do a joint distribution plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">JointGrid</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;overweight&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">)</span>
<span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
<span class="c1"># bins =  np.arange(0, high + 1.5) - 0.5 # [-0.5, 0.5, 1.5]</span>
<span class="n">g</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">,</span><span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">plot_marginals</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/9da7c03b5f4fb6e370b6370ea77ed06831c18090cc97f97c42c5dc8d2c2ef3af.png" src="../../_images/9da7c03b5f4fb6e370b6370ea77ed06831c18090cc97f97c42c5dc8d2c2ef3af.png" />
</div>
</div>
<p>The darker tone of color corresponds to a higher impulse of the joint distribution.</p>
<p>Indeed we can see that the combo of Adelie + overweight = 0 and Gentoo + overweight = 1 presents
a darker tone than the rest, indicating that <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=0, Y=A]\)</span> and <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=1, Y=G]\)</span> are the highest impulses of the joint distribution.</p>
<p>In our table they correspond to 0.365 and 0.342 respectively, which is consistent with the
plot.</p>
<p>The top and right are the marginal distribution of <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X_1\)</span> respectively. They are
just relative frequencies of both <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X_1\)</span> respectively.</p>
<p>Note the above all uses histogram as default, where we used normal histograms to
“estimate” the PDF of the joint distribution. We can also use a kernel density estimation (KDE) to
do so, which is a bit more smooth and accurate. Note everything here is just an estimation. We will
use it in continuous distributions later.</p>
<p>To see the empirical conditional distribution of <span class="math notranslate nohighlight">\(X_1=0\)</span> given <span class="math notranslate nohighlight">\(Y=C\)</span> for example,
it is simply given by the table above. To calculate we ask ourselves the following question:</p>
<p>What is <span class="math notranslate nohighlight">\(P(X_1=0|Y=C)\)</span>? We simply look at the table constructed earlier and see that it is <span class="math notranslate nohighlight">\(0.8971\)</span>. But to
read it off this joint distribution table, you first need to recognize that when <span class="math notranslate nohighlight">\(Y=C\)</span>, we have shrinked our table to only the rows where <span class="math notranslate nohighlight">\(Y=C\)</span> (2nd row). Then we look at the column where <span class="math notranslate nohighlight">\(X_1=0\)</span> and see that it is 61, then we divide by the sum of the row, which is 68, to get <span class="math notranslate nohighlight">\(0.8971\)</span>. Alternatively, it is
the same as saying that <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=0, Y=C] / \mathbb{P}[Y=C] = 61 / 68 = 0.8971\)</span>.</p>
<p>In this scenario, the author mentioned that we can actually directly compute the posterior probability from the empirical joint distribution table.</p>
<p>For example, if we want to calculate the posterior probability of <span class="math notranslate nohighlight">\(Y=A\)</span> given <span class="math notranslate nohighlight">\(X_1=0\)</span>,
we simply look at the column <span class="math notranslate nohighlight">\(X_1=0\)</span> and calculate the relative frequency of <span class="math notranslate nohighlight">\(Y=A\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Y=A|X_1=0] = \frac{126}{193} = 0.652
\]</div>
<p>or equivalently</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Y=A|X_1=0] = \frac{0.365}{0.560} = 0.652
\]</div>
<p>Note that we are still talking about empirical here, so nothing is really proven yet.</p>
<p>In a similar fashion, we have</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Y=C|X_1=0] = \frac{61}{193} = 0.315
\]</div>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Y=G|X_1=0] = \frac{6}{193} = 0.031
\]</div>
<p>This should not be surprising, since if we can construct the joint probability table,
then both the marginal and conditional probability tables can be constructed from it.
We can confirm this by computing the posterior distribution using the formula above,
using Bayes’ rule.</p>
<p>Firstly, our prior says that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[Y=A] &amp;= \frac{151}{342} = 0.4415 \\
\mathbb{P}[Y=C] &amp;= \frac{68}{342} = 0.1988 \\
\mathbb{P}[Y=G] &amp;= \frac{123}{342} = 0.3596 \\
\end{aligned}
\end{split}\]</div>
<p>These values will handle the <span class="math notranslate nohighlight">\(\mathbb{P}[Y=y]\)</span> term in the formula above.
I have to emphasize again that all of these are empirical probabilities, the actual
probability of the species of the penguin is not known, i.e <span class="math notranslate nohighlight">\(\mathbb{P}[Y=y]\)</span> is not known
but we can reasonably estimate it using statistics, and in this case we estimate
it using the relative frequency of each species, we will see later that the
relative frequency is an estimator of the actual probability by Maximum Likelihood Estimation.</p>
<p>Next, we find the likelihood terms of <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=0|Y=y]\)</span> for each species <span class="math notranslate nohighlight">\(y\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[X_1=0|Y=A] &amp;= \frac{126}{151} = 0.8344 \\
\mathbb{P}[X_1=0|Y=C] &amp;= \frac{61}{68} = 0.8971 \\
\mathbb{P}[X_1=0|Y=G] &amp;= \frac{6}{123} = 0.0488 \\
\end{aligned}
\end{split}\]</div>
<p>Again, these are empirical probabilities, we are not sure if these are the actual probabilities of the features given the species, but we can reasonably estimate it using statistics, and
in this case we again use relative frequency to estimate it. We will see later this is modelled
by the Multinomial (Categorical) distribution with parameter <span class="math notranslate nohighlight">\(\pi_y\)</span>.</p>
<p>The Categorical distribution is a generalization of the Bernoulli and Binomial distributions.
When <span class="math notranslate nohighlight">\(k=2\)</span> and <span class="math notranslate nohighlight">\(n=1\)</span>, it is the Bernoulli distribution. When <span class="math notranslate nohighlight">\(k=2\)</span> and <span class="math notranslate nohighlight">\(n&gt;1\)</span>, it is the Binomial distribution.
When <span class="math notranslate nohighlight">\(k&gt;2\)</span> and <span class="math notranslate nohighlight">\(n=1\)</span>, it is the Categorical distribution.</p>
<p>Plugging these <strong>priors</strong> and <strong>likelihoods</strong> into the formula above, we get the
denominator, the normalizing constant, which is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[X_1=0] &amp;= \mathbb{P}[X_1=0|Y=A] \mathbb{P}[Y=A] \\
&amp;+ \mathbb{P}[X_1=0|Y=C] \mathbb{P}[Y=C] \\
&amp;+ \mathbb{P}[X_1=0|Y=G] \mathbb{P}[Y=G] \\
&amp;= \dfrac{193}{342} = 0.565
\end{aligned}
\end{split}\]</div>
<p>We pause a while to note that <span class="math notranslate nohighlight">\(\mathbb{P}[X_1]\)</span> is the probability of observing <span class="math notranslate nohighlight">\(X_1=x_1\)</span>,
which is independent of <span class="math notranslate nohighlight">\(Y\)</span>. We can compute it using the law of total probability.</p>
<p>Of course, this is also merely the relative frequency of <span class="math notranslate nohighlight">\(X_1=0\)</span> in the dataset, which is expected
since <span class="math notranslate nohighlight">\(X_1\)</span> is discrete (binary), but we will never know the actual probability of <span class="math notranslate nohighlight">\(X_1=0\)</span>. We can also
estimate it using Binomial distribution if we assume that it is a Bernoulli process, but
if it is continuous, then it is often harder to estimate it. We will see later that
we can omit the denominator since it is “constant” for all <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>Finally, by Bayes’ rule, we get the posterior probability of <span class="math notranslate nohighlight">\(Y=A\)</span> given <span class="math notranslate nohighlight">\(X_1=0\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[Y=A|X_1=0] &amp;= \dfrac{\mathbb{P}[X_1=0|Y=A] \mathbb{P}[Y=A]}{\mathbb{P}[X_1=0]} \\
&amp;= \dfrac{151/342 \times 126/151}{193/342} \\
&amp;= \dfrac{126}{193} = 0.6528
\end{aligned}
\end{split}\]</div>
<p>which is the same as the one we calculated earlier using the empirical joint distribution table.</p>
<p>In a similar fashion, we get the posterior probability of <span class="math notranslate nohighlight">\(Y=C\)</span> given <span class="math notranslate nohighlight">\(X_1=0\)</span>, and <span class="math notranslate nohighlight">\(Y=G\)</span> given <span class="math notranslate nohighlight">\(X_1=0\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[Y=C|X_1=0] &amp;= \dfrac{68/342 \times 61/68}{193/342} = \dfrac{61}{193} = 0.3161 \\
\mathbb{P}[Y=G|X_1=0] &amp;= \dfrac{123/342 \times 6/123}{193/342} = \dfrac{6}{193} = 0.0311
\end{aligned}
\end{split}\]</div>
<p>And the argmax of these three posterior probabilities is <span class="math notranslate nohighlight">\(Y=A\)</span>, so we predict that the penguin is of species <span class="math notranslate nohighlight">\(A\)</span>.
We observe that to get the argmax, we do not need the denominator, because it is the same for all <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>So we can omit the denominator, and we get the same result, it may no longer sum to 1, but
it does not affect the final result.</p>
<p>We also saw here that if our prior is very low, then even though the likelihood is high, the posterior can still be
low if <code class="docutils literal notranslate"><span class="pre">prior</span> <span class="pre">&lt;&lt;</span> <span class="pre">likelihood</span></code>. This is the reason why we need to use prior knowledge to help us make better predictions.</p>
</section>
<section id="one-quantitative-predictor">
<h3><a class="toc-backref" href="#id10" role="doc-backlink">One Quantitative Predictor</a><a class="headerlink" href="#one-quantitative-predictor" title="Link to this heading">#</a></h3>
<p>We now ignore the earlier categorical predictor <span class="math notranslate nohighlight">\(X_1\)</span> and focus on the quantitative predictor <span class="math notranslate nohighlight">\(X_2\)</span>,
<code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>. This penguin has a <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> of 50mm,
so we want to predict the species of the penguin given this information.</p>
<p>We know that as we move on to continuous space, we can no longer use “relative frequency” to estimate the probability of a continuous variable happening, as we will see later.</p>
<p>Let’s do some EDA.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bill_length_mm</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[[</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="s2">&quot;class_id&quot;</span><span class="p">]]</span>
<span class="n">display</span><span class="p">(</span><span class="n">bill_length_mm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>species</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39.1</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>39.5</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>40.3</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36.7</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>39.3</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>337</th>
      <td>47.2</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>338</th>
      <td>46.8</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>339</th>
      <td>50.4</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>340</th>
      <td>45.2</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>341</th>
      <td>49.9</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>342 rows × 3 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x2_mean</span> <span class="o">=</span> <span class="n">bill_length_mm</span><span class="p">[</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Mean bill length across the whole population &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;without conditioning on class: </span><span class="si">{</span><span class="n">x2_mean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> mm&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Mean bill length across the whole population without conditioning on class: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">43.92</span> mm
</pre>
</div></div>
</div>
<p>The kdeplot above is for an univariate, empirical estimation of the whole dataset, not
conditional on any class label.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plotting both distibutions on the same figure</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x2_mean</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="c1"># plt.legend()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/e9a023554a2b461319557562ddeeac780e61b8146df4ad7587ba2ccc8e4d0ceb.png" src="../../_images/e9a023554a2b461319557562ddeeac780e61b8146df4ad7587ba2ccc8e4d0ceb.png" />
</div>
</div>
<p>To see the conditional distribution, we can use the <code class="docutils literal notranslate"><span class="pre">hue</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">seaborn.kdeplot</span></code> to plot the conditional distribution <span class="math notranslate nohighlight">\(f_{X_2|Y}(x_2|y)\)</span>. Recall that this conditional distribution
is a distribution of <span class="math notranslate nohighlight">\(X_2\)</span> in the reduced sample space <span class="math notranslate nohighlight">\(\mathcal{\Omega}_{X_2|Y}\)</span>, where <span class="math notranslate nohighlight">\(Y=y\)</span> has happened.</p>
<p>More concretely, you just imagine that given
say Adelie has happened, then we zoom into the reduced sample space of the dataset where <span class="math notranslate nohighlight">\(Y\)</span> is Adelie, and plot the distribution of <span class="math notranslate nohighlight">\(X_2\)</span> in this <strong>reduced sample space</strong> (reduced dataset). Things get a bit more complicated when we have more than one predictor, but the idea is the same, we will see later as well.</p>
<p>I want to emphasize that for 1 predictor conditioned on another random variable,
in this case <span class="math notranslate nohighlight">\(X_2\)</span> conditioned on <span class="math notranslate nohighlight">\(Y\)</span>, the conditional distribution is like a <strong>univariate distribution</strong>
in <span class="math notranslate nohighlight">\(X_2\)</span>. This is because once we <span class="math notranslate nohighlight">\(Y=y\)</span> has happened,
there is no randomness left in <span class="math notranslate nohighlight">\(Y\)</span>, we are only looking at the distribution of <span class="math notranslate nohighlight">\(X_2\)</span> in the reduced sample space <span class="math notranslate nohighlight">\(\mathcal{\Omega}_{X_2|Y}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x2</span> <span class="o">=</span> <span class="mi">50</span> <span class="c1"># penguin bill length</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plotting both distibutions on the same figure</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span>
    <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Density plot of bill length&quot;</span><span class="p">)</span>
<span class="c1"># plt.legend()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/bb2ffa75b7769dbf541ed9b2699180795bdb18f241857d3b5b3706ac56fb1dc1.png" src="../../_images/bb2ffa75b7769dbf541ed9b2699180795bdb18f241857d3b5b3706ac56fb1dc1.png" />
</div>
</div>
<p>We have seen the conditional distribution plot above, let see the joint distribution of <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.
Note very carefully that this is a <strong>joint distribution</strong> of <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, not a <strong>conditional distribution</strong> of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">JointGrid</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">plot_marginals</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.JointGrid at 0x7fadcff0f3a0&gt;
</pre></div>
</div>
<img alt="../../_images/05193e98e79a067b489459a52a7650bd195fba9162cefa2e9657e75e381d47a0.png" src="../../_images/05193e98e79a067b489459a52a7650bd195fba9162cefa2e9657e75e381d47a0.png" />
<img alt="../../_images/6b6547b5893d0a51a88f766811be14e353894aec7083ec1fc8d125c36925857a.png" src="../../_images/6b6547b5893d0a51a88f766811be14e353894aec7083ec1fc8d125c36925857a.png" />
</div>
</div>
<p>We see that the for this penguin with <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> of 50mm, our gut feeling tells us
that it most likely is not an Adelie, since the distribution of <span class="math notranslate nohighlight">\(X_2\)</span> for Adelie is
much less than 50 mm. It could be a Chinstrap or a Gentoo, but we are not sure which one,
though Chinstrap is tends to be longer for bill length, but the earlier section has
told us that we should weigh the prior probability of each species into consideration.</p>
<p>We can again use Bayes’ rule to compute the posterior probability of <span class="math notranslate nohighlight">\(Y=A\)</span> given <span class="math notranslate nohighlight">\(X_2=50\)</span>,
this time we use the notation <span class="math notranslate nohighlight">\(f\)</span> to represent our earlier <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2}(y|x_2) &amp;= \dfrac{f_{X_2|Y}(x_2|y) f_{Y}(y)}{f_{X_2}(x_2)} \\
\end{aligned}
\end{split}\]</div>
<p>For example, since our given feature is <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> of 50mm, we see</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
\begin{aligned}
f_{Y|X_2}(A|50) &amp;= \dfrac{f_{X_2|Y}(50|A) f_{Y}(A)}{f_{X_2}(50)} \\
f_{Y|X_2}(C|50) &amp;= \dfrac{f_{X_2|Y}(50|C) f_{Y}(C)}{f_{X_2}(50)} \\
f_{Y|X_2}(G|50) &amp;= \dfrac{f_{X_2|Y}(50|G) f_{Y}(G)}{f_{X_2}(50)} \\
\end{aligned}
\end{split}\]</div>
<p>Again, we use argmax to solve the problem,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\underset{y \in \{A, C, G\}}{\text{argmax}} f_{Y|X_2}(y|50) &amp;= \underset{y \in \{A, C, G\}}{\text{argmax}} \dfrac{f_{X_2|Y}(50|y) f_{Y}(y)}{f_{X_2}(50)} \\
&amp;= \underset{y \in \{A, C, G\}}{\text{argmax}} \dfrac{f_{X_2|Y}(50|y) f_{Y}(y)}{\sum_{y' \in \{A, C, G\}} f_{X_2|Y}(50|y') f_{Y}(y')}\\
\end{aligned}
\end{split}\]</div>
<p>Now we met our first hurdle here since <span class="math notranslate nohighlight">\(f_{X_2|Y}(50|y)\)</span> is not easy to compute since
<span class="math notranslate nohighlight">\(X_2\)</span> is a continuous variable, we cannot construct a empirical joint distribution table like
how we did earlier (<code class="docutils literal notranslate"><span class="pre">species</span></code> vs <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> does not work here).</p>
<p>Further, we haven’t assumed a model for <span class="math notranslate nohighlight">\(X_2\)</span> yet from which to define the likelihood <span class="math notranslate nohighlight">\(\mathbb{P}[X_2=50|Y=y]\)</span> or <span class="math notranslate nohighlight">\(\mathcal{L}(X_2=50|Y=y)\)</span>. We can do like previously to assume <strong>naively (pun intended)</strong> that the distribution of <span class="math notranslate nohighlight">\(X_2\)</span> <strong>given Y</strong> is Gaussian, note carefully
that this is a <strong>conditional distribution</strong> of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>, we can also say in same
term that <span class="math notranslate nohighlight">\(X_2\)</span> is <strong>continuous</strong> and <strong>conditionally normal</strong>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
X_2 \mid Y=A \sim \mathcal{N}(\mu_A, \sigma_A^2) \\
X_2 \mid Y=C \sim \mathcal{N}(\mu_C, \sigma_C^2) \\
X_2 \mid Y=G \sim \mathcal{N}(\mu_G, \sigma_G^2)
\end{aligned}
\end{split}\]</div>
<p>Notice here that it is possible that the three conditional distributions are different with
different <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>. Technically, we can even assume that the three conditional
distributions come from different families, but we will stick to the Gaussian family for now.
We usually call this the <strong>Gaussian Naive Bayes</strong> model.</p>
<p>From the conditional plot above, we can see that the three species are not well separated in the joint distribution space, so we cannot expect a good performance from the Gaussian Naive Bayes model. For example,
50 mm could very well be either Gentoo or Chinstrap from the plot since they are not well separated.</p>
<p>In our example, the conditional distribution of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> appears quite Gaussian.
Even if not so, the Central Limit Theorem tells us that the sum of many independent random
variables tends to be Gaussian, so we can still use the Gaussian Naive Bayes model
if we have enough data (?).</p>
<p>The next question is how do we estimate the <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> for each <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>?
We can use the <strong>Maximum Likelihood Estimation</strong> (MLE) method to estimate the parameters.</p>
<p>It turns out that the MLE of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> for each <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> is the sample mean
and sample standard deviation of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>. They are unbiased estimators of the true
<span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>!</p>
<p>The below table summarizes the sample (empirical) mean and sample standard deviation of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>.
For example, the sample mean of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y=A\)</span> is 38.8 mm, and the sample standard deviation
is 2.66 mm.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Species</p></th>
<th class="head"><p>Sample Mean</p></th>
<th class="head"><p>Sample Standard Deviation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>38.8</p></td>
<td><p>2.66</p></td>
</tr>
<tr class="row-odd"><td><p>C</p></td>
<td><p>48.8</p></td>
<td><p>3.34</p></td>
</tr>
<tr class="row-even"><td><p>G</p></td>
<td><p>47.5</p></td>
<td><p>3.08</p></td>
</tr>
</tbody>
</table>
</div>
<p>Remember again, the sample mean and sample standard deviation are unbiased estimators of the true
<span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, and can be shown by MLE.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bill_length_mean_std</span> <span class="o">=</span> <span class="n">bill_length_mm</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;species&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;bill_length_mm&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">]})</span>
<span class="n">bill_length_mean_std</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">bill_length_mm</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
    </tr>
    <tr>
      <th>species</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>38.791391</td>
      <td>2.663405</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>48.833824</td>
      <td>3.339256</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>47.504878</td>
      <td>3.081857</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s plot the normal distribution with the sample mean and sample standard deviation for each <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>.
We also round off the sample mean and sample standard deviation to 2 decimal places for convenience and
stay true to the original book.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># rv_adelie = stats.norm(bill_length_mean_std.loc[&#39;Adelie&#39;][&#39;bill_length_mm&#39;][&#39;mean&#39;], bill_length_mean_std.loc[&#39;Adelie&#39;][&#39;bill_length_mm&#39;][&#39;std&#39;])</span>
<span class="c1"># rv_chinstrap = stats.norm(bill_length_mean_std.loc[&#39;Chinstrap&#39;][&#39;bill_length_mm&#39;][&#39;mean&#39;], bill_length_mean_std.loc[&#39;Chinstrap&#39;][&#39;bill_length_mm&#39;][&#39;std&#39;])</span>
<span class="c1"># rv_gentoo = stats.norm(bill_length_mean_std.loc[&#39;Gentoo&#39;][&#39;bill_length_mm&#39;][&#39;mean&#39;], bill_length_mean_std.loc[&#39;Gentoo&#39;][&#39;bill_length_mm&#39;][&#39;std&#39;])</span>

<span class="n">rv_adelie</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">38.8</span><span class="p">,</span> <span class="mf">2.66</span><span class="p">)</span>
<span class="n">rv_chinstrap</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">48.8</span><span class="p">,</span> <span class="mf">3.34</span><span class="p">)</span>
<span class="n">rv_gentoo</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">47.5</span><span class="p">,</span> <span class="mf">3.08</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_adelie</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adelie&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_chinstrap</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Chinstrap&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_gentoo</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;g-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gentoo&#39;</span><span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="o">+</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50.5 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;49.5 mm&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;bill_length_mm&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability density&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/e13a3c21e3180a833130c6642651c03dc544163346ce8422bc576d9ccb0a099a.png" src="../../_images/e13a3c21e3180a833130c6642651c03dc544163346ce8422bc576d9ccb0a099a.png" />
</div>
</div>
<p>As we can see, the this naive assumption of Gaussian distribution for <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> is not
perfect, but it isn’t too bad either. Note the distinction in the plot here and previously.
The previous diagram is the empirical density plot of the raw data, while this one is the
density plot of the conditional gaussian distribution of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> where we have
used the sample mean and sample standard deviation as the parameters of the Gaussian <span class="math notranslate nohighlight">\(X_2 \mid Y \sim \mathcal{N}(\mu, \sigma^2)\)</span>.</p>
<p>Now we can finally solve our “hurdle” problem of computing <span class="math notranslate nohighlight">\(f_{X_2|Y}(50|y)\)</span> for each <span class="math notranslate nohighlight">\(y \in \{A, C, G\}\)</span>.</p>
<p>We can use the Gaussian density function to compute the probability density of <span class="math notranslate nohighlight">\(X_2=50\)</span> given <span class="math notranslate nohighlight">\(Y=y\)</span>.
Geometrically, we can see that the probability density of <span class="math notranslate nohighlight">\(X_2=50\)</span> given <span class="math notranslate nohighlight">\(Y=y\)</span> is the area under the
curve of the Gaussian density function at <span class="math notranslate nohighlight">\(X_2=50\)</span> for each <span class="math notranslate nohighlight">\(Y=y\)</span> around a small neighborhood <span class="math notranslate nohighlight">\(\delta\)</span>
of <span class="math notranslate nohighlight">\(X_2=50\)</span>. Illustrated in diagram above, the <span class="math notranslate nohighlight">\(\delta=0.5\)</span> mm and the area under the curve is
computed by the integral of the Gaussian density function from <span class="math notranslate nohighlight">\(X_2=49.5\)</span> to <span class="math notranslate nohighlight">\(X_2=50.5\)</span>. In reality however,
the <span class="math notranslate nohighlight">\(\delta\)</span> is infinitesimally small.</p>
<p>In practice, we just need to compute the probability density of <span class="math notranslate nohighlight">\(X_2=50\)</span> given <span class="math notranslate nohighlight">\(Y=y\)</span> at <span class="math notranslate nohighlight">\(X_2=50\)</span> and
not the actual probability. Note very carefully that PDF is not probability, it is the probability density!!!</p>
<p>As mentioned earlier, we should compute
the posterior conditional PDF and maximize over it instead of the posterior conditional probability
since probability at a point is 0 for continuous variables.</p>
<p>And so,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{X_2 \mid Y}(x_2=50 \mid y=A) &amp;= \frac{1}{\sqrt{2\pi}\sigma_A} \exp \left( -\frac{(x_2 - \mu_A)^2}{2\sigma_A^2} \right) \\
&amp;= \frac{1}{\sqrt{2\pi}\sigma_A} \exp \left( -\frac{(50 - \mu_A)^2}{2\sigma_A^2} \right) \\
&amp;= \frac{1}{\sqrt{38.8} \cdot 2.66} \exp \left( -\frac{(50 - 38.8)^2}{2 \cdot 2.66^2} \right) \\
&amp;= 0.0000212 
\end{aligned}
\end{split}\]</div>
<p>Similarly,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{X_2 \mid Y}(x_2=50 \mid y=C) &amp;= 0.112 \\
f_{X_2 \mid Y}(x_2=50 \mid y=G) &amp;= 0.09317 \\
\end{aligned}
\end{split}\]</div>
<p>Note that <span class="math notranslate nohighlight">\(\mu_A\)</span> and <span class="math notranslate nohighlight">\(\sigma_A\)</span> are the sample mean and sample standard deviation of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y=A\)</span>.
Notation wise it is fine but you can also view it as <span class="math notranslate nohighlight">\(\mu_{A|X_2}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{A|X_2}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">px2_given_adelie</span> <span class="o">=</span> <span class="n">rv_adelie</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="n">px2_given_chinstrap</span> <span class="o">=</span> <span class="n">rv_chinstrap</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="n">px2_given_gentoo</span> <span class="o">=</span> <span class="n">rv_gentoo</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_2=50|Adelie) = </span><span class="si">{</span><span class="n">px2_given_adelie</span><span class="si">:</span><span class="s1">.7f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_2=50|Chinstrap) = </span><span class="si">{</span><span class="n">px2_given_chinstrap</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_2=50|Gentoo) = </span><span class="si">{</span><span class="n">px2_given_gentoo</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_2</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">50</span>|Adelie<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000212</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_2</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">50</span>|Chinstrap<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.112</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_2</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">50</span>|Gentoo<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.09317</span>
</pre>
</div></div>
</div>
<p>As an example, the probability density of <span class="math notranslate nohighlight">\(X_2=50\)</span> given <span class="math notranslate nohighlight">\(Y=A\)</span> is <span class="math notranslate nohighlight">\(0.0000212 \text{ mm}^{-1}\)</span>, and indeed from
the plot above, the area under the curve is definitely the smallest, and the lowest since there is
almost no Adelie with 50 mm bill length.</p>
<p>So the marginal PDF of observing a penguin with a 50 mm bill length is,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{X_2}(50) &amp;= \sum_{y \in \mathcal{Y}} f_{X_2|Y}(50|y) f_{Y}(y) \\
&amp;= \frac{151}{342} \cdot 0.0000212 + \frac{68}{342} \cdot 0.112 + \frac{123}{342} \cdot 0.09317 \\
&amp;= 0.05579
\end{aligned}
\end{split}\]</div>
<p>Once again, this number is not a probability, it is the probability density, it just means for
every 1 mm, there is a 0.05579 mm chance of observing a penguin with a 50 mm bill length
around a small neighborhood <span class="math notranslate nohighlight">\(\delta\)</span> mm of 50 mm.
In laymen, it is how “dense” the probability is at that point.</p>
<p>Then, the posterior conditional PDF of <span class="math notranslate nohighlight">\(Y\)</span> given <span class="math notranslate nohighlight">\(X_2=50\)</span> is,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2}(y=A|x_2=50) &amp;= \frac{f_{X_2|Y}(x_2=50|y=A) f_{Y}(y=A)}{f_{X_2}(x_2=50)} \\
&amp;= \dfrac{(151/342) \cdot 0.0000212}{0.05579} \\
&amp;\approx 0.0002
\end{aligned}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2}(y=C|x_2=50) \approx 0.3992 \\
\end{aligned}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2}(y=G|x_2=50) \approx 0.6006 \\
\end{aligned}
\end{split}\]</div>
<p>Again note that these are not probabilities, they are probability densities. But since they have
the same denominator, it is normalized and so sum up to 1 in this case. This time round,
the final results was pushed over again by the fact that Gentoo is more common in the wild (prior <span class="math notranslate nohighlight">\(P(Y=G)\approx 0.3605\)</span>).</p>
</section>
<section id="two-continuous-predictors">
<h3><a class="toc-backref" href="#id11" role="doc-backlink">Two (Continuous) Predictors</a><a class="headerlink" href="#two-continuous-predictors" title="Link to this heading">#</a></h3>
<p>The reality is that the data is usually multi-dimensional, and we need to use multiple predictors
to make a prediction.</p>
<p>In the previous two examples, we have seen that for the same penguin with the following features,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code>: <span class="math notranslate nohighlight">\(&lt; 4200 \mathrm{~g}\)</span> (<code class="docutils literal notranslate"><span class="pre">overweight</span></code> = 0 if <code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code> <span class="math notranslate nohighlight">\(&lt; 4200 \mathrm{~g}\)</span>, 1 otherwise)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>: <span class="math notranslate nohighlight">\(50 \mathrm{~mm}\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>: <span class="math notranslate nohighlight">\(195 \mathrm{~mm}\)</span></p></li>
</ul>
<p>the predictions for the species is an Adelie if we only use <code class="docutils literal notranslate"><span class="pre">overweight</span></code>, and
a Gentoo if we only use <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>. This inconsistency suggest that
our model may have room for improvement. Intuitively, we can add
multiple predictors to our model to make a more accurate prediction, though
this is not always the case if the predictors are correlated, or if there are
too many predictors (curse of dimensionality).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">flipper_length_mm</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[[</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="s2">&quot;class_id&quot;</span><span class="p">]]</span>
<span class="n">display</span><span class="p">(</span><span class="n">flipper_length_mm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>flipper_length_mm</th>
      <th>species</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>181.0</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>186.0</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>195.0</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>193.0</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>190.0</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>337</th>
      <td>214.0</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>338</th>
      <td>215.0</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>339</th>
      <td>222.0</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>340</th>
      <td>212.0</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>341</th>
      <td>213.0</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>342 rows × 3 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x3_mean</span> <span class="o">=</span> <span class="n">flipper_length_mm</span><span class="p">[</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Mean flipper length across the whole population &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;without conditioning on class: </span><span class="si">{</span><span class="n">x3_mean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> mm&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Mean flipper length across the whole population without conditioning on class: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">200.92</span> mm
</pre>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plotting both distibutions on the same figure</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span>
    <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x3_mean</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Density plot of flipper length.&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/d30c7e64ae10359daae359c0be3091b90d01e6ed61861ae0c1179ca8364cda95.png" src="../../_images/d30c7e64ae10359daae359c0be3091b90d01e6ed61861ae0c1179ca8364cda95.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x3</span> <span class="o">=</span> <span class="mi">195</span> <span class="c1"># penguin flipper length</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plotting both distibutions on the same figure</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span>
    <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195 mm&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Density plot of flipper length&quot;</span><span class="p">)</span>
<span class="c1"># plt.legend()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/98920f3f6ec839e0f9631de03462c3ff8f742acb1a5119b663eec82a6e1cdbe7.png" src="../../_images/98920f3f6ec839e0f9631de03462c3ff8f742acb1a5119b663eec82a6e1cdbe7.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plotting both distibutions on the same figure</span>
<span class="n">x2</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span>
    <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Density plot of bill length&quot;</span><span class="p">)</span>
<span class="c1"># plt.legend()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/bb2ffa75b7769dbf541ed9b2699180795bdb18f241857d3b5b3706ac56fb1dc1.png" src="../../_images/bb2ffa75b7769dbf541ed9b2699180795bdb18f241857d3b5b3706ac56fb1dc1.png" />
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> are plotted above as density plots,
just by looking at them alone may be hard to distinguish between the
Chinstrap and Gentoo for the <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> plot because they are
quite close (overlap in density curve) with each other, while if you
only look at the <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> plot, you can see that the Chinstrap and
Adelie are now quite close to each other, but if you combine
both <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> together, you can see that
it is much easier to distinguish between them.</p>
<p>This plot is from <a class="reference external" href="https://seaborn.pydata.org/tutorial/distributions.html#distribution-visualization-in-other-settings">Seaborn guide</a>, one can see with default setting
we have a joint plot of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> with the marginal
histograms on the side. The joint plot is a scatter plot of the two variables.</p>
<p>The plot with <code class="docutils literal notranslate"><span class="pre">kind=hist</span></code> will show the joint distribution as a histogram, and the
rectangular bins are colored by the density of the points in each bin. The darker
the color the more points in that bin. You can understand this as impulses from chan’s book.</p>
<p>Lastly, the plot with <code class="docutils literal notranslate"><span class="pre">kind=kde</span></code> will show the joint distribution as a contour plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;hist&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span>
    <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span>
    <span class="c1"># cbar=True,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.JointGrid at 0x7fadbb065040&gt;
</pre></div>
</div>
<img alt="../../_images/cea13726906990f32e3f48c13f851c442ba5b45c99f3f29722f0c5ec87b43bd0.png" src="../../_images/cea13726906990f32e3f48c13f851c442ba5b45c99f3f29722f0c5ec87b43bd0.png" />
<img alt="../../_images/c227941050c595d0d721fd21d5d522dda3a453468873f0aee11b5af4fb4f3ecc.png" src="../../_images/c227941050c595d0d721fd21d5d522dda3a453468873f0aee11b5af4fb4f3ecc.png" />
<img alt="../../_images/654df864a9c8ec0ead51b623381b765ec9afd3fa62778c646dc863db9fca8c8e.png" src="../../_images/654df864a9c8ec0ead51b623381b765ec9afd3fa62778c646dc863db9fca8c8e.png" />
</div>
</div>
<p>The contour plot is a 2d slice of the 3d density plot where <span class="math notranslate nohighlight">\(z = f_{X_1, X_2}(x_1, x_2)\)</span> is constant.</p>
<p>To see the joint distribution conditioned on the class (species) <span class="math notranslate nohighlight">\(Y\)</span>, where <span class="math notranslate nohighlight">\(Y\)</span>
can be treated as a random variable as well <a class="footnote-reference brackets" href="#id3" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>, we can use the <code class="docutils literal notranslate"><span class="pre">hue</span></code> argument.</p>
<p>To emphasise, the way to approach conditional distributions is to zoom in on the
“reduced” sample space, for example if I want to look at the conditional distribution
of <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(X_3\)</span> conditioned on <span class="math notranslate nohighlight">\(Y=G\)</span>, then you should look at the green colored
hues.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;hist&quot;</span>
<span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.JointGrid at 0x7fadb9b47160&gt;
</pre></div>
</div>
<img alt="../../_images/1338c154edaf1733da4f1eafab39810e90ada3b8028f6b76674282c10f8a3361.png" src="../../_images/1338c154edaf1733da4f1eafab39810e90ada3b8028f6b76674282c10f8a3361.png" />
<img alt="../../_images/c0452cf6cd9c243797be9ec10e25e59024d6b132c97a414b8af39f61ad9d2ddd.png" src="../../_images/c0452cf6cd9c243797be9ec10e25e59024d6b132c97a414b8af39f61ad9d2ddd.png" />
<img alt="../../_images/65303c17881643b9f75cfdb27cb8dde60df71576a82ada26522462d8dc25f5f8.png" src="../../_images/65303c17881643b9f75cfdb27cb8dde60df71576a82ada26522462d8dc25f5f8.png" />
</div>
</div>
<p>Now we plot two dashed lines for where <span class="math notranslate nohighlight">\(X_2=50\)</span> and <span class="math notranslate nohighlight">\(X_3=195\)</span> respectively, and
see that when combined together, the penguin lies amongst the Chinstrap species,
and it is not even close to the other two speces!!</p>
<p>To internalize this concept, we are again looking at the argmax expression below:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{y} &amp;= \arg\max_{y \in \mathcal{Y}} \mathbb{P}(Y=y|X_2=x_2,X_3=x_3) \\
        &amp;= \arg\max_{y \in \mathcal{Y}} \mathbb{P}(Y=y|X_2=50,X_3=195) \\
\end{aligned}
\end{split}\]</div>
<p>or equivalently,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{y} &amp;= \arg\max_{y \in \mathcal{Y}} f_{Y|X_2,X_3}(y|x_2,x_3) \\
        &amp;= \arg\max_{y \in \mathcal{Y}} f_{Y|X_2,X_3}(y|50,195) \\
\end{aligned}
\end{split}\]</div>
<p>We want to know <strong>given each species <span class="math notranslate nohighlight">\(Y\)</span></strong>, which <span class="math notranslate nohighlight">\(y\)</span> <strong>maximizes</strong>
this conditional probability density function <span class="math notranslate nohighlight">\(f_{Y|X_2,X_3}(y|x_2,x_3)\)</span>.
In other words, given <span class="math notranslate nohighlight">\(X_2=50\)</span> and <span class="math notranslate nohighlight">\(X_3=195\)</span>, which species <span class="math notranslate nohighlight">\(Y\)</span> has the highest
“probability” of being the true species of the penguin. And from the diagram,
we can see that the Chinstrap species has the highest probability of being the true
species of the penguin since geometrically it lies closest to where Chinstrap
will is. We will see later that the geometric interpretation of this
is correct, with the formula.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195 mm&quot;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;hist&quot;</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195 mm&quot;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195 mm&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/a75530d6f90fbdf18ad752052a9fa26fb390dd7fc88effef87b204c6ee6fa799.png" src="../../_images/a75530d6f90fbdf18ad752052a9fa26fb390dd7fc88effef87b204c6ee6fa799.png" />
<img alt="../../_images/393cd5cc340464643749f0a552750c53216ad49ce8799a0cd108e3f78d0c6fe3.png" src="../../_images/393cd5cc340464643749f0a552750c53216ad49ce8799a0cd108e3f78d0c6fe3.png" />
<img alt="../../_images/618324dd5060d8d6a56e703908ef7d5cefaebcdb1f33782549834f6583af9378.png" src="../../_images/618324dd5060d8d6a56e703908ef7d5cefaebcdb1f33782549834f6583af9378.png" />
</div>
</div>
<section id="conditional-independence">
<h4><a class="toc-backref" href="#id12" role="doc-backlink">Conditional Independence</a><a class="headerlink" href="#conditional-independence" title="Link to this heading">#</a></h4>
<p>Let’s use naive Bayes to make a prediction for the same penguin with the following features
<span class="math notranslate nohighlight">\(X_2=x_2\)</span> and <span class="math notranslate nohighlight">\(X_3=x_3\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2,X_3}(y|x_2,x_3) &amp;= \frac{f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)}{f_{X_2,X_3}(x_2,x_3)} \\
                         &amp;= \frac{f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)}{\sum_{y \in \mathcal{Y}} f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)} \\
\end{aligned}
\end{split}\]</div>
<p>Another hurdle is presented in front of us, we need to compute the conditional
joint distribution (PDF) <span class="math notranslate nohighlight">\(f_{X_2,X_3|Y}(x_2,x_3|y)\)</span>, which is not easy to compute.</p>
<p>This is because we were dealing with only one-dimensional
distribution, even though there are two variables just now, but as I mentioned,
when we condition on <span class="math notranslate nohighlight">\(Y\)</span>, we are looking at the reduced sample space of <span class="math notranslate nohighlight">\(X\)</span> in
which <span class="math notranslate nohighlight">\(Y\)</span> is fixed,
and not the joint sample space of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. This is the reason why we can happily
use 1-dimensional Gaussian to get the conditional distribution of <span class="math notranslate nohighlight">\(X_2\)</span>.</p>
<p>To reconcile this, Naive Bayes assumes that the predictors are <strong>conditionally independent</strong><a class="footnote-reference brackets" href="#id4" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>.
It states that given <span class="math notranslate nohighlight">\(D\)</span> continuous predictors <span class="math notranslate nohighlight">\(X_1, \ldots, X_D\)</span>, they are called conditionally
independent given <span class="math notranslate nohighlight">\(Y\)</span> if the joint distribution of <span class="math notranslate nohighlight">\(X_1, \ldots, X_D\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> can be written as</p>
<div class="math notranslate nohighlight">
\[
f_{X_1,\ldots,X_D|Y}(x_1,\ldots,x_D|y) = \prod_{d=1}^n f_{X_d|Y}(x_d|y)
\]</div>
<p>The theorem holds for discrete case as well with the difference being that the
PDF is replaced by the PMF.</p>
<p>This theorem means that <em><strong>within each class (species)</strong></em>, the predictors are independent.
More concretely, if we say that <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(X_3\)</span> are conditionally independent given <span class="math notranslate nohighlight">\(Y\)</span>,
then we are saying that <em><strong>within each class (species)</strong></em>, the <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> (<span class="math notranslate nohighlight">\(X_2\)</span>)
is independent of the <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> (<span class="math notranslate nohighlight">\(X_3\)</span>). This is a very strong assumption,
but is at the heart of Naive Bayes and many other algorithms. It simplifies the parameters a lot
(see d2l on the parameters reduction). Such a strong assumption is usually not always true,
see the plot below again, within the class <code class="docutils literal notranslate"><span class="pre">Gentoo</span></code>, we can see that the <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>
and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> exhibit some positive correlation. We will still use this assumption
even though it is not perfect.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>species</th>
      <th>island</th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>overweight</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.1</td>
      <td>18.7</td>
      <td>181.0</td>
      <td>3750.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.5</td>
      <td>17.4</td>
      <td>186.0</td>
      <td>3800.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>40.3</td>
      <td>18.0</td>
      <td>195.0</td>
      <td>3250.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>36.7</td>
      <td>19.3</td>
      <td>193.0</td>
      <td>3450.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.3</td>
      <td>20.6</td>
      <td>190.0</td>
      <td>3650.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>337</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>47.2</td>
      <td>13.7</td>
      <td>214.0</td>
      <td>4925.0</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>338</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>46.8</td>
      <td>14.3</td>
      <td>215.0</td>
      <td>4850.0</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>339</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>50.4</td>
      <td>15.7</td>
      <td>222.0</td>
      <td>5750.0</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>340</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>45.2</td>
      <td>14.8</td>
      <td>212.0</td>
      <td>5200.0</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>341</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>49.9</td>
      <td>16.1</td>
      <td>213.0</td>
      <td>5400.0</td>
      <td>1</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>342 rows × 8 columns</p>
</div></div></div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">numeric_only</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> <span class="c1"># correlation matrix but not conditioned on class</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>overweight</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>bill_length_mm</th>
      <td>1.000000</td>
      <td>-0.235053</td>
      <td>0.656181</td>
      <td>0.595110</td>
      <td>0.448506</td>
      <td>0.731369</td>
    </tr>
    <tr>
      <th>bill_depth_mm</th>
      <td>-0.235053</td>
      <td>1.000000</td>
      <td>-0.583851</td>
      <td>-0.471916</td>
      <td>-0.533576</td>
      <td>-0.744076</td>
    </tr>
    <tr>
      <th>flipper_length_mm</th>
      <td>0.656181</td>
      <td>-0.583851</td>
      <td>1.000000</td>
      <td>0.871202</td>
      <td>0.762945</td>
      <td>0.854307</td>
    </tr>
    <tr>
      <th>body_mass_g</th>
      <td>0.595110</td>
      <td>-0.471916</td>
      <td>0.871202</td>
      <td>1.000000</td>
      <td>0.851748</td>
      <td>0.750491</td>
    </tr>
    <tr>
      <th>overweight</th>
      <td>0.448506</td>
      <td>-0.533576</td>
      <td>0.762945</td>
      <td>0.851748</td>
      <td>1.000000</td>
      <td>0.689371</td>
    </tr>
    <tr>
      <th>class_id</th>
      <td>0.731369</td>
      <td>-0.744076</td>
      <td>0.854307</td>
      <td>0.750491</td>
      <td>0.689371</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Adelie</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Adelie&quot;</span><span class="p">]</span>
<span class="n">Chinstrap</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Chinstrap&quot;</span><span class="p">]</span>
<span class="n">Gentoo</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Gentoo&quot;</span><span class="p">]</span>

<span class="n">display</span><span class="p">(</span><span class="n">Adelie</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">numeric_only</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">display</span><span class="p">(</span><span class="n">Chinstrap</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">numeric_only</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">display</span><span class="p">(</span><span class="n">Gentoo</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">numeric_only</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>overweight</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>bill_length_mm</th>
      <td>1.000000</td>
      <td>0.391492</td>
      <td>0.325785</td>
      <td>0.548866</td>
      <td>0.338386</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>bill_depth_mm</th>
      <td>0.391492</td>
      <td>1.000000</td>
      <td>0.307620</td>
      <td>0.576138</td>
      <td>0.319450</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>flipper_length_mm</th>
      <td>0.325785</td>
      <td>0.307620</td>
      <td>1.000000</td>
      <td>0.468202</td>
      <td>0.336676</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>body_mass_g</th>
      <td>0.548866</td>
      <td>0.576138</td>
      <td>0.468202</td>
      <td>1.000000</td>
      <td>0.715684</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>overweight</th>
      <td>0.338386</td>
      <td>0.319450</td>
      <td>0.336676</td>
      <td>0.715684</td>
      <td>1.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>class_id</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>overweight</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>bill_length_mm</th>
      <td>1.000000</td>
      <td>0.653536</td>
      <td>0.471607</td>
      <td>0.513638</td>
      <td>0.287084</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>bill_depth_mm</th>
      <td>0.653536</td>
      <td>1.000000</td>
      <td>0.580143</td>
      <td>0.604498</td>
      <td>0.375972</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>flipper_length_mm</th>
      <td>0.471607</td>
      <td>0.580143</td>
      <td>1.000000</td>
      <td>0.641559</td>
      <td>0.398093</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>body_mass_g</th>
      <td>0.513638</td>
      <td>0.604498</td>
      <td>0.641559</td>
      <td>1.000000</td>
      <td>0.655613</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>overweight</th>
      <td>0.287084</td>
      <td>0.375972</td>
      <td>0.398093</td>
      <td>0.655613</td>
      <td>1.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>class_id</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>overweight</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>bill_length_mm</th>
      <td>1.000000</td>
      <td>0.643384</td>
      <td>0.661162</td>
      <td>0.669166</td>
      <td>0.236458</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>bill_depth_mm</th>
      <td>0.643384</td>
      <td>1.000000</td>
      <td>0.706563</td>
      <td>0.719085</td>
      <td>0.235313</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>flipper_length_mm</th>
      <td>0.661162</td>
      <td>0.706563</td>
      <td>1.000000</td>
      <td>0.702667</td>
      <td>0.240309</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>body_mass_g</th>
      <td>0.669166</td>
      <td>0.719085</td>
      <td>0.702667</td>
      <td>1.000000</td>
      <td>0.425197</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>overweight</th>
      <td>0.236458</td>
      <td>0.235313</td>
      <td>0.240309</td>
      <td>0.425197</td>
      <td>1.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>class_id</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It is obvious that the assumption of conditional independence is not true from the empirical data
above. However, we will still use this assumption even though it is not perfect, and in the event
if our Naive Bayes does not perform well, we know where went wrong…</p>
<p>Back to our</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2,X_3}(y|x_2,x_3) &amp;= \frac{f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)}{f_{X_2,X_3}(x_2,x_3)} \\
                         &amp;= \frac{f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)}{\sum_{y \in \mathcal{Y}} f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)} \\
\end{aligned}
\end{split}\]</div>
<p>We now have an answer on how to unpack the joint conditional distribution <span class="math notranslate nohighlight">\(f_{X_2,X_3|Y}(x_2,x_3|y)\)</span>.</p>
<p>We can merely do</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{X_2,X_3|Y}(x_2,x_3|y) &amp;= f_{X_2|Y}(x_2|y) f_{X_3|Y}(x_3|y) \\
\end{aligned}
\end{split}\]</div>
<p>so that our previous expression becomes</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2,X_3}(y|x_2,x_3) &amp;= \frac{f_{X_2|Y}(x_2|y) f_{X_3|Y}(x_3|y) f_{Y}(y)}{\sum_{y \in \mathcal{Y}} f_{X_2|Y}(x_2|y) f_{X_3|Y}(x_3|y) f_{Y}(y)} \\
\end{aligned}
\end{split}\]</div>
<p>We have already gotten the conditional distribution of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> earlier, <span class="math notranslate nohighlight">\(f_{X_2|Y}(x_2|y)\)</span> is already
found. We can use the same method to find the conditional distribution of <span class="math notranslate nohighlight">\(X_3\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">flipper_length_mean_std</span> <span class="o">=</span> <span class="n">flipper_length_mm</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;species&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">]})</span>
<span class="n">flipper_length_mean_std</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">flipper_length_mm</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
    </tr>
    <tr>
      <th>species</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>189.953642</td>
      <td>6.539457</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>195.823529</td>
      <td>7.131894</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>217.186992</td>
      <td>6.484976</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x2_x3_mean_std</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;species&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">],</span> <span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">]}</span>
<span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">x2_x3_mean_std</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">bill_length_mm</th>
      <th colspan="2" halign="left">flipper_length_mm</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
    </tr>
    <tr>
      <th>species</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>38.791391</td>
      <td>2.663405</td>
      <td>189.953642</td>
      <td>6.539457</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>48.833824</td>
      <td>3.339256</td>
      <td>195.823529</td>
      <td>7.131894</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>47.504878</td>
      <td>3.081857</td>
      <td>217.186992</td>
      <td>6.484976</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rv_adelie</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">190.</span><span class="p">,</span> <span class="mf">6.54</span><span class="p">)</span>
<span class="n">rv_chinstrap</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">196.</span><span class="p">,</span> <span class="mf">7.13</span><span class="p">)</span>
<span class="n">rv_gentoo</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">217.</span><span class="p">,</span> <span class="mf">6.48</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_adelie</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adelie&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_chinstrap</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Chinstrap&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_gentoo</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;g-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gentoo&#39;</span><span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x3</span><span class="o">+</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195.5 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x3</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;194.5 mm&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;flipper_length_mm&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability density&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/35826a5b0c5cd8b30f0fce3cfdf99e53bcccb2f0d1afce77cacbe185fcbc52ea.png" src="../../_images/35826a5b0c5cd8b30f0fce3cfdf99e53bcccb2f0d1afce77cacbe185fcbc52ea.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">px3_given_adelie</span> <span class="o">=</span> <span class="n">rv_adelie</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span>
<span class="n">px3_given_chinstrap</span> <span class="o">=</span> <span class="n">rv_chinstrap</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span>
<span class="n">px3_given_gentoo</span> <span class="o">=</span> <span class="n">rv_gentoo</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_3=195|Adelie) = </span><span class="si">{</span><span class="n">px3_given_adelie</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_3=195|Chinstrap) = </span><span class="si">{</span><span class="n">px3_given_chinstrap</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_3=195|Gentoo) = </span><span class="si">{</span><span class="n">px3_given_gentoo</span><span class="si">:</span><span class="s1">.7f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_3</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">195</span>|Adelie<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.04554</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_3</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">195</span>|Chinstrap<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.05541</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_3</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">195</span>|Gentoo<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0001934</span>
</pre>
</div></div>
</div>
<p>For formality, the code above translates to</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{X_3|Y}(x_3=195|y=A) &amp;= \frac{1}{\sqrt{2\pi}\sigma_{A}} \exp\left(-\frac{(195-\mu_{A})^2}{2\sigma_A^2}\right) \\
&amp;= 0.04554
\end{aligned}
\end{split}\]</div>
<p>Similarly, we can compute the other two conditional distributions to be <span class="math notranslate nohighlight">\(0.05541\)</span> and <span class="math notranslate nohighlight">\(0.0001934\)</span> respectively.</p>
<p>Next, we compute the denominator, which is the joint distribution of observing <span class="math notranslate nohighlight">\(X_2=50\)</span> and <span class="math notranslate nohighlight">\(X_3=195\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\sum_{y \in \mathcal{Y}} f_{X_2|Y}(x_2|y) f_{X_3|Y}(x_3|y) f_{Y}(y) &amp;= \sum_{y \in \mathcal{Y}} f_{X_2|Y}(x_2=50|y) f_{X_3|Y}(x_3=195|y) f_{Y}(y) \\
&amp;= f_{X_2|Y=A}(x_2=50|y=A) f_{X_3|Y=A}(x_3=195|y=A) f_{Y}(y=A) \\
&amp;+ f_{X_2|Y=C}(x_2=50|y=C) f_{X_3|Y=C}(x_3=195|y=C) f_{Y}(y=C) \\
&amp;+ f_{X_2|Y=G}(x_2=50|y=G) f_{X_3|Y=G}(x_3=195|y=G) f_{Y}(y=G) \\
&amp;= 0.0000212 \cdot 0.04554 \cdot \frac{151}{342} \\
&amp;+ 0.112 \cdot 0.05541 \cdot \frac{68}{342} \\
&amp;+ 0.09317 \cdot 0.0001934 \cdot \frac{123}{342} \\
&amp;\approx 0.001241
\end{aligned}
\end{split}\]</div>
<p>We plug into Bayes’ rule to get the posterior probability of <span class="math notranslate nohighlight">\(Y=A\)</span> given <span class="math notranslate nohighlight">\(X_2=50\)</span> and <span class="math notranslate nohighlight">\(X_3=195\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y=A|X_2,X_3}(y=A|x_2=50,x_3=195) &amp;= \frac{f_{X_2|Y=A}(x_2=50|y=A) f_{X_3|Y=A}(x_3=195|y=A) f_{Y}(y=A)}{\sum_{y \in \mathcal{Y}} f_{X_2|Y}(x_2|y) f_{X_3|Y}(x_3|y) f_{Y}(y)} \\
&amp;= \frac{0.0000212 \cdot 0.04554 \cdot \frac{151}{342}}{0.001241} \\
&amp;\approx 0.0003
\end{aligned}
\end{split}\]</div>
<p>Similarly, we can compute the posterior probability of <span class="math notranslate nohighlight">\(Y=C\)</span> and <span class="math notranslate nohighlight">\(Y=G\)</span> given <span class="math notranslate nohighlight">\(X_2=50\)</span> and <span class="math notranslate nohighlight">\(X_3=195\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y=C|X_2,X_3}(y=C|x_2=50,x_3=195) &amp;\approx 0.9944 \\
f_{Y=G|X_2,X_3}(y=G|x_2=50,x_3=195) &amp;\approx 0.0052
\end{aligned}
\end{split}\]</div>
<p>We then take the argmax of the posterior probabilities to get the prediction. In this case,
it is <span class="math notranslate nohighlight">\(Y=C\)</span> with a posterior probability of <span class="math notranslate nohighlight">\(0.9944\)</span>.</p>
</section>
</section>
<section id="three-predictors">
<h3><a class="toc-backref" href="#id13" role="doc-backlink">Three Predictors</a><a class="headerlink" href="#three-predictors" title="Link to this heading">#</a></h3>
<p>Even though not mentioned in the book, we can also use 3 predictors to make a prediction.
The three predictors are <code class="docutils literal notranslate"><span class="pre">overweight</span></code>, <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>, and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>. The tricky
part is that <code class="docutils literal notranslate"><span class="pre">overweight</span></code> is a categorical variable, and <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>
are continuous variables. We can still do it though, <a class="reference external" href="https://dafriedman97.github.io/mlbook/content/c4/concept.html#model-structure">dafriedman97</a>
mentioned that we for a random vector <span class="math notranslate nohighlight">\(\mathbf{X} = (X_{1}, X_{2}, \ldots, X_{D})\)</span>, the individual
predictors can take on different distributions. In our case, <code class="docutils literal notranslate"><span class="pre">overweight</span></code> is assumed to be follow a Bernoulli distribution,
<code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> are assumed to be follow a Gaussian distribution. Note again that
this is an assumption, and we can always change it to something else if we want to since Naive Bayes does
not have any assumptions on the distribution of the predictors (potentially confusing part!).</p>
</section>
<section id="summary">
<h3><a class="toc-backref" href="#id14" role="doc-backlink">Summary</a><a class="headerlink" href="#summary" title="Link to this heading">#</a></h3>
<p>Here we summarize a few key points.</p>
<ul class="simple">
<li><p>If prior is low but likelihood is high, then posterior may not be high if prior &lt;&lt; likelihood.</p></li>
<li><p>The normalizing constant is constant during argmax comparison, and hence is often omitted. You can
always recover the normalizing constant since you have the posterior and the numerator.</p></li>
<li><p>The key here is estimation theory, for example, to estimate the priors, all we need to do is to
find the proportion of each class in the training set. This proportion is an unbiased estimator
of the true prior probability.</p></li>
<li><p>Conditional Independence is key for Naive Bayes to work, but if your model does not do well,
then this assumption may be violated. Note that the conditional independence assumption along
with the <span class="math notranslate nohighlight">\(\iid\)</span> assumpiton are the only assumptions for Naive Bayes. Assuming the conditional
distribution is Gaussian is not an assumption, it is just a way to make the model tractable.
You can come up with your own assumptions for the conditional distribution.</p></li>
</ul>
</section>
</section>
<section id="pytorch">
<h2><a class="toc-backref" href="#id15" role="doc-backlink">PyTorch</a><a class="headerlink" href="#pytorch" title="Link to this heading">#</a></h2>
<p>Subset data to only include <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>.</p>
<p>Further split the data into training and test sets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[[</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;class_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">estimate_prior_parameters</span><span class="p">(</span><span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate the prior distribution of the classes based on the</span>
<span class="sd">    relative frequencies of the classes in the dataset.&quot;&quot;&quot;</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">distribution</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">probs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">distribution</span>
</pre></div>
</div>
</div>
</div>
<p>The prior distribution of the <strong>whole</strong> (not split) is indeed the same as the prior distribution we
got in the previous section <a class="reference internal" href="#naive-bayes-penguin-the-prior"><span class="std std-ref">The Prior</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">estimate_prior_parameters</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prior distribution: </span><span class="si">{</span><span class="n">prior</span><span class="o">.</span><span class="n">probs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Prior distribution: <span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.4415</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.1988</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.3596</span><span style="font-weight: bold">])</span>
</pre>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">estimate_likelihood_parameters</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimate the parameters of X conditional on y where X | y is</span>
<span class="sd">    assumed to be univariate gaussian for each X_d in X.&quot;&quot;&quot;</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># mean vector = loc -&gt; (n_classes, n_features)</span>
    <span class="n">loc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
    <span class="c1"># covariance matrix -&gt; (n_classes, n_features)</span>
    <span class="c1"># diagonal matrix since features are independent</span>
    <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
        <span class="n">X_where_k</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">k</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">):</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">X_where_k</span><span class="p">[:,</span> <span class="n">d</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">X_where_k</span><span class="p">[:,</span> <span class="n">d</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
            <span class="n">loc</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">d</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean</span>
            <span class="n">covariance_matrix</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">]</span> <span class="o">=</span> <span class="n">var</span>

    <span class="n">distribution</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span>
        <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">covariance_matrix</span><span class="o">=</span><span class="n">covariance_matrix</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">distribution</span>
</pre></div>
</div>
</div>
</div>
<p>Sanity check that mean and variance are correct when compared to the results from pandas dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x2_x3_mean_std_var</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;species&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">,</span> <span class="s2">&quot;var&quot;</span><span class="p">],</span> <span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">,</span> <span class="s2">&quot;var&quot;</span><span class="p">]})</span>
<span class="n">display</span><span class="p">(</span><span class="n">x2_x3_mean_std_var</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="3" halign="left">bill_length_mm</th>
      <th colspan="3" halign="left">flipper_length_mm</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>var</th>
      <th>mean</th>
      <th>std</th>
      <th>var</th>
    </tr>
    <tr>
      <th>species</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>38.791391</td>
      <td>2.663405</td>
      <td>7.093725</td>
      <td>189.953642</td>
      <td>6.539457</td>
      <td>42.764503</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>48.833824</td>
      <td>3.339256</td>
      <td>11.150630</td>
      <td>195.823529</td>
      <td>7.131894</td>
      <td>50.863916</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>47.504878</td>
      <td>3.081857</td>
      <td>9.497845</td>
      <td>217.186992</td>
      <td>6.484976</td>
      <td>42.054911</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_conditionals</span> <span class="o">=</span> <span class="n">estimate_likelihood_parameters</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean vector:</span><span class="se">\n</span><span class="si">{</span><span class="n">class_conditionals</span><span class="o">.</span><span class="n">mean</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Covariance matrix:</span><span class="se">\n</span><span class="si">{</span><span class="n">class_conditionals</span><span class="o">.</span><span class="n">covariance_matrix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Mean vector:
<span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">38.7914</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">189.9536</span><span style="font-weight: bold">]</span>,
        <span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">48.8338</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">195.8235</span><span style="font-weight: bold">]</span>,
        <span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">47.5049</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">217.1870</span><span style="font-weight: bold">]])</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Covariance matrix:
<span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([[[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">7.0937</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span><span style="font-weight: bold">]</span>,
         <span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">42.7645</span><span style="font-weight: bold">]]</span>,

        <span style="font-weight: bold">[[</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11.1506</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span><span style="font-weight: bold">]</span>,
         <span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">50.8639</span><span style="font-weight: bold">]]</span>,

        <span style="font-weight: bold">[[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">9.4978</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span><span style="font-weight: bold">]</span>,
         <span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">42.0549</span><span style="font-weight: bold">]]])</span>
</pre>
</div></div>
</div>
<p>The mean is a <span class="math notranslate nohighlight">\(3 \times 2\)</span> matrix, and the (co)variance is a <span class="math notranslate nohighlight">\(3 \times 2 \times 2\)</span> matrix and
can be mapped to the <code class="docutils literal notranslate"><span class="pre">x2_x3_mean_std_var</span></code> table.</p>
<p>For the mean matrix, the first row is the mean (<span class="math notranslate nohighlight">\(\boldsymbol{\mu}_{X_1|Y=A}\)</span>) of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> for Adelie,
the second row is the mean (<span class="math notranslate nohighlight">\(\boldsymbol{\mu}_{X_1|Y=C}\)</span>) of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> for Chinstrap, and the third row
is the mean (<span class="math notranslate nohighlight">\(\boldsymbol{\mu}_{X_1|Y=G}\)</span>) of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> for Gentoo.</p>
<p>For instance, the first row is <span class="math notranslate nohighlight">\([38.7914, 189.9536]\)</span> is indeed the mean of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> for Adelie.</p>
<p>For the covariance matrix, the first row is a <span class="math notranslate nohighlight">\(2 \times 2\)</span> matrix,
which corresponds to <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_{X_1|Y=A}\)</span>, the second row is <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_{X_1|Y=C}\)</span>, and the third row is <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_{X_1|Y=G}\)</span>.</p>
<p>For instance, the first row being <span class="math notranslate nohighlight">\([[7.0937, 0], [0, 42.7645]]\)</span> is indeed the covariance matrix of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> for Adelie where <span class="math notranslate nohighlight">\(7.0937\)</span> is the variance of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <span class="math notranslate nohighlight">\(42.7645\)</span> is the variance of <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>.</p>
<p>Now, this may seem confusing at first, as we have established that each
conditional distribution <span class="math notranslate nohighlight">\(X_d|Y\)</span> is a Gaussian distribution,
and since all <span class="math notranslate nohighlight">\(D\)</span> of them are independent, we estimate the mean and variance of each
univariate Gaussian distribution. However, the way we have done it just now
suggests that we are estimating the mean and variance of a multivariate Gaussian
distribution. What’s the catch here?</p>
<p>The catch is in <a class="reference internal" href="../../probability_theory/05_joint_distributions/0506_random_vectors/concept.html"><span class="std std-doc">Random Vectors</span></a>, finding the mean vector and covariance matrix of <span class="math notranslate nohighlight">\(D\)</span> independent
random variables <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_D\)</span> is equivalent to finding the mean and
variance of each univariate Gaussian distribution. So by construction,
the diagonals of each covariance matrix in <code class="docutils literal notranslate"><span class="pre">class_conditionals.covariance_matrix</span></code> are the
variance of each univariate Gaussian distribution, and the off-diagonals are 0.</p>
<p>This is a compact way to represent the mean and covariance matrix of a multivariate Gaussian distribution where each of its components are independent.</p>
<p>In my <a class="reference external" href="https://github.com/gao-hongnan/gaohn-probability-stats/blob/naive-bayes/src/generative/naive_bayes/naive_bayes.py">code</a>, <code class="docutils literal notranslate"><span class="pre">theta</span></code> is a <span class="math notranslate nohighlight">\(K \times D = 3 \times 2\)</span> matrix, where <span class="math notranslate nohighlight">\(K\)</span> is the number of classes and <span class="math notranslate nohighlight">\(D\)</span> is the number of predictors. But inside each
entry of <code class="docutils literal notranslate"><span class="pre">theta</span></code>, it is a <span class="math notranslate nohighlight">\(1 \times 2\)</span> row vector (a tuple of two numbers). So in the end
it is also a <span class="math notranslate nohighlight">\(3 \times 2 \times 2\)</span> matrix, but means very different things from the above pytorch example.</p>
<p>In our <code class="docutils literal notranslate"><span class="pre">theta</span></code>, the first row is a <span class="math notranslate nohighlight">\(2 \times 2\)</span> matrix encoding <span class="math notranslate nohighlight">\(\mu_{X_1|Y=A}\)</span>, <span class="math notranslate nohighlight">\(\mu_{X_2|Y=A}\)</span>, <span class="math notranslate nohighlight">\(\sigma_{X_1|Y=A}\)</span>, and <span class="math notranslate nohighlight">\(\sigma_{X_2|Y=A}\)</span>, the second row is a <span class="math notranslate nohighlight">\(2 \times 2\)</span> encoding <span class="math notranslate nohighlight">\(\mu_{X_1|Y=C}\)</span>, <span class="math notranslate nohighlight">\(\mu_{X_2|Y=C}\)</span>, <span class="math notranslate nohighlight">\(\sigma_{X_1|Y=C}\)</span>, and <span class="math notranslate nohighlight">\(\sigma_{X_2|Y=C}\)</span>, and the third row is a <span class="math notranslate nohighlight">\(2 \times 2\)</span> encoding <span class="math notranslate nohighlight">\(\mu_{X_1|Y=G}\)</span>, <span class="math notranslate nohighlight">\(\mu_{X_2|Y=G}\)</span>, <span class="math notranslate nohighlight">\(\sigma_{X_1|Y=G}\)</span>, and <span class="math notranslate nohighlight">\(\sigma_{X_2|Y=G}\)</span>.</p>
<p>Below is some functions to plot the contours.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_meshgrid</span><span class="p">(</span><span class="n">x0_range</span><span class="p">,</span> <span class="n">x1_range</span><span class="p">,</span> <span class="n">num_points</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x0_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x0_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_points</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x1_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x1_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_points</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">contour_plot</span><span class="p">(</span><span class="n">x0_range</span><span class="p">,</span> <span class="n">x1_range</span><span class="p">,</span> <span class="n">prob_fn</span><span class="p">,</span> <span class="n">batch_shape</span><span class="p">,</span> <span class="n">colours</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_points</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">X0</span><span class="p">,</span> <span class="n">X1</span> <span class="o">=</span> <span class="n">get_meshgrid</span><span class="p">(</span><span class="n">x0_range</span><span class="p">,</span> <span class="n">x1_range</span><span class="p">,</span> <span class="n">num_points</span><span class="o">=</span><span class="n">num_points</span><span class="p">)</span>
    <span class="n">X_input_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">X0</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">X1</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">X_input_space</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_input_space</span><span class="p">)</span>

    <span class="n">Z</span> <span class="o">=</span> <span class="n">prob_fn</span><span class="p">(</span><span class="n">X_input_space</span><span class="p">)</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="c1"># convert log pdf to pdf</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="c1"># Z = prob_fn(np.expand_dims(np.array([X0.ravel(), X1.ravel()]).T, 1))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">,</span> <span class="o">*</span><span class="n">X0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">levels</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">Z</span><span class="p">[</span><span class="n">batch</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">colours</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">levels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">Z</span><span class="p">[</span><span class="n">batch</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="n">colours</span><span class="p">[</span><span class="n">batch</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_data</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">colours</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="n">inx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">inx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">inx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">colours</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training set&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Adelie&quot;</span><span class="p">,</span> <span class="s2">&quot;Chinstrap&quot;</span><span class="p">,</span> <span class="s2">&quot;Gentoo&quot;</span><span class="p">]</span>
<span class="n">class_colours</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We assume the features are conditionally independent given the class label, and follows a Gaussian.</p>
<p>Note we need to use <code class="docutils literal notranslate"><span class="pre">torch.exp</span></code> to exponentiate the log-likelihood back to normal scale, as the log-likelihood is in log-space.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_conditionals</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">195</span><span class="p">])),</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">class_conditionals</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">195</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([-13.8483,  -5.0759, -11.0133]),
 tensor([9.6774e-07, 6.2458e-03, 1.6482e-05]))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plot_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">class_names</span><span class="p">,</span> <span class="n">class_colours</span><span class="p">)</span>
<span class="n">x0_min</span><span class="p">,</span> <span class="n">x0_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">contour_plot</span><span class="p">(</span>
    <span class="p">(</span><span class="n">x0_min</span><span class="p">,</span> <span class="n">x0_max</span><span class="p">),</span>
    <span class="p">(</span><span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span><span class="p">),</span>
    <span class="n">class_conditionals</span><span class="o">.</span><span class="n">log_prob</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">,</span>
    <span class="n">class_colours</span><span class="p">,</span>
    <span class="n">num_points</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training set with class-conditional density contours&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/7a2736f99f5d6bca96e17a50233e7c09dbeb5468ef227d59265964b645ea0963.png" src="../../_images/7a2736f99f5d6bca96e17a50233e7c09dbeb5468ef227d59265964b645ea0963.png" />
</div>
</div>
<p>So the above contour plot represents each class conditional distribution, for example,
the blue dots are Adelie with <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> on the x-axis and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> on the y-axis and the contour is a 2d visualization of the joint distribution of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> given Adelie (<span class="math notranslate nohighlight">\(\mathbb{P}(X_1, X_2|Y=A)\)</span>) where the
contour represents a multi-variate Gaussian distribution with mean and covariance matrix,
in particular the covariance matrix is a diagonal matrix since we assume the features are conditionally independent given the class label.</p>
<p>Of course the real data points (blue scatters) are not exactly on the contour, since
there is no reason to believe that Adelie’s <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> are exactly Gaussian distributed with such mean and covariance matrix.</p>
</section>
<section id="further-readings">
<h2><a class="toc-backref" href="#id16" role="doc-backlink">Further Readings</a><a class="headerlink" href="#further-readings" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>JOHNSON, ALICIA A. “Chapter 14. Naive Bayes Classification.” In Bayes Rules!: An Introduction to Applied Bayesian Modeling. S.l.: CHAPMAN &amp; HALL CRC, 2022.</p></li>
<li><p><a class="reference external" href="https://www.python-graph-gallery.com/">Python Graph Gallery</a></p></li>
<li><p><a class="reference external" href="https://seaborn.pydata.org/tutorial/distributions.html">Seaborn Visualizing distributions</a></p>
<ul>
<li><p><a class="reference external" href="https://seaborn.pydata.org/generated/seaborn.jointplot.html">Jointplot for bivariate distributions</a></p></li>
<li><p><a class="reference external" href="https://seaborn.pydata.org/generated/seaborn.histplot.html">Histplot for bivariate distributions</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.kaggle.com/code/parulpandey/penguin-dataset-the-new-iris">https://www.kaggle.com/code/parulpandey/penguin-dataset-the-new-iris</a></p></li>
<li><p><a class="reference external" href="https://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/08/18/Naive-bayes-and-logistic-regression.html">https://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/08/18/Naive-bayes-and-logistic-regression.html</a></p></li>
</ul>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id3" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">2</a><span class="fn-bracket">]</span></span>
<p>In Naive Bayes, both the predictor and the target are random variables, while
it is not the case for logistic regression. Regardless, once you condition on <span class="math notranslate nohighlight">\(Y\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>
is no longer random.</p>
</aside>
<aside class="footnote brackets" id="id4" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">1</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://statproofbook.github.io/D/ind-cond">https://statproofbook.github.io/D/ind-cond</a></p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./influential/naive_bayes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="03_implementation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Naives Bayes Implementation</p>
      </div>
    </a>
    <a class="right-next"
       href="05_application_mnist.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Naive Bayes Application (MNIST)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dependencies">Dependencies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">Problem Statement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-prior">The Prior</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classifying-one-penguin">Classifying one penguin</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-categorical-feature">One Categorical Feature</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-quantitative-predictor">One Quantitative Predictor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#two-continuous-predictors">Two (Continuous) Predictors</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-independence">Conditional Independence</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#three-predictors">Three Predictors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch">PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-readings">Further Readings</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gao Hongnan
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>