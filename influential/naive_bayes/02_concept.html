
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Concept &#8212; Omniverse</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=bb35926c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../../_static/tabs.js?v=3ee01567"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-MYW5YKC2WF"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-MYW5YKC2WF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-MYW5YKC2WF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"defeq": "\\overset{\\text{def}}{=}", "defa": "\\overset{\\text{(a)}}{=}", "defb": "\\overset{\\text{(b)}}{=}", "defc": "\\overset{\\text{(c)}}{=}", "defd": "\\overset{\\text{(d)}}{=}", "st": "\\mid", "mod": "\\mid", "S": "\\Omega", "s": "\\omega", "e": "\\exp", "P": "\\mathbb{P}", "R": "\\mathbb{R}", "expectation": "\\mathbb{E}", "v": "\\mathbf{v}", "a": "\\mathbf{a}", "b": "\\mathbf{b}", "c": "\\mathbf{c}", "u": "\\mathbf{u}", "w": "\\mathbf{w}", "x": "\\mathbf{x}", "y": "\\mathbf{y}", "z": "\\mathbf{z}", "0": "\\mathbf{0}", "1": "\\mathbf{1}", "A": "\\mathbf{A}", "B": "\\mathbf{B}", "C": "\\mathbf{C}", "E": "\\mathcal{F}", "eventA": "\\mathcal{A}", "lset": "\\left\\{", "rset": "\\right\\}", "lsq": "\\left[", "rsq": "\\right]", "lpar": "\\left(", "rpar": "\\right)", "lcurl": "\\left\\{", "rcurl": "\\right\\}", "pmf": "p_X", "pdf": "f_X", "pdftwo": "f_{X,Y}", "pdfjoint": "f_{\\mathbf{X}}", "pmfjointxy": "p_{X, Y}", "pdfjointxy": "f_{X, Y}", "cdf": "F_X", "pspace": "(\\Omega, \\mathcal{F}, \\mathbb{P})", "var": "\\operatorname{Var}", "std": "\\operatorname{Std}", "bern": "\\operatorname{Bernoulli}", "binomial": "\\operatorname{Binomial}", "geometric": "\\operatorname{Geometric}", "poisson": "\\operatorname{Poisson}", "uniform": "\\operatorname{Uniform}", "normal": "\\operatorname{Normal}", "gaussian": "\\operatorname{Gaussian}", "gaussiansymbol": "\\mathcal{N}", "exponential": "\\operatorname{Exponential}", "iid": "\\textbf{i.i.d.}", "and": "\\text{and}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'influential/naive_bayes/02_concept';</script>
    <link rel="canonical" href="https://www.gaohongnan.com/influential/naive_bayes/02_concept.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Naives Bayes Implementation" href="03_implementation.html" />
    <link rel="prev" title="Naive Bayes" href="01_intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Omniverse - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Omniverse - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Omniverse
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Notations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notations/machine_learning.html">Machine Learning Notations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Influential Ideas and Papers</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../generative_pretrained_transformer/01_intro.html">Generative Pre-trained Transformers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/02_notations.html">Notations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/03_concept.html">The Concept of Generative Pre-trained Transformers (GPT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/04_implementation.html">The Implementation of Generative Pre-trained Transformers (GPT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/05_adder.html">Training a Mini-GPT to Learn Two-Digit Addition</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../low_rank_adaptation/01_intro.html">Low-Rank Adaptation Of Large Language Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../low_rank_adaptation/02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../low_rank_adaptation/03_implementation.html">Implementation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../empirical_risk_minimization/01_intro.html">Empirical Risk Minimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../empirical_risk_minimization/02_concept.html">Concept: Empirical Risk Minimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../empirical_risk_minimization/03_bayes_optimal_classifier.html">Bayes Optimal Classifier</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../learning_theory/01_intro.html">Is The Learning Problem Solvable?</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../learning_theory/02_concept.html">Concept: Learning Theory</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../kmeans_clustering/01_intro.html">Lloyd’s K-Means Clustering Algorithm</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/02_concept.html">Concept: K-Means Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/03_implementation.html">Implementation: K-Means (Lloyd)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/04_image_segmentation.html">Application: Image Compression and Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/05_conceptual_questions.html">Conceptual Questions</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="01_intro.html">Naive Bayes</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_implementation.html">Naives Bayes Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_example_penguins.html">Naive Bayes Application: Penguins</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_application_mnist.html">Naive Bayes Application (MNIST)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../gaussian_mixture_models/01_intro.html">Mixture Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_mixture_models/02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_mixture_models/03_implementation.html">Gaussian Mixture Models Implementation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../linear_regression/01_intro.html">Linear Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../linear_regression/02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_regression/03_implementation.html">Implementation</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Playbook</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../playbook/training/intro.html">Training Dynamics And Tricks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_calculate_flops_in_transformer_based_models.html">How to Calculate the Number of FLOPs in Transformer Based Models?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/why_cosine_annealing_warmup_stabilize_training.html">Why Does Cosine Annealing With Warmup Stabilize Training?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_finetune_decoder_with_last_token_pooling.html">How To Fine-Tune Decoder-Only Models For Sequence Classification Using Last Token Pooling?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_finetune_decoder_with_cross_attention.html">How To Fine-Tune Decoder-Only Models For Sequence Classification With Cross-Attention?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_teacher_student_knowledge_distillation.html">How To Do Teacher-Student Knowledge Distillation?</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/why_softmax_preserves_order_translation_invariant_not_invariant_scaling.html">Softmax Preserves Order, Is Translation Invariant But Not Invariant Under Scaling.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/how_to_inspect_function_and_class_signatures.html">How to Inspect Function and Class Signatures in Python?</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Probability Theory</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/intro.html">Chapter 1. Mathematical Preliminaries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/01_combinatorics.html">Permutations and Combinations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/02_calculus.html">Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/03_contours.html">Contour Maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/02_probability/intro.html">Chapter 2. Probability</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0202_probability_space.html">Probability Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0203_probability_axioms.html">Probability Axioms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0204_conditional_probability.html">Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0205_independence.html">Independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0206_bayes_theorem.html">Baye’s Theorem and the Law of Total Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/summary.html">Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/intro.html">Chapter 3. Discrete Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0301_random_variables.html">Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0302_discrete_random_variables.html">Discrete Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0303_probability_mass_function.html">Probability Mass Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0304_cumulative_distribution_function.html">Cumulative Distribution Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0305_expectation.html">Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0306_moments_and_variance.html">Moments and Variance</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/intro.html">Discrete Uniform Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/0307_discrete_uniform_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/0307_discrete_uniform_distribution_application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/intro.html">Bernoulli Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/0308_bernoulli_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/0308_bernoulli_distribution_application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/iid.html">Independent and Identically Distributed (IID)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/intro.html">Binomial Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_implementation.html">Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_application.html">Real World Examples</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/geometric/intro.html">Geometric Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/geometric/0310_geometric_distribution_concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/intro.html">Poisson Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/0311_poisson_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/0311_poisson_distribution_implementation.html">Implementation</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/summary.html">Important</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/intro.html">Chapter 4. Continuous Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/from_discrete_to_continuous.html">From Discrete to Continuous</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0401_continuous_random_variables.html">Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0402_probability_density_function.html">Probability Density Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0403_expectation.html">Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0404_moments_and_variance.html">Moments and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0405_cumulative_distribution_function.html">Cumulative Distribution Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0406_mean_median_mode.html">Mean, Median and Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0407_continuous_uniform_distribution.html">Continuous Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0408_exponential_distribution.html">Exponential Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0409_gaussian_distribution.html">Gaussian Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0410_skewness_and_kurtosis.html">Skewness and Kurtosis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0411_convolve_and_sum_of_random_variables.html">Convolution and Sum of Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0412_functions_of_random_variables.html">Functions of Random Variables</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/intro.html">Chapter 5. Joint Distributions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/05_joint_distributions/from_single_variable_to_joint_distributions.html">From Single Variable to Joint Distributions</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0501_joint_pmf_pdf/intro.html">Joint PMF and PDF</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0501_joint_pmf_pdf/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0502_joint_expectation_and_correlation/intro.html">Joint Expectation and Correlation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0502_joint_expectation_and_correlation/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/intro.html">Conditional PMF and PDF</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/intro.html">Conditional Expectation and Variance</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0505_sum_of_random_variables/intro.html">Sum of Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0505_sum_of_random_variables/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0506_random_vectors/intro.html">Random Vectors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0506_random_vectors/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/intro.html">Multivariate Gaussian Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/application_transformation.html">Application: Plots and Transformations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/psd.html">Covariance Matrix is Positive Semi-Definite</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/eigendecomposition.html">Eigendecomposition and Covariance Matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/geometry_of_multivariate_gaussian.html">The Geometry of Multivariate Gaussians</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/intro.html">Chapter 6. Sample Statistics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/intro.html">Moment Generating and Characteristic Functions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/moment_generating_function.html">Moment Generating Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/moment_generating_function_application_sum_of_rv.html">Application: Moment Generating Function and the Sum of Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/characteristic_function.html">Characteristic Function</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/intro.html">Probability Inequalities</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/concept.html">Probability Inequalities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/application.html">Application: Learning Theory</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/intro.html">Law of Large Numbers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/convergence.html">Convergence of Sample Average</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/application.html">Application: Learning Theory</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/08_estimation_theory/intro.html">Chapter 8. Estimation Theory</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/08_estimation_theory/maximum_likelihood_estimation/intro.html">Maximum Likelihood Estimation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/08_estimation_theory/maximum_likelihood_estimation/concept.html">Concept</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Operations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/distributed/intro.html">Distributed Systems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/01_notations.html">Notations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/02_basics.html">Basics Of Distributed Data Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/03_how_to_setup_slurm_in_aws.html">How to Setup SLURM and ParallelCluster in AWS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/04_ablation.html">Ablations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/profiling/intro.html">Profiling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/01_synchronize.html">Synchronize CUDA To Time CUDA Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/02_timeit.html">Profiling Code With Timeit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/03_time_profiler.html">PyTorch’s Event And Profiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/04_small_gpt_profile.html">Profile GPT Small Time And Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/05_memory_leak.html">CUDA Memory Allocations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/00_intro.html">The Lifecycle of an AIOps System</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/01_problem_formulation.html">Stage 1. Problem Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/02_project_scoping.html">Stage 2. Project Scoping And Framing The Problem</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/03_dataops_pipeline.html">Stage 3. Data Pipeline (Data Engineering and DataOps)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/031_data_source_and_format.html">Stage 3.1. Data Source and Formats</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/032_data_model_and_storage.html">Stage 3.2. Data Model and Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/033_etl.html">Stage 3.3. Extract, Transform, Load (ETL)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/04_mlops_data_pipeline.html">Stage 4. Data Extraction (MLOps), Data Analysis (Data Science), Data Preparation (Data Science)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline.html">Stage 5. Model Development and Training (MLOps)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/051_model_selection.html">Stage 5.1. Model Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/052_metric_selection.html">Stage 5.2. Metric Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/053_experiment_tracking.html">Stage 5.3. Experiment Tracking And Versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/054_model_testing.html">Stage 5.4. Model Testing</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/06_model_evaluation.html">Stage 6. Model Evaluation (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/07_model_validation_registry_and_pushing_model_to_production.html">Stage 7. Model Validation, Registry and Pushing Model to Production (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/08_model_deployment_and_serving.html">Stage 8. Model Serving (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/09_model_monitoring.html">Stage 9. Model Monitoring (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/010_continuous_integration_deployment_learning_and_training.html">Stage 10. Continuous Integration, Deployment, Learning and Training (DevOps, DataOps, MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/011_infrastructure_and_tooling_for_mlops.html">Stage 11. Infrastructure and Tooling for MLOps</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Software Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/config_management/intro.html">Config, State, Metadata Management</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/config_management/concept.html">Configuration Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/config_management/01-pydra.html">Pydantic And Hydra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/config_management/02-state.html">State And Metadata Management</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/design_patterns/intro.html">Design Patterns</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/dependency_inversion_principle.html">Dependency Inversion Principle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/named_constructor.html">Named Constructor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/strategy.html">Strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/registry.html">Registry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/god_object_pattern.html">Context Object Pattern (God Object)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/factory_method.html">Factory Method</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/python/intro.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/iterator_protocol.html">The Iterator Protocol</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/decorator.html">Decorator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/generators_over_lists.html">Generators Over Lists For Memory Efficiency</a></li>




<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/pydantic.html">Pydantic Is All You Need - Jason Liu</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/intro.html">Concurrency, Parallelism and Asynchronous Programming</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/overview.html">Notations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/generator_yield.html">A Rudimentary Introduction to Generator and Yield in Python</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Computer Science</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../computer_science/type_theory/intro.html">Type Theory, A Very Rudimentary Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/01-subtypes.html">Subtypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/02-type-safety.html">Type Safety</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/03-subsumption.html">Subsumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/04-generics.html">Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/05-typevar-bound-constraints.html">Bound and Constraint in Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/06-invariance-covariance-contravariance.html">Invariance, Covariance and Contravariance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/07-pep-3124-overloading.html">Function Overloading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/08-pep-661-sentinel-values.html">Sentinel Types</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Structures and Algorithms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/complexity_analysis/intro.html">Complexity Analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/complexity_analysis/master_theorem.html">Master Theorem </a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/stack/intro.html">Stack</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/stack/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/searching_algorithms/linear_search/intro.html">Linear Search</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/linear_search/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/intro.html">Binary Search</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/problems/875-koko-eating-bananas.html">Koko Eating Bananas</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Algebra</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linear_algebra/01_preliminaries/intro.html">Preliminaries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/01_preliminaries/01-fields.html">Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/01_preliminaries/02-systems-of-linear-equations.html">Systems of Linear Equations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linear_algebra/02_vectors/intro.html">Vectors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/01-vector-definition.html">Vector and Its Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/02-vector-operation.html">Vector and Its Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/03-vector-norm.html">Vector Norm and Distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/04-vector-products.html">A First Look at Vector Products</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References, Resources and Roadmap</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../citations.html">IEEE (Style) Citations</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gao-hongnan/omniverse" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gao-hongnan/omniverse/issues/new?title=Issue%20on%20page%20%2Finfluential/naive_bayes/02_concept.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/influential/naive_bayes/02_concept.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Concept</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#notations">Notations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminative-vs-generative">Discriminative vs Generative</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-setup">Naive Bayes Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-prediction">Inference/Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-naive-bayes-form">The Naive Bayes Form</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-form">Simple Form</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extended-form">Extended form</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-naive-bayes-assumptions">The Naive Bayes Assumptions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#independent-and-identically-distributed-i-i-d">Independent and Identically Distributed (i.i.d.)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-independence">Conditional Independence</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-vector">Parameter Vector</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inductive-bias-distribution-assumptions">Inductive Bias (Distribution Assumptions)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#targets-categorical-distribution">Targets (Categorical Distribution)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-features-categorical-distribution">Discrete Features (Categorical Distribution)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-features-gaussian-distribution">Continuous Features (Gaussian Distribution)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mixed-features-discrete-and-continuous">Mixed Features (Discrete and Continuous)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-fitting">Model Fitting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-algorithm">Fitting Algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimation">Maximum Likelihood Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-priors">Estimating Priors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimation-for-priors-categorical-distribution">Maximum Likelihood Estimation for Priors (Categorical Distribution)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-likelihood-gaussian-version">Estimating Likelihood (Gaussian Version)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimate-for-likelihood-continuous-feature-parameters">Maximum Likelihood Estimate for Likelihood (Continuous Feature Parameters)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-boundary">Decision Boundary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#connection-with-logistic-regression">Connection with Logistic Regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-and-space-complexity">Time and Space Complexity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="concept">
<h1>Concept<a class="headerlink" href="#concept" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="https://twitter.com/gaohongnan"><img alt="Twitter Handle" src="https://img.shields.io/badge/Twitter-&#64;gaohongnan-blue?style=social&amp;logo=twitter" /></a>
<a class="reference external" href="https://linkedin.com/in/gao-hongnan"><img alt="LinkedIn Profile" src="https://img.shields.io/badge/&#64;gaohongnan-blue?style=social&amp;logo=linkedin" /></a>
<a class="reference external" href="https://github.com/gao-hongnan"><img alt="GitHub Profile" src="https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&amp;logo=github" /></a>
<img alt="Tag" src="https://img.shields.io/badge/Tag-Organized_Chaos-orange" /></p>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#notations" id="id17">Notations</a></p>
<ul>
<li><p><a class="reference internal" href="#discriminative-vs-generative" id="id18">Discriminative vs Generative</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#naive-bayes-setup" id="id19">Naive Bayes Setup</a></p></li>
<li><p><a class="reference internal" href="#inference-prediction" id="id20">Inference/Prediction</a></p></li>
<li><p><a class="reference internal" href="#the-naive-bayes-form" id="id21">The Naive Bayes Form</a></p>
<ul>
<li><p><a class="reference internal" href="#simple-form" id="id22">Simple Form</a></p></li>
<li><p><a class="reference internal" href="#extended-form" id="id23">Extended form</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#the-naive-bayes-assumptions" id="id24">The Naive Bayes Assumptions</a></p>
<ul>
<li><p><a class="reference internal" href="#independent-and-identically-distributed-i-i-d" id="id25">Independent and Identically Distributed (i.i.d.)</a></p></li>
<li><p><a class="reference internal" href="#conditional-independence" id="id26">Conditional Independence</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#parameter-vector" id="id27">Parameter Vector</a></p></li>
<li><p><a class="reference internal" href="#inductive-bias-distribution-assumptions" id="id28">Inductive Bias (Distribution Assumptions)</a></p>
<ul>
<li><p><a class="reference internal" href="#targets-categorical-distribution" id="id29">Targets (Categorical Distribution)</a></p></li>
<li><p><a class="reference internal" href="#discrete-features-categorical-distribution" id="id30">Discrete Features (Categorical Distribution)</a></p></li>
<li><p><a class="reference internal" href="#continuous-features-gaussian-distribution" id="id31">Continuous Features (Gaussian Distribution)</a></p></li>
<li><p><a class="reference internal" href="#mixed-features-discrete-and-continuous" id="id32">Mixed Features (Discrete and Continuous)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#model-fitting" id="id33">Model Fitting</a></p>
<ul>
<li><p><a class="reference internal" href="#fitting-algorithm" id="id34">Fitting Algorithm</a></p></li>
<li><p><a class="reference internal" href="#maximum-likelihood-estimation" id="id35">Maximum Likelihood Estimation</a></p></li>
<li><p><a class="reference internal" href="#estimating-priors" id="id36">Estimating Priors</a></p></li>
<li><p><a class="reference internal" href="#maximum-likelihood-estimation-for-priors-categorical-distribution" id="id37">Maximum Likelihood Estimation for Priors (Categorical Distribution)</a></p></li>
<li><p><a class="reference internal" href="#estimating-likelihood-gaussian-version" id="id38">Estimating Likelihood (Gaussian Version)</a></p>
<ul>
<li><p><a class="reference internal" href="#maximum-likelihood-estimate-for-likelihood-continuous-feature-parameters" id="id39">Maximum Likelihood Estimate for Likelihood (Continuous Feature Parameters)</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#decision-boundary" id="id40">Decision Boundary</a></p>
<ul>
<li><p><a class="reference internal" href="#connection-with-logistic-regression" id="id41">Connection with Logistic Regression</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#time-and-space-complexity" id="id42">Time and Space Complexity</a></p></li>
<li><p><a class="reference internal" href="#references" id="id43">References</a></p></li>
</ul>
</nav>
<section id="notations">
<h2><a class="toc-backref" href="#id17" role="doc-backlink">Notations</a><a class="headerlink" href="#notations" title="Link to this heading">#</a></h2>
<div class="proof definition admonition" id="underlying-distributions">
<p class="admonition-title"><span class="caption-number">Definition 36 </span> (Underlying Distributions)</p>
<section class="definition-content" id="proof-content">
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathcal{X}\)</span>: Input space consists of all possible inputs <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>: Label space = <span class="math notranslate nohighlight">\(\{1, 2, \ldots, K\}\)</span> where <span class="math notranslate nohighlight">\(K\)</span> is the number of classes.</p></li>
<li><p>The mapping between <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> is given by <span class="math notranslate nohighlight">\(c: \mathcal{X} \rightarrow \mathcal{Y}\)</span> where <span class="math notranslate nohighlight">\(c\)</span> is called <em>concept</em> according to the PAC learning theory.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{D}\)</span>: The fixed but unknown distribution of the data. Usually, this refers
to the joint distribution of the input and the label,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \mathcal{D} &amp;= \mathbb{P}(\mathcal{X}, \mathcal{Y} ; \boldsymbol{\theta}) \\
  &amp;= \mathbb{P}_{\{\mathcal{X}, \mathcal{Y} ; \boldsymbol{\theta}\}}(\mathbf{x}, y)
  \end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}\)</span> and <span class="math notranslate nohighlight">\(y \in \mathcal{Y}\)</span>, and <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> is the
parameter vector of the distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</li>
</ul>
</section>
</div><div class="proof definition admonition" id="dataset-definition">
<p class="admonition-title"><span class="caption-number">Definition 37 </span> (Dataset)</p>
<section class="definition-content" id="proof-content">
<p>Now, consider a dataset <span class="math notranslate nohighlight">\(\mathcal{D}_{\{\mathbf{x}, y\}}\)</span> consisting of <span class="math notranslate nohighlight">\(N\)</span> samples (observations) and <span class="math notranslate nohighlight">\(D\)</span> predictors (features) drawn <strong>jointly</strong> and <strong>indepedently and identically distributed</strong> (i.i.d.) from <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. Note we will refer to the dataset <span class="math notranslate nohighlight">\(\mathcal{D}_{\{\mathbf{x}, y\}}\)</span> with the same notation as the underlying distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> from now on.</p>
<ul>
<li><p>The training dataset <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> can also be represented compactly as a set:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{align*}
    \mathcal{D} \overset{\mathbf{def}}{=} \mathcal{D}_{\{\mathbf{x}, y\}} &amp;= \left\{\mathbf{x}^{(n)}, y^{(n)}\right\}_{n=1}^N \\
    &amp;= \left\{\left(\mathbf{x}^{(1)}, y^{(1)}\right), \left(\mathbf{x}^{(2)}, y^{(2)}\right), \cdots, \left(\mathbf{x}^{(N)}, y^{(N)}\right)\right\} \\
    &amp;= \left\{\mathbf{X}, \mathbf{y}\right\}
    \end{align*}
    \end{split}\]</div>
<p>where we often subscript <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and <span class="math notranslate nohighlight">\(y\)</span> with <span class="math notranslate nohighlight">\(n\)</span> to denote the <span class="math notranslate nohighlight">\(n\)</span>-th sample from the dataset, i.e.
<span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> and <span class="math notranslate nohighlight">\(y^{(n)}\)</span>. Most of the times, <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> is bolded since
it represents a vector of <span class="math notranslate nohighlight">\(D\)</span> number of features, while <span class="math notranslate nohighlight">\(y^{(n)}\)</span> is not bolded since it is a scalar, though
it is not uncommon for <span class="math notranslate nohighlight">\(y^{(n)}\)</span> to be bolded as well if you represent it with K-dim one-hot vector.</p>
</li>
<li><p>For the n-th sample <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span>, we often denote the <span class="math notranslate nohighlight">\(d\)</span>-th feature as <span class="math notranslate nohighlight">\(x_d^{(n)}\)</span> and the representation of <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> as a vector as:</p>
<div class="math notranslate nohighlight">
\[
  \mathbf{x}^{(n)} \in \mathbb{R}^{D} = \begin{bmatrix} x_1^{(n)} &amp; x_2^{(n)} &amp; \cdots &amp; x_D^{(n)} \end{bmatrix}_{D \times 1}
  \]</div>
<p>is a sample of size <span class="math notranslate nohighlight">\(D\)</span>, drawn (jointly with <span class="math notranslate nohighlight">\(y\)</span>) <span class="math notranslate nohighlight">\(\textbf{i.i.d.}\)</span> from <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</li>
<li><p>We often add an extra feature <span class="math notranslate nohighlight">\(x_0^{(n)} = 1\)</span> to <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> to represent the bias term.
i.e.</p>
<div class="math notranslate nohighlight">
\[
  \mathbf{x}^{(n)} \in \mathbb{R}^{D+1} = \begin{bmatrix} x_0^{(n)} &amp; x_1^{(n)} &amp; x_2^{(n)} &amp; \cdots &amp; x_D^{(n)} \end{bmatrix}_{(D+1) \times 1}
  \]</div>
</li>
<li><p>For the n-th sample’s label <span class="math notranslate nohighlight">\(y^{(n)} \overset{\mathbf{def}}{=} c(\mathbf{x}^{(n)})\)</span>, if we were to represent it as K-dim one-hot vector, we would have:</p>
<div class="math notranslate nohighlight">
\[
  y^{(n)} \in \mathbb{R}^{K} = \begin{bmatrix} 0 &amp; 0 &amp; \cdots &amp; 1 &amp; \cdots &amp; 0 \end{bmatrix}_{K \times 1}
  \]</div>
<p>where the <span class="math notranslate nohighlight">\(1\)</span> is at the <span class="math notranslate nohighlight">\(k\)</span>-th position, and <span class="math notranslate nohighlight">\(k\)</span> is the class label of the n-th sample.</p>
</li>
<li><p>Everything defined above is for <strong>one single sample/data point</strong>, to represent it as a matrix, we can define
a design matrix <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> and a label vector <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> as follows,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{aligned}
  \mathbf{X} \in \mathbb{R}^{N \times D} &amp;= \begin{bmatrix} \mathbf{x}^{(1)} \\ \mathbf{x}^{(2)} \\ \vdots \\ \mathbf{x}^{(N)} \end{bmatrix} = \begin{bmatrix} x_1^{(1)} &amp; x_2^{(1)} &amp; \cdots &amp; x_D^{(1)} \\ x_1^{(2)} &amp; x_2^{(2)} &amp; \cdots &amp; x_D^{(2)} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ x_1^{(N)} &amp; x_2^{(N)} &amp; \cdots &amp; x_D^{(N)} \end{bmatrix}_{N \times D} \\
  \end{aligned}
  \end{split}\]</div>
<p>as the matrix of all samples. Note that each row is a sample and each column is a feature. We can append a column of 1’s to the first column of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> to represent the bias term.</p>
<p><strong>In this section, we also talk about random vectors <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> so we will replace the design matrix <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> with <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> to avoid confusion.</strong></p>
<p>Subsequently, for the label vector <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>, we can define it as follows,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{aligned}
  \mathbf{y} \in \mathbb{R}^{N} = \begin{bmatrix} y^{(1)} \\ y^{(2)} \\ \vdots \\ y^{(N)} \end{bmatrix}
  \end{aligned}
  \end{split}\]</div>
</li>
</ul>
</section>
</div><div class="proof example admonition" id="joint-distribution-example">
<p class="admonition-title"><span class="caption-number">Example 12 </span> (Joint Distribution Example)</p>
<section class="example-content" id="proof-content">
<p>For example, if the number of features, <span class="math notranslate nohighlight">\(D = 2\)</span>, then let’s say</p>
<div class="math notranslate nohighlight">
\[
\mathbf{X}^{(n)} = \begin{bmatrix} X^{(n)}_1 &amp; X^{(n)}_2 \end{bmatrix} \in \mathbb{R}^2
\]</div>
<p>consists of two Gaussian random variables,
with <span class="math notranslate nohighlight">\(\mu_1\)</span> and <span class="math notranslate nohighlight">\(\mu_2\)</span> being the mean of the two distributions,
and <span class="math notranslate nohighlight">\(\sigma_1\)</span> and <span class="math notranslate nohighlight">\(\sigma_2\)</span> being the variance of the two distributions;
furthermore, <span class="math notranslate nohighlight">\(Y^{(n)}\)</span> is a Bernoulli random variable with parameter <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span>, then we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\boldsymbol{\theta} &amp;= \begin{bmatrix} \mu_1 &amp; \sigma_1 &amp; \mu_2 &amp; \sigma_2 &amp; \boldsymbol{\pi}\end{bmatrix} \\
&amp;= \begin{bmatrix} \boldsymbol{\mu} &amp; \boldsymbol{\sigma} &amp; \boldsymbol{\pi} \end{bmatrix}
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\mu} = \begin{bmatrix} \mu_1 &amp; \mu_2 \end{bmatrix}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\sigma} = \begin{bmatrix} \sigma_1 &amp; \sigma_2 \end{bmatrix}\)</span>.</p>
</section>
</div><div class="proof remark admonition" id="some-remarks">
<p class="admonition-title"><span class="caption-number">Remark 26 </span> (Some remarks)</p>
<section class="remark-content" id="proof-content">
<ul class="simple">
<li><p>From now on, we will refer the realization of <span class="math notranslate nohighlight">\(Y\)</span> as <span class="math notranslate nohighlight">\(k\)</span> instead.</p></li>
<li><p>For some sections, when I mention <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>, it means the random vector which resides in the
<span class="math notranslate nohighlight">\(D\)</span>-dimensional space, not the design matrix. This also means that this random vector refers
to a single sample, not the entire dataset.</p></li>
</ul>
</section>
</div><div class="proof definition admonition" id="joint-and-conditional-probability">
<p class="admonition-title"><span class="caption-number">Definition 38 </span> (Joint and Conditional Probability)</p>
<section class="definition-content" id="proof-content">
<p>We are often interested in finding the probability of a label given a sample,</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\mathbb{P}(Y = k \mid \mathbf{X} = \mathbf{x}) &amp;= \mathbb{P}(Y = k \mid \mathbf{X} = \left(x_1, x_2, \ldots, x_D\right))
\end{aligned}
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
\mathbf{X} \in \mathbb{R}^{D} = \begin{bmatrix} X_1 &amp; X_2 &amp; \cdots &amp; X_D \end{bmatrix}
\]</div>
<p>is a random vector and its realizations,</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x} = \begin{bmatrix} x_1 &amp; x_2 &amp; \cdots &amp; x_D \end{bmatrix}
\]</div>
<p>and therefore, <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> can be characterized by an <span class="math notranslate nohighlight">\(D\)</span>-dimensional PDF</p>
<div class="math notranslate nohighlight">
\[
f_{\mathbf{X}}(\mathbf{x}) = f_{X_1, X_2, \ldots, X_D}(x_1, x_2, \ldots, x_D ; \boldsymbol{\theta})
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
Y \in \mathbb{Z} \quad \text{and} \quad k \in \mathbb{Z}
\]</div>
<p>is a discrete random variable (in our case classification) and its realization respectively, and therefore, <span class="math notranslate nohighlight">\(Y\)</span> can be characterized by a discrete PDF (PMF)</p>
<div class="math notranslate nohighlight">
\[
f_{Y}(k ; \boldsymbol{\pi}) \sim \text{Categorical}(\boldsymbol{\pi})
\]</div>
<p><strong>Note that we are talking about one single sample tuple <span class="math notranslate nohighlight">\(\left(\mathbf{x}, y\right)\)</span> here. I did not
index the sample tuple with <span class="math notranslate nohighlight">\(n\)</span> because this sample can be any sample in the unknown distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{X}, \mathcal{Y}}(\mathbf{x}, y)\)</span>
and not only from our given dataset <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</strong></p>
</section>
</div><div class="proof definition admonition" id="likelihood">
<p class="admonition-title"><span class="caption-number">Definition 39 </span> (Likelihood)</p>
<section class="definition-content" id="proof-content">
<p>We denote the likelihood function as <span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = k)\)</span>,
which is the probability of observing <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> given that the sample belongs to class <span class="math notranslate nohighlight">\(Y = k\)</span>.</p>
</section>
</div><div class="proof definition admonition" id="prior">
<p class="admonition-title"><span class="caption-number">Definition 40 </span> (Prior)</p>
<section class="definition-content" id="proof-content">
<p>We denote the prior probability of class <span class="math notranslate nohighlight">\(k\)</span> as <span class="math notranslate nohighlight">\(\mathbb{P}(Y = k)\)</span>, which usually
follows a discrete distribution such as the Categorical distribution.</p>
</section>
</div><div class="proof definition admonition" id="posterior">
<p class="admonition-title"><span class="caption-number">Definition 41 </span> (Posterior)</p>
<section class="definition-content" id="proof-content">
<p>We denote the posterior probability of class <span class="math notranslate nohighlight">\(k\)</span> given <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> as <span class="math notranslate nohighlight">\(\mathbb{P}(Y = k \mid \mathbf{X} = \mathbf{x})\)</span>.</p>
</section>
</div><div class="proof definition admonition" id="marginal-distribution-and-normalization-constant">
<p class="admonition-title"><span class="caption-number">Definition 42 </span> (Marginal Distribution and Normalization Constant)</p>
<section class="definition-content" id="proof-content">
<p>We denote the normalizing constant as <span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{X} = \mathbf{x}) = \sum_{k=1}^K \mathbb{P}(Y = k) \mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = k)\)</span>.</p>
</section>
</div><section id="discriminative-vs-generative">
<h3><a class="toc-backref" href="#id18" role="doc-backlink">Discriminative vs Generative</a><a class="headerlink" href="#discriminative-vs-generative" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Discriminative classifiers model the conditional distribution <span class="math notranslate nohighlight">\(\mathbb{P}(Y = k \mid \mathbf{X} =  \mathbf{x})\)</span>.
This means we are modelling the conditional distribution of the target <span class="math notranslate nohighlight">\(Y\)</span> given the input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.
This also means that we are using <strong>conditional maximum likelihood</strong> to estimate the parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>.</p></li>
<li><p>Generative classifiers model the conditional distribution <span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = k)\)</span>.
This means we are modelling the conditional distribution of the input <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> given the target <span class="math notranslate nohighlight">\(Y\)</span>.
Then we can use Bayes’ rule to compute the conditional distribution of the target <span class="math notranslate nohighlight">\(Y\)</span> given the input <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>.
This also means that we are using <strong>joint maximum likelihood</strong> to estimate the parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>.</p></li>
<li><p>Both the target <span class="math notranslate nohighlight">\(Y\)</span> and the input <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> are random variables in the generative model.
In the discriminative model, only the target <span class="math notranslate nohighlight">\(Y\)</span> is a random variable as the input <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is fixed (we do not need to estimate anything about the input <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>).</p></li>
<li><p>For example, Logistic Regression models the target <span class="math notranslate nohighlight">\(Y\)</span> as a function of predictor’s <span class="math notranslate nohighlight">\(\mathbf{X} = \begin{bmatrix}X_1 \\ X_2 \\ \vdots \\X_D \end{bmatrix}\)</span>.</p></li>
<li><p>Naive bayes models both the target <span class="math notranslate nohighlight">\(Y\)</span> and the predictors <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> as a function of each other.
This means we are modelling the joint distribution of the target <span class="math notranslate nohighlight">\(Y\)</span> and the predictors <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>.</p></li>
</ul>
</section>
</section>
<section id="naive-bayes-setup">
<h2><a class="toc-backref" href="#id19" role="doc-backlink">Naive Bayes Setup</a><a class="headerlink" href="#naive-bayes-setup" title="Link to this heading">#</a></h2>
<p>Let</p>
<div class="math notranslate nohighlight">
\[
\mathcal{D} = \left \{ \left(\mathrm{X}^{(n)}, Y^{(n)} \right) \right \}_{n=1}^N = \left \{ \left(\mathrm{x}^{(n)}, y^{(n)} \right) \right \}_{n=1}^N
\]</div>
<p>be the dataset with <span class="math notranslate nohighlight">\(N\)</span> samples and <span class="math notranslate nohighlight">\(D\)</span> predictors.</p>
<p>All samples are assumed to be <strong>independent and identically distributed (i.i.d.)</strong> from the unknown but fixed joint distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(\mathcal{X}, \mathcal{Y} ; \boldsymbol{\theta})\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\left \{ \left(\mathrm{X}^{(n)}, Y^{(n)} \right) \right \} \overset{\small{\text{i.i.d.}}}{\sim} \mathbb{P}(\mathcal{X}, \mathcal{Y} ; \boldsymbol{\theta}) \quad \text{for } n = 1, 2, \cdots, N
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> is the parameter vector of the joint distribution. See <a class="reference internal" href="#joint-distribution-example">Example 12</a> for an example of such.</p>
</section>
<section id="inference-prediction">
<span id="naive-bayes-inference-prediction"></span><h2><a class="toc-backref" href="#id20" role="doc-backlink">Inference/Prediction</a><a class="headerlink" href="#inference-prediction" title="Link to this heading">#</a></h2>
<p>Before we look at the fitting/estimating process, let’s look at the inference/prediction process.</p>
<p>Suppose the problem at hand has <span class="math notranslate nohighlight">\(K\)</span> classes, <span class="math notranslate nohighlight">\(k = 1, 2, \cdots, K\)</span>, where <span class="math notranslate nohighlight">\(k\)</span> is the index of the class.</p>
<p>Then, to find the class of a new test sample <span class="math notranslate nohighlight">\(\mathbf{x}^{(q)} \in \mathbb{R}^{D}\)</span> with <span class="math notranslate nohighlight">\(D\)</span> features,
we can compute the conditional probability of each class <span class="math notranslate nohighlight">\(Y = k\)</span> given the sample <span class="math notranslate nohighlight">\(\mathbf{x}^{(q)}\)</span>:</p>
<div class="proof algorithm admonition" id="naive-bayes-inference-algorithm">
<p class="admonition-title"><span class="caption-number">Algorithm 4 </span> (Naive Bayes Inference Algorithm)</p>
<section class="algorithm-content" id="proof-content">
<ul>
<li><p>Compute the conditional probability of each class <span class="math notranslate nohighlight">\(Y = k\)</span> given the sample <span class="math notranslate nohighlight">\(\mathbf{x}^{(q)}\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eq-conditional-naive-bayes">
<span class="eqno">(41)<a class="headerlink" href="#equation-eq-conditional-naive-bayes" title="Link to this equation">#</a></span>\[
  \mathbb{P}(Y = k \mid \mathbf{X} = \mathbf{x}^{(q)}) = \dfrac{\mathbb{P}(Y = k) \mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)} \mid Y = k)}{\mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)})} \quad \text{for } k = 1, 2, \cdots, K
  \]</div>
</li>
<li><p>Choose the class <span class="math notranslate nohighlight">\(k\)</span> that maximizes the conditional probability:</p>
<div class="math notranslate nohighlight" id="equation-eq-argmax-naive-bayes-1">
<span class="eqno">(42)<a class="headerlink" href="#equation-eq-argmax-naive-bayes-1" title="Link to this equation">#</a></span>\[
  \hat{y}^{(q)} = \arg\max_{k=1}^K \mathbb{P}(Y = k \mid \mathbf{X} = \mathbf{x}^{(q)})
  \]</div>
</li>
<li><p>The observant reader would have noticed that the normalizing constant
<span class="math notranslate nohighlight">\(\mathbb{P}\left(X = \mathbf{x}^{(q)}\right)\)</span> is the same for all <span class="math notranslate nohighlight">\(k\)</span>.
Therefore, we can ignore it and simply choose the class <span class="math notranslate nohighlight">\(k\)</span> that maximizes
the numerator of the conditional probability in <a class="reference internal" href="#equation-eq-conditional-naive-bayes">(41)</a>:</p>
<div class="math notranslate nohighlight" id="equation-eq-argmax-naive-bayes-2">
<span class="eqno">(43)<a class="headerlink" href="#equation-eq-argmax-naive-bayes-2" title="Link to this equation">#</a></span>\[
  \hat{y}^{(q)} = \arg\max_{k=1}^K \mathbb{P}(Y = k) \mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)} \mid Y = k)
  \]</div>
<p>since where the normalizing constant is ignored, the conditional probability</p>
<div class="math notranslate nohighlight" id="equation-eq-proportional-naive-bayes">
<span class="eqno">(44)<a class="headerlink" href="#equation-eq-proportional-naive-bayes" title="Link to this equation">#</a></span>\[
  \mathbb{P}(Y = k \mid \mathbf{X} = \mathbf{x}^{(q)}) \propto \mathbb{P}(Y = k) \mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)} \mid Y = k)
  \]</div>
<p>by a constant factor <span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)})\)</span>.</p>
<p>Note however, to recover the normalizing constant is easy, since the numerator <span class="math notranslate nohighlight">\(\mathbb{P}(Y = k) \mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)} \mid Y = k) \)</span>
must sum up to 1 over all <span class="math notranslate nohighlight">\(k\)</span>, and therefore, the normalizing constant is simply <span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)}) = \sum_{k=1}^K \mathbb{P}(Y = k) \mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)} \mid Y = k)\)</span>.</p>
</li>
<li><p>Expressing it in vector form, we have</p>
<div class="math notranslate nohighlight" id="equation-eq-argmax-naive-bayes-3">
<span class="eqno">(45)<a class="headerlink" href="#equation-eq-argmax-naive-bayes-3" title="Link to this equation">#</a></span>\[\begin{split}
  \begin{aligned}
  \hat{\mathbf{y}} &amp;= \arg\max_{k=1}^K \begin{bmatrix} \mathbb{P}(Y=1) \mathbb{P}(\mathbf{X} = \mathbf{x}\mid Y = 1) \\ \mathbb{P}(Y=2) \mathbb{P}(\mathbf{X} = \mathbf{x}\mid Y = 2) \\ \vdots \\ \mathbb{P}(Y=K) \mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = K) \end{bmatrix}_{K \times 1} \\
  &amp;= \arg\max_{k=1}^K \begin{bmatrix} \mathbb{P}(Y=1) \\ \mathbb{P}(Y=2) \\ \cdots \\ \mathbb{P}(Y=K) \end{bmatrix}\circ \begin{bmatrix} \mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = 1) \\ \mathbb{P}(\mathbf{X} = \mathbf{x}\mid Y = 2) \\ \vdots \\ \mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = K) \end{bmatrix} \\
  &amp;= \arg\max_{k=1}^K \mathbf{M_1} \circ \mathbf{M_2} \\
  &amp;= \arg\max_{k=1}^K \mathbf{M_1} \circ \mathbf{M_3} \\
  \end{aligned}
  \end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-m1">
<span class="eqno">(46)<a class="headerlink" href="#equation-eq-naive-bayes-m1" title="Link to this equation">#</a></span>\[\begin{split}
  \mathbf{M_1} = \begin{bmatrix}
  \mathbb{P}(Y = 1) \\
  \mathbb{P}(Y = 2) \\
  \vdots \\
  \mathbb{P}(Y = K)
  \end{bmatrix}_{K \times 1}
  \end{split}\]</div>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-m2">
<span class="eqno">(47)<a class="headerlink" href="#equation-eq-naive-bayes-m2" title="Link to this equation">#</a></span>\[\begin{split}
  \mathbf{M_2} = \begin{bmatrix}
  \mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = 1) \\
  \mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = 2) \\
  \vdots \\
  \mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = K)
  \end{bmatrix}_{K \times 1}
  \end{split}\]</div>
<p>and</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-m3">
<span class="eqno">(48)<a class="headerlink" href="#equation-eq-naive-bayes-m3" title="Link to this equation">#</a></span>\[\begin{split}
  \mathbf{M_3} &amp;= \begin{bmatrix}
  \mathbb{P}(X_1 = x_1 \mid Y = 1 ; \theta_{11}) &amp; \mathbb{P}(X_2 = x_2 \mid Y = 1 ; \theta_{12}) &amp; \cdots &amp; \mathbb{P}(X_D = x_D \mid Y = 1 ; \theta_{1D}) \\
  \mathbb{P}(X_1 = x_1 \mid Y = 2 ; \theta_{21}) &amp; \mathbb{P}(X_2 = x_2 \mid Y = 2 ; \theta_{22}) &amp; \cdots &amp; \mathbb{P}(X_D = x_D \mid Y = 2 ; \theta_{2D}) \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  \mathbb{P}(X_1 = x_1 \mid Y = K ; \theta_{K1}) &amp; \mathbb{P}(X_2 = x_2 \mid Y = K ; \theta_{K2}) &amp; \cdots &amp; \mathbb{P}(X_D = x_D \mid Y = K ; \theta_{KD})
  \end{bmatrix}_{K \times D} \\
  \end{split}\]</div>
<p>Note superscript <span class="math notranslate nohighlight">\(q\)</span> is removed for simplicity, and <span class="math notranslate nohighlight">\(\circ\)</span> is the element-wise (Hadamard) product.
We will also explain why we replace <span class="math notranslate nohighlight">\(\mathbf{M_2}\)</span> with <span class="math notranslate nohighlight">\(\mathbf{M_3}\)</span> in <a class="reference internal" href="#naive-bayes-conditional-independence"><span class="std std-ref">Conditional Independence</span></a>.</p>
</li>
</ul>
</section>
</div><p>Now if we just proceed to estimate the conditional probability <span class="math notranslate nohighlight">\(\mathbb{P}(Y = k \mid \mathbf{X} = \mathbf{x}^{(q)})\)</span>, we will need to estimate the joint probability <span class="math notranslate nohighlight">\(\mathbb{P}(X = \mathbf{x}^{(q)}, Y = k)\)</span>, since by definition, we have</p>
<div class="math notranslate nohighlight" id="equation-eq-joint-naive-bayes-1">
<span class="eqno">(49)<a class="headerlink" href="#equation-eq-joint-naive-bayes-1" title="Link to this equation">#</a></span>\[
\mathbb{P}(X = \mathbf{x}^{(q)}, Y = k) = \mathbb{P}(Y = k) \mathbb{P}(X = \mathbf{x}^{(q)} \mid Y = k)
\]</div>
<p>which is intractable<a class="footnote-reference brackets" href="#intractable" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>.</p>
<p>However, if we can <em><strong>estimate</strong></em> the conditional probability (likelihood) <span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)} \mid Y = k)\)</span>
and the prior probability <span class="math notranslate nohighlight">\(\mathbb{P}(Y = k)\)</span>, then we can use Bayes’ rule to
compute the posterior conditional probability <span class="math notranslate nohighlight">\(\mathbb{P}(Y = k \mid \mathbf{X} = \mathbf{x}^{(q)})\)</span>.</p>
</section>
<section id="the-naive-bayes-form">
<h2><a class="toc-backref" href="#id21" role="doc-backlink">The Naive Bayes Form</a><a class="headerlink" href="#the-naive-bayes-form" title="Link to this heading">#</a></h2>
<p>Quoted from <a class="reference external" href="https://en.wikipedia.org/wiki/Bayes%27_theorem#Simple_form_2">Wikipedia</a>, it is worth noting that
there’s a few forms of Naive Bayes:</p>
<section id="simple-form">
<h3><a class="toc-backref" href="#id22" role="doc-backlink">Simple Form</a><a class="headerlink" href="#simple-form" title="Link to this heading">#</a></h3>
<p>If <span class="math notranslate nohighlight">\(X\)</span> is continuous and <span class="math notranslate nohighlight">\(Y\)</span> is discrete,</p>
<div class="math notranslate nohighlight">
\[
f_{X \mid Y=y}(x)=\frac{P(Y=y \mid X=x) f_X(x)}{P(Y=y)}
\]</div>
<p>where each <span class="math notranslate nohighlight">\(f\)</span> is a density function.</p>
<p>If <span class="math notranslate nohighlight">\(X\)</span> is discrete and <span class="math notranslate nohighlight">\(Y\)</span> is continuous,</p>
<div class="math notranslate nohighlight">
\[
P(X=x \mid Y=y)=\frac{f_{Y \mid X=x}(y) P(X=x)}{f_Y(y)} .
\]</div>
<p>If both <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are continuous,</p>
<div class="math notranslate nohighlight">
\[
f_{X \mid Y=y}(x)=\frac{f_{Y \mid X=x}(y) f_X(x)}{f_Y(y)} .
\]</div>
</section>
<section id="extended-form">
<h3><a class="toc-backref" href="#id23" role="doc-backlink">Extended form</a><a class="headerlink" href="#extended-form" title="Link to this heading">#</a></h3>
<p>A continuous event space is often conceptualized in terms of the numerator terms. It is then useful to eliminate the denominator using the law of total probability. For <span class="math notranslate nohighlight">\(f_Y(y)\)</span>, this becomes an integral:</p>
<div class="math notranslate nohighlight">
\[
f_Y(y)=\int_{-\infty}^{\infty} f_{Y \mid X=\xi}(y) f_X(\xi) d \xi
\]</div>
</section>
</section>
<section id="the-naive-bayes-assumptions">
<h2><a class="toc-backref" href="#id24" role="doc-backlink">The Naive Bayes Assumptions</a><a class="headerlink" href="#the-naive-bayes-assumptions" title="Link to this heading">#</a></h2>
<p>In this section, we talk about some implicit and explicit assumptions of the Naive Bayes model.</p>
<section id="independent-and-identically-distributed-i-i-d">
<h3><a class="toc-backref" href="#id25" role="doc-backlink">Independent and Identically Distributed (i.i.d.)</a><a class="headerlink" href="#independent-and-identically-distributed-i-i-d" title="Link to this heading">#</a></h3>
<p>In supervised learning, implicitly or explicitly, one <em>always</em> assumes that the training set</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{D} &amp;= \left\{\left(\mathbf{x}^{(1)}, y^{(1)}\right), \left(\mathbf{x}^{(2)}, y^{(2)}\right), \cdots, \left(\mathbf{x}^{(N)}, y^{(N)}\right)\right\} \\
\end{aligned}
\end{split}\]</div>
<p>is composed of <span class="math notranslate nohighlight">\(N\)</span> input/response tuples</p>
<div class="math notranslate nohighlight">
\[
\left({\mathbf{X}}^{(n)} = \mathbf{x}^{(n)}, Y^{(n)} = y^{(n)}\right)
\]</div>
<p>that are <em><strong>independently drawn from the same (identical) joint distribution</strong></em></p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}_{\{\mathcal{X}, \mathcal{Y} ; \boldsymbol{\theta}\}}(\mathbf{x}, y)
\]</div>
<p>with</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(\mathbf{X} = \mathbf{x}, Y = y ; \boldsymbol{\theta}) = \mathbb{P}(Y = y \mid \mathbf{X} = \mathbf{x}) \mathbb{P}(\mathbf{X} = \mathbf{x})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{P}(Y = y \mid \mathbf{X} = \mathbf{x})\)</span> is the conditional probability of <span class="math notranslate nohighlight">\(Y\)</span> given <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>,
the relationship that the learner algorithm/concept <span class="math notranslate nohighlight">\(c\)</span> is trying to capture.</p>
<div class="proof definition admonition" id="iid-assumption">
<p class="admonition-title"><span class="caption-number">Definition 43 </span> (The i.i.d. Assumption)</p>
<section class="definition-content" id="proof-content">
<p>Mathematically, this i.i.d. assumption writes (also defined in <a class="reference internal" href="../../probability_theory/03_discrete_random_variables/iid.html#def_iid">Definition 92</a>):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\left({\mathbf{X}}^{(n)}, Y^{(n)}\right) &amp;\sim \mathbb{P}_{\{\mathcal{X}, \mathcal{Y}, \boldsymbol{\theta}\}}(\mathbf{x}, y) \quad \text{and}\\
\left({\mathbf{X}}^{(n)}, Y^{(n)}\right) &amp;\text{ independent of } \left({\mathbf{X}}^{(m)}, Y^{(m)}\right) \quad \forall n \neq m \in \{1, 2, \ldots, N\}
\end{aligned}
\end{split}\]</div>
<p>and we sometimes denote</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\left(\mathbf{x}^{(n)}, y^{(n)}\right) \overset{\text{i.i.d.}}{\sim} \mathbb{P}_{\{\mathcal{X}, \mathcal{Y}, \boldsymbol{\theta}\}}(\mathbf{x}, y)
\end{aligned}
\]</div>
</section>
</div><p>The confusion in the <strong>i.i.d.</strong> assumption is that we are not talking about the individual random variables
<span class="math notranslate nohighlight">\(X_1^{(n)}, X_2^{(n)}, \ldots, X_D^{(n)}\)</span> here, but the entire random vector <span class="math notranslate nohighlight">\(\mathbf{X}^{(n)}\)</span>.</p>
<p>This means there is no assumption of <span class="math notranslate nohighlight">\(X_1^{(n)}, X_2^{(n)}, \ldots, X_D^{(n)}\)</span> being <strong>i.i.d.</strong>. Instead, the samples
<span class="math notranslate nohighlight">\(\mathbf{X}^{(1)}, \mathbf{X}^{(2)}, \ldots, \mathbf{X}^{(N)}\)</span> are <strong>i.i.d.</strong>.</p>
</section>
<section id="conditional-independence">
<span id="naive-bayes-conditional-independence"></span><h3><a class="toc-backref" href="#id26" role="doc-backlink">Conditional Independence</a><a class="headerlink" href="#conditional-independence" title="Link to this heading">#</a></h3>
<p>The core assumption of the Naive Bayes model is that the predictors <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>
are conditionally independent given the class label <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>But how did we arrive at the conditional independence assumption? Let’s look at what we wanted to achieve in the first place.</p>
<p>Recall that our goal in <a class="reference internal" href="#naive-bayes-inference-prediction"><span class="std std-ref">Inference/Prediction</span></a> is to find the class <span class="math notranslate nohighlight">\(k \in \{1, 2, \cdots, K\}\)</span> that maximizes the <strong>posterior</strong> probability
<span class="math notranslate nohighlight">\(\mathbb{P}(Y = k \mid \mathbf{X} = \mathbf{x}^{(q)} ; \boldsymbol{\theta})\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-eq-argmax-naive-bayes-4">
<span class="eqno">(50)<a class="headerlink" href="#equation-eq-argmax-naive-bayes-4" title="Link to this equation">#</a></span>\[\begin{split}
\begin{aligned}
\hat{y}^{(q)} &amp;= \arg \max_{k} \mathbb{P}(Y = k \mid \mathbf{X} = \mathbf{x}^{(q)} ; \boldsymbol{\theta}) \\
              &amp;= \arg \max_{k} \frac{\mathbb{P}(Y = k, \mathbf{X} = \mathbf{x}^{(q)} ; \boldsymbol{\theta})}{\mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)} ; \boldsymbol{\theta})} \\
              &amp;= \arg \max_{k} \frac{\mathbb{P}(Y = k ; \boldsymbol{\pi}) \mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)} \mid Y = k ; \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}})}{\mathbb{P}(\mathbf{X} = \mathbf{x}^{(q)} ; \boldsymbol{\theta})}\\
\end{aligned}
\end{split}\]</div>
<p>We have seen earlier in <a class="reference internal" href="#naive-bayes-inference-algorithm">Algorithm 4</a> that since the denominator
is constant for all <span class="math notranslate nohighlight">\(k\)</span>, we can ignore it and just maximize the numerator.</p>
<div class="math notranslate nohighlight" id="equation-eq-argmax-naive-bayes-5">
<span class="eqno">(51)<a class="headerlink" href="#equation-eq-argmax-naive-bayes-5" title="Link to this equation">#</a></span>\[\begin{split}
\begin{aligned}
\hat{y}^{(q)} &amp;= \arg \max_{k} \mathbb{P}\left(Y = k ; \boldsymbol{\pi}\right) \mathbb{P}\left(\mathbf{X} = \mathbf{x}^{(q)} \mid Y = k ; \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\right) \\
\end{aligned}
\end{split}\]</div>
<p>This suggests we need to find estimates for both the <strong>prior</strong> and the <strong>likelihood</strong>. This of course
involves us finding the <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> that maximize the likelihood function<a class="footnote-reference brackets" href="#likelihood-1" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>, which we will talk about later.</p>
<p>In order to meaningfully optimize the expression, we need to decompose the expression <a class="reference internal" href="#equation-eq-argmax-naive-bayes-5">(51)</a>
into its components that contain the parameters we want to estimate.</p>
<div class="math notranslate nohighlight" id="equation-eq-joint-distribution">
<span class="eqno">(52)<a class="headerlink" href="#equation-eq-joint-distribution" title="Link to this equation">#</a></span>\[\begin{split}
\begin{aligned}
\mathbb{P}(Y = k ; \boldsymbol{\pi}) \mathbb{P}(\mathbf{X} \mid Y = k ; \boldsymbol{\theta}) &amp;= \mathbb{P}((Y, \mathbf{X}) ; \boldsymbol{\theta}, \boldsymbol{\pi}) \\
&amp;= \mathbb{P}(Y, X_1, X_2, \ldots X_D)
\end{aligned}
\end{split}\]</div>
<p>which is actually the joint distribution of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> and <span class="math notranslate nohighlight">\(Y\)</span><a class="footnote-reference brackets" href="#joint-distribution" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>.</p>
<p>This joint distribution expression <a class="reference internal" href="#equation-eq-joint-distribution">(52)</a> can be further decomposed by the chain rule of probability<a class="footnote-reference brackets" href="#chain-rule-of-probability" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a> as</p>
<div class="math notranslate nohighlight" id="equation-eq-joint-distribution-decomposed">
<span class="eqno">(53)<a class="headerlink" href="#equation-eq-joint-distribution-decomposed" title="Link to this equation">#</a></span>\[\begin{split}
\begin{aligned}
\mathbb{P}(Y, X_1, X_2, \ldots X_D) &amp;= \mathbb{P}(Y) \mathbb{P}(X_1, X_2, \ldots X_D \mid Y) \\
&amp;= \mathbb{P}(Y) \mathbb{P}(X_1 \mid Y) \mathbb{P}(X_2 \mid Y, X_1) \cdots \mathbb{P}(X_D \mid Y, X_1, X_2, \ldots X_{D-1}) \\
&amp;= \mathbb{P}(Y) \prod_{d=1}^D \mathbb{P}(X_d \mid Y, X_1, X_2, \ldots X_{d-1}) \\
&amp;= \mathbb{P}(Y) \prod_{d=1}^{D} \mathbb{P}\left(X_d \middle \vert \bigcap_{d'=1}^{d-1} X_{d'}\right)
\end{aligned}
\end{split}\]</div>
<p>This alone does not get us any further, we still need to estimate roughly <span class="math notranslate nohighlight">\(2^{D}\)</span> parameters<a class="footnote-reference brackets" href="#dparameters" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a>,
which is computationally expensive. Not to forget that we need to estimate for each class <span class="math notranslate nohighlight">\(k \in \{1, 2, 3, \ldots, K\}\)</span>
which has a complexity of <span class="math notranslate nohighlight">\(\sim \mathcal{O}(2^DK)\)</span>.</p>
<div class="proof remark admonition" id="2dparameters">
<p class="admonition-title"><span class="caption-number">Remark 27 </span> (Why <span class="math notranslate nohighlight">\(2^D\)</span> parameters?)</p>
<section class="remark-content" id="proof-content">
<p>Let’s simplify the problem by assuming each feature <span class="math notranslate nohighlight">\(X_d\)</span> and the class label <span class="math notranslate nohighlight">\(Y\)</span> are binary random variables,
i.e. <span class="math notranslate nohighlight">\(X_d \in \{0, 1\}\)</span> and <span class="math notranslate nohighlight">\(Y \in \{0, 1\}\)</span>.</p>
<p>Then <span class="math notranslate nohighlight">\(\mathbb{P}(Y, X_1, X_2, \ldots X_D)\)</span> is a joint distribution of <span class="math notranslate nohighlight">\(D+1\)</span> random variables, each with <span class="math notranslate nohighlight">\(2\)</span> values.</p>
<p>This means the sample space of <span class="math notranslate nohighlight">\(\mathbb{P}(Y, X_1, X_2, \ldots X_D)\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{S} &amp;= \{(0, 1)\} \times \{(0, 1)\} \times \{(0, 1)\} \times \cdots \times \{(0, 1)\} \\
&amp;= \{(0, 0, 0, \ldots, 0), (0, 0, 0, \ldots, 1), (0, 0, 1, \ldots, 0), \ldots, (1, 1, 1, \ldots, 1)\}
\end{aligned}
\end{split}\]</div>
<p>which has <span class="math notranslate nohighlight">\(2^{D+1}\)</span> elements.
To really get the exact joint distribution, we need to estimate the probability of each element in the sample space, which is <span class="math notranslate nohighlight">\(2^{D+1}\)</span> parameters.</p>
<p>This has two caveats:</p>
<ol class="arabic simple">
<li><p>There are too many parameters to estimate, which is computationally expensive. Imagine if <span class="math notranslate nohighlight">\(D\)</span> is 1000, we need to estimate <span class="math notranslate nohighlight">\(2^{1000}\)</span> parameters, which is infeasible.</p></li>
<li><p>Even if we can estimate all the parameters, we are essentially overfitting the data by memorizing the training data. There is no learning involved.</p></li>
</ol>
</section>
</div><p>This is where the “Naive” assumption comes in. The Naive Bayes’ classifier assumes that
the features are conditionally independent<a class="footnote-reference brackets" href="#id15" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a> given the class label.</p>
<p>More formally stated,</p>
<div class="proof definition admonition" id="conditional-independence">
<p class="admonition-title"><span class="caption-number">Definition 44 </span> (Conditional Independence)</p>
<section class="definition-content" id="proof-content">
<div class="math notranslate nohighlight" id="equation-eq-conditional-independence">
<span class="eqno">(54)<a class="headerlink" href="#equation-eq-conditional-independence" title="Link to this equation">#</a></span>\[
\mathbb{P}(X_d \mid Y = k, X_{d^{'}}) = \mathbb{P}(X_d \mid Y = k) \quad \text{for all } d \neq d^{'}
\]</div>
</section>
</div><p>with this assumption, we can further simplify expression <a class="reference internal" href="#equation-eq-joint-distribution-decomposed">(53)</a> as</p>
<div class="math notranslate nohighlight" id="equation-eq-conditional-independence-naive-bayes-1">
<span class="eqno">(55)<a class="headerlink" href="#equation-eq-conditional-independence-naive-bayes-1" title="Link to this equation">#</a></span>\[\begin{split}
\begin{aligned}
\mathbb{P}(Y, X_1, X_2, \ldots X_D) &amp;= \mathbb{P}(Y ; \boldsymbol{\pi}) \prod_{d=1}^D \mathbb{P}(X_d \mid Y ; \theta_{d}) \\
\end{aligned}
\end{split}\]</div>
<p>More precisely, after the simplification in <a class="reference internal" href="#equation-eq-conditional-independence-naive-bayes-1">(55)</a>,
the argmax expression in <a class="reference internal" href="#equation-eq-conditional-naive-bayes">(41)</a> can be written as</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-classifier-1">
<span class="eqno">(56)<a class="headerlink" href="#equation-eq-naive-bayes-classifier-1" title="Link to this equation">#</a></span>\[\begin{split}
\begin{aligned}
\mathbb{P}(Y = k \mid \mathbf{X} = \mathbf{x} ; \boldsymbol{\theta}) &amp; = \dfrac{\mathbb{P}(Y = k ; \boldsymbol{\pi}) \mathbb{P}(\mathbf{X} \mid Y = k ; \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}})}{\mathbb{P}(\mathbf{X})} \\
&amp;= \dfrac{\mathbb{P}(Y, X_1, X_2, \ldots X_D)}{\mathbb{P}(\mathbf{X})} \\
&amp;= \dfrac{\mathbb{P}(Y = k ; \boldsymbol{\pi}) \prod_{d=1}^D \mathbb{P}(X_d = x_d \mid Y = k ; \theta_{kd})}{\mathbb{P}(\mathbf{X} = \mathbf{x})} \\
\end{aligned}
\end{split}\]</div>
<p>Consequently, our argmax expression in <a class="reference internal" href="#equation-eq-argmax-naive-bayes-2">(43)</a> can be written as</p>
<div class="math notranslate nohighlight" id="equation-eq-argmax-naive-bayes-6">
<span class="eqno">(57)<a class="headerlink" href="#equation-eq-argmax-naive-bayes-6" title="Link to this equation">#</a></span>\[
\arg \max_{k=1}^K \mathbb{P}(Y = k \mid \mathbf{X}) = \arg \max_{k=1}^K \mathbb{P}(Y = k ; \boldsymbol{\pi}) \prod_{d=1}^D \mathbb{P}(X_d = x_d \mid Y = k ; \theta_{kd})
\]</div>
<p>We also make some updates to the vector form <a class="reference internal" href="#equation-eq-argmax-naive-bayes-3">(45)</a> by updating <span class="math notranslate nohighlight">\(\mathbf{M_2}\)</span> to:</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-m2-updated">
<span class="eqno">(58)<a class="headerlink" href="#equation-eq-naive-bayes-m2-updated" title="Link to this equation">#</a></span>\[\begin{split}
\begin{aligned}
  \mathbf{M_2} &amp;= \begin{bmatrix}
  \mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = 1) \\
  \mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = 2) \\
  \vdots \\
  \mathbb{P}(\mathbf{X} = \mathbf{x} \mid Y = K)
  \end{bmatrix}_{K \times 1} \\
  &amp;= \begin{bmatrix}
  \mathbb{P}(X_1 = x_1 \mid Y = 1 ; \theta_{11}) \mathbb{P}(X_2 = x_2 \mid Y = 1 ; \theta_{12}) \cdots \mathbb{P}(X_D = x_D \mid Y = 1 ; \theta_{1D}) \\
  \mathbb{P}(X_1 = x_1 \mid Y = 2 ; \theta_{21}) \mathbb{P}(X_2 = x_2 \mid Y = 2 ; \theta_{22}) \cdots \mathbb{P}(X_D = x_D \mid Y = 2 ; \theta_{2D}) \\
  \vdots \\
  \mathbb{P}(X_1 = x_1 \mid Y = K ; \theta_{K1}) \mathbb{P}(X_2 = x_2 \mid Y = K ; \theta_{K2}) \cdots \mathbb{P}(X_D = x_D \mid Y = K ; \theta_{KD})
  \end{bmatrix}_{K \times 1} \\
\end{aligned}
\end{split}\]</div>
<p>To easily recover each row of <span class="math notranslate nohighlight">\(\mathbf{M_2}\)</span>, it is efficient to define a <span class="math notranslate nohighlight">\(K \times D\)</span> matrix, denoted <span class="math notranslate nohighlight">\(\mathbf{M_3}\)</span></p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-m3-explained">
<span class="eqno">(59)<a class="headerlink" href="#equation-eq-naive-bayes-m3-explained" title="Link to this equation">#</a></span>\[\begin{split}
\begin{aligned}
  \mathbf{M_3} &amp;= \begin{bmatrix}
  \mathbb{P}(X_1 = x_1 \mid Y = 1 ; \theta_{11}) &amp; \mathbb{P}(X_2 = x_2 \mid Y = 1 ; \theta_{12}) &amp; \cdots &amp; \mathbb{P}(X_D = x_D \mid Y = 1 ; \theta_{1D}) \\
  \mathbb{P}(X_1 = x_1 \mid Y = 2 ; \theta_{21}) &amp; \mathbb{P}(X_2 = x_2 \mid Y = 2 ; \theta_{22}) &amp; \cdots &amp; \mathbb{P}(X_D = x_D \mid Y = 2 ; \theta_{2D}) \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  \mathbb{P}(X_1 = x_1 \mid Y = K ; \theta_{K1}) &amp; \mathbb{P}(X_2 = x_2 \mid Y = K ; \theta_{K2}) &amp; \cdots &amp; \mathbb{P}(X_D = x_D \mid Y = K ; \theta_{KD})
  \end{bmatrix}_{K \times D} \\
\end{aligned}
\end{split}\]</div>
<p>where we can easily recover each row of <span class="math notranslate nohighlight">\(\mathbf{M_2}\)</span> by taking the product of the corresponding row of <span class="math notranslate nohighlight">\(\mathbf{M_3}\)</span>.</p>
</section>
</section>
<section id="parameter-vector">
<h2><a class="toc-backref" href="#id27" role="doc-backlink">Parameter Vector</a><a class="headerlink" href="#parameter-vector" title="Link to this heading">#</a></h2>
<p>In the last section on <a class="reference internal" href="#naive-bayes-conditional-independence"><span class="std std-ref">Conditional Independence</span></a>, we indicated parameters in the expressions.
Here we discuss a little on this newly introduced notation.</p>
<p>Each <span class="math notranslate nohighlight">\(\pi_k\)</span> of <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span> refers to the prior probability of class <span class="math notranslate nohighlight">\(k\)</span>, and <span class="math notranslate nohighlight">\(\theta_{kd}\)</span> refers to the parameter of the
class conditional density for class <span class="math notranslate nohighlight">\(k\)</span> and feature <span class="math notranslate nohighlight">\(d\)</span><a class="footnote-reference brackets" href="#kdparameters" id="id7" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a>. Furthermore,
the boldsymbol <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> is the parameter vector,</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\theta} = \left(\boldsymbol{\pi}, \{\theta_{kd}\}_{k=1, d=1}^{K, D} \right) = \left(\boldsymbol{\pi}, \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\right)
\]</div>
<div class="proof definition admonition" id="parameter-vector">
<p class="admonition-title"><span class="caption-number">Definition 45 </span> (The Parameter Vector)</p>
<section class="definition-content" id="proof-content">
<p>There is not much to say about the categorical component <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span>, since we are
just estimating the prior probabilities of the classes.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\pi} = \begin{bmatrix} \pi_1 \\ \pi_2 \\ \vdots \\ \pi_K \end{bmatrix}_{K \times 1}
\end{split}\]</div>
<p>The parameter vector (matrix) <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}=\{\theta_{kd}\}_{k=1, d=1}^{K, D}\)</span> is a bit more complicated.
It resides in the <span class="math notranslate nohighlight">\(\mathbb{R}^{K \times D}\)</span> space, where each element <span class="math notranslate nohighlight">\(\theta_{kd}\)</span> is the parameter
associated with feature <span class="math notranslate nohighlight">\(d\)</span> conditioned on class <span class="math notranslate nohighlight">\(k\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}} = \begin{bmatrix}
\theta_{11} &amp; \theta_{12} &amp; \dots &amp; \theta_{1D} \\
\theta_{21} &amp; \theta_{22} &amp; \dots &amp; \theta_{2D} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\theta_{K1} &amp; \theta_{K2} &amp; \dots &amp; \theta_{KD}
\end{bmatrix}_{K \times D}
\end{split}\]</div>
<p>So if <span class="math notranslate nohighlight">\(K=3\)</span> and <span class="math notranslate nohighlight">\(D=2\)</span>, then the parameter vector <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> is a <span class="math notranslate nohighlight">\(3 \times 2\)</span> matrix, i.e.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}} = \begin{bmatrix}
\theta_{11} &amp; \theta_{12} \\
\theta_{21} &amp; \theta_{22} \\
\theta_{31} &amp; \theta_{32}
\end{bmatrix}_{3 \times 2}
\end{split}\]</div>
<p>This means we have effectively reduced our complexity from <span class="math notranslate nohighlight">\(\sim \mathcal{O}(2^D)\)</span> to <span class="math notranslate nohighlight">\(\sim \mathcal{O}(KD + 1)\)</span>
assuming the same setup in <a class="reference internal" href="#2dparameters">Remark 27</a>.</p>
<p>One big misconception is that the elements in <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> are scalar values.
This is not true, for example, let’s look at the first entry <span class="math notranslate nohighlight">\(\theta_{11}\)</span>, corresponding to
the parameter of class <span class="math notranslate nohighlight">\(K=1\)</span> and feature <span class="math notranslate nohighlight">\(D=1\)</span>, i.e. <span class="math notranslate nohighlight">\(\theta_{11}\)</span> is the parameter of the class conditional
density <span class="math notranslate nohighlight">\(\mathbb{P}(X_1 \mid Y = 1)\)</span>. Now <span class="math notranslate nohighlight">\(X_1\)</span> can take on any value in <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>, which is indeed a scalar,
we further assume that <span class="math notranslate nohighlight">\(X_1\)</span> takes on a univariate Gaussian distribution, then <span class="math notranslate nohighlight">\(\theta_{11}\)</span> is a vector of length 2, i.e.</p>
<div class="math notranslate nohighlight">
\[
\theta_{11} = \begin{bmatrix} \mu_{11} &amp; \sigma_{11} \end{bmatrix}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu_{11}\)</span> is the mean of the Gaussian distribution and <span class="math notranslate nohighlight">\(\sigma_{11}\)</span> is the standard deviation of the Gaussian distribution.
This is something we need to take note of.</p>
<p><strong>We have also reduced the problem of estimating the joint distribution to just individual conditional distributions.</strong></p>
<p>Overall, before this assumption, you can think of estimating the joint distribution of <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>,
and after this assumption, you can simply individually estimate each conditional distribution.</p>
</section>
</div><p>Notice that the shape of <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span> is <span class="math notranslate nohighlight">\(K \times 1\)</span>, and the shape of <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> is <span class="math notranslate nohighlight">\(K \times D\)</span>.
This corresponds to the shape of the matrix <span class="math notranslate nohighlight">\(\mathbf{M_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{M_3}\)</span> as defined in
<a class="reference internal" href="#equation-eq-naive-bayes-m1">(46)</a> and <a class="reference internal" href="#equation-eq-naive-bayes-m3">(48)</a>, respectively. This is expected since
<span class="math notranslate nohighlight">\(\mathbf{M_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{M_3}\)</span> hold the PDFs while <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> hold the parameters
of these PDFs.</p>
<div class="proof remark admonition" id="remark-empirical-parameters">
<p class="admonition-title"><span class="caption-number">Remark 28 </span> (Empirical Parameters)</p>
<section class="remark-content" id="proof-content">
<p>It is worth noting that we are discussing the parameter vectors <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span>
and <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> which represents the true
underlying distribution. However, our ultimate goal is to estimate these parameters because
we do not have the underlying distributions at hand, otherwise there is no need to do
machine learning.</p>
<p>More concretely, our task is to find</p>
<div class="math notranslate nohighlight">
\[
\hat{\boldsymbol{\pi}} \quad \text{ and } \quad \hat{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}}
\]</div>
</section>
</div></section>
<section id="inductive-bias-distribution-assumptions">
<h2><a class="toc-backref" href="#id28" role="doc-backlink">Inductive Bias (Distribution Assumptions)</a><a class="headerlink" href="#inductive-bias-distribution-assumptions" title="Link to this heading">#</a></h2>
<p>We still need to introduce some inductive bias into <a class="reference internal" href="#equation-eq-naive-bayes-classifier-1">(56)</a>, more concretely, we need to make some assumptions about the distribution
of <span class="math notranslate nohighlight">\(\mathbb{P}(Y)\)</span> and <span class="math notranslate nohighlight">\(\mathbb{P}(X_d \mid Y)\)</span>.</p>
<p>For the target variable, we typically model it as a categorical distribution,</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(Y) \sim \mathrm{Categorical}(\boldsymbol{\pi})
\]</div>
<p>For the conditional distribution of the features, we typically model it according to what type of features we have.</p>
<p>For example, if we have binary features, then we can model it as a Bernoulli distribution,</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(X_d \mid Y) \sim \mathrm{Bernoulli}(\theta_{dk})
\]</div>
<p>If we have categorical features, then we can model it as a multinomial/catgorical distribution,</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(X_d \mid Y) \sim \mathrm{Multinomial}(\boldsymbol{\theta}_{dk})
\]</div>
<p>If we have continuous features, then we can model it as a Gaussian distribution,</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(X_d \mid Y) \sim \mathcal{N}(\mu_{dk}, \sigma_{dk}^2)
\]</div>
<p>To reiterate, we want to make some inductive bias assumptions of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> conditional on <span class="math notranslate nohighlight">\(Y\)</span>,
as well as with <span class="math notranslate nohighlight">\(Y\)</span>. Note very carefully that we are not talking about the marginal distribution of
<span class="math notranslate nohighlight">\(\mathbf{X}\)</span> here, instead, we are talking about the conditional distribution of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>. The distinction is subtle, but important.</p>
<section id="targets-categorical-distribution">
<h3><a class="toc-backref" href="#id29" role="doc-backlink">Targets (Categorical Distribution)</a><a class="headerlink" href="#targets-categorical-distribution" title="Link to this heading">#</a></h3>
<p>As mentioned earlier, both <span class="math notranslate nohighlight">\(Y^{(n)}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{X}^{(n)}\)</span> are random variables/vectors.
This means we need to estimate both of them.</p>
<p>We first conveniently assume that <span class="math notranslate nohighlight">\(Y^{(n)}\)</span> is a discrete random variable, and
follows the <strong><a class="reference external" href="https://en.wikipedia.org/wiki/Categorical_distribution">Category distribution</a></strong><a class="footnote-reference brackets" href="#categorical-distribution" id="id8" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a>,
an extension of the Bernoulli distribution to multiple classes. Instead of a single parameter <span class="math notranslate nohighlight">\(p\)</span> (probability of success for Bernoulli),
the Category distribution has a vector <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span> of <span class="math notranslate nohighlight">\(K\)</span> parameters.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\pi} = \begin{bmatrix} \pi_1 \\ \vdots \\ \pi_K \end{bmatrix}_{K \times 1}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\pi_k\)</span> is the probability of <span class="math notranslate nohighlight">\(Y^{(n)}\)</span> taking on value <span class="math notranslate nohighlight">\(k\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-eq-target-category-distribution">
<span class="eqno">(60)<a class="headerlink" href="#equation-eq-target-category-distribution" title="Link to this equation">#</a></span>\[\begin{split}
Y^{(n)} \overset{\small{\text{i.i.d.}}}{\sim} \text{Category}(\boldsymbol{\pi}) \quad \text{where } \boldsymbol{\pi} = \begin{bmatrix} \pi_1 \\ \vdots \\ \pi_K \end{bmatrix}_{K \times 1}
\end{split}\]</div>
<p>Equivalently,</p>
<div class="math notranslate nohighlight" id="equation-eq-category-distribution">
<span class="eqno">(61)<a class="headerlink" href="#equation-eq-category-distribution" title="Link to this equation">#</a></span>\[
\mathbb{P}(Y^{(n)} = k) = \pi_k \quad \text{for } k = 1, 2, \cdots, K
\]</div>
<p>Consequently, we just need to estimate <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span> to recover <span class="math notranslate nohighlight">\(\mathbf{M_1}\)</span> defined in <a class="reference internal" href="#equation-eq-naive-bayes-m1">(46)</a>.</p>
<p>Find <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\pi}}\)</span> such that <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\pi}}\)</span> maximizes the likelihood of the observed data.</p>
<div class="math notranslate nohighlight">
\[
\hat{\boldsymbol{\pi}} = \arg\max_{\boldsymbol{\pi}} \mathcal{L}(\boldsymbol{\pi} \mid \mathcal{D})
\]</div>
<div class="proof definition admonition" id="categorical-distribution">
<p class="admonition-title"><span class="caption-number">Definition 46 </span> (Categorical Distribution)</p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(Y\)</span> be a discrete random variable with <span class="math notranslate nohighlight">\(K\)</span> number of states.
Then <span class="math notranslate nohighlight">\(Y\)</span> follows a categorical distribution with parameters <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span> if</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(Y = k) = \pi_k \quad \text{for } k = 1, 2, \cdots, K
\]</div>
<p>Consequently, the PMF of the categorical distribution is defined more compactly as,</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(Y = k) = \prod_{k=1}^K \pi_k^{I\{Y = k\}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(I\{Y = k\}\)</span> is the indicator function that is equal to 1 if <span class="math notranslate nohighlight">\(Y = k\)</span> and 0 otherwise.</p>
</section>
</div><div class="proof definition admonition" id="categorical-multinomial-distribution">
<p class="admonition-title"><span class="caption-number">Definition 47 </span> (Categorical (Multinomial) Distribution)</p>
<section class="definition-content" id="proof-content">
<p>This formulation is adopted by Bishop’s<span id="id9">[<a class="reference internal" href="../../bibliography.html#id4" title="Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics). Springer, 1 edition, 2007. ISBN 0387310738. URL: http://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738%3FSubscriptionId%3D13CT5CVB80YFWJEPWS02%26tag%3Dws%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3D0387310738.">Bishop, 2007</a>]</span>, the categorical distribution is defined as</p>
<div class="math notranslate nohighlight" id="equation-eq-categorical-distribution-bishop">
<span class="eqno">(62)<a class="headerlink" href="#equation-eq-categorical-distribution-bishop" title="Link to this equation">#</a></span>\[
\mathbb{P}(\mathbf{Y} = \mathbf{y}; \boldsymbol{\pi}) = \prod_{k=1}^K \pi_k^{y_k}
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{y} = \begin{bmatrix} y_1 \\ y_2 \\ \vdots \\ y_K \end{bmatrix}
\end{split}\]</div>
<p>is an one-hot encoded vector of size <span class="math notranslate nohighlight">\(K\)</span>,</p>
<p>The <span class="math notranslate nohighlight">\(y_k\)</span> is the <span class="math notranslate nohighlight">\(k\)</span>-th element of <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>, and is equal to 1 if <span class="math notranslate nohighlight">\(Y = k\)</span> and 0 otherwise.
The <span class="math notranslate nohighlight">\(\pi_k\)</span> is the <span class="math notranslate nohighlight">\(k\)</span>-th element of <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span>, and is the probability of <span class="math notranslate nohighlight">\(Y = k\)</span>.</p>
<p>This notation alongside with the indicator notation in the previous definition allows us to manipulate
the likelihood function easier.</p>
</section>
</div><div class="proof example admonition" id="categorical-distribution-example">
<p class="admonition-title"><span class="caption-number">Example 13 </span> (Categorical Distribution Example)</p>
<section class="example-content" id="proof-content">
<p>Consider rolling a fair six-sided die. Let <span class="math notranslate nohighlight">\(Y\)</span> be the random variable that represents the outcome
of the dice roll. Then <span class="math notranslate nohighlight">\(Y\)</span> follows a categorical distribution with parameters <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span> where <span class="math notranslate nohighlight">\(\pi_k = \frac{1}{6}\)</span> for <span class="math notranslate nohighlight">\(k = 1, 2, \cdots, 6\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(Y = k) = \frac{1}{6} \quad \text{for } k = 1, 2, \cdots, 6
\]</div>
<p>For example, if we roll a 3, then <span class="math notranslate nohighlight">\(\mathbb{P}(Y = 3) = \frac{1}{6}\)</span>.</p>
<p>With the more compact notation, the indicator function is <span class="math notranslate nohighlight">\(I\{Y = k\} = 1\)</span> if <span class="math notranslate nohighlight">\(Y = 3\)</span> and <span class="math notranslate nohighlight">\(0\)</span> otherwise. Therefore, the PMF is</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(Y = k) = \prod_{k=1}^6 \frac{1}{6}^{I\{Y = k\}} = \left(\frac{1}{6}\right)^0 \cdot \left(\frac{1}{6}\right)^0 \cdot \left(\frac{1}{6}\right)^1 \cdot \left(\frac{1}{6}\right)^0 \cdot \left(\frac{1}{6}\right)^0 \cdot \left(\frac{1}{6}\right)^0 = \frac{1}{6}
\]</div>
<p>Using Bishop’s notation, the PMF is still the same, only the realization <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> is not a scalar,
but instead a vector of size <span class="math notranslate nohighlight">\(6\)</span>. In the case where <span class="math notranslate nohighlight">\(Y = 3\)</span>, the vector <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{y} = \begin{bmatrix} 0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0 \end{bmatrix}
\end{split}\]</div>
</section>
</div></section>
<section id="discrete-features-categorical-distribution">
<h3><a class="toc-backref" href="#id30" role="doc-backlink">Discrete Features (Categorical Distribution)</a><a class="headerlink" href="#discrete-features-categorical-distribution" title="Link to this heading">#</a></h3>
<p>Now, our next task is find parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> to model the conditional distribution of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> given <span class="math notranslate nohighlight">\(Y = k\)</span>,
and consequently, recovering the matrix <span class="math notranslate nohighlight">\(\mathbf{M_3}\)</span> defined in <a class="reference internal" href="#equation-eq-naive-bayes-m3">(48)</a>.</p>
<p>In the case where (all) the features <span class="math notranslate nohighlight">\(X_d\)</span> are categorical (<span class="math notranslate nohighlight">\(D\)</span> number of features),
i.e. <span class="math notranslate nohighlight">\(X_d \in \{1, 2, \cdots, C\}\)</span>,
we can use the categorical distribution to model the (<span class="math notranslate nohighlight">\(D\)</span>-dimensional) conditional
distribution of <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{D}\)</span> given <span class="math notranslate nohighlight">\(Y = k\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-categorical-feature-1">
<span class="eqno">(63)<a class="headerlink" href="#equation-eq-naive-bayes-categorical-feature-1" title="Link to this equation">#</a></span>\[
\begin{align*}
\mathbf{X} \mid Y = k &amp;\overset{\small{\text{i.i.d.}}}{\sim} \text{Category}\left(\boldsymbol{\pi}_{\{\mathbf{X} \mid Y\}}\right) \quad \text{for } k = 1, 2, \cdots, K
\end{align*}
\]</div>
<p>where</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-categorical-feature-2">
<span class="eqno">(64)<a class="headerlink" href="#equation-eq-naive-bayes-categorical-feature-2" title="Link to this equation">#</a></span>\[\begin{split}
\boldsymbol{\pi}_{\{\mathbf{X} \mid Y\}} = \begin{bmatrix} \pi_{1, 1} &amp; \dots &amp; \pi_{1, D} \\ \vdots &amp; \ddots &amp; \vdots \\ \pi_{K, 1} &amp; \dots &amp; \pi_{K, D} \end{bmatrix}_{K \times D} \\
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(\boldsymbol{\pi}_{\{\mathbf{X} \mid Y\}}\)</span> is a matrix of size <span class="math notranslate nohighlight">\(K \times D\)</span> where each
element <span class="math notranslate nohighlight">\(\pi_{k, d}\)</span> is the parameter for the
probability distribution (PDF) of <span class="math notranslate nohighlight">\(X_d\)</span> given <span class="math notranslate nohighlight">\(Y = k\)</span>.</p>
<div class="math notranslate nohighlight">
\[
X_d \mid Y = k \overset{\small{\text{i.i.d.}}}{\sim} \text{Category}(\pi_{k, d})
\]</div>
<p>Furthermore,
each <span class="math notranslate nohighlight">\(\pi_{k, d}\)</span> is <strong>not a scalar</strong> but a <strong>vector of size <span class="math notranslate nohighlight">\(C\)</span></strong> holding the probability of <span class="math notranslate nohighlight">\(X_d = c\)</span> given <span class="math notranslate nohighlight">\(Y = k\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
\pi_{k, d} = \begin{bmatrix} \pi_{k, d, 1} &amp; \dots &amp; \pi_{k, d, C} \end{bmatrix}
\end{align*}
\]</div>
<p>Then the (chained) multi-dimensional conditional PDF of <span class="math notranslate nohighlight">\(\mathbf{X} = \begin{bmatrix} X_1 &amp; \dots &amp; X_D \end{bmatrix}\)</span> given <span class="math notranslate nohighlight">\(Y = k\)</span> is</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-categorical-feature-3">
<span class="eqno">(65)<a class="headerlink" href="#equation-eq-naive-bayes-categorical-feature-3" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\mathbb{P}(\mathbf{X} = \mathbf{x} | Y = k ; \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}) &amp;= \prod_{d=1}^D \text{Categorical}(X_d \mid Y = k; \pi_{k, d}) \\
&amp;= \prod_{d=1}^D \prod_{c=1}^C \pi_{k, d, c}^{x_{c, d}} \quad \text{for } c = 1, 2, \cdots, C \text{ and } k = 1, 2, \cdots, K
\end{align*}
\end{split}\]</div>
<p>As an example, if <span class="math notranslate nohighlight">\(C=3\)</span>, <span class="math notranslate nohighlight">\(D=2\)</span> and <span class="math notranslate nohighlight">\(K=4\)</span>, then the <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> is a <span class="math notranslate nohighlight">\(K \times D = 4 \times 2\)</span> matrix, but for
each entry <span class="math notranslate nohighlight">\(\pi_{k, d}\)</span>, is a <span class="math notranslate nohighlight">\(1 \times C\)</span> vector. If one really wants, we can also represent this as a
<span class="math notranslate nohighlight">\(4 \times 2 \times 3\)</span> tensor, especially in the case of implementing it in code.</p>
<p>To be more verbose, when we find</p>
<div class="math notranslate nohighlight">
\[
\mathbf{X} \mid Y = k \overset{\small{\text{i.i.d.}}}{\sim} \text{Category}(\boldsymbol{\pi}_{\{\mathbf{X} \mid Y\}})
\]</div>
<p>we are actually finding for all <span class="math notranslate nohighlight">\(k = 1, 2, \cdots, K\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathbf{X} \mid Y = 1 &amp;\overset{\small{\text{i.i.d.}}}{\sim} \text{Category}(\boldsymbol{\pi}_{\{\mathbf{X} \mid Y=1\}}) \\
\mathbf{X} \mid Y = 2 &amp;\overset{\small{\text{i.i.d.}}}{\sim} \text{Category}(\boldsymbol{\pi}_{\{\mathbf{X} \mid Y=2\}}) \\
\vdots \\
\mathbf{X} \mid Y = K &amp;\overset{\small{\text{i.i.d.}}}{\sim} \text{Category}(\boldsymbol{\pi}_{\{\mathbf{X} \mid Y=K\}})
\end{align*}
\end{split}\]</div>
<p>This is because we are also finding the argmax of the number of classes <span class="math notranslate nohighlight">\(K\)</span> when we seek
the expression <span class="math notranslate nohighlight">\(\arg\max_{k=1, 2, \cdots, K} \mathbb{P}(Y = k | \mathbf{X} = \mathbf{x})\)</span>,
and therefore, we need to find the conditional PDF of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> for each class <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>Each row above corresponds to each row of the matrix <span class="math notranslate nohighlight">\(\mathbf{M_2}\)</span> defined in <a class="reference internal" href="#equation-eq-naive-bayes-m2">(47)</a>. We
can further decompose each <span class="math notranslate nohighlight">\(\mathbf{X} \mid Y = k\)</span> into <span class="math notranslate nohighlight">\(D\)</span> independent random variables, each of which
is modeled by a categorical distribution, thereby recovering each element of <span class="math notranslate nohighlight">\(\mathbf{M_3}\)</span> <a class="reference internal" href="#equation-eq-naive-bayes-m3">(48)</a>.</p>
<p>See <strong>Kevin Murphy’s Probabilistic Machine Learning: An Introduction</strong> pp 358 for more details.</p>
</section>
<section id="continuous-features-gaussian-distribution">
<span id="id10"></span><h3><a class="toc-backref" href="#id31" role="doc-backlink">Continuous Features (Gaussian Distribution)</a><a class="headerlink" href="#continuous-features-gaussian-distribution" title="Link to this heading">#</a></h3>
<p>Here, the task is still the same, to find parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> to model the conditional distribution of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> given <span class="math notranslate nohighlight">\(Y = k\)</span>,
and consequently, recovering the matrix <span class="math notranslate nohighlight">\(\mathbf{M_3}\)</span> defined in <a class="reference internal" href="#equation-eq-naive-bayes-m3">(48)</a>.</p>
<p>In the case where (all) the features <span class="math notranslate nohighlight">\(X_d\)</span> are continuous (<span class="math notranslate nohighlight">\(D\)</span> number of features),
we can use the Gaussian distribution to model the conditional distribution of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> given <span class="math notranslate nohighlight">\(Y = k\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-continuous-feature-1">
<span class="eqno">(66)<a class="headerlink" href="#equation-eq-naive-bayes-continuous-feature-1" title="Link to this equation">#</a></span>\[
\begin{align*}
\mathbf{X} \mid Y = k \overset{\small{\text{i.i.d.}}}{\sim} \mathcal{N}(\theta_{\{\mathbf{X} \mid Y\}}) \quad \text{for } k = 1, 2, \cdots, K
\end{align*}
\]</div>
<p>where</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-continuous-feature-2">
<span class="eqno">(67)<a class="headerlink" href="#equation-eq-naive-bayes-continuous-feature-2" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\theta_{\{\mathbf{X} \mid Y\}} &amp;= \begin{bmatrix} \theta_{1, 1} &amp; \dots &amp; \theta_{1, D} \\ \vdots &amp; \ddots &amp; \vdots \\ \theta_{K, 1} &amp; \dots &amp; \theta_{K, D} \end{bmatrix}_{K \times D} \\
&amp;= \begin{bmatrix} (\mu_{1, 1}, \sigma_{1, 1}^2) &amp; \dots &amp; (\mu_{1, D}, \sigma_{1, D}^2) \\ \vdots &amp; \ddots &amp; \vdots \\ (\mu_{K, 1}, \sigma_{K, 1}^2) &amp; \dots &amp; (\mu_{K, D}, \sigma_{K, D}^2) \end{bmatrix}_{K \times D}
\end{align*}
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> is a <span class="math notranslate nohighlight">\(K \times D\)</span> matrix, where each element
<span class="math notranslate nohighlight">\(\theta_{k, d}\)</span> is a tuple of the mean and variance of the
Gaussian distribution modeling the conditional distribution of <span class="math notranslate nohighlight">\(X_d\)</span> given <span class="math notranslate nohighlight">\(Y = k\)</span>.</p>
<p>To be more precise, each element in the matrix <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> is a tuple of the mean and variance of the
Gaussian distribution modeling the conditional distribution of <span class="math notranslate nohighlight">\(X_d\)</span> given <span class="math notranslate nohighlight">\(Y = k\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-continuous-feature-3">
<span class="eqno">(68)<a class="headerlink" href="#equation-eq-naive-bayes-continuous-feature-3" title="Link to this equation">#</a></span>\[
\begin{align*}
X_d \mid Y = k &amp;\overset{\small{\text{i.i.d.}}}{\sim} \mathcal{N}(\mu_{k, d}, \sigma_{k, d}^2) \quad \text{for } k = 1, 2, \cdots, K
\end{align*}
\]</div>
<p>Then the (chained) multivariate Gaussian distribution of <span class="math notranslate nohighlight">\(\mathbf{X} = \begin{bmatrix} X_1 &amp; \dots &amp; X_D \end{bmatrix}\)</span> given <span class="math notranslate nohighlight">\(Y = k\)</span> is</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-continuous-feature-4">
<span class="eqno">(69)<a class="headerlink" href="#equation-eq-naive-bayes-continuous-feature-4" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\mathbb{P}\left(\mathbf{X} = \mathbf{x} \mid Y = k ; \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\right) &amp;= \prod_{d=1}^D \mathcal{N}(x_d \mid \mu_{k, d}, \sigma_{k, d}^2) \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu_{k, d}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{k, d}^2\)</span> are the mean and variance of the
Gaussian distribution modeling the conditional distribution of <span class="math notranslate nohighlight">\(X_d\)</span> given <span class="math notranslate nohighlight">\(Y = k\)</span>.</p>
<p>So in this case it amounts to estimating <span class="math notranslate nohighlight">\(\hat{\mu}_{k, d}\)</span> and <span class="math notranslate nohighlight">\(\hat{\sigma}_{k, d}^2\)</span> for each <span class="math notranslate nohighlight">\(k\)</span> and <span class="math notranslate nohighlight">\(d\)</span>.</p>
</section>
<section id="mixed-features-discrete-and-continuous">
<h3><a class="toc-backref" href="#id32" role="doc-backlink">Mixed Features (Discrete and Continuous)</a><a class="headerlink" href="#mixed-features-discrete-and-continuous" title="Link to this heading">#</a></h3>
<p>So far we have assumed that each feature <span class="math notranslate nohighlight">\(X_d\)</span> is either all discrete, or all continuous. This
need not be the case, and may not always be the case. In reality, we may have a mixture of both.</p>
<p>For example, if <span class="math notranslate nohighlight">\(X_1\)</span> corresponds to the smoking status of a person (i.e. whether they smoke or not),
then this feature is binary, and can be modeled by a Bernoulli distribution.
On the other hand, if <span class="math notranslate nohighlight">\(X_2\)</span> corresponds to the weight of a person, then this feature is continuous, and can be modeled by a Gaussian distribution.
The nice thing is since within each class <span class="math notranslate nohighlight">\(k\)</span>, the features <span class="math notranslate nohighlight">\(X_d\)</span> are independent of each other, we can model each feature <span class="math notranslate nohighlight">\(X_d\)</span> by its own distribution.</p>
<p>So, carrying over the example above, we have,</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-mixed-feature-1">
<span class="eqno">(70)<a class="headerlink" href="#equation-eq-naive-bayes-mixed-feature-1" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
X_1 \mid Y = k &amp;\overset{\small{\text{i.i.d.}}}{\sim} \text{Bernoulli}(\pi_{\{X_1 \mid Y=k\}}) \\
X_2 \mid Y = k &amp;\overset{\small{\text{i.i.d.}}}{\sim} \text{Gaussian}(\mu_{\{X_2 \mid Y=k\}}, \sigma_{\{X_2 \mid Y=k\}}^2)
\end{align*}
\end{split}\]</div>
<p>and subsequently, the chained PDF is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathbb{P}\left(X_1 = x_1, X_2 = x_2 \mid Y = k ; \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\right) &amp;= \prod_{d=1}^D \mathbb{P}\left(X_d = x_d \mid Y = k ; \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\right) \\
&amp;= \mathbb{P}\left(X_1 = x_1 \mid Y = k ; \boldsymbol{\pi}_{\{X_1 \mid Y\}}\right) \mathbb{P}\left(X_2 = x_2 \mid Y = k ; \boldsymbol{\theta}_{\{X_2 \mid Y\}}\right) \\
&amp;= \pi_{\{X_1 \mid Y=k\}}^{x_1} (1 - \pi_{\{X_1 \mid Y=k\}})^{1 - x_1} \mathcal{N}(x_2 \mid \mu_{\{X_2 \mid Y=k\}}, \sigma_{\{X_2 \mid Y=k\}}^2)
\end{align*}
\end{split}\]</div>
<p>See more details in <a class="reference external" href="https://dafriedman97.github.io/mlbook/content/c4/concept.html">Machine Learning from Scratch</a>.</p>
</section>
</section>
<section id="model-fitting">
<h2><a class="toc-backref" href="#id33" role="doc-backlink">Model Fitting</a><a class="headerlink" href="#model-fitting" title="Link to this heading">#</a></h2>
<p>We have so far laid out the model prediction process, the implicit and explicit assumptions, as well as
the model parameters.</p>
<p>Now, we need to figure out how to fit the model parameters to the data. After all, once we
find the model parameters that best fit the data, we can use the model to make predictions
using matrix <span class="math notranslate nohighlight">\(\mathbf{M_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{M_3}\)</span> as defined in <a class="reference internal" href="#naive-bayes-inference-algorithm">Algorithm 4</a>.</p>
<section id="fitting-algorithm">
<h3><a class="toc-backref" href="#id34" role="doc-backlink">Fitting Algorithm</a><a class="headerlink" href="#fitting-algorithm" title="Link to this heading">#</a></h3>
<div class="proof algorithm admonition" id="prf:naive-bayes-estimation-algorithm">
<p class="admonition-title"><span class="caption-number">Algorithm 5 </span> (Naive Bayes Estimation Algorithm)</p>
<section class="algorithm-content" id="proof-content">
<p>For each entry in matrix <span class="math notranslate nohighlight">\(\mathbf{M_1}\)</span>, we seek to find its corresponding estimated parameter vector <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\pi}}\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-estimation-1">
<span class="eqno">(71)<a class="headerlink" href="#equation-eq-naive-bayes-estimation-1" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\hat{\boldsymbol{\pi}} &amp;= \begin{bmatrix} \hat{\pi}_1 \\ \vdots \\ \hat{\pi}_K \end{bmatrix}_{K \times 1} \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{\pi}_k\)</span> is the estimated (empirical) probability of class <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>For each entry in matrix <span class="math notranslate nohighlight">\(\mathbf{M_3}\)</span>, we seek to find its corresponding estimated parameter matrix <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}_{\{\mathbf{X} \mid Y\}}\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-estimation-2">
<span class="eqno">(72)<a class="headerlink" href="#equation-eq-naive-bayes-estimation-2" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\hat{\boldsymbol{\theta}}_{\{\mathbf{X} \mid Y\}} &amp;= \begin{bmatrix} \hat{\boldsymbol{\theta}}_{\{\mathbf{X} \mid Y=1\}} \\ \vdots \\ \hat{\boldsymbol{\theta}}_{\{\mathbf{X} \mid Y=K\}} \end{bmatrix}_{K \times D} \\
&amp;= \begin{bmatrix} \hat{\theta}_{\{X_1 \mid Y=1\}} &amp; \cdots &amp; \hat{\theta}_{\{X_D \mid Y=1\}} \\ \vdots &amp; \ddots &amp; \vdots \\ \hat{\theta}_{\{X_1 \mid Y=K\}} &amp; \cdots &amp; \hat{\theta}_{\{X_D \mid Y=K\}} \end{bmatrix}_{K \times D} \\
&amp;= \begin{bmatrix} \hat{\theta}_{11} &amp; \cdots &amp; \hat{\theta}_{1D} \\ \vdots &amp; \ddots &amp; \vdots \\ \hat{\theta}_{K1} &amp; \cdots &amp; \hat{\theta}_{KD} \end{bmatrix}_{K \times D} \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{\theta}_{kd}\)</span> is the probability of feature <span class="math notranslate nohighlight">\(X_d\)</span> given class <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>Both the underlying distribution <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> are estimated by maximizing the likelihood of the data,
using the Maximum Likelihood Estimation (MLE) method to obtain the maximum likelihood estimates (MLEs), which are denoted by <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\pi}}\)</span> and <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}_{\{\mathbf{X} \mid Y\}}\)</span> respectively.</p>
</section>
</div></section>
<section id="maximum-likelihood-estimation">
<h3><a class="toc-backref" href="#id35" role="doc-backlink">Maximum Likelihood Estimation</a><a class="headerlink" href="#maximum-likelihood-estimation" title="Link to this heading">#</a></h3>
<p>First, read chapter 8.1 of <span id="id11">[<a class="reference internal" href="../../bibliography.html#id15" title="Stanley H. Chan. Introduction to probability for Data Science. Michigan Publishing, 2021.">Chan, 2021</a>]</span> for a refresher on MLE.</p>
<div class="proof remark admonition" id="remark-univariate-mle">
<p class="admonition-title"><span class="caption-number">Remark 29 </span> (Univariate Maximum Likelihood Estimation)</p>
<section class="remark-content" id="proof-content">
<p>In <a class="reference external" href="https://dafriedman97.github.io/mlbook/content/c4/concept.html#linear-discriminative-analysis-lda">LDA</a>,
<span class="math notranslate nohighlight">\(\mathbf{X} \mid Y=k\)</span>, the distribution of the features <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> conditioned on <span class="math notranslate nohighlight">\(Y=k\)</span>, has no
assumption of conditional independence. Therefore, we need to estimate the parameters of
<span class="math notranslate nohighlight">\(\mathbf{X} = \{\mathbf{X}_1, \dots, \mathbf{X}_D\}\)</span> jointly.</p>
<p>More concretely,</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
\mathbf{X} \mid Y = k \overset{\text{i.i.d.}}{\sim} \mathcal{N}\left(\boldsymbol{\mu}_{\{X \mid Y=k\}}, \boldsymbol{\Sigma}_{\{X \mid Y=k\}}\right) \quad \forall k \in \{1, \dots, K\}
\end{align*}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_{\{X \mid Y=k\}}\)</span> is the mean vector of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> given <span class="math notranslate nohighlight">\(Y=k\)</span>, and <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_{\{X \mid Y=k\}}\)</span> is the covariance matrix of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> given <span class="math notranslate nohighlight">\(Y=k\)</span>.</p>
<p>However, in the case of Naive Bayes, the assumption of conditional independence allows us to estimate the parameters of <span class="math notranslate nohighlight">\(\mathbf{X} = \{\mathbf{X}_1, \dots, \mathbf{X}_D\}\)</span> univariately,
conditional on <span class="math notranslate nohighlight">\(Y=k\)</span>.</p>
<p>Looking at expression <a class="reference internal" href="#equation-eq-naive-bayes-estimation-2">(72)</a>, we can see that each element
is indeed univariate, and we can estimate the parameters of each element univariately.</p>
</section>
</div><p>Everything we have talked about is just 1 single sample, and that won’t work in the realm of
estimating the best parameters that fit the data. Since we are given a dataset <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>
consisting of <span class="math notranslate nohighlight">\(N\)</span> samples, we can estimate the parameters of the model by maximizing the likelihood of the data.</p>
<div class="proof definition admonition" id="def:naive-bayes-likelihood">
<p class="admonition-title"><span class="caption-number">Definition 48 </span> (Likelihood Function of Naive Bayes)</p>
<section class="definition-content" id="proof-content">
<p>Given <strong>i.i.d.</strong> random variables<a class="footnote-reference brackets" href="#iid-tuple" id="id12" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a> <span class="math notranslate nohighlight">\(\left(\mathbf{X}^{(1)}, Y^{(1)}\right), \left(\mathbf{X}^{(2)}, Y^{(2)}\right), \dots, \left(\mathbf{X}^{(N)}, Y^{(N)}\right)\)</span>,
we can write the likelihood function (joint probability distribution)
as the product of the individual PDF of each sample<a class="footnote-reference brackets" href="#iid-likelihood" id="id13" role="doc-noteref"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></a>:</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-likelihood-1">
<span class="eqno">(73)<a class="headerlink" href="#equation-eq-naive-bayes-likelihood-1" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\mathcal{L}(\boldsymbol{\theta} \mid \mathcal{D}) \overset{\mathrm{def}}{=} \mathbb{P}(\mathcal{D} ; \boldsymbol{\theta}) &amp;= \mathbb{P}\left(\mathcal{D} ; \left\{\boldsymbol{\pi}, \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}} \right\}\right) \\
&amp;\overset{(a)}{=} \mathbb{P}\left(\left(\mathbf{X}^{(1)}, Y^{(1)}\right), \left(\mathbf{X}^{(2)}, Y^{(2)}\right), \dots, \left(\mathbf{X}^{(N)}, Y^{(N)}\right) ; \left\{\boldsymbol{\pi}, \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}} \right\}\right) \\
&amp;\overset{(b)}{=} \prod_{n=1}^N  \mathbb{P}\left(Y^{(n)}=k ; \boldsymbol{\pi}\right) \mathbb{P}\left(\mathrm{X}^{(n)} \mid Y^{(n)} = k ; \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}} \right)  \\
&amp;\overset{(c)}{=} \prod_{n=1}^N  \left\{\mathbb{P}\left(Y^{(n)}=k ; \boldsymbol{\pi}\right) \prod_{d=1}^D \mathbb{P}\left(X_d^{(n)} \mid Y^{(n)} = k ; \boldsymbol{\theta}_{k, d}\right) \right\} \\
\end{align*}
\end{split}\]</div>
<p>where each <span class="math notranslate nohighlight">\(\left(\mathbf{X}^{(n)}, Y^{(n)}\right)\)</span> in equation <span class="math notranslate nohighlight">\((a)\)</span> is a sample from the dataset <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>
and can be expressed more verbosely as a joint distribution <span class="math notranslate nohighlight">\(\left(\mathbf{X}^{(n)}, Y^{(n)}\right) = \left(\mathbf{X}_1^{(n)}, \dots, \mathbf{X}_D^{(n)}, Y^{(n)}\right)\)</span>
as in <a class="reference internal" href="#equation-eq-joint-distribution">(52)</a>.</p>
<p>Equation <span class="math notranslate nohighlight">\((b)\)</span> is the product of the individual PDF of each sample, where the multiplicand is as in <a class="reference internal" href="#equation-eq-joint-distribution">(52)</a>.</p>
<p>Equation <span class="math notranslate nohighlight">\((c)\)</span> is then a consequence of <a class="reference internal" href="#equation-eq-conditional-independence-naive-bayes-1">(55)</a>.</p>
</section>
</div><p>Then we can maximize</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-likelihood-target">
<span class="eqno">(74)<a class="headerlink" href="#equation-eq-naive-bayes-likelihood-target" title="Link to this equation">#</a></span>\[
\prod_{n=1}^N  \mathbb{P}\left(Y^{(n)}=k ; \boldsymbol{\pi}\right)
\]</div>
<p>and</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-likelihood-feature">
<span class="eqno">(75)<a class="headerlink" href="#equation-eq-naive-bayes-likelihood-feature" title="Link to this equation">#</a></span>\[
\prod_{n=1}^N  \prod_{d=1}^D \mathbb{P}\left(X_d^{(n)} \middle \vert Y^{(n)} = k ; \boldsymbol{\theta}_{k, d}\right)
\]</div>
<p>individually since the above can be decomposed<a class="footnote-reference brackets" href="#decomposed-likelihood" id="id14" role="doc-noteref"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></a>.</p>
<div class="proof definition admonition" id="def:naive-bayes-log-likelihood">
<p class="admonition-title"><span class="caption-number">Definition 49 </span> (Log Likelihood Function of Naive Bayes)</p>
<section class="definition-content" id="proof-content">
<p>For numerical stability, we can take the log of the likelihood function:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\log \mathcal{L}(\boldsymbol{\theta} \mid \mathcal{D}) &amp;= \log \mathbb{P}\left(\mathcal{D} ; \left\{\boldsymbol{\pi}, \boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}} \right\}\right) \\
\end{align*}
\end{split}\]</div>
<p>where the log of the product of the individual PDF of each sample is the sum of the log of each PDF. We
will go into that later.</p>
</section>
</div><p>Stated formally,</p>
<div class="proof definition admonition" id="def:naive-bayes-max-priors">
<p class="admonition-title"><span class="caption-number">Definition 50 </span> (Maximize Priors)</p>
<section class="definition-content" id="proof-content">
<p>The notation for maximizing the prior probabilities is as follows:</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-priors">
<span class="eqno">(76)<a class="headerlink" href="#equation-eq-naive-bayes-max-priors" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\hat{\boldsymbol{\pi}} &amp;= \arg \max_{\boldsymbol{\pi}} \mathcal{L}(\boldsymbol{\pi} ; \mathcal{D}) \\
&amp;= \arg \max_{\boldsymbol{\pi}} \prod_{n=1}^N  \mathbb{P}\left(Y^{(n)}=k ; \boldsymbol{\pi}\right) \\
\end{align*}
\end{split}\]</div>
<p>A reminder that the shape of <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\pi}}\)</span> is <span class="math notranslate nohighlight">\(K \times 1\)</span>.</p>
</section>
</div><p>Similarly, we can maximize the likelihood function of the feature parameters:</p>
<div class="proof definition admonition" id="def:naive-bayes-max-feature-params">
<p class="admonition-title"><span class="caption-number">Definition 51 </span> (Maximize Feature Parameters)</p>
<section class="definition-content" id="proof-content">
<p>The notation for maximizing the feature parameters is as follows:</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-feature-params">
<span class="eqno">(77)<a class="headerlink" href="#equation-eq-naive-bayes-max-feature-params" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\hat{\boldsymbol{\theta}}_{\{\mathbf{X} \mid Y\}} &amp;= \arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \mathcal{L}(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}} ; \mathcal{D}) \\
&amp;= \arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \prod_{n=1}^N  \prod_{d=1}^D \mathbb{P}\left(X_d^{(n)} \mid Y^{(n)} = k ; \boldsymbol{\theta}_{k, d}\right) \\
\end{align*}
\end{split}\]</div>
<p>A reminder that the shape of <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}_{\{\mathbf{X} \mid Y\}}\)</span> is <span class="math notranslate nohighlight">\(K \times D\)</span>.</p>
</section>
</div></section>
<section id="estimating-priors">
<h3><a class="toc-backref" href="#id36" role="doc-backlink">Estimating Priors</a><a class="headerlink" href="#estimating-priors" title="Link to this heading">#</a></h3>
<p>Before we start the formal estimation process, it is intuitive to think that the prior probabilities <span class="math notranslate nohighlight">\(\boldsymbol{\pi}_k\)</span> should be proportional to the number of samples in each class. In other words, if we have <span class="math notranslate nohighlight">\(N_1\)</span> samples in class 1, <span class="math notranslate nohighlight">\(N_2\)</span> samples in class 2, and so on, then we should have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\pi_1 &amp;\propto N_1 \\
\pi_2 &amp;\propto N_2 \\
\vdots &amp; \quad \vdots \\
\pi_K &amp;\propto N_K
\end{align*}
\end{split}\]</div>
<p>For instance, if we have a dataset with <span class="math notranslate nohighlight">\(N=100\)</span> samples with <span class="math notranslate nohighlight">\(K=3\)</span> classes, and <span class="math notranslate nohighlight">\(N_1 = 10\)</span>, <span class="math notranslate nohighlight">\(N_2 = 30\)</span> and <span class="math notranslate nohighlight">\(N_3 = 60\)</span>, then we should have <span class="math notranslate nohighlight">\(\pi_1 = \frac{10}{100} = 0.1\)</span>, <span class="math notranslate nohighlight">\(\pi_2 = \frac{30}{100} = 0.3\)</span> and <span class="math notranslate nohighlight">\(\pi_3 = \frac{60}{100} = 0.6\)</span>. This is just the relative frequency of each class and
seems to be a sensible choice.</p>
<p>It turns out our intuition matches the formal estimation process derived from the maximum likelihood estimation (MLE) principle.</p>
</section>
<section id="maximum-likelihood-estimation-for-priors-categorical-distribution">
<h3><a class="toc-backref" href="#id37" role="doc-backlink">Maximum Likelihood Estimation for Priors (Categorical Distribution)</a><a class="headerlink" href="#maximum-likelihood-estimation-for-priors-categorical-distribution" title="Link to this heading">#</a></h3>
<p>We have seen earlier that we can maximize the priors and likelihood (target and feature parameters) separately.</p>
<p>Let’s start with the priors. Let’s state the expression from <a class="reference internal" href="#equation-eq-naive-bayes-max-priors">(76)</a> in definition
<a class="reference internal" href="#def:naive-bayes-max-priors">Definition 50</a> again:</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-priors-repeated">
<span class="eqno">(78)<a class="headerlink" href="#equation-eq-naive-bayes-max-priors-repeated" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\hat{\boldsymbol{\pi}} &amp;= \arg \max_{\boldsymbol{\pi}} \mathcal{L}(\boldsymbol{\pi} ; \mathcal{D}) \\
&amp;= \arg \max_{\boldsymbol{\pi}} \prod_{n=1}^N  \mathbb{P}\left(Y^{(n)}=k ; \boldsymbol{\pi}\right) \\
\end{align*}
\end{split}\]</div>
<p>We need to write the multiplicand in <a class="reference internal" href="#equation-eq-naive-bayes-max-priors-repeated">(78)</a> in terms of
the PDF of the Category distribution, as decribed in <a class="reference internal" href="#equation-eq-categorical-distribution-bishop">(62)</a>.
Extending from <a class="reference internal" href="#equation-eq-naive-bayes-max-priors-repeated">(78)</a>, we have:</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-priors-2">
<span class="eqno">(79)<a class="headerlink" href="#equation-eq-naive-bayes-max-priors-2" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\hat{\boldsymbol{\pi}} &amp;= \arg \max_{\boldsymbol{\pi}} \mathcal{L}(\boldsymbol{\pi} ; \mathcal{D}) \\
&amp;= \arg \max_{\boldsymbol{\pi}} \prod_{n=1}^N  \mathbb{P}\left(Y^{(n)}=k ; \boldsymbol{\pi}\right) \\
&amp;\overset{\mathrm{(a)}}{=} \arg \max_{\boldsymbol{\pi}} \prod_{n=1}^N  \left(\prod_{k=1}^K \pi_k^{y^{(n)}_k}\right) \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\left(\prod_{k=1}^K \pi_k^{y^{(n)}_k} \right)\)</span> in equation <span class="math notranslate nohighlight">\((a)\)</span> is a consequence
of the definition of the Category distribution in <a class="reference internal" href="#categorical-multinomial-distribution">Definition 47</a>.</p>
<p>Subsequently, knowing maximizing the log likelihood is the same as maximizing the likelihood, we have:</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-priors-3">
<span class="eqno">(80)<a class="headerlink" href="#equation-eq-naive-bayes-max-priors-3" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\hat{\boldsymbol{\pi}} &amp;= \arg \max_{\boldsymbol{\pi}} \mathcal{L}(\boldsymbol{\pi} ; \mathcal{D}) \\
&amp;= \arg \max_{\boldsymbol{\pi}} \log \mathcal{L}(\boldsymbol{\pi} ; \mathcal{D}) \\
&amp;\overset{\mathrm{(b)}}{=} \arg \max_{\boldsymbol{\pi}} \sum_{n=1}^N \log \left(\prod_{k=1}^K \pi_k^{y^{(n)}_k} \right) \\
&amp;\overset{\mathrm{(c)}}{=} \arg \max_{\boldsymbol{\pi}} \sum_{n=1}^N \sum_{k=1}^K y^{(n)}_k \log \pi_k \\
&amp;\overset{\mathrm{(d)}}{=} \arg \max_{\boldsymbol{\pi}} \sum_{k=1}^K N_k \log \pi_k \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(N_k\)</span> is the number of samples that belong to the <span class="math notranslate nohighlight">\(k\)</span>-th category.</p>
<div class="proof remark admonition" id="notation-overload">
<p class="admonition-title"><span class="caption-number">Remark 30 </span> (Notation Overload)</p>
<section class="remark-content" id="proof-content">
<p>We note to ourselves that we are reusing, and hence abusing the notation <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> for the log-likelihood function to be the same as the likelihood function, this is just for the ease of re-defining a new symbol for the log-likelihood function, <span class="math notranslate nohighlight">\(\log \mathcal{L}\)</span>.</p>
</section>
</div><p>Equation <span class="math notranslate nohighlight">\((b)\)</span> is derived because placing the logarithm outside the product is equivalent to summing the logarithms of the terms in the product.</p>
<p>Equation <span class="math notranslate nohighlight">\((d)\)</span> is derived by expanding equation <span class="math notranslate nohighlight">\((c)\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\sum_{n=1}^N \sum_{k=1}^K y^{(n)}_k \log \pi_k &amp;= \sum_{n=1}^N \left( \sum_{k=1}^K y^{(n)}_k \log \pi_k \right) \\
&amp;= y^{(1)}_1 \log \pi_1 + y^{(1)}_2 \log \pi_2 + \dots + y^{(1)}_K \log \pi_K \\
&amp;+ y^{(2)}_1 \log \pi_1 + y^{(2)}_2 \log \pi_2 + \dots + y^{(2)}_K \log \pi_K \\
&amp;+ \qquad \vdots \qquad \\
&amp;+ y^{(N)}_1 \log \pi_1 + y^{(N)}_2 \log \pi_2 + \dots + y^{(N)}_K \log \pi_K \\
&amp;\overset{(e)}{=} \left( y^{(1)}_1 + y^{(2)}_1 + \dots + y^{(N)}_1 \right) \log \pi_1 \\
&amp;+ \left( y^{(1)}_2 + y^{(2)}_2 + \dots + y^{(N)}_2 \right) \log \pi_2 \\
&amp;+ \qquad \vdots \qquad \\
&amp;+ \left( y^{(1)}_K + y^{(2)}_K + \dots + y^{(N)}_K \right) \log \pi_K \\
&amp;\overset{(f)}{=} N_1 \log \pi_1 + N_2 \log \pi_2 + \dots + N_K \log \pi_K \\
&amp;= \sum_{k=1}^K N_k \log \pi_k \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\((e)\)</span> is derived by summing each column, and <span class="math notranslate nohighlight">\(N_k = y^{(1)}_k + y^{(2)}_k + \dots + y^{(N)}_k\)</span>
is nothing but the number of samples that belong to the <span class="math notranslate nohighlight">\(k\)</span>-th category. One just need to recall that
if we have say 6 samples of class <span class="math notranslate nohighlight">\((0, 1, 2, 0, 1, 1)\)</span> where <span class="math notranslate nohighlight">\(K=3\)</span>, then the one-hot encoded
representation of the samples will be</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
\end{array}
\right]
\end{align*}
\end{split}\]</div>
<p>and summing each column will give us <span class="math notranslate nohighlight">\(N_1 = 2\)</span>, <span class="math notranslate nohighlight">\(N_2 = 3\)</span>, and <span class="math notranslate nohighlight">\(N_3 = 1\)</span>.</p>
<p>Now we are finally ready to solve the estimation (optimization) problem for <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-priors-4">
<span class="eqno">(81)<a class="headerlink" href="#equation-eq-naive-bayes-max-priors-4" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\hat{\boldsymbol{\pi}} &amp;= \underset{\boldsymbol{\pi}}{\mathrm{argmax}} ~~ \sum_{k=1}^K N_k \log \pi_k \\
\end{align*}
\end{split}\]</div>
<p>subject to the constraint that</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-priors-constraint">
<span class="eqno">(82)<a class="headerlink" href="#equation-eq-naive-bayes-max-priors-constraint" title="Link to this equation">#</a></span>\[
\sum_{k=1}^K \pi_k = 1
\]</div>
<p>which is just saying the probabilities must sum up to 1.</p>
<p>We can also write the expression as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\max_{\boldsymbol{\pi}} &amp;~~ \sum_{k=1}^K N_k \log \pi_k \\
\text{subject to} &amp;~~ \sum_{k=1}^K \pi_k = 1
\end{aligned}
\end{split}\]</div>
<p>This is a constrained optimization problem, and we can solve it using the Lagrangian method.</p>
<div class="proof definition admonition" id="lagrangian-method">
<p class="admonition-title"><span class="caption-number">Definition 52 </span> (Lagrangian Method)</p>
<section class="definition-content" id="proof-content">
<p>The Lagrangian method is a method to solve constrained optimization problems. The idea is to
convert the constrained optimization problem into an unconstrained optimization problem by
introducing a Lagrangian multiplier <span class="math notranslate nohighlight">\(\lambda\)</span> and then solve the unconstrained optimization
problem.</p>
<p>Given a function <span class="math notranslate nohighlight">\(f(\mathrm{x})\)</span> and a constraint <span class="math notranslate nohighlight">\(g(\mathrm{x}) = 0\)</span>, the Lagrangian function,
<span class="math notranslate nohighlight">\(\mathcal{L}(\mathrm{x}, \lambda)\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\mathcal{L}(\mathrm{x}, \lambda) &amp;= f(\mathrm{x}) - \lambda g(\mathrm{x}) \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda\)</span> is the Lagrangian multiplier and may be either positive or negative. Then,
the critical points of the Lagrangian function are the same as the critical points of the
original constrained optimization problem, i.e. setting the gradient vector of the Lagrangian
function <span class="math notranslate nohighlight">\(\nabla \mathcal{L}(\mathrm{x}, \lambda) = 0\)</span> with respect to <span class="math notranslate nohighlight">\(\mathrm{x}\)</span> and <span class="math notranslate nohighlight">\(\lambda\)</span>.</p>
</section>
</div><p>One note is that the notation of <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> seems to be overloaded again with the Lagrangian function,
we will have to change it to <span class="math notranslate nohighlight">\(\mathcal{L}_\lambda\)</span> to avoid confusion. So, to reiterate, solving the Lagrangian function is equivalent to solving the constrained optimization problem.</p>
<p>In our problem, we can convert it to Lagrangian form as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\hat{\boldsymbol{\pi}} &amp;= \underset{\boldsymbol{\pi}}{\mathrm{argmax}} ~~ \mathcal{L}_\lambda(\boldsymbol{\pi}, \lambda ; \mathcal{D}) \\
&amp;= \underset{\boldsymbol{\pi}}{\mathrm{argmax}} ~~ \underbrace{\mathcal{L}(\boldsymbol{\pi} ; \mathcal{D})}_{f(\boldsymbol{\pi})} - \lambda \left(\underbrace{\sum_{k=1}^K \pi_k - 1}_{g(\boldsymbol{\pi})} \right) \\
&amp;= \underset{\boldsymbol{\pi}}{\mathrm{argmax}} ~~ \sum_{k=1}^K N_k \log \pi_k - \lambda \left( \sum_{k=1}^K \pi_k - 1 \right) \\
\end{align*}
\end{split}\]</div>
<p>which is now an unconstrained optimization problem. Note that we used subtraction instead of addition form of the
Lagrangian function, so that we can frame it as a maximization problem (i.e. we want to reduce the “additional cost”
<span class="math notranslate nohighlight">\(\lambda\)</span>, which is a positive number, so if we add it, the expression will become a min-max problem,
we can just put a minus sign, so it become a max-max problem).</p>
<p>We can now solve it by setting the gradient vector of the Lagrangian function</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-priors-lagrangian-1">
<span class="eqno">(83)<a class="headerlink" href="#equation-eq-naive-bayes-max-priors-lagrangian-1" title="Link to this equation">#</a></span>\[
\nabla \mathcal{L}_\lambda(\boldsymbol{\pi}, \lambda ; \mathcal{D}) = 0
\]</div>
<p>with respect to <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span> and <span class="math notranslate nohighlight">\(\lambda\)</span>, as follows,</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-priors-lagrangian-2">
<span class="eqno">(84)<a class="headerlink" href="#equation-eq-naive-bayes-max-priors-lagrangian-2" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\nabla \mathcal{L}_\lambda(\boldsymbol{\pi}, \lambda ; \mathcal{D}) &amp;\overset{\mathrm{def}}{=} \frac{\partial \mathcal{L}_\lambda(\boldsymbol{\pi}, \lambda ; \mathcal{D})}{\partial \boldsymbol{\pi}} = 0 \quad \text{and} \quad \frac{\partial \mathcal{L}_\lambda(\boldsymbol{\pi}, \lambda ; \mathcal{D})}{\partial \lambda} = 0 \\
&amp;\iff \frac{\partial}{\partial \boldsymbol{\pi}} \left( \sum_{k=1}^K N_k \log \pi_k - \lambda \left( \sum_{k=1}^K \pi_k - 1 \right) \right) = 0 \quad \text{and} \quad \frac{\partial \mathcal{L}_\lambda(\boldsymbol{\pi}, \lambda ; \mathcal{D})}{\partial \lambda} = 0 \\
\\
&amp;\iff \begin{bmatrix} \frac{\partial \mathcal{L}_\lambda}{\partial \pi_1} \\ \vdots \\ \frac{\partial \mathcal{L}_\lambda}{\partial \pi_K} \end{bmatrix} = \begin{bmatrix} 0 \\ \vdots \\ 0 \end{bmatrix} \quad \text{and} \quad \frac{\partial \mathcal{L}_\lambda(\boldsymbol{\pi}, \lambda ; \mathcal{D})}{\partial \lambda} = 0 \\
&amp;\iff \begin{bmatrix} \frac{\partial}{\partial \pi_1} \left( N_1 \log \pi_1 - \lambda \left( \pi_1 - 1 \right) \right) \\ \vdots \\ \frac{\partial}{\partial \pi_K} \left( N_K \log \pi_K - \lambda \left( \pi_K - 1 \right) \right) \end{bmatrix} = \begin{bmatrix} 0 \\ \vdots \\ 0 \end{bmatrix} \quad \text{and} \quad \frac{\partial \mathcal{L}_\lambda(\boldsymbol{\pi}, \lambda ; \mathcal{D})}{\partial \lambda} = 0 \\
&amp;\iff \begin{bmatrix} \frac{N_1}{\pi_1} - \lambda \\ \vdots \\ \frac{N_K}{\pi_K} - \lambda \end{bmatrix} = \begin{bmatrix} 0 \\ \vdots \\ 0 \end{bmatrix} \quad \text{and} \quad \sum_{k=1}^K \pi_k - 1 = 0 \\
\end{align*}
\end{split}\]</div>
<p>The reason we can unpack <span class="math notranslate nohighlight">\(\frac{\partial}{\partial \pi_k}\left( \sum_{k=1}^K N_k \log \pi_k - \lambda \left( \sum_{k=1}^K \pi_k - 1 \right) \right)\)</span> as <span class="math notranslate nohighlight">\(\frac{\partial}{\partial \pi_k} \left( N_k \log \pi_k - \lambda \left( \pi_k - 1 \right) \right)\)</span> is because we are dealing with partial derivatives, so other terms other than <span class="math notranslate nohighlight">\(\pi_k\)</span> are constant.</p>
<p>Finally, we have a system of equations for each <span class="math notranslate nohighlight">\(\pi_k\)</span> and if we can solve for <span class="math notranslate nohighlight">\(\pi_k\)</span> for each <span class="math notranslate nohighlight">\(k\)</span>, we can then find the best estimate of <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span>. It turns out to solve for <span class="math notranslate nohighlight">\(\pi_k\)</span>, we have to find <span class="math notranslate nohighlight">\(\lambda\)</span> first, and this can be solved by setting <span class="math notranslate nohighlight">\(\sum_{k=1}^K \pi_k - 1 = 0\)</span> and solving for <span class="math notranslate nohighlight">\(\lambda\)</span>, which is the last equation in the system of equations above. We first express each <span class="math notranslate nohighlight">\(\pi_k\)</span> in terms of <span class="math notranslate nohighlight">\(\lambda\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{N_1}{\pi_1} - \lambda &amp;= 0 \implies \pi_1 = \frac{N_1}{\lambda} \\
\frac{N_2}{\pi_2} - \lambda &amp;= 0 \implies \pi_2 = \frac{N_2}{\lambda} \\
\vdots \\
\frac{N_K}{\pi_K} - \lambda &amp;= 0 \implies \pi_K = \frac{N_K}{\lambda} \\
\end{align*}
\end{split}\]</div>
<p>Then we substitute these expressions into the last equation in the system of equations above, and solve for <span class="math notranslate nohighlight">\(\lambda\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\sum_{k=1}^K \pi_k - 1 = 0 &amp;\implies \sum_{k=1}^K \frac{N_k}{\lambda} - 1 = 0 \\
&amp;\implies \sum_{k=1}^K \frac{N_k}{\lambda} = 1 \\
&amp;\implies \sum_{k=1}^K N_k = \lambda \\
&amp;\implies \lambda = \sum_{k=1}^K N_k \\
&amp;\implies \lambda = N \\
\end{align*}
\end{split}\]</div>
<p>and therefore, we can now solve for <span class="math notranslate nohighlight">\(\pi_k\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\hat{\pi}} = \begin{bmatrix}
\pi_1 = \frac{N_1}{N} \\ \pi_2 = \frac{N_2}{N} \\ \vdots \\ \pi_K = \frac{N_K}{N}
\end{bmatrix}_{K \times 1}
\implies \pi_k = \frac{N_k}{N} \quad \text{for} \quad k = 1, 2, \ldots, K
\end{split}\]</div>
<p>We conclude that the maximum likelihood estimate of <span class="math notranslate nohighlight">\(\boldsymbol{\pi}\)</span>
is the same as the empirical relative frequency of each class in the training data. This coincides with our intuition.</p>
<p>For completeness of expression,</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-priors-final">
<span class="eqno">(85)<a class="headerlink" href="#equation-eq-naive-bayes-max-priors-final" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\hat{\boldsymbol{\pi}} &amp;= \arg \max_{\boldsymbol{\pi}} \mathcal{L}\left( \boldsymbol{\pi} ; \mathcal{D} \right) \\
&amp;= \begin{bmatrix} \hat{\pi}_1 \\ \vdots \\ \hat{\pi}_K \end{bmatrix} \\
&amp;= \begin{bmatrix} \frac{N_1}{N} \\ \vdots \\ \frac{N_K}{N} \end{bmatrix}
\end{align*}
\end{split}\]</div>
</section>
<section id="estimating-likelihood-gaussian-version">
<h3><a class="toc-backref" href="#id38" role="doc-backlink">Estimating Likelihood (Gaussian Version)</a><a class="headerlink" href="#estimating-likelihood-gaussian-version" title="Link to this heading">#</a></h3>
<p>Intuition: The likelihood parameters are the mean and variance of each feature for each class.</p>
<section id="maximum-likelihood-estimate-for-likelihood-continuous-feature-parameters">
<h4><a class="toc-backref" href="#id39" role="doc-backlink">Maximum Likelihood Estimate for Likelihood (Continuous Feature Parameters)</a><a class="headerlink" href="#maximum-likelihood-estimate-for-likelihood-continuous-feature-parameters" title="Link to this heading">#</a></h4>
<p>Now that we have found the maximum likelihood estimate for the prior probabilities,
we now find the maximum likelihood estimate for the likelihood parameters.</p>
<p>Let’s look at the expression <a class="reference internal" href="#equation-eq-naive-bayes-max-feature-params">(77)</a> from <a class="reference internal" href="#def:naive-bayes-max-feature-params">Definition 51</a> again:</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-feature-params-repeated">
<span class="eqno">(86)<a class="headerlink" href="#equation-eq-naive-bayes-max-feature-params-repeated" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\hat{\boldsymbol{\theta}}_{\{\mathbf{X} \mid Y\}} &amp;= \arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \mathcal{L}(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}} ; \mathcal{D}) \\
&amp;= \arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \prod_{n=1}^N  \prod_{d=1}^D \mathbb{P}\left(X_d^{(n)} \middle \vert Y^{(n)} = k ; \boldsymbol{\theta}_{k, d} \right) \\
\end{align*}
\end{split}\]</div>
<p>We will give a formulation for the case when all features <span class="math notranslate nohighlight">\(X_d\)</span> are continuous. As mentioned
in <a class="reference internal" href="#continuous-features-gaussian-distribution"><span class="std std-ref">Continuous Features (Gaussian Distribution)</span></a>, we will assume that the features <span class="math notranslate nohighlight">\(X_d\)</span> given class <span class="math notranslate nohighlight">\(Y=k\)</span>
are distributed according to a Gaussian distribution.</p>
<div class="warning admonition">
<p class="admonition-title">Hand Wavy</p>
<p>This section will be a bit hand wavy as I did not derive it by hand, but one just need to remember we need
to find a total of <span class="math notranslate nohighlight">\(K \times D\)</span> parameters. Of course, in the case of Gaussian distribution, that means
we need to find a total of <span class="math notranslate nohighlight">\(K \times D \times 2\)</span> parameters, where the <span class="math notranslate nohighlight">\(2\)</span> comes from the mean and variance.</p>
</div>
<p>Before we write the multiplicand in <a class="reference internal" href="#equation-eq-naive-bayes-max-feature-params-repeated">(86)</a> in terms of the PDF
of the Gaussian distribution, we will follow Kevin Murphy’s method (pp 329) and represent</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-feature-params-kevin-murphy-1">
<span class="eqno">(87)<a class="headerlink" href="#equation-eq-naive-bayes-max-feature-params-kevin-murphy-1" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \prod_{n=1}^N  \prod_{d=1}^D \mathbb{P}\left(X_d^{(n)} \middle \vert Y^{(n)} = k ; \boldsymbol{\theta}_{k, d} \right) &amp;= \arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \prod_{n=1}^N  \prod_{k=1}^K \prod_{d=1}^D \mathbb{P}\left(X_d^{(n)} \middle \vert Y^{(n)} = k ; \boldsymbol{\theta}_{k, d} \right)^{I\left\{ Y^{(n)} = k \right\}} \\
\end{align*}
\end{split}\]</div>
<p>Then he applied the log function to both sides of <a class="reference internal" href="#equation-eq-naive-bayes-max-feature-params-kevin-murphy-1">(87)</a>,</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-feature-params-kevin-murphy-2">
<span class="eqno">(88)<a class="headerlink" href="#equation-eq-naive-bayes-max-feature-params-kevin-murphy-2" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \log \left( \prod_{n=1}^N  \prod_{k=1}^K \prod_{d=1}^D \mathbb{P}\left(X_d^{(n)} \middle \vert Y^{(n)} = k ; \boldsymbol{\theta}_{k, d} \right)^{I\left\{ Y^{(n)} = k \right\}} \right) &amp;= \arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \sum_{n=1}^N  \sum_{k=1}^K \sum_{d=1}^D I\left\{ Y^{(n)} = k \right\} \log \left( \mathbb{P}\left(X_d^{(n)} \middle \vert Y^{(n)} = k ; \boldsymbol{\theta}_{k, d} \right) \right) \\
&amp;= \arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \sum_{k=1}^K \sum_{d=1}^D \left [\sum_{n=1: Y^{(n)} = k}^N \log \left(\mathbb{P}\left(X_d^{(n)} \middle \vert Y = k ; \boldsymbol{\theta}_{k, d} \right) \right)\right]\\
\end{align*}
\end{split}\]</div>
<p>where the notation <span class="math notranslate nohighlight">\(n=1: Y^{(n)} = k\)</span> means that we are summing over all <span class="math notranslate nohighlight">\(n\)</span> where <span class="math notranslate nohighlight">\(Y^{(n)} = k\)</span>. In other words,
we are looking at all the data points where the class label is <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>We can further simplify <a class="reference internal" href="#equation-eq-naive-bayes-max-feature-params-kevin-murphy-2">(88)</a> as:</p>
<div class="math notranslate nohighlight" id="equation-eq-naive-bayes-max-feature-params-kevin-murphy-3">
<span class="eqno">(89)<a class="headerlink" href="#equation-eq-naive-bayes-max-feature-params-kevin-murphy-3" title="Link to this equation">#</a></span>\[\begin{split}
\begin{align*}
\arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \sum_{k=1}^K \sum_{d=1}^D \left [\sum_{n=1: Y^{(n)} = k}^N \log \left(\mathbb{P}\left(X_d^{(n)} \middle \vert Y = k ; \boldsymbol{\theta}_{k, d} \right) \right)\right] &amp;= \arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \sum_{k=1}^K \sum_{d=1}^D \log \mathbb{P}\left(\mathcal{D}_{dk} ; \boldsymbol{\theta}_{k, d} \right) \\
&amp;= \arg \max_{\boldsymbol{\theta}_{k, d}} \log \mathbb{P}\left(\mathcal{D}_{11} ; \boldsymbol{\theta}_{1, 1} \right) + \log \mathbb{P}\left(\mathcal{D}_{12} ; \boldsymbol{\theta}_{1, 2} \right) + \cdots + \log \mathbb{P}\left(\mathcal{D}_{1D} ; \boldsymbol{\theta}_{1, D} \right) + \log \mathbb{P}\left(\mathcal{D}_{21} ; \boldsymbol{\theta}_{2, 1} \right) + \log \mathbb{P}\left(\mathcal{D}_{22} ; \boldsymbol{\theta}_{2, 2} \right) + \cdots + \log \mathbb{P}\left(\mathcal{D}_{2D} ; \boldsymbol{\theta}_{2, D} \right) + \cdots + \log \mathbb{P}\left(\mathcal{D}_{K1} ; \boldsymbol{\theta}_{K, 1} \right) + \log \mathbb{P}\left(\mathcal{D}_{K2} ; \boldsymbol{\theta}_{K, 2} \right) + \cdots + \log \mathbb{P}\left(\mathcal{D}_{KD} ; \boldsymbol{\theta}_{K, D} \right) \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{D}_{dk}\)</span> is the data set of all the data points of feature <span class="math notranslate nohighlight">\(d\)</span> and class <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>Now we can <em><strong>individually maximize</strong></em> the parameters of each feature and class pair in <a class="reference internal" href="#equation-eq-naive-bayes-max-feature-params-kevin-murphy-3">(89)</a>, i.e. estimate <span class="math notranslate nohighlight">\(\mathcal{D}_{dk}\)</span> for each <span class="math notranslate nohighlight">\(d\)</span> and <span class="math notranslate nohighlight">\(k\)</span>.</p>
<div class="proof example admonition" id="example-naive-bayes-feature-1-class-2">
<p class="admonition-title"><span class="caption-number">Example 14 </span> (Example on Feature 1 and Class 2)</p>
<section class="example-content" id="proof-content">
<p>For example, <span class="math notranslate nohighlight">\(\mathcal{D}_{12}\)</span> refers to all the data points of feature <span class="math notranslate nohighlight">\(1\)</span> and class <span class="math notranslate nohighlight">\(2\)</span> and we can
maximize the parameters of this data set <span class="math notranslate nohighlight">\(\mathcal{D}_{12}\)</span> in a similar vein from <a class="reference internal" href="#def:naive-bayes-max-feature-params">Definition 51</a>,
but now instead of
multiplying the probabilities, we are summing the log probabilities.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\arg \max_{\theta_{1, 2}} \log \mathbb{P}\left(\mathcal{D}_{12} ; \theta_{1, 2} \right) &amp;= \arg \max_{\theta_{1, 2}} \sum_{n=1: Y^{(n)} = 2}^N \log \left(\mathbb{P}\left(X_1^{(n)} \middle \vert Y = 2 ; \theta_{1, 2} \right) \right) \\
\end{align*}
\end{split}\]</div>
<p>where we will attempt to find the best estimate <span class="math notranslate nohighlight">\(\theta_{1, 2} = \left(\mu_{2, 1}, \sigma_{2, 1} \right)\)</span> for the parameters of the Gaussian distribution of feature <span class="math notranslate nohighlight">\(1\)</span> and class <span class="math notranslate nohighlight">\(2\)</span>.</p>
<p>It turns out that the maximum likelihood estimate for the parameters of the Gaussian distribution is the sample mean and sample variance of the data set <span class="math notranslate nohighlight">\(\mathcal{D}_{12}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\hat{\theta}_{1, 2} := \arg \max_{\theta_{1, 2}} \log \mathbb{P}\left(\mathcal{D}_{12} ; \theta_{1, 2} \right) &amp;= \begin{bmatrix} \hat{\mu_{2, 1}} \\ \hat{\sigma}_{2, 1} \end{bmatrix} \\
&amp;= \begin{bmatrix} \frac{1}{N_2} \sum_{n=1}^{N_2} x_1^{(n)} \\ \sqrt{\frac{1}{N_2} \sum_{n=1}^{N_2} \left( x_1^{(n)} - \hat{\mu}_{2, 1} \right)^2} \end{bmatrix} \\
&amp;= \begin{bmatrix} \bar{x}_{2, 1} \\ s_{2, 1} \end{bmatrix} \\
\end{align*}
\end{split}\]</div>
</section>
</div><p>Now for the general form</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\hat{\theta}_{k, d} := \arg \max_{\theta_{k, d}} \log \mathbb{P}\left(\mathcal{D}_{dk} ; \theta_{k, d} \right) &amp;= \begin{bmatrix} \hat{\mu}_{k, d} \\ \hat{\sigma}_{k, d} \end{bmatrix} \\
&amp;= \begin{bmatrix} \frac{1}{N_k} \sum_{n=1}^{N_k} x_d^{(n)} \\ \sqrt{\frac{1}{N_k} \sum_{n=1}^{N_k} \left( x_d^{(n)} - \hat{\mu}_{k, d} \right)^2} \end{bmatrix} \\
&amp;= \begin{bmatrix} \bar{x}_{k, d} \\ s_{k, d} \end{bmatrix} \\
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{x}_{k, d}\)</span> is the sample mean of the data set <span class="math notranslate nohighlight">\(\mathcal{D}_{dk}\)</span> and <span class="math notranslate nohighlight">\(s_{k, d}\)</span> is the sample standard deviation of the data set <span class="math notranslate nohighlight">\(\mathcal{D}_{dk}\)</span>.</p>
<p>For completeness, the parameter matrix <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}\)</span> defined in <a class="reference internal" href="#equation-eq-naive-bayes-estimation-2">(72)</a> becomes:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}} &amp;= \begin{bmatrix} \boldsymbol{\theta}_{11} &amp; \boldsymbol{\theta}_{12} &amp; \cdots &amp; \boldsymbol{\theta}_{1D} \\ \boldsymbol{\theta}_{21} &amp; \boldsymbol{\theta}_{22} &amp; \cdots &amp; \boldsymbol{\theta}_{2D} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \boldsymbol{\theta}_{K1} &amp; \boldsymbol{\theta}_{K2} &amp; \cdots &amp; \boldsymbol{\theta}_{KD} \end{bmatrix} \\
&amp;= \begin{bmatrix} \left(\bar{x}_{1, 1}, s_{1, 1} \right) &amp; \left(\bar{x}_{1, 2}, s_{1, 2} \right) &amp; \cdots &amp; \left(\bar{x}_{1, D}, s_{1, D} \right) \\ \left(\bar{x}_{2, 1}, s_{2, 1} \right) &amp; \left(\bar{x}_{2, 2}, s_{2, 2} \right) &amp; \cdots &amp; \left(\bar{x}_{2, D}, s_{2, D} \right) \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \left(\bar{x}_{K, 1}, s_{K, 1} \right) &amp; \left(\bar{x}_{K, 2}, s_{K, 2} \right) &amp; \cdots &amp; \left(\bar{x}_{K, D}, s_{K, D} \right) \end{bmatrix} \\
\end{align*}
\end{split}\]</div>
<hr class="docutils" />
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp;= \arg \max_{\boldsymbol{\theta}_{\{\mathbf{X} \mid Y\}}} \sum_{k=1}^K \sum_{d=1}^D \left [\sum_{n=1: Y^{(n)} = k}^N \log \left(\frac{1}{\sqrt{2 \pi \sigma_{k, d}^2}} \exp \left( -\frac{1}{2 \sigma_{k, d}^2} \left( X_d^{(n)} - \mu_{k, d} \right)^2 \right) \right)\right] \\
\end{align*}
\end{split}\]</div>
<p>See derivations from section 4.2.5 and 4.2.6 of Probabilistic Machine Learning: An Introduction by Kevin Murphy
for the univariate and multivariate Gaussian case respectively.</p>
</section>
</section>
</section>
<section id="decision-boundary">
<h2><a class="toc-backref" href="#id40" role="doc-backlink">Decision Boundary</a><a class="headerlink" href="#decision-boundary" title="Link to this heading">#</a></h2>
<figure class="align-default" id="fig-naive-bayes-linear">
<img alt="../../_images/cs4780_lecture5_naive_bayes.png" src="../../_images/cs4780_lecture5_naive_bayes.png" />
<figcaption>
<p><span class="caption-number">Fig. 15 </span><span class="caption-text">Naive Bayes leads to a linear decision boundary in many common cases. Illustrated here is the case where <span class="math notranslate nohighlight">\(P\left(x_\alpha \mid y\right)\)</span> is Gaussian and where <span class="math notranslate nohighlight">\(\sigma_{\alpha, c}\)</span> is identical for all <span class="math notranslate nohighlight">\(c\)</span> (but can differ across dimensions <span class="math notranslate nohighlight">\(\alpha\)</span> ). The boundary of the ellipsoids indicate regions of equal probabilities <span class="math notranslate nohighlight">\(P(\mathbf{x} \mid y)\)</span>. The red decision line indicates the decision boundary where <span class="math notranslate nohighlight">\(P(y=1 \mid \mathbf{x})=P(y=2 \mid \mathbf{x})\)</span>.. Image Credit: <a class="reference external" href="https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote05.html">CS 4780</a></span><a class="headerlink" href="#fig-naive-bayes-linear" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Here <span class="math notranslate nohighlight">\(\alpha\)</span> is just index <span class="math notranslate nohighlight">\(d\)</span>.</p>
<p>Suppose that <span class="math notranslate nohighlight">\(y_i \in\{-1,+1\}\)</span> and features are multinomial
We can show that</p>
<div class="math notranslate nohighlight">
\[
h(\mathbf{x})=\underset{y}{\operatorname{argmax}} P(y) \prod_{\alpha-1}^d P\left(x_\alpha \mid y\right)=\operatorname{sign}\left(\mathbf{w}^{\top} \mathbf{x}+b\right)
\]</div>
<p>That is,</p>
<div class="math notranslate nohighlight">
\[
\mathbf{w}^{\top} \mathbf{x}+b&gt;0 \Longleftrightarrow h(\mathbf{x})=+1 .
\]</div>
<p>As before, we define <span class="math notranslate nohighlight">\(P\left(x_\alpha \mid y=+1\right) \propto \theta_{\alpha+}^{x_\alpha}\)</span> and <span class="math notranslate nohighlight">\(P(Y=+1)=\pi_{+}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
{[\mathbf{w}]_\alpha } &amp; =\log \left(\theta_{\alpha+}\right)-\log \left(\theta_{\alpha-}\right) \\
b &amp; =\log \left(\pi_{+}\right)-\log \left(\pi_{-}\right)
\end{aligned}
\end{split}\]</div>
<p>If we use the above to do classification, we can compute for <span class="math notranslate nohighlight">\(\mathbf{w}^{\top} \cdot \mathbf{x}+b\)</span>
Simplifying this further leads to</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp; \mathbf{w}^{\top} \mathbf{x}+b&gt;0 \Longleftrightarrow \sum_{\alpha=1}^d[\mathbf{x}]_\alpha \overbrace{\left(\log \left(\theta_{\alpha+}\right)-\log \left(\theta_{\alpha-}\right)\right)}^{\left[\mathbf{w}]_\alpha\right.}+\overbrace{\log \left(\pi_{+}\right)-\log \left(\pi_{-}\right)}^b&gt;0 \quad \text{ (Plugging in definition of w,b.) } \\
&amp; \Longleftrightarrow \exp \left(\sum_{\alpha=1}^d[\mathbf{x}]_\alpha\left(\log \left(\theta_{\alpha+}\right)-\log \left(\theta_{\alpha-}\right)\right)+\log \left(\pi_{+}\right)-\log \left(\pi_{-}\right)\right)&gt;1 \quad \text { (exponentiating both sides) } \\
&amp; \Longleftrightarrow \prod_{\alpha=1}^d \frac{\exp \left(\log \theta_{\alpha+}^{[\mathbf{x}]_\alpha}+\log \left(\pi_{+}\right)\right)}{\exp \left(\log \theta_{\alpha-}^{[\mathbf{x}]_\alpha}+\log \left(\pi_{-}\right)\right)}&gt;1 \quad \text{ (Because $a \log (b)=\log \left(b^a\right)$ and $\exp (a-b)=\frac{e^a}{e^b}$ operations) } \\
&amp; \Longleftrightarrow \prod_{\alpha=1}^d \frac{\theta_{\alpha+}^{[\mathbf{x}]_\alpha} \pi_{+}}{\theta_{\alpha-}^{[\mathbf{x}]_\alpha} \pi_{-}}&gt;1 \quad \text{ (Because $\exp (\log (a))=a$ and $e^{a+b}=e^a e^b$) } \\
&amp; \Longleftrightarrow \frac{\prod_{\alpha=1}^d P\left([\mathbf{x}]_\alpha \mid Y=+1\right) \pi_{+}}{\prod_{\alpha=1}^d P\left([\mathbf{x}]_\alpha \mid Y=-1\right) \pi_{-}}&gt;1 \quad \text{ (Because $P\left([\mathbf{x}]_\alpha \mid Y=-1\right)=\theta_{\alpha-}^{\mathbf{x}]_\alpha}$) } \\
&amp; \Longleftrightarrow \frac{P(\mathbf{x} \mid Y=+1) \pi_{+}}{P(\mathbf{x} \mid Y=-1) \pi_{-}}&gt;1 \quad \text{ (By the naive Bayes assumption.) } \\
&amp; \Longleftrightarrow \frac{P(Y=+1 \mid \mathbf{x})}{P(Y=-1 \mid \mathbf{x})}&gt;1 \quad \text{ (By Bayes rule (the denominator $P(\mathbf{x})$ cancels out, and $\pi_{+}=P(Y=+1)$.)) } \\
&amp; \Longleftrightarrow P(Y=+1 \mid \mathbf{x})&gt;P(Y=-1 \mid \mathbf{x}) \\
&amp; \Longleftrightarrow \underset{y}{\operatorname{argmax}} P(Y=y \mid \mathbf{x})=+1 \quad \text{ (the point x lies on the positive side of the hyperplane iff Naive Bayes predicts +1) } \\
&amp;
\end{aligned}
\end{split}\]</div>
<section id="connection-with-logistic-regression">
<h3><a class="toc-backref" href="#id41" role="doc-backlink">Connection with Logistic Regression</a><a class="headerlink" href="#connection-with-logistic-regression" title="Link to this heading">#</a></h3>
<p>In the case of continuous features (Gaussian Naive Bayes), when the variance is independent of the class <span class="math notranslate nohighlight">\(\left(\sigma_{\alpha c}\right.\)</span> is identical for all <span class="math notranslate nohighlight">\(c\)</span> ), we can show that</p>
<div class="math notranslate nohighlight">
\[
P(y \mid \mathbf{x})=\frac{1}{1+e^{-y\left(\mathbf{w}^{\top} \mathbf{x}+b\right)}}
\]</div>
<p>This model is also known as logistic regression. <span class="math notranslate nohighlight">\(N B\)</span> and <span class="math notranslate nohighlight">\(L R\)</span> produce asymptotically the same model if the Naive Bayes assumption holds.</p>
<p>See more proofs below:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote05.html">https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote05.html</a>.</p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/142215/how-is-naive-bayes-a-linear-classifier">https://stats.stackexchange.com/questions/142215/how-is-naive-bayes-a-linear-classifier</a></p></li>
<li><p>Section 9.3.4 of Probabilistic Machine Learning: An Introduction.</p></li>
</ul>
</section>
</section>
<section id="time-and-space-complexity">
<h2><a class="toc-backref" href="#id42" role="doc-backlink">Time and Space Complexity</a><a class="headerlink" href="#time-and-space-complexity" title="Link to this heading">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(N\)</span> be the number of training samples, <span class="math notranslate nohighlight">\(D\)</span> be the number of features, and <span class="math notranslate nohighlight">\(K\)</span> be the number of classes.</p>
<p>During training, the time complexity is <span class="math notranslate nohighlight">\(\mathcal{O}(NKD)\)</span> if we are using a brute force approach.
In my <a class="reference external" href="https://github.com/gao-hongnan/gaohn-probability-stats/blob/naive-bayes/src/generative/naive_bayes/naive_bayes.py">implementation</a>,
the main training loop is in <code class="docutils literal notranslate"><span class="pre">_estimate_prior_parameters</span></code> and <code class="docutils literal notranslate"><span class="pre">_estimate_likelihood_parameters</span></code> methods.</p>
<p>In the former, we are looping through the classes <span class="math notranslate nohighlight">\(K\)</span> times, but a hidden operation is calculating the
sum of the class counts, which is <span class="math notranslate nohighlight">\(\mathcal{O}(N)\)</span>, so the time complexity is <span class="math notranslate nohighlight">\(\mathcal{O}(NK)\)</span>, using the
vectorized operation <code class="docutils literal notranslate"><span class="pre">np.sum</span></code> helps speed up a bit.</p>
<p>In the latter, we are looping through the classes <span class="math notranslate nohighlight">\(K\)</span> times, and for each class, we are looping through
the features <span class="math notranslate nohighlight">\(D\)</span> times, and in each feature loop, we are calculating the mean and variance of the feature,
so the operation of calculating the mean and variance is <span class="math notranslate nohighlight">\(\mathcal{O}(N) + \mathcal{O}(N)\)</span> respectively, bringing the time complexity
to <span class="math notranslate nohighlight">\(\mathcal{O}(2NKD) \approx \mathcal{O}(NKD)\)</span>. Even though we are using <code class="docutils literal notranslate"><span class="pre">np.mean</span></code> and <code class="docutils literal notranslate"><span class="pre">np.var</span></code> to speed up, the time complexity
for brute force approach is still <span class="math notranslate nohighlight">\(\mathcal{O}(NKD)\)</span>.</p>
<p>For the space complexity, we are storing the prior parameters and likelihood parameters, which are of size <span class="math notranslate nohighlight">\(K\)</span> and <span class="math notranslate nohighlight">\(KD\)</span> respectively,
in code, that corresponds to <code class="docutils literal notranslate"><span class="pre">self.pi</span></code> and <code class="docutils literal notranslate"><span class="pre">self.theta</span></code>, so the space complexity is <span class="math notranslate nohighlight">\(\mathcal{O}(K + KD) \approx \mathcal{O}(KD)\)</span>.</p>
<p>During inference/prediction, the time complexity for predicting one single sample
is <span class="math notranslate nohighlight">\(\mathcal{O}(KD)\)</span>, because the <code class="docutils literal notranslate"><span class="pre">predict_one_sample</span></code> method primarily calls the <code class="docutils literal notranslate"><span class="pre">_calculate_posterior</span></code> method, which in
turn invokes <code class="docutils literal notranslate"><span class="pre">_calculate_prior</span></code> and <code class="docutils literal notranslate"><span class="pre">_calculate_joint_likelihood</span></code> methods, and the time complexity of these two methods
is <span class="math notranslate nohighlight">\(\mathcal{O}(1)\)</span> and <span class="math notranslate nohighlight">\(\mathcal{O}(KD)\)</span> respectively. For <code class="docutils literal notranslate"><span class="pre">_calculate_prior</span></code>, it just involves us looking up the
<code class="docutils literal notranslate"><span class="pre">self.prior</span></code> parameter, which is a constant time operation. For <code class="docutils literal notranslate"><span class="pre">_calculate_joint_likelihood</span></code>, it involves us looping through
the class <span class="math notranslate nohighlight">\(K\)</span> times and looping through the features <span class="math notranslate nohighlight">\(D\)</span> times, so the time complexity is <span class="math notranslate nohighlight">\(\mathcal{O}(KD)\)</span>, the <code class="docutils literal notranslate"><span class="pre">mean</span></code>
and <code class="docutils literal notranslate"><span class="pre">var</span></code> parameters are now constant time since they are just looked up from <code class="docutils literal notranslate"><span class="pre">self.theta</span></code>. There is however a <code class="docutils literal notranslate"><span class="pre">np.prod</span></code> operation
towards the end, but the overall time complexity should still be in the order of <span class="math notranslate nohighlight">\(\mathcal{O}(KD)\)</span>.</p>
<p>For the space complexity, besides the stored (not counted) parameters, we are storing the posterior probabilities, which is of size <span class="math notranslate nohighlight">\(K\)</span>,
in code, that corresponds to <code class="docutils literal notranslate"><span class="pre">self.posterior</span></code>, so the space complexity is <span class="math notranslate nohighlight">\(\mathcal{O}(K)\)</span>, and if <span class="math notranslate nohighlight">\(K\)</span> is small, then the space complexity
is <span class="math notranslate nohighlight">\(\mathcal{O}(1)\)</span>.</p>
<div class="pst-scrollable-table-container"><table class="table" id="time-complexity-naive-bayes">
<caption><span class="caption-number">Table 12 </span><span class="caption-text">Time Complexity of Naive Bayes</span><a class="headerlink" href="#time-complexity-naive-bayes" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Train</p></th>
<th class="head"><p>Inference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\mathcal{O}(NKD)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mathcal{O}(KD)\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<div class="pst-scrollable-table-container"><table class="table" id="space-complexity-naive-bayes">
<caption><span class="caption-number">Table 13 </span><span class="caption-text">Space Complexity of Naive Bayes</span><a class="headerlink" href="#space-complexity-naive-bayes" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Train</p></th>
<th class="head"><p>Inference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\mathcal{O}(KD)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mathcal{O}(1)\)</span></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="references">
<h2><a class="toc-backref" href="#id43" role="doc-backlink">References</a><a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J. “Chapter 22.7 Maximum Likelihood.” In Dive into Deep Learning, 2021.</p></li>
<li><p>Chan, Stanley H. “Chapter 8.1. Maximum-Likelihood Estimation.” In Introduction to Probability for Data Science, 172-180. Ann Arbor, Michigan: Michigan Publishing Services, 2021</p></li>
<li><p>Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J. “Chapter 22.9 Naive Bayes.” In Dive into Deep Learning, 2021.</p></li>
<li><p>Hal Daumé III. “Chapter 9.3. Naive Bayes Models.” In A Course in Machine Learning, January 2017.</p></li>
<li><p>Murphy, Kevin P. “Chapter 9.3. Naive Bayes Models.” In Probabilistic Machine Learning: An Introduction. Cambridge (Massachusetts): The MIT Press, 2022.</p></li>
<li><p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. “Chapter 4.4.4. Naive Bayes” In An Introduction to Statistical Learning: With Applications in R. Boston: Springer, 2022.</p></li>
<li><p>Mitchell, Tom Michael. Machine Learning. New York: McGraw-Hill, 1997. (His new chapter on Generate and Discriminative Classifiers: Naive Bayes and Logistic Regression)</p></li>
<li><p>Jurafsky, Dan, and James H. Martin. “Chapter 4. Naive Bayes and Sentiment Classification” In Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition. Noida: Pearson, 2022.</p></li>
<li><p>Bishop, Christopher M. “Chapter 4.2. Probabilistic Generative Models.” In Pattern Recognition and Machine Learning. New York: Springer-Verlag, 2016</p></li>
</ul>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="intractable" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Cite Dive into Deep Learning on this. Also, the joint probability is intractable because the number of parameters to estimate is exponential in the number of features. Use binary bits example, see my notes.</p>
</aside>
<aside class="footnote brackets" id="likelihood-1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Not to be confused with the likelihood term <span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{X} \mid Y)\)</span> in Bayes’ terminology.</p>
</aside>
<aside class="footnote brackets" id="joint-distribution" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Joint_probability_distribution#Discrete_case">Joint Probability Distribution</a></p>
</aside>
<aside class="footnote brackets" id="chain-rule-of-probability" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">4</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Chain_rule_(probability)">Chain Rule of Probability</a></p>
</aside>
<aside class="footnote brackets" id="dparameters" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">5</a><span class="fn-bracket">]</span></span>
<p>Dive into Deep Learning, Section 22.9, this is only assuming that each feature <span class="math notranslate nohighlight">\(\mathbf{x}_d^{(n)}\)</span> is binary, i.e. <span class="math notranslate nohighlight">\(\mathbf{x}_d^{(n)} \in \{0, 1\}\)</span>.</p>
</aside>
<aside class="footnote brackets" id="id15" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">6</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Conditional_independence">Conditional Independence</a></p>
</aside>
<aside class="footnote brackets" id="kdparameters" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">7</a><span class="fn-bracket">]</span></span>
<p>Probablistic Machine Learning: An Introduction, Section 9.3, pp 328</p>
</aside>
<aside class="footnote brackets" id="categorical-distribution" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">8</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Categorical_distribution">Category Distribution</a></p>
</aside>
<aside class="footnote brackets" id="iid-tuple" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">9</a><span class="fn-bracket">]</span></span>
<p><span class="math notranslate nohighlight">\(\left(\mathbf{X}^{(n)}, Y^{(1)}\right)\)</span> is written as a tuple, when in fact they can be considered 1 single variable.</p>
</aside>
<aside class="footnote brackets" id="iid-likelihood" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">10</a><span class="fn-bracket">]</span></span>
<p>Refer to page 470 of <span id="id16">[<a class="reference internal" href="../../bibliography.html#id15" title="Stanley H. Chan. Introduction to probability for Data Science. Michigan Publishing, 2021.">Chan, 2021</a>]</span>. Note that we cannot write it as a product if the data is not independent and identically distributed.</p>
</aside>
<aside class="footnote brackets" id="decomposed-likelihood" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">11</a><span class="fn-bracket">]</span></span>
<p>Cite Kevin Murphy and Bishop.</p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./influential/naive_bayes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="01_intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Naive Bayes</p>
      </div>
    </a>
    <a class="right-next"
       href="03_implementation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Naives Bayes Implementation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#notations">Notations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discriminative-vs-generative">Discriminative vs Generative</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-setup">Naive Bayes Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-prediction">Inference/Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-naive-bayes-form">The Naive Bayes Form</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-form">Simple Form</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extended-form">Extended form</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-naive-bayes-assumptions">The Naive Bayes Assumptions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#independent-and-identically-distributed-i-i-d">Independent and Identically Distributed (i.i.d.)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-independence">Conditional Independence</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-vector">Parameter Vector</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inductive-bias-distribution-assumptions">Inductive Bias (Distribution Assumptions)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#targets-categorical-distribution">Targets (Categorical Distribution)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-features-categorical-distribution">Discrete Features (Categorical Distribution)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-features-gaussian-distribution">Continuous Features (Gaussian Distribution)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mixed-features-discrete-and-continuous">Mixed Features (Discrete and Continuous)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-fitting">Model Fitting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-algorithm">Fitting Algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimation">Maximum Likelihood Estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-priors">Estimating Priors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimation-for-priors-categorical-distribution">Maximum Likelihood Estimation for Priors (Categorical Distribution)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-likelihood-gaussian-version">Estimating Likelihood (Gaussian Version)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimate-for-likelihood-continuous-feature-parameters">Maximum Likelihood Estimate for Likelihood (Continuous Feature Parameters)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-boundary">Decision Boundary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#connection-with-logistic-regression">Connection with Logistic Regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-and-space-complexity">Time and Space Complexity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gao Hongnan
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>