
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Concept: Learning Theory &#8212; Omniverse</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=bb35926c" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../../_static/tabs.js?v=3ee01567"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-MYW5YKC2WF"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-MYW5YKC2WF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-MYW5YKC2WF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"defeq": "\\overset{\\text{def}}{=}", "defa": "\\overset{\\text{(a)}}{=}", "defb": "\\overset{\\text{(b)}}{=}", "defc": "\\overset{\\text{(c)}}{=}", "defd": "\\overset{\\text{(d)}}{=}", "st": "\\mid", "mod": "\\mid", "S": "\\Omega", "s": "\\omega", "e": "\\exp", "P": "\\mathbb{P}", "R": "\\mathbb{R}", "expectation": "\\mathbb{E}", "v": "\\mathbf{v}", "a": "\\mathbf{a}", "b": "\\mathbf{b}", "c": "\\mathbf{c}", "u": "\\mathbf{u}", "w": "\\mathbf{w}", "x": "\\mathbf{x}", "y": "\\mathbf{y}", "z": "\\mathbf{z}", "0": "\\mathbf{0}", "1": "\\mathbf{1}", "A": "\\mathbf{A}", "B": "\\mathbf{B}", "C": "\\mathbf{C}", "E": "\\mathcal{F}", "eventA": "\\mathcal{A}", "lset": "\\left\\{", "rset": "\\right\\}", "lsq": "\\left[", "rsq": "\\right]", "lpar": "\\left(", "rpar": "\\right)", "lcurl": "\\left\\{", "rcurl": "\\right\\}", "pmf": "p_X", "pdf": "f_X", "pdftwo": "f_{X,Y}", "pdfjoint": "f_{\\mathbf{X}}", "pmfjointxy": "p_{X, Y}", "pdfjointxy": "f_{X, Y}", "cdf": "F_X", "pspace": "(\\Omega, \\mathcal{F}, \\mathbb{P})", "var": "\\operatorname{Var}", "std": "\\operatorname{Std}", "bern": "\\operatorname{Bernoulli}", "binomial": "\\operatorname{Binomial}", "geometric": "\\operatorname{Geometric}", "poisson": "\\operatorname{Poisson}", "uniform": "\\operatorname{Uniform}", "normal": "\\operatorname{Normal}", "gaussian": "\\operatorname{Gaussian}", "gaussiansymbol": "\\mathcal{N}", "exponential": "\\operatorname{Exponential}", "iid": "\\textbf{i.i.d.}", "and": "\\text{and}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'influential/learning_theory/02_concept';</script>
    <link rel="canonical" href="https://www.gaohongnan.com/influential/learning_theory/02_concept.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Lloyd’s K-Means Clustering Algorithm" href="../kmeans_clustering/01_intro.html" />
    <link rel="prev" title="Is The Learning Problem Solvable?" href="01_intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Omniverse - Home"/>
    <img src="../../_static/logo.png" class="logo__image only-dark pst-js-only" alt="Omniverse - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Omniverse
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Notations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notations/machine_learning.html">Machine Learning Notations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Influential Ideas and Papers</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../generative_pretrained_transformer/01_intro.html">Generative Pre-trained Transformers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/02_notations.html">Notations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/03_concept.html">The Concept of Generative Pre-trained Transformers (GPT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/04_implementation.html">The Implementation of Generative Pre-trained Transformers (GPT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generative_pretrained_transformer/05_adder.html">Training a Mini-GPT to Learn Two-Digit Addition</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../low_rank_adaptation/01_intro.html">Low-Rank Adaptation Of Large Language Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../low_rank_adaptation/02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../low_rank_adaptation/03_implementation.html">Implementation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../empirical_risk_minimization/01_intro.html">Empirical Risk Minimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../empirical_risk_minimization/02_concept.html">Concept: Empirical Risk Minimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../empirical_risk_minimization/03_bayes_optimal_classifier.html">Bayes Optimal Classifier</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="01_intro.html">Is The Learning Problem Solvable?</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Concept: Learning Theory</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../kmeans_clustering/01_intro.html">Lloyd’s K-Means Clustering Algorithm</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/02_concept.html">Concept: K-Means Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/03_implementation.html">Implementation: K-Means (Lloyd)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/04_image_segmentation.html">Application: Image Compression and Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kmeans_clustering/05_conceptual_questions.html">Conceptual Questions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../naive_bayes/01_intro.html">Naive Bayes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../naive_bayes/02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../naive_bayes/03_implementation.html">Naives Bayes Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../naive_bayes/04_example_penguins.html">Naive Bayes Application: Penguins</a></li>
<li class="toctree-l2"><a class="reference internal" href="../naive_bayes/05_application_mnist.html">Naive Bayes Application (MNIST)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../gaussian_mixture_models/01_intro.html">Mixture Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_mixture_models/02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gaussian_mixture_models/03_implementation.html">Gaussian Mixture Models Implementation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../linear_regression/01_intro.html">Linear Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../linear_regression/02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_regression/03_implementation.html">Implementation</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Playbook</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../playbook/training/intro.html">Training Dynamics And Tricks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_calculate_flops_in_transformer_based_models.html">How to Calculate the Number of FLOPs in Transformer Based Models?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/why_cosine_annealing_warmup_stabilize_training.html">Why Does Cosine Annealing With Warmup Stabilize Training?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_finetune_decoder_with_last_token_pooling.html">How To Fine-Tune Decoder-Only Models For Sequence Classification Using Last Token Pooling?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_finetune_decoder_with_cross_attention.html">How To Fine-Tune Decoder-Only Models For Sequence Classification With Cross-Attention?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../playbook/training/how_to_teacher_student_knowledge_distillation.html">How To Do Teacher-Student Knowledge Distillation?</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/why_softmax_preserves_order_translation_invariant_not_invariant_scaling.html">Softmax Preserves Order, Is Translation Invariant But Not Invariant Under Scaling.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../playbook/how_to_inspect_function_and_class_signatures.html">How to Inspect Function and Class Signatures in Python?</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Probability Theory</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/intro.html">Chapter 1. Mathematical Preliminaries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/01_combinatorics.html">Permutations and Combinations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/02_calculus.html">Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/03_contours.html">Contour Maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/01_mathematical_preliminaries/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/02_probability/intro.html">Chapter 2. Probability</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0202_probability_space.html">Probability Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0203_probability_axioms.html">Probability Axioms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0204_conditional_probability.html">Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0205_independence.html">Independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/0206_bayes_theorem.html">Baye’s Theorem and the Law of Total Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/02_probability/summary.html">Summary</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/intro.html">Chapter 3. Discrete Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0301_random_variables.html">Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0302_discrete_random_variables.html">Discrete Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0303_probability_mass_function.html">Probability Mass Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0304_cumulative_distribution_function.html">Cumulative Distribution Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0305_expectation.html">Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/0306_moments_and_variance.html">Moments and Variance</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/intro.html">Discrete Uniform Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/0307_discrete_uniform_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/uniform/0307_discrete_uniform_distribution_application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/intro.html">Bernoulli Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/0308_bernoulli_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/bernoulli/0308_bernoulli_distribution_application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/iid.html">Independent and Identically Distributed (IID)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/intro.html">Binomial Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_implementation.html">Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_application.html">Real World Examples</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/geometric/intro.html">Geometric Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/geometric/0310_geometric_distribution_concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/intro.html">Poisson Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/0311_poisson_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/poisson/0311_poisson_distribution_implementation.html">Implementation</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/summary.html">Important</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/03_discrete_random_variables/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/intro.html">Chapter 4. Continuous Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/from_discrete_to_continuous.html">From Discrete to Continuous</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0401_continuous_random_variables.html">Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0402_probability_density_function.html">Probability Density Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0403_expectation.html">Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0404_moments_and_variance.html">Moments and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0405_cumulative_distribution_function.html">Cumulative Distribution Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0406_mean_median_mode.html">Mean, Median and Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0407_continuous_uniform_distribution.html">Continuous Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0408_exponential_distribution.html">Exponential Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0409_gaussian_distribution.html">Gaussian Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0410_skewness_and_kurtosis.html">Skewness and Kurtosis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0411_convolve_and_sum_of_random_variables.html">Convolution and Sum of Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/04_continuous_random_variables/0412_functions_of_random_variables.html">Functions of Random Variables</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/intro.html">Chapter 5. Joint Distributions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../probability_theory/05_joint_distributions/from_single_variable_to_joint_distributions.html">From Single Variable to Joint Distributions</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0501_joint_pmf_pdf/intro.html">Joint PMF and PDF</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0501_joint_pmf_pdf/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0502_joint_expectation_and_correlation/intro.html">Joint Expectation and Correlation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0502_joint_expectation_and_correlation/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/intro.html">Conditional PMF and PDF</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/application.html">Application</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/intro.html">Conditional Expectation and Variance</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0505_sum_of_random_variables/intro.html">Sum of Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0505_sum_of_random_variables/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0506_random_vectors/intro.html">Random Vectors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0506_random_vectors/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/intro.html">Multivariate Gaussian Distribution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/application_transformation.html">Application: Plots and Transformations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/psd.html">Covariance Matrix is Positive Semi-Definite</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/eigendecomposition.html">Eigendecomposition and Covariance Matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/geometry_of_multivariate_gaussian.html">The Geometry of Multivariate Gaussians</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/intro.html">Chapter 6. Sample Statistics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/intro.html">Moment Generating and Characteristic Functions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/moment_generating_function.html">Moment Generating Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/moment_generating_function_application_sum_of_rv.html">Application: Moment Generating Function and the Sum of Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/characteristic_function.html">Characteristic Function</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/intro.html">Probability Inequalities</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/concept.html">Probability Inequalities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/application.html">Application: Learning Theory</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/intro.html">Law of Large Numbers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/convergence.html">Convergence of Sample Average</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/application.html">Application: Learning Theory</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../probability_theory/08_estimation_theory/intro.html">Chapter 8. Estimation Theory</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../probability_theory/08_estimation_theory/maximum_likelihood_estimation/intro.html">Maximum Likelihood Estimation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../probability_theory/08_estimation_theory/maximum_likelihood_estimation/concept.html">Concept</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Operations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/distributed/intro.html">Distributed Systems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/01_notations.html">Notations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/02_basics.html">Basics Of Distributed Data Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/03_how_to_setup_slurm_in_aws.html">How to Setup SLURM and ParallelCluster in AWS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/distributed/04_ablation.html">Ablations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/profiling/intro.html">Profiling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/01_synchronize.html">Synchronize CUDA To Time CUDA Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/02_timeit.html">Profiling Code With Timeit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/03_time_profiler.html">PyTorch’s Event And Profiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/04_small_gpt_profile.html">Profile GPT Small Time And Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/profiling/05_memory_leak.html">CUDA Memory Allocations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/00_intro.html">The Lifecycle of an AIOps System</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/01_problem_formulation.html">Stage 1. Problem Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/02_project_scoping.html">Stage 2. Project Scoping And Framing The Problem</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/03_dataops_pipeline.html">Stage 3. Data Pipeline (Data Engineering and DataOps)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/031_data_source_and_format.html">Stage 3.1. Data Source and Formats</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/032_data_model_and_storage.html">Stage 3.2. Data Model and Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/03_dataops_pipeline/033_etl.html">Stage 3.3. Extract, Transform, Load (ETL)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/04_mlops_data_pipeline.html">Stage 4. Data Extraction (MLOps), Data Analysis (Data Science), Data Preparation (Data Science)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline.html">Stage 5. Model Development and Training (MLOps)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/051_model_selection.html">Stage 5.1. Model Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/052_metric_selection.html">Stage 5.2. Metric Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/053_experiment_tracking.html">Stage 5.3. Experiment Tracking And Versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/machine_learning_lifecycle/05_model_development_selection_and_training/054_model_testing.html">Stage 5.4. Model Testing</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/06_model_evaluation.html">Stage 6. Model Evaluation (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/07_model_validation_registry_and_pushing_model_to_production.html">Stage 7. Model Validation, Registry and Pushing Model to Production (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/08_model_deployment_and_serving.html">Stage 8. Model Serving (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/09_model_monitoring.html">Stage 9. Model Monitoring (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/machine_learning_lifecycle/010_continuous_integration_deployment_learning_and_training.html">Stage 10. Continuous Integration, Deployment, Learning and Training (DevOps, DataOps, MLOps)</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Software Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/config_management/intro.html">Config, State, Metadata Management</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/config_management/concept.html">Configuration Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/config_management/01-pydra.html">Pydantic And Hydra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/config_management/02-state.html">State And Metadata Management</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/design_patterns/intro.html">Design Patterns</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/dependency_inversion_principle.html">Dependency Inversion Principle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/named_constructor.html">Named Constructor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/strategy.html">Strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/registry.html">Registry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/god_object_pattern.html">Context Object Pattern (God Object)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/factory_method.html">Factory Method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/design_patterns/singleton.html">Singleton</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/python/intro.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/new_vs_init.html">Init vs New</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/iterator_protocol.html">The Iterator Protocol</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/decorator.html">Decorator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/generators_over_lists.html">Generators Over Lists For Memory Efficiency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/pydantic.html">Pydantic Is All You Need - Jason Liu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/mutable_default.html">Do Not Use Mutable Default Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/set_vs_list.html">Set Over List For Frequent Membership Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/late_binding_closures.html">Late Binding Closures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/python/is_vs_equality.html">Is vs Equality</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/intro.html">Concurrency, Parallelism and Asynchronous Programming</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/generator_yield.html">A Rudimentary Introduction to Generator and Yield in Python</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Computer Science</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../computer_science/type_theory/intro.html">Type Theory, A Very Rudimentary Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/01-subtypes.html">Subtypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/02-type-safety.html">Type Safety</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/03-subsumption.html">Subsumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/04-generics.html">Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/05-typevar-bound-constraints.html">Bound and Constraint in Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/06-invariance-covariance-contravariance.html">Invariance, Covariance and Contravariance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/07-pep-3124-overloading.html">Function Overloading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/08-pep-661-sentinel-values.html">Sentinel Types</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Structures and Algorithms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/complexity_analysis/intro.html">Complexity Analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/complexity_analysis/master_theorem.html">Master Theorem </a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/stack/intro.html">Stack</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/stack/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/searching_algorithms/linear_search/intro.html">Linear Search</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/linear_search/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/intro.html">Binary Search</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/problems/875-koko-eating-bananas.html">Koko Eating Bananas</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Algebra</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linear_algebra/01_preliminaries/intro.html">Preliminaries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/01_preliminaries/01-fields.html">Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/01_preliminaries/02-systems-of-linear-equations.html">Systems of Linear Equations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linear_algebra/02_vectors/intro.html">Vectors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/01-vector-definition.html">Vector and Its Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/02-vector-operation.html">Vector and Its Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/03-vector-norm.html">Vector Norm and Distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/04-vector-products.html">A First Look at Vector Products</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References, Resources and Roadmap</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../citations.html">IEEE (Style) Citations</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gao-hongnan/omniverse" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gao-hongnan/omniverse/issues/new?title=Issue%20on%20page%20%2Finfluential/learning_theory/02_concept.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/influential/learning_theory/02_concept.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Concept: Learning Theory</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#some-abuse-of-notations">Some Abuse of Notations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">Problem Statement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#notations">Notations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#is-learning-feasible">Is Learning Feasible?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learing-outside-the-training-set-mathcal-s-deterministic-case">Learing Outside the Training Set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> (Deterministic Case)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#identically-and-independently-distributed-random-variables">Identically and Independently Distributed Random Variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learing-outside-the-training-set-mathcal-s-probabilistic-case">Learing Outside the Training Set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> (Probabilistic Case)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-generalization-gap">The Generalization Gap</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-law-of-large-numbers">The Law of Large Numbers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hoeffding-s-inequality">Hoeffding’s Inequality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-hoeffding-s-inequality-with-the-chebyshev-s-inequality">Comparing Hoeffding’s Inequality with the Chebyshev’s Inequality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-hoeffding-s-inequality-in-classification">Example: Hoeffding’s Inequality in Classification</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pac-framework">PAC Framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hoeffding-inequality-is-invalid-for-h-s-learnt-from-mathcal-s">Hoeffding Inequality is Invalid for <span class="math notranslate nohighlight">\(h_S\)</span> learnt from <span class="math notranslate nohighlight">\(\mathcal{S}\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#union-bound">Union Bound</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#framing-learning-theory-with-hoeffding-s-inequality">Framing Learning Theory with Hoeffding’s Inequality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feasibility-from-the-two-view-points">Feasibility from the Two View Points</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complex-hypothesis-set-and-complex-target-function">Complex Hypothesis Set and Complex Target Function</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vc-analysis">VC-Analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generalization-bound">Generalization Bound</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-growth-function">The Growth Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-vc-dimension">The VC Dimension</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sauers-lemma-and-bounding-the-growth-function">Sauer’s Lemma and Bounding the Growth Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretating-the-generalization-bound">Interpretating the Generalization Bound</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-complexity">Sample Complexity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-complexity">Model Complexity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-data">Testing Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-must-h-be-fixed-and-defined-before-generating-the-dataset-mathcal-s">Why must <span class="math notranslate nohighlight">\(h\)</span> be fixed and defined before generating the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#some-intuition-on-the-difference-between-a-priori-and-a-posteriori">Some intuition on the difference between <em>a-priori</em> and <em>a-posteriori</em>:</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#a-priori">A-priori:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#a-posteriori">A-posteriori:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#your-specific-setup">Your specific setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#your-specific-questions">Your specific questions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-readings">Further Readings</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="concept-learning-theory">
<h1>Concept: Learning Theory<a class="headerlink" href="#concept-learning-theory" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="https://twitter.com/gaohongnan"><img alt="Twitter Handle" src="https://img.shields.io/badge/Twitter-&#64;gaohongnan-blue?style=social&amp;logo=twitter" /></a>
<a class="reference external" href="https://linkedin.com/in/gao-hongnan"><img alt="LinkedIn Profile" src="https://img.shields.io/badge/&#64;gaohongnan-blue?style=social&amp;logo=linkedin" /></a>
<a class="reference external" href="https://github.com/gao-hongnan"><img alt="GitHub Profile" src="https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&amp;logo=github" /></a>
<img alt="Tag" src="https://img.shields.io/badge/Tag-Organized_Chaos-orange" /></p>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#some-abuse-of-notations" id="id2">Some Abuse of Notations</a></p></li>
<li><p><a class="reference internal" href="#problem-statement" id="id3">Problem Statement</a></p></li>
<li><p><a class="reference internal" href="#notations" id="id4">Notations</a></p></li>
<li><p><a class="reference internal" href="#is-learning-feasible" id="id5">Is Learning Feasible?</a></p>
<ul>
<li><p><a class="reference internal" href="#learing-outside-the-training-set-mathcal-s-deterministic-case" id="id6">Learing Outside the Training Set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> (Deterministic Case)</a></p></li>
<li><p><a class="reference internal" href="#identically-and-independently-distributed-random-variables" id="id7">Identically and Independently Distributed Random Variables</a></p></li>
<li><p><a class="reference internal" href="#learing-outside-the-training-set-mathcal-s-probabilistic-case" id="id8">Learing Outside the Training Set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> (Probabilistic Case)</a></p></li>
<li><p><a class="reference internal" href="#the-generalization-gap" id="id9">The Generalization Gap</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#the-law-of-large-numbers" id="id10">The Law of Large Numbers</a></p></li>
<li><p><a class="reference internal" href="#hoeffding-s-inequality" id="id11">Hoeffding’s Inequality</a></p>
<ul>
<li><p><a class="reference internal" href="#comparing-hoeffding-s-inequality-with-the-chebyshev-s-inequality" id="id12">Comparing Hoeffding’s Inequality with the Chebyshev’s Inequality</a></p></li>
<li><p><a class="reference internal" href="#example-hoeffding-s-inequality-in-classification" id="id13">Example: Hoeffding’s Inequality in Classification</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#pac-framework" id="id14">PAC Framework</a></p></li>
<li><p><a class="reference internal" href="#hoeffding-inequality-is-invalid-for-h-s-learnt-from-mathcal-s" id="id15">Hoeffding Inequality is Invalid for <span class="math notranslate nohighlight">\(h_S\)</span> learnt from <span class="math notranslate nohighlight">\(\mathcal{S}\)</span></a></p></li>
<li><p><a class="reference internal" href="#union-bound" id="id16">Union Bound</a></p></li>
<li><p><a class="reference internal" href="#framing-learning-theory-with-hoeffding-s-inequality" id="id17">Framing Learning Theory with Hoeffding’s Inequality</a></p></li>
<li><p><a class="reference internal" href="#feasibility-from-the-two-view-points" id="id18">Feasibility from the Two View Points</a></p>
<ul>
<li><p><a class="reference internal" href="#complex-hypothesis-set-and-complex-target-function" id="id19">Complex Hypothesis Set and Complex Target Function</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#vc-analysis" id="id20">VC-Analysis</a></p>
<ul>
<li><p><a class="reference internal" href="#generalization-bound" id="id21">Generalization Bound</a></p></li>
<li><p><a class="reference internal" href="#the-growth-function" id="id22">The Growth Function</a></p></li>
<li><p><a class="reference internal" href="#the-vc-dimension" id="id23">The VC Dimension</a></p></li>
<li><p><a class="reference internal" href="#sauers-lemma-and-bounding-the-growth-function" id="id24">Sauer’s Lemma and Bounding the Growth Function</a></p></li>
<li><p><a class="reference internal" href="#interpretating-the-generalization-bound" id="id25">Interpretating the Generalization Bound</a></p></li>
<li><p><a class="reference internal" href="#sample-complexity" id="id26">Sample Complexity</a></p></li>
<li><p><a class="reference internal" href="#model-complexity" id="id27">Model Complexity</a></p></li>
<li><p><a class="reference internal" href="#testing-data" id="id28">Testing Data</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#why-must-h-be-fixed-and-defined-before-generating-the-dataset-mathcal-s" id="id29">Why must <span class="math notranslate nohighlight">\(h\)</span> be fixed and defined before generating the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>?</a></p>
<ul>
<li><p><a class="reference internal" href="#some-intuition-on-the-difference-between-a-priori-and-a-posteriori" id="id30">Some intuition on the difference between <em>a-priori</em> and <em>a-posteriori</em>:</a></p>
<ul>
<li><p><a class="reference internal" href="#a-priori" id="id31">A-priori:</a></p></li>
<li><p><a class="reference internal" href="#a-posteriori" id="id32">A-posteriori:</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#your-specific-setup" id="id33">Your specific setup</a></p>
<ul>
<li><p><a class="reference internal" href="#your-specific-questions" id="id34">Your specific questions</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#further-readings" id="id35">Further Readings</a></p></li>
</ul>
</nav>
<p>This topic is quite theoretical and heavy. I do not have the ability to explain
them in an intuitive way. Therefore, most of the content here is adapted from
the following sources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://engineering.purdue.edu/ChanGroup/ECE595/files/chapter4.pdf">ECE595: Learning Theory</a></p></li>
<li><p><a class="reference external" href="https://mostafa-samir.github.io/ml-theory-pt2/">Mostafa Samir: Machine Learning Theory</a></p></li>
<li><p><a class="reference external" href="https://wei2624.github.io/MachineLearning/sv_learning_theory/">Zhang Wei: Learning Theory</a></p></li>
</ul>
<p>Therefore, this section serves as a document/reference and all credits go to the
authors of the above sources.</p>
<section id="some-abuse-of-notations">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Some Abuse of Notations</a><a class="headerlink" href="#some-abuse-of-notations" title="Link to this heading">#</a></h2>
<div class="proof remark admonition" id="remark-learning-problem-notations-learning-theory">
<p class="admonition-title"><span class="caption-number">Remark 13 </span> (Notations)</p>
<section class="remark-content" id="proof-content">
<p>We will abbrieviate:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} := \mathcal{R}_{\mathcal{D}}\left\{h\right\}
\]</div>
<div class="math notranslate nohighlight">
\[
\mathbb{P}_{\mathcal{D}} := \mathcal{D}
\]</div>
<p>when the context is clear.</p>
<p>The author used <span class="math notranslate nohighlight">\(g\)</span> as the final hypothesis learnt by the algorithm, we will however use <span class="math notranslate nohighlight">\(h_S\)</span> to denote
<span class="math notranslate nohighlight">\(g\)</span>. Therefore, some images from the author will have <span class="math notranslate nohighlight">\(g\)</span> instead of <span class="math notranslate nohighlight">\(h_S\)</span>.</p>
</section>
</div></section>
<section id="problem-statement">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Problem Statement</a><a class="headerlink" href="#problem-statement" title="Link to this heading">#</a></h2>
<p>When we have built a classifier, one question people always ask is how good the
classifier is. They want to evaluate the classifier. They want to see whether
the classifier is able to predict what it is supposed to predict. Often times,
the “gold standard” is to report the classification accuracy: Give me a testing
dataset, and I will tell you how many times the classifier has done correctly.
This is one way of evaluating the classifier. However, does this evaluation
method really tells us how good the classifier is? Not clear. All it says is
that for this classifier trained on a particular training dataset and tested on
a particular testing dataset, the classifier performs such and such. Will it
perform well if we train the classifier using another training set, maybe
containing more data points? Will it perform well if we test it on a different
testing dataset? It seems that we lack a way to quantify the generalization
ability of our classifier.</p>
<p>There is another difficulty. When we train the classifier, we can only access
the training data but not the testing data. This is like taking an exam. We can
never see the exam questions when we study, for otherwise we will defeat the
purpose of the exam! Since we only have the training set when we design our
classifier, how do we tell whether we have trained a good classifier? Should we
choose a more complex model? How many samples do we need? Remember, we cannot
use any testing data and so all the evaluation has to be done internally using
the training data. How to do that? Again, we are missing a way to quantify the
performance of the classifier.</p>
<p>The objective of this chapter is to answer a few theoretical (and also
practical) questions in learning:</p>
<ol class="arabic simple">
<li><p>Is learning feasible?</p></li>
<li><p>How much can a classifier generalize?</p></li>
<li><p>What is the relationship between number of training samples and the
complexity of the classifier?</p></li>
<li><p>How do we tell whether we have obtained a good classifier during the
training?</p></li>
</ol>
</section>
<section id="notations">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Notations</a><a class="headerlink" href="#notations" title="Link to this heading">#</a></h2>
<p>Let’s refresh ourselves with some notations.</p>
<p>We have a training dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> sampled <span class="math notranslate nohighlight">\(\textbf{i.i.d.}\)</span> from the
underlying and unknown distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\mathcal{S} = \left\{(\mathbf{x}^{(1)}, y^{(1)}), (\mathbf{x}^{(2)}, y^{(2)}), \ldots, (\mathbf{x}^{(N)}, y^{(N)})\right\} \overset{\text{iid}}{\sim} \mathcal{D}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)} \in \mathbb{R}^{D}\)</span> is the input vector and
<span class="math notranslate nohighlight">\(y^{(n)} \in \mathcal{Y}\)</span> is the corresponding label. We call <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span>
the <span class="math notranslate nohighlight">\(n\)</span>-th input vector and <span class="math notranslate nohighlight">\(y^{(n)}\)</span> the <span class="math notranslate nohighlight">\(n\)</span>-th label. We call <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>
the training dataset. We call <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> (<span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span>) the
underlying distribution.</p>
<p>Now there is an unknown target function
<span class="math notranslate nohighlight">\(f: \mathcal{X} \rightarrow \mathcal{Y}\)</span><a class="footnote-reference brackets" href="#f-and-c" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> which maps <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to a
label <span class="math notranslate nohighlight">\(y=f(\mathbf{x})\)</span>. The set <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> contains all the input vectors,
and we call <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> the input space. The set <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> contains the
corresponding labels, and we call <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> the output space.</p>
<p>In any supervised learning scenario, there is always a training set
<span class="math notranslate nohighlight">\(\mathcal{S}\)</span> sampled from <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span>. The training set contains
<span class="math notranslate nohighlight">\(N\)</span> input-output pairs
<span class="math notranslate nohighlight">\(\left(\mathbf{x}^{(1)}, y^{(1)}\right), \ldots,\left(\mathbf{x}^{(N)}, y^{(N)}\right)\)</span>,
where <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> and <span class="math notranslate nohighlight">\(y^{(n)}\)</span> are related via <span class="math notranslate nohighlight">\(y^{(n)}=\)</span>
<span class="math notranslate nohighlight">\(f\left(\mathbf{x}^{(n)}\right)\)</span>, for <span class="math notranslate nohighlight">\(n=1, \ldots, N\)</span>. These input-output pairs
are called the data points or samples. Since <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is a finite
collection of data points, there are many <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}\)</span> that do
not live in the training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. A data point <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> that
is inside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is called an <strong>in-sample</strong>, and a data point
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span> that is outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is called an <strong>out-sample</strong>.</p>
<p>When we say that we use a machine learning algorithm to learn a classifier, we
mean that we have an algorithmic procedure <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> (i.e. Logistic
Regression, KNN etc) which uses the training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> to select a
hypothesis function <span class="math notranslate nohighlight">\(h_S: \mathcal{X} \rightarrow \mathcal{Y}\)</span>. The hypothesis
function is again a mapping from <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> to <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, because it
tells what a sample <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is being classified. However, a hypothesis
function <span class="math notranslate nohighlight">\(h_S\)</span> learned by the algorithm is not the same as the target function
<span class="math notranslate nohighlight">\(f\)</span>. We never know <span class="math notranslate nohighlight">\(f\)</span> because <span class="math notranslate nohighlight">\(f\)</span> is simply unknown. No matter how much we
learn, the hypothesis function <span class="math notranslate nohighlight">\(h_S\)</span> is at best an approximation of <span class="math notranslate nohighlight">\(f\)</span>. The
approximation error can be zero in some hand-craved toy examples, but in general
<span class="math notranslate nohighlight">\(h_S \neq f\)</span>. All hypothesis functions are contained in the hypothesis set
<span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. If the hypothesis set is finite, then
<span class="math notranslate nohighlight">\(\mathcal{H}=\left\{h_{1}, \ldots, h_{M}\right\}\)</span>, and <span class="math notranslate nohighlight">\(h_S\)</span> will be one of
these <span class="math notranslate nohighlight">\(h_{m}\)</span> ‘s. A hypothesis set can be infinite, for example we can perturb a
perceptron decision boundary by an infinitesimal step to an infinite hypothesis
set. An infinite hypothesis set is denoted by
<span class="math notranslate nohighlight">\(\mathcal{H}=\left\{h_{\sigma}\right\}\)</span>, where <span class="math notranslate nohighlight">\(\sigma\)</span> denotes a continuous
parameter.</p>
<p>The drawings in <a class="reference internal" href="#ece595-fig4-1"><span class="std std-numref">Fig. 7</span></a> illustrate a few key concepts we just
mentioned. On the left hand side there is an input space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, which
contains a small subset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. The subset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is the training
set, which includes a finite number of training samples or in-samples. There is
an unknown target function <span class="math notranslate nohighlight">\(f\)</span>. The target function <span class="math notranslate nohighlight">\(f\)</span> maps an
<span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> to produce an output
<span class="math notranslate nohighlight">\(y^{(n)}=f\left(\mathbf{x}^{(n)}\right)\)</span>, hence giving a colored dots in the
middle of the figure. The objective of learning is to learn a classifier which
can classify the red from the blue. The space containing all the possible
hypothesis is the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, which contains
<span class="math notranslate nohighlight">\(h_{1}, \ldots, h_{M}\)</span>. The final hypothesis function returned by the learning
algorithm is <span class="math notranslate nohighlight">\(h_S\)</span>.</p>
<figure class="align-default" id="ece595-fig4-1">
<img alt="../../_images/ece595_fig4.1.jpeg" src="../../_images/ece595_fig4.1.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 7 </span><span class="caption-text">[Left] Treat the cloud as the entire input space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and correspondingly the output space <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>. The dots are the in-samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>. The target function is a mapping <span class="math notranslate nohighlight">\(f\)</span> which takes <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> and send it to <span class="math notranslate nohighlight">\(y^{(n)}\)</span>. The red and blue colors indicate the class label. [Right] A learning algorithm picks a hypothesis function <span class="math notranslate nohighlight">\(h_S\)</span> from the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}=\left\{h_{1}, \ldots, h_{M}\right\}\)</span>. Note that some hypotheses are good, and some are bad. A good learning algorithm will pick a good hypothesis, and a bad learning algorithm can pick a bad hypothesis.</span><a class="headerlink" href="#ece595-fig4-1" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#ece595-fig4-2"><span class="std std-numref">Fig. 8</span></a> illustrates what we called a probabilistic learning
model. It is called a probabilistic learning model because there is an unknown
distribution <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span>. The training samples
<span class="math notranslate nohighlight">\(\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right\}\)</span> are generated
according to <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>. The same
<span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span> also generates the testing samples
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. It is possible to lift the probabilistic assumption so that the
training samples are drawn deterministically. In this case, the samples are
simply fixed set of data points
<span class="math notranslate nohighlight">\(\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right\}\)</span>. The deterministic
assumption will make learning infeasible, as we will see shortly. Therefore, we
shall mainly focus on the probabilistic assumption.</p>
<figure class="align-default" id="ece595-fig4-2">
<img alt="../../_images/ece595_fig4.2.jpeg" src="../../_images/ece595_fig4.2.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 8 </span><span class="caption-text">All essential components of a machine learning model.</span><a class="headerlink" href="#ece595-fig4-2" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="is-learning-feasible">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Is Learning Feasible?</a><a class="headerlink" href="#is-learning-feasible" title="Link to this heading">#</a></h2>
<p>The first question we ask is: Suppose we have a training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, can
we learn the target function <span class="math notranslate nohighlight">\(f\)</span> ? If the answer is YES, then we are all in
business, because it means that we will be able to predict the data we have not
seen. If the answer is NO, then machine learning is a lair and we should all go
home, because it means that we can only memorize what we have seen but we will
not be able to predict what we have not seen.</p>
<p>Interestingly, the answer to this question depends on how we define the training
samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> ‘s. If <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> ‘s are deterministically
defined, then the answer is NO because <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> can contain no information
about the out-samples. Thus, there is no way to learn outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. If
<span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> ‘s are drawn from a probabilistic distribution, then the
answer is YES because the distribution will tell us something about the
out-samples. Let us look at these two situations one by one.</p>
<section id="learing-outside-the-training-set-mathcal-s-deterministic-case">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">Learing Outside the Training Set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> (Deterministic Case)</a><a class="headerlink" href="#learing-outside-the-training-set-mathcal-s-deterministic-case" title="Link to this heading">#</a></h3>
<p>Let us look at the deterministic case. Consider a 3-dimensional input space
<span class="math notranslate nohighlight">\(\mathcal{X}=\{0,1\}^{3}\)</span>. Each vector <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}\)</span> is a binary
vector containing three elements, e.g., <span class="math notranslate nohighlight">\(\mathbf{x}=[0,0,1]^{T}\)</span> or
<span class="math notranslate nohighlight">\(\mathbf{x}=[1,0,1]^{T}\)</span>. Since there are 3 elements and each element take a
binary state, there are totally <span class="math notranslate nohighlight">\(2^{3}=8\)</span> input vectors in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>.</p>
<p>How about the number of possible target functions <span class="math notranslate nohighlight">\(f\)</span> can we have? Remember, a
target function <span class="math notranslate nohighlight">\(f\)</span> is a mapping which converts an input vector <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to
a label <span class="math notranslate nohighlight">\(y\)</span>. For simplicity let us assume that <span class="math notranslate nohighlight">\(f\)</span> maps <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to a binary
output <span class="math notranslate nohighlight">\(y \in\{+1,-1\}\)</span>. Since there are 8 input vectors, we can think of <span class="math notranslate nohighlight">\(f\)</span> as
a 8-bit vector, e.g., <span class="math notranslate nohighlight">\(f=[-1,+1,-1,-1,-1,+1,+1,+1]\)</span>, where each entry represents
the output. If we do the calculation, we can show that there are totally
<span class="math notranslate nohighlight">\(2^{8}=256\)</span> possible target functions.</p>
<p>Here is the learning problem. Can we learn <span class="math notranslate nohighlight">\(f\)</span> from <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> ? To ensure
that <span class="math notranslate nohighlight">\(f\)</span> is unknown, we will not disclose what <span class="math notranslate nohighlight">\(f\)</span> is. Instead, we assume that
there is a training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> containing 6 training samples
<span class="math notranslate nohighlight">\(\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(6)}\right\}\)</span>. Corresponding to
each <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> is the label <span class="math notranslate nohighlight">\(y^{(n)}\)</span>. The relationship between
<span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> and <span class="math notranslate nohighlight">\(y^{(n)}\)</span> is shown in the table below. So our task is to
pick a target function from the 256 possible choices.</p>
<div class="pst-scrollable-table-container"><table class="table" id="truth-table-1">
<caption><span class="caption-number">Table 6 </span><span class="caption-text">Truth Table for 6 samples</span><a class="headerlink" href="#truth-table-1" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(y^{(n)}\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,1,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,1,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<div class="pst-scrollable-table-container"><table class="table" id="boolean-function-truth-table">
<caption><span class="caption-number">Table 7 </span><span class="caption-text">Function Table</span><a class="headerlink" href="#boolean-function-truth-table" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(y^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(h_S\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_1\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_2\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_3\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_4\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,1,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,1,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,1,0]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ / \bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,1,1]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ / \bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<p>Since we have seen 6 out of 8 input vectors in <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, there remains two
input vectors we have not seen and need to predict. Thus, we can quickly reduce
the number of possible target functions to <span class="math notranslate nohighlight">\(2^{2}=4\)</span>. Let us call these target
functions <span class="math notranslate nohighlight">\(f_{1}, f_{2}, f_{3}\)</span> and <span class="math notranslate nohighlight">\(f_{4}\)</span>. The boolean structure of these
target functions are shown on the right hand side of the table above. Note that
the first 6 entries of each <span class="math notranslate nohighlight">\(f_{i}\)</span> is fixed because they are already observed
in <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
<p>In the table above we write down the final hypothesis function <span class="math notranslate nohighlight">\(h_S\)</span>. The last
two entries of <span class="math notranslate nohighlight">\(h_S\)</span> is to be determined by the learning algorithm. If the
learning algorithm decides <span class="math notranslate nohighlight">\(\circ\)</span>, then we will have both <span class="math notranslate nohighlight">\(\circ\)</span>. If the
learning algorithm decides a <span class="math notranslate nohighlight">\(\circ\)</span> followed by a <span class="math notranslate nohighlight">\(\bullet\)</span>, then we will have
a <span class="math notranslate nohighlight">\(\circ\)</span> followed by a <span class="math notranslate nohighlight">\(\bullet\)</span>. So the final hypothesis function <span class="math notranslate nohighlight">\(h_S\)</span> can be
one of the 4 possible choices, same number of choices of the target functions.</p>
<p>Since we assert that <span class="math notranslate nohighlight">\(f\)</span> is unknown, by only observing the first 6 entries we
will have 4 equally good hypothesis functions. They are equally good, because no
matter which hypothesis function we choose, the last 2 entries will agree or
disagree with the target depending on which one is the true target function. For
example, on the left hand side of the table below, the true target function is
<span class="math notranslate nohighlight">\(f_{1}\)</span> and so our <span class="math notranslate nohighlight">\(h_S\)</span> is correct. But if the true target function is <span class="math notranslate nohighlight">\(f_{3}\)</span>,
e.g., the right hand side of the table, then our <span class="math notranslate nohighlight">\(h_S\)</span> is wrong. We can repeat
the experiment by choosing another <span class="math notranslate nohighlight">\(h_S\)</span>, and we can prove that not matter which
<span class="math notranslate nohighlight">\(h_S\)</span> we choose, we only have <span class="math notranslate nohighlight">\(25 \%\)</span> chance of picking the correct one. This is
the same as drawing a lottery from 4 numbers. The information we learned from
the training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> does not allow us to infer anything outside
<span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
<div class="pst-scrollable-table-container"><table class="table" id="boolean-function-truth-table-f1">
<caption><span class="caption-number">Table 8 </span><span class="caption-text">Function Table with <span class="math notranslate nohighlight">\(f_1\)</span> as True Function</span><a class="headerlink" href="#boolean-function-truth-table-f1" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(y^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(h_S\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\textcolor{red}{f_1}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_2\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_3\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_4\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,1,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,1,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,1,0]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,1,1]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<div class="pst-scrollable-table-container"><table class="table" id="boolean-function-truth-table-f3">
<caption><span class="caption-number">Table 9 </span><span class="caption-text">Function Table with <span class="math notranslate nohighlight">\(f_3\)</span> as True Function</span><a class="headerlink" href="#boolean-function-truth-table-f3" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(y^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(h_S\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_1\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_2\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\textcolor{red}{f_3}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_4\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,1,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,1,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,1,0]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,1,1]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<p>The above analysis shows that learning is infeasible if we have a deterministic
generator generating the training samples. The argument holds regardless which
learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> we use, and what hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>
we choose. Whether <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> contains the correct hypothesis function, and
whether <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> can pick the correct hypothesis, there is no difference in
terms of predicting outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. We can also extend the analysis from
binary function to general learning problem. As long as <span class="math notranslate nohighlight">\(f\)</span> remains unknown, it
is impossible to predict outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
</section>
<section id="identically-and-independently-distributed-random-variables">
<h3><a class="toc-backref" href="#id7" role="doc-backlink">Identically and Independently Distributed Random Variables</a><a class="headerlink" href="#identically-and-independently-distributed-random-variables" title="Link to this heading">#</a></h3>
<p>For the following section, we will discuss the case from a probabilistic
perspective.</p>
<p>However, we will need to assume that the random variables are identically and
independently distributed (i.i.d.). This means that the random variables are
drawn from the same distribution and are independent of each other.</p>
<p>For formal definition, see
<a class="reference internal" href="../../probability_theory/03_discrete_random_variables/iid.html"><span class="std std-doc">here</span></a>.</p>
<p>This assumption is ubiquitous in machine learning. Not only does it simplify the
analysis, it also solidifies many theories governing the framework underlying
machine learning.</p>
<p>This assumption is a strong one and is not always true in practice. However, it
is a reasonable one.</p>
<p>See extracted paragraph from
<a class="reference external" href="https://mostafa-samir.github.io">Machine Learning Theory</a> below:</p>
<p>This assumption is essential for us. We need it to start using the tools form
probability theory to investigate our generalization probability, and it’s a
very reasonable assumption because:</p>
<ol class="arabic simple">
<li><p>It’s more likely for a dataset used for inferring about an underlying
probability distribution to be all sampled for that same distribution. If
this is not the case, then the statistics we get from the dataset will be
noisy and won’t correctly reflect the target underlying distribution.</p></li>
<li><p>It’s more likely that each sample in the dataset is chosen without
considering any other sample that has been chosen before or will be chosen
after. If that’s not the case and the samples are dependent, then the dataset
will suffer from a bias towards a specific direction in the distribution, and
hence will fail to reflect the underlying distribution correctly.</p></li>
</ol>
</section>
<section id="learing-outside-the-training-set-mathcal-s-probabilistic-case">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Learing Outside the Training Set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> (Probabilistic Case)</a><a class="headerlink" href="#learing-outside-the-training-set-mathcal-s-probabilistic-case" title="Link to this heading">#</a></h3>
<p>The deterministic analysis gives us a pessimistic result. Now, let us look at a
probabilistic analysis. On top of the training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, we pose an
assumption. We assume that all <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}\)</span> is drawn from a
distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>. This includes all the
in-samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)} \in \mathcal{S}\)</span> and the out-samples
<span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}\)</span>. At a first glance, putting a distributional
assumption <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span> does not seem any different
from the deterministic case: We still have a training set
<span class="math notranslate nohighlight">\(\mathcal{S}=\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right\}\)</span>, and <span class="math notranslate nohighlight">\(f\)</span>
is still unknown. How can we learn the unknown <span class="math notranslate nohighlight">\(f\)</span> using just the training
samples?</p>
<p>Suppose that we pick a hypothesis function <span class="math notranslate nohighlight">\(h\)</span> from the hypothesis set
<span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. For every in-sample <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span>, we check whether the
output returned by <span class="math notranslate nohighlight">\(h\)</span> is the same as the output returned by <span class="math notranslate nohighlight">\(f\)</span>, i.e.,
<span class="math notranslate nohighlight">\(\left\{h\left(\mathbf{x}^{(n)}\right)=f\left(\mathbf{x}^{(n)}\right)\right\}\)</span>,
for <span class="math notranslate nohighlight">\(n=1, \ldots, N\)</span>. If
<span class="math notranslate nohighlight">\(\left\{h\left(\mathbf{x}^{(n)}\right)=f\left(\mathbf{x}^{(n)}\right)\right\}\)</span>,
then we say that the in-sample <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> is correctly classified in the
training. If
<span class="math notranslate nohighlight">\(\left\{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)\right\}\)</span>,
then we say that <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> is incorrectly classified. Averaging over
all the <span class="math notranslate nohighlight">\(N\)</span> samples, we obtain a quantity called the in-sample error, or the
training error. In our
<a class="reference internal" href="../../notations/machine_learning.html"><span class="std std-doc">machine learning notations</span></a>, the in-sample
error is our Empirical Risk Minimization (ERM) function
<span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{S}}\left(h\right)\)</span>.</p>
<div class="proof definition admonition" id="prf:definition:zero-one-loss">
<p class="admonition-title"><span class="caption-number">Definition 20 </span> (Zero-One Loss)</p>
<section class="definition-content" id="proof-content">
<p>The zero-one loss is defined as</p>
<div class="math notranslate nohighlight" id="equation-eq-zero-one-loss">
<span class="eqno">(7)<a class="headerlink" href="#equation-eq-zero-one-loss" title="Link to this equation">#</a></span>\[
\mathcal{L}\left(\left(\mathbf{x}, y\right), h\right) = \boldsymbol{1}\left\{h\left(\mathbf{x}\right) \neq y\right\}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{1}\left\{h\left(\mathbf{x}\right) \neq y\right\}\)</span> is the indicator function that returns 1 if the condition is true, and 0 otherwise.</p>
</section>
</div><p>With this,</p>
<div class="proof definition admonition" id="prf:definition:in-sample-error">
<p class="admonition-title"><span class="caption-number">Definition 21 </span> (In-Sample Error (Empirical Risk Minimization))</p>
<section class="definition-content" id="proof-content">
<p>Consider a training set <span class="math notranslate nohighlight">\(\mathcal{S} = \left\{(\mathbf{x}^{(1)}, y^{(1)}), (\mathbf{x}^{(2)}, y^{(2)}), \ldots, (\mathbf{x}^{(N)}, y^{(N)})\right\} \overset{\text{iid}}{\sim} \mathbb{P}_{\mathcal{D}}\)</span>, and a target function <span class="math notranslate nohighlight">\(f\)</span>. The in-sample error (or the training error) of a hypothesis function <span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span> is the empirical average of the zero-one loss <span class="math notranslate nohighlight">\(\mathcal{L}\left(\left(\mathbf{x}, y\right), h\right) : =\left\{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)\right\}\)</span> :</p>
<div class="math notranslate nohighlight" id="equation-eq-in-sample-error">
<span class="eqno">(8)<a class="headerlink" href="#equation-eq-in-sample-error" title="Link to this equation">#</a></span>\[\begin{split}
\begin{aligned}
\hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} :&amp;= \frac{1}{N} \sum_{n=1}^N \mathcal{L}\left(\left(\mathbf{x}^{(n)}, y^{(n)}\right), h\right) \\
&amp;= \frac{1}{N} \sum_{n=1}^N \boldsymbol{1}\left\{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)\right\} \\
&amp;= \mathbb{E}_{\mathcal{S}}\left[\mathcal{L}\left(\left(\mathbf{x}, y\right), h\right)\right]
\end{aligned}
\end{split}\]</div>
</section>
</div><p>Training error is the amount of error we have during the training process. A
good learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> should pick a hypothesis <span class="math notranslate nohighlight">\(h\)</span> that gives
low training error. Training error is sometimes called the cost (empirical risk)
function (or the loss function) when we post the learning problem as an
optimization. Thus, picking a good hypothesis is equivalent to minimizing the
training error.</p>
<p>How about the out-samples? Since we assume that <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is drawn from a
distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>, we can define the
out-sample error as the probability that <span class="math notranslate nohighlight">\(\{h(\mathbf{x}) \neq f(\mathbf{x})\}\)</span>,
for all <span class="math notranslate nohighlight">\(\mathbf{x} \sim \mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>.</p>
<div class="proof definition admonition" id="prf:definition:out-sample-error">
<p class="admonition-title"><span class="caption-number">Definition 22 </span> (Out-Sample Error (Generalization Error))</p>
<section class="definition-content" id="proof-content">
<p>Consider an input space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> containing elements <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> drawn from a distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span>, and a target function <span class="math notranslate nohighlight">\(f\)</span>. The out-sample error (or the true risk/testing error) of a hypothesis function <span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} :&amp;= \mathbb{P} \left[\left\{h\left(\mathbf{x}\right) \neq f\left(\mathbf{x}\right)\right\}\right] \\
&amp;= \mathbb{E}_{\mathcal{D}}\left[\mathcal{L}((\mathbf{x}, y), h)\right] \\
&amp;= \mathbb{E}_{\mathcal{D}}\left[\boldsymbol{1}\left\{h\left(\mathbf{x}\right) \neq f\left(\mathbf{x}\right)\right\}\right] \\
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{P}[\cdot]\)</span> measures the probability of the statement based on the distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>.</p>
</section>
</div><p>How did we derive from a probability of classifying one sample wrongly to the
expectation over the loss function?</p>
<p>Since <span class="math notranslate nohighlight">\(\boldsymbol{1}\)</span> is a binary function, the out-sample error is the
expected value of a sample being misclassified over the entire distribution:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}= &amp; \mathbb{P}[h(\mathbf{x}) \neq f(\mathbf{x})] \\
= &amp; \underbrace{\boldsymbol{1}_{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)}}_{=1} \mathbb{P}\left\{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)\right\} \\
&amp; \quad+\underbrace{\boldsymbol{1}_{h\left(\mathbf{x}^{(n)}\right)=f\left(\mathbf{x}^{(n)}\right)}}_{=0}\left(1-\mathbb{P}\left\{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)\right\}\right) \\
= &amp; \mathbb{E}_{\mathcal{D}}\left\{\boldsymbol{1}_{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)}\right\} .
\end{aligned}
\end{split}\]</div>
<p>Therefore, the relationship between the in-sample error
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\)</span>
and out-sample error
<span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\)</span> is
equivalent to the relationship between the empirical average and the population
mean of a random variable, where the random variable is the loss function
<span class="math notranslate nohighlight">\(\mathcal{L}\)</span>.</p>
<p><a class="reference internal" href="#ece595-fig4-3"><span class="std std-numref">Fig. 9</span></a> shows how an in-sample error is computed.</p>
<figure class="align-default" id="ece595-fig4-3">
<img alt="../../_images/ece595_fig4.3.jpeg" src="../../_images/ece595_fig4.3.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 9 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}\)</span> is evaluated using the training data, whereas <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span> is evaluated using the testing sample. Here the author uses
<span class="math notranslate nohighlight">\(\mathbb{E}_{\text{in}}\)</span> and <span class="math notranslate nohighlight">\(\mathbb{E}_{\text{out}}\)</span> to denote the in-sample and out-sample error, respectively.</span><a class="headerlink" href="#ece595-fig4-3" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>To this end, we recap of what we have:</p>
<p>We have a hypothesis space <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> of functions that we can use to
approximate the underlying distribution. We have a loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>
that we can use to measure the quality of our approximation. We have a learning
algorithm that can be used to find the best function in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> that
approximates the underlying distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. We have a test dataset
<span class="math notranslate nohighlight">\(\mathcal{S}_{\mathrm{\text{test}}}\)</span> sampled <span class="math notranslate nohighlight">\(\textbf{i.i.d.}\)</span> from the
underlying and unknown distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<p>We want to know the probability that our learning algorithm will find a function
in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> that approximates the underlying distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>
well enough to generalize well to the test dataset
<span class="math notranslate nohighlight">\(\mathcal{S}_{\mathrm{\text{test}}}\)</span>.</p>
<p>In other words, the learning problem at hand is to find a hypothesis
<span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span> that minimizes the expected risk <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}\)</span> over
the training samples <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> which is generated by the underlying unknown
true distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> such that the generalization risk/error
<span class="math notranslate nohighlight">\(\mathcal{R} \leq \hat{\mathcal{R}} + \epsilon\)</span> with high probability.</p>
<p>How can we do that? Let’s start with the Law of Large Numbers.</p>
<div class="proof remark admonition" id="remark-learning-problem-notations">
<p class="admonition-title"><span class="caption-number">Remark 14 </span> (Notation)</p>
<section class="remark-content" id="proof-content">
<p>It should be clear from context that <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> is the <strong>generalization error</strong> of the hypothesis
<span class="math notranslate nohighlight">\(h\)</span> over the entire distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. In other words, this is the expected error based on
the entire distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<p>On the other hand, <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}\)</span> is the <strong>empirical risk</strong> of the hypothesis <span class="math notranslate nohighlight">\(h\)</span> over the
training samples <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
</section>
</div></section>
<section id="the-generalization-gap">
<h3><a class="toc-backref" href="#id9" role="doc-backlink">The Generalization Gap</a><a class="headerlink" href="#the-generalization-gap" title="Link to this heading">#</a></h3>
<div class="proof definition admonition" id="def-generalization-gap">
<p class="admonition-title"><span class="caption-number">Definition 23 </span> (Generalization Gap)</p>
<section class="definition-content" id="proof-content">
<p>Given a sample set <span class="math notranslate nohighlight">\(\mathcal{S} = \left\{\left(\mathbf{x}^{(n)}, y^{(n)}\right)\right\}_{n=1}^{N}\)</span>
drawn <span class="math notranslate nohighlight">\(\textbf{i.i.d.}\)</span> from the distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>, a hypothesis <span class="math notranslate nohighlight">\(h_S \in \mathcal{H}\)</span> learnt by the
algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> on <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, and a specific definition of loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> (i.e. zero-one loss), the <strong>generalization gap</strong> is defined as:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\epsilon_{gen}(h_S) = \left|\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h_S)\right\} - \hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h_S)\right\}\right|.
\end{aligned}
\]</div>
</section>
</div></section>
</section>
<section id="the-law-of-large-numbers">
<h2><a class="toc-backref" href="#id10" role="doc-backlink">The Law of Large Numbers</a><a class="headerlink" href="#the-law-of-large-numbers" title="Link to this heading">#</a></h2>
<p>Recall that in the section <a class="reference internal" href="../empirical_risk_minimization/02_concept.html#emprical-risk-approximates-true-risk"><span class="std std-ref">Empirical Risk Minimization approximates True Risk Minimization</span></a> of
<a class="reference internal" href="../empirical_risk_minimization/02_concept.html"><span class="std std-doc">the chapter on ERM</span></a>, we mentioned
that the the Empirical Risk approximates the True Risk as the number of samples
<span class="math notranslate nohighlight">\(N\)</span> grows. This is the
<a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/concept.html"><span class="std std-doc">Law of Large Numbers</span></a>
that was mentioned in an earlier
<a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/concept.html"><span class="std std-doc">chapter</span></a>.</p>
<p>We restate the Weak Law of Large Numbers from
<a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/concept.html#theorem-weak-law-of-large-numbers">Theorem 70</a> below again, but with notation more
aligned to our notations in
<a class="reference internal" href="../../notations/machine_learning.html"><span class="std std-doc">machine learning notations chapter</span></a>. In
particular, we use <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> suggesting that the random variable is the loss
value of <span class="math notranslate nohighlight">\(\mathcal{L}(\cdot)\)</span>. In other words, <span class="math notranslate nohighlight">\(\mathcal{L}^{(n)}\)</span> is treated as
realizations of the random variable <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> on the <span class="math notranslate nohighlight">\(n\)</span>-th sample.</p>
<div class="proof theorem admonition" id="theorem-weak-law-of-large-numbers-restated">
<p class="admonition-title"><span class="caption-number">Theorem 4 </span> (Weak Law of Large Numbers)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\mathcal{L}^{(1)}, \ldots, \mathcal{L}^{(N)}\)</span> be <span class="math notranslate nohighlight">\(\textbf{i.i.d.}\)</span> random variables with <strong>common</strong> mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Each <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is distributed by the same probability distribution <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> (<span class="math notranslate nohighlight">\(\mathcal{D}\)</span>).</p>
<p>Let <span class="math notranslate nohighlight">\(\bar{\mathcal{L}}\)</span> be the sample average defined in <a class="reference internal" href="../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/concept.html#equation-eq-sample-average">(213)</a> and <span class="math notranslate nohighlight">\(\mathbb{E}[\mathcal{L}^2] &lt; \infty\)</span>.</p>
<p>Then, for any <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>, we have</p>
<div class="math notranslate nohighlight" id="equation-eq-weak-law-of-large-numbers-3">
<span class="eqno">(9)<a class="headerlink" href="#equation-eq-weak-law-of-large-numbers-3" title="Link to this equation">#</a></span>\[
\lim_{N\to\infty}\mathbb{P}\left[\left|\underset{\mathcal{L} \sim P}{\mathbb{E}}[\mathcal{L}]-\frac{1}{N} \sum_{n=1}^N \mathbf{x}^{(n)}\right|&gt;\epsilon\right] := \lim_{N\to\infty} \mathbb{P}\left[\left|\mu - \bar{\mathcal{L}}^{(N)} \right| &gt; \epsilon\right] = 0
\]</div>
<p>This means that</p>
<div class="math notranslate nohighlight" id="equation-eq-weak-law-of-large-numbers-4">
<span class="eqno">(10)<a class="headerlink" href="#equation-eq-weak-law-of-large-numbers-4" title="Link to this equation">#</a></span>\[
\bar{\mathcal{L}} \xrightarrow{p} \underset{\mathcal{L} \sim P}{\mathbb{E}}[\mathcal{L}] \quad \text{as } N \to \infty
\]</div>
</section>
</div><p>In other words, as sample size <span class="math notranslate nohighlight">\(N\)</span> grows, the probability that the sample
average <span class="math notranslate nohighlight">\(\bar{\mathcal{L}}\)</span> differs from the population mean <span class="math notranslate nohighlight">\(\mu\)</span> by more than
<span class="math notranslate nohighlight">\(\epsilon\)</span> approaches zero. Note this is not saying that the <em>probability</em> of
the difference between the sample average and the population mean is more than
epsilon is zero, the expression is the probability that the difference is more
than epsilon! So in laymen terms, as <span class="math notranslate nohighlight">\(N\)</span> grows, then it is guaranteed that the
difference between the sample average and the population mean is no more than
<span class="math notranslate nohighlight">\(\epsilon\)</span>. This seems strong since <span class="math notranslate nohighlight">\(\epsilon\)</span> can be arbitrarily small, but it
is still a probability bound.</p>
<p>Then recall that the True Risk Function is defined as:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} := \mathbb{E}_{\mathcal{D}}\left[\mathcal{L}((\mathbf{x}, y), h)\right]
\]</div>
<p>and the Empirical Risk Function is defined as:</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} := \frac{1}{N} \sum_{n=1}^N \mathcal{L}\left(\left(\mathbf{x}^{(n)}, y^{(n)}\right), h\right)
\]</div>
<p>Furthermore, since <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is defined to be a random variable representing
the loss/error of a single sample, then we can rewrite the True Risk Function
as:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} := \mathbb{E}_{\mathcal{D}}\left[\mathcal{L}\left((\mathbf{x}, y), h\right)\right]
\]</div>
<p>which means that the True Risk Function is the expected loss/error of all
possible samples. This is because we treat <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> as a <strong>random
variable</strong> and we take the expected value of it.</p>
<div class="proof remark admonition" id="remark-random-variable-is-a-function">
<p class="admonition-title"><span class="caption-number">Remark 15 </span> (Random Variable is a Function)</p>
<section class="remark-content" id="proof-content">
<p>The notation might seem overloaded and abused, but since random variable in itself is a function,
and <span class="math notranslate nohighlight">\(\mathcal{L}(\cdot)\)</span> is also a function mapping states <span class="math notranslate nohighlight">\((\mathbf{x}, y)\)</span> to a real number,
then we can treat <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> as a random variable representing the loss/error of a single sample.</p>
</section>
</div><p>Now, define <span class="math notranslate nohighlight">\(\mathcal{L}^{(n)}\)</span> to be the loss/error of the <span class="math notranslate nohighlight">\(n\)</span>-th sample in the
train dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. Then we can rewrite the Empirical Risk Function as:</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} := \frac{1}{N} \sum_{n=1}^N \mathcal{L}^{(n)}
\]</div>
<p>which means that the Empirical Risk Function is the average loss/error of all
training samples.</p>
<p>Notice that they both have exactly the same form as the Weak Law of Large
Numbers, so we can apply the Weak Law of Large Numbers to the True Risk Function
and the Empirical Risk Function. This natural application of the Weak Law of
Large Numbers allows us to answer the following question (also in
<a class="reference internal" href="01_intro.html#equation-eq-learning-problem-solvable">(18)</a>):</p>
<div class="proof remark admonition" id="remark-summary-1">
<p class="admonition-title"><span class="caption-number">Remark 16 </span> (Summary)</p>
<section class="remark-content" id="proof-content">
<p>Given a dataset <span class="math notranslate nohighlight">\(\mathcal{S} = \left\{\left(\mathbf{x}^{(n)}, y^{(n)}\right)\right\}_{n=1}^N\)</span>, and a <strong>fixed</strong> and <strong>single</strong> hypothesis <span class="math notranslate nohighlight">\(h\)</span>, the Weak Law of Large Numbers tells us that as the number of samples in your training set increases from <span class="math notranslate nohighlight">\(N\)</span> to <span class="math notranslate nohighlight">\(\infty\)</span>, the Empirical Risk Function will converge to the True Risk Function.</p>
<div class="math notranslate nohighlight" id="equation-eq-convergence-of-empirical-risk-to-true-risk">
<span class="eqno">(11)<a class="headerlink" href="#equation-eq-convergence-of-empirical-risk-to-true-risk" title="Link to this equation">#</a></span>\[
\lim_{N \rightarrow \infty} \mathbb{P}\left[\left|\mathcal{R}_{\mathcal{D}}(h) - \hat{\mathcal{R}}_{\mathcal{S}}(h)\right|&gt;\epsilon\right]=0
\]</div>
<p>where the notation of <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> and <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}\)</span> are simplified to only contain <span class="math notranslate nohighlight">\(h\)</span> for readability.</p>
<p>Well, this is something. At least we know that if we can bump up the number of samples
in our training set to <span class="math notranslate nohighlight">\(\infty\)</span>, then we can guarantee that the Empirical Risk Function will be close to the True Risk Function. But this is not really very useful, because we can’t really get <span class="math notranslate nohighlight">\(\infty\)</span> samples in practice.</p>
<p>Can we do better by finding an upper bound on the
right hand side of <a class="reference internal" href="#equation-eq-convergence-of-empirical-risk-to-true-risk">(11)</a>? This bound has to be
a function of the number of samples <span class="math notranslate nohighlight">\(N\)</span> so we at least know how many samples we need to get a good approximation of the True Risk Function, or even if we cannot get more samples, then what
is the theoretical maximum error we can expect from the Empirical Risk Function?</p>
</section>
</div></section>
<section id="hoeffding-s-inequality">
<h2><a class="toc-backref" href="#id11" role="doc-backlink">Hoeffding’s Inequality</a><a class="headerlink" href="#hoeffding-s-inequality" title="Link to this heading">#</a></h2>
<p>Earlier, we also saw the discussion of this inequality in a previous
<a class="reference internal" href="../../probability_theory/06_sample_statistics/0602_probability_inequalities/concept.html"><span class="std std-doc">chapter</span></a>.
This inequality will help us answer the question above.</p>
<p>We restate the Hoeffding’s Inequality here, but in machine learning context:</p>
<div class="proof theorem admonition" id="theorem-hoeffding-inequality-restated">
<p class="admonition-title"><span class="caption-number">Theorem 5 </span> (Hoeffding’s Inequality)</p>
<section class="theorem-content" id="proof-content">
<p>Consider a dataset <span class="math notranslate nohighlight">\(\mathcal{S} = \left\{\left(\mathbf{x}^{(n)}, y^{(n)}\right)\right\}_{n=1}^N\)</span> drawn i.i.d. from an unknown distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. Let the hypothesis
set <span class="math notranslate nohighlight">\(\mathcal{H} = \left\{h_{1}, \ldots, h_{K}\right\}\)</span> be a finite set of hypotheses. Then, suppose we fix a hypothesis <span class="math notranslate nohighlight">\(h\)</span> in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> (for any <span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span>) before we look at the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, which means
we have not learnt <span class="math notranslate nohighlight">\(h_S\)</span> yet.</p>
<p>Furthermore, let <span class="math notranslate nohighlight">\(\mathcal{L}((\mathbf{x}, y), h)\)</span> be the loss/error of a single sample <span class="math notranslate nohighlight">\((\mathbf{x}, y)\)</span> with respect to the hypothesis <span class="math notranslate nohighlight">\(h\)</span> such that
<span class="math notranslate nohighlight">\(0 \leq \mathcal{L}((\mathbf{x}, y), h) \leq 1\)</span> and <span class="math notranslate nohighlight">\(\mathbb{E}\left[\mathcal{L}((\mathbf{x}, y), h)\right]\)</span> be the expected loss/error over the entire distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<p>We can then define a sequence of random variables <span class="math notranslate nohighlight">\(\left\{\mathcal{L}^{(n)}\right\}_{n=1}^N\)</span> such that <span class="math notranslate nohighlight">\(\mathcal{L}^{(n)}\)</span> is the loss/error of the <span class="math notranslate nohighlight">\(n\)</span>-th sample in the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
<p>Then for any <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>, we have the following bound:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}\left[\left|\mathbb{E}\left[\mathcal{L}((\mathbf{x}, y), h)\right] - \frac{1}{N} \sum_{n=1}^N \mathcal{L}^{(n)}\left(\left(\mathbf{x}^{(n)}, y^{(n)}\right), h\right)\right|&gt;\epsilon\right] &amp;= \mathbb{P}\left[\left|\mathcal{R}_{\mathcal{D}}(h) - \hat{\mathcal{R}}_{\mathcal{S}}(h)\right|&gt;\epsilon\right] \\
&amp;\leq 2 e^{-2 \epsilon^{2} N}
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the number of samples in the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> and <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}\)</span> are the True Risk Function and the Empirical Risk Function respectively.</p>
</section>
</div><div class="proof remark admonition" id="remark-things-to-note">
<p class="admonition-title"><span class="caption-number">Remark 17 </span> (Things to Note (Important))</p>
<section class="remark-content" id="proof-content">
<ol class="arabic simple">
<li><p>Note that both <span class="math notranslate nohighlight">\(\mathcal{L}((\mathbf{x}, y), h)\)</span> and the samples
<span class="math notranslate nohighlight">\(\left(\mathbf{x}^{(n)}, y^{(n)}\right)\)</span> are drawn from the same distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p></li>
<li><p><strong>Important</strong>: Note carefully this <span class="math notranslate nohighlight">\(h\)</span> is even picked even before the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is generated from <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. This is not a trivial concept and requires quite some justification. See <a class="reference internal" href="#why-must-h-be-fixed"><span class="std std-ref">Why must h be fixed and defined before generating the dataset \mathcal{S}?</span></a>.</p></li>
<li><p>The random variable must be bounded between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>, so your loss function must be bounded between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>. This is simple to do usually since you usually apply sigmoid/softmax to your output to get a probability between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span> to feed into your loss function.</p></li>
</ol>
</section>
</div><p>As the number of training samples <span class="math notranslate nohighlight">\(N\)</span> grows, the in-sample error
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h)\)</span> (which is the training error) converges
exponentially to the out-sample error <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h)\)</span> (which is
the testing error). The in-sample error <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h)\)</span> is
something we can compute numerically using the training set. The out-sample
error is an unknown quantity because we do not know the target function <span class="math notranslate nohighlight">\(f\)</span>.
Hoeffding inequality says even though we do not know
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h)\)</span>, for large enough <span class="math notranslate nohighlight">\(N\)</span> the in-sample error
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h)\)</span> will be sufficiently close to
<span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h)\)</span>. Therefore, we will be able to tell how good the
hypothesis function is without accessing the unknown target function.</p>
<section id="comparing-hoeffding-s-inequality-with-the-chebyshev-s-inequality">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Comparing Hoeffding’s Inequality with the Chebyshev’s Inequality</a><a class="headerlink" href="#comparing-hoeffding-s-inequality-with-the-chebyshev-s-inequality" title="Link to this heading">#</a></h3>
<p>Let us take a quick comparison between the Hoeffding inequality and the
Chebyshev inequality. Chebyshev inequality states that</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left[\left|\mathbb{E}\left[\mathcal{L}((\mathbf{x}, y), h)\right] - \frac{1}{N} \sum_{n=1}^N \mathcal{L}^{(n)}\right|&gt;\epsilon\right]\leq \frac{\sigma^{2}}{\epsilon^{2} N} .
\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma^{2}\)</span> is the variance of the loss/error
<span class="math notranslate nohighlight">\(\mathcal{L}((\mathbf{x}, y), h)\)</span>.</p>
<p>If we let <span class="math notranslate nohighlight">\(2 e^{-2 \epsilon^{2} N} \leq \delta\)</span> for some <span class="math notranslate nohighlight">\(\delta\)</span> in Hoeffding
inequality, and <span class="math notranslate nohighlight">\(\frac{\sigma^{2}}{\epsilon^{2} N}\)</span> for some <span class="math notranslate nohighlight">\(\delta\)</span> in
Chebyshev inequality, we can easily see that the two inequalities imply</p>
<div class="math notranslate nohighlight">
\[
N \geq-\frac{1}{2 \epsilon^{2}} \log \frac{\delta}{2}, \quad \text { and } \quad N \geq \frac{\sigma^{2}}{\epsilon^{2} \delta} .
\]</div>
<p>For simplicity let us assume that <span class="math notranslate nohighlight">\(\sigma=1, \epsilon=0.1\)</span> and <span class="math notranslate nohighlight">\(\delta=0.01\)</span>.
Then the above calculation will give <span class="math notranslate nohighlight">\(N \geq 265\)</span> for Hoeffding whereas
<span class="math notranslate nohighlight">\(N \geq 10000\)</span> for Chebyshev. That means, Hoeffding inequality has a much lower
prediction of how many samples we need to achieve an error of
<span class="math notranslate nohighlight">\(\delta \leq 0.01\)</span>.</p>
<figure class="align-default" id="ece595-fig4-4">
<img alt="../../_images/ece595_fig4.4.jpeg" src="../../_images/ece595_fig4.4.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 10 </span><span class="caption-text">Comparing Hoeffding inequality and Chebyshev inequality to predict the actual probability bound.</span><a class="headerlink" href="#ece595-fig4-4" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>We see that Chebyshev is a more <strong>conservative</strong> bound than Hoeffding, and is
less strong than Hoeffding since Hoeffding does not need to know <em>anything</em>
about the random variable <span class="math notranslate nohighlight">\(\mathcal{L}((\mathbf{x}, y), h)\)</span> on the right hand
side of the inequality.</p>
</section>
<section id="example-hoeffding-s-inequality-in-classification">
<h3><a class="toc-backref" href="#id13" role="doc-backlink">Example: Hoeffding’s Inequality in Classification</a><a class="headerlink" href="#example-hoeffding-s-inequality-in-classification" title="Link to this heading">#</a></h3>
<p><em>Notation may be slightly different from the rest of the section.</em></p>
<p>Following exampled adapted from
<a class="reference external" href="http://faculty.washington.edu/yenchic/18W_425/Lec15_conc.pdf">STAT425</a>.</p>
<p>A powerful feature of the Hoeffding’s inequality is that it holds regardless of
the classifier. Namely, even if we are considering many different types of
classifiers, some are decision trees, some are kNN, some are logistic
regression, they all satisfy equation above.</p>
<p>What this means is this inequality holds for any classifier <span class="math notranslate nohighlight">\(h\)</span> and any loss
function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>.</p>
<p>So even if your loss function is not <span class="math notranslate nohighlight">\(0-1\)</span> loss, you can still use the
Hoeffding’s inequality. Say cross-entropy loss, then you just need to know that
the difference between the expected loss of the classifier and the empirical
loss of the classifier is bounded by the right hand side of the inequality.</p>
</section>
</section>
<section id="pac-framework">
<h2><a class="toc-backref" href="#id14" role="doc-backlink">PAC Framework</a><a class="headerlink" href="#pac-framework" title="Link to this heading">#</a></h2>
<p>The probabilistic analysis is called a probably approximately correct (PAC)
framework. The word <span class="math notranslate nohighlight">\(\mathrm{P}-\mathrm{A}-\mathrm{C}\)</span> comes from three
principles of the Hoeffding inequality:</p>
<ul class="simple">
<li><p><strong>Probably</strong>: We use the probability
<span class="math notranslate nohighlight">\(\textcolor{red}{\mathbb{P}}\left[\left|\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} - \hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\right|&gt;\epsilon \right] \leq 2 e^{-2 \epsilon^{2} N}\)</span>
as a measure to quantify the error.</p></li>
<li><p><strong>Approximately</strong>: The in-sample error is an approximation of the out-sample
error, as given by
<span class="math notranslate nohighlight">\(\mathbb{P}\left[\textcolor{red}{\left|\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} - \hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\right|&gt;\epsilon}\right] \leq 2 e^{-2 \epsilon^{2} N}\)</span>.
The approximation error is controlled by <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p></li>
<li><p><strong>Correct</strong>: The error is bounded by the right hand side of the Hoeffding
inequality:
<span class="math notranslate nohighlight">\(\mathbb{P}\left[\left|\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} - \hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\right|&gt;\epsilon\right] \textcolor{red}{\leq 2 e^{-2 \epsilon^{2} N}}\)</span>.
The accuracy is controlled by <span class="math notranslate nohighlight">\(N\)</span> for a fixed <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p></li>
</ul>
</section>
<section id="hoeffding-inequality-is-invalid-for-h-s-learnt-from-mathcal-s">
<h2><a class="toc-backref" href="#id15" role="doc-backlink">Hoeffding Inequality is Invalid for <span class="math notranslate nohighlight">\(h_S\)</span> learnt from <span class="math notranslate nohighlight">\(\mathcal{S}\)</span></a><a class="headerlink" href="#hoeffding-inequality-is-invalid-for-h-s-learnt-from-mathcal-s" title="Link to this heading">#</a></h2>
<p>Now, there is one last problem we need to resolve. The above Hoeffding
inequality holds for a fixed hypothesis function <span class="math notranslate nohighlight">\(h\)</span>. This means that <span class="math notranslate nohighlight">\(h\)</span> is
already chosen before we generate the dataset. If we allow <span class="math notranslate nohighlight">\(h\)</span> to change after
we have generated the dataset, then the Hoeffding inequality is no longer valid.
What do we mean by after generating the dataset? In any learning scenario, we
are given a training dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. Based on this dataset, we have to
choose a hypothesis function <span class="math notranslate nohighlight">\(h_S\)</span> from the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. The
hypothesis <span class="math notranslate nohighlight">\(h_S\)</span> we choose depends on what samples are inside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> and
which learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> we use. So <span class="math notranslate nohighlight">\(h_S\)</span> changes after the
dataset is generated.</p>
<p>Now this is a non-trivial problem, and to fully understand this requires close
scrutiny. Recall in <a class="reference internal" href="#remark-things-to-note">Remark 17</a>’s point 2, we said that <span class="math notranslate nohighlight">\(h\)</span>
is fixed prior to generating the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> and using <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>
to learn <span class="math notranslate nohighlight">\(h_S\)</span> from <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
<p>Here are some links that explains the issue in details on where exactly the
problem lies. All in all, one just needs to know that the <strong><em>assumption of
<span class="math notranslate nohighlight">\(\textbf{i.i.d.}\)</span> is broken in Hoeffding’s Inequality if you allow <span class="math notranslate nohighlight">\(h\)</span> to change
to <span class="math notranslate nohighlight">\(h_S\)</span> after learning from <span class="math notranslate nohighlight">\(\mathcal{S}\)</span></em></strong>.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://math.stackexchange.com/questions/2097429/hoeffdings-inequality-and-learning">1. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/201746/changeing-the-hypothesis-while-generating-samples">2. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/157905/in-learning-theory-why-cant-we-bound-like-pe-ing-e-outg-epsilon">3. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
</ul>
<hr class="docutils" />
<p>This has serious implications! The logic that follows is that before learning,
for any fixed <span class="math notranslate nohighlight">\(h\)</span>, we can bound the error by the Hoeffding’s Inequality. But
now, there is no guarantee that
<span class="math notranslate nohighlight">\(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right|&gt;\epsilon\)</span>
(the “bad event”) is less than <span class="math notranslate nohighlight">\(\delta\)</span> (the “bad event probability”). It could
be less, it could be more, no one knows, but we do know that
<span class="math notranslate nohighlight">\(h_S \in \mathcal{H}\)</span>.</p>
<p>Let’s see how we can make use of this property to bound the error for the
<strong>entire hypothesis set</strong> <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> instead of just a single hypothesis <span class="math notranslate nohighlight">\(h\)</span>.</p>
</section>
<section id="union-bound">
<h2><a class="toc-backref" href="#id16" role="doc-backlink">Union Bound</a><a class="headerlink" href="#union-bound" title="Link to this heading">#</a></h2>
<p>Suppose that <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> contains <span class="math notranslate nohighlight">\(M\)</span> hypothesis functions
<span class="math notranslate nohighlight">\(h_{1}, \ldots, h_{M}\)</span>. The final hypothesis <span class="math notranslate nohighlight">\(h_S\)</span> that your learning algorithm
<span class="math notranslate nohighlight">\(\mathcal{A}\)</span> picked is one of these potential hypotheses. To have
<span class="math notranslate nohighlight">\(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right|&gt;\epsilon\)</span>,
we need to ensure that at least one of the <span class="math notranslate nohighlight">\(M\)</span> potential hypotheses can satisfy
the inequality.</p>
<div class="proof remark admonition" id="prf:remark-bounding-the-entire-hypothesis-set">
<p class="admonition-title"><span class="caption-number">Remark 18 </span> (Bounding the Entire Hypothesis Set)</p>
<section class="remark-content" id="proof-content">
<p>This part helps visualize why you need to use union bound to bound all hypotheses in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>.</p>
<p>This is best read together with the example in <a class="reference external" href="https://en.wikipedia.org/wiki/Boole%27s_inequality#Example">Wikipedia</a>.</p>
<p><strong>First</strong>, we must establish that for the <span class="math notranslate nohighlight">\(h_S\)</span> learnt by <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> on the
dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, the generalization gap <span class="math notranslate nohighlight">\(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right|\)</span> is no longer bounded by the Hoeffding Inequality. We turn our attention to bounding
the entire hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> instead of just a single hypothesis <span class="math notranslate nohighlight">\(h\)</span>.</p>
<p><strong>Second</strong>, let us define the bad event <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> to be:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{B} = \left\{\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right| &gt; \epsilon\right\}
\]</div>
<p>which is the event that the error is greater than <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<p>Then it follows that <span class="math notranslate nohighlight">\(\mathcal{B}_m\)</span> is the bad event for the <span class="math notranslate nohighlight">\(m\)</span>th hypothesis <span class="math notranslate nohighlight">\(h_m\)</span> in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{B}_m = \left\{\left|\mathcal{R}_{\mathcal{D}}(h_m) - \hat{\mathcal{R}}_{\mathcal{S}}(h_m)\right| &gt; \epsilon\right\}
\]</div>
<p>We define the good event <span class="math notranslate nohighlight">\(\mathcal{B}^{\mathrm{c}}\)</span> to be the good event, the complement of the bad event to be:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{B}^{\mathrm{c}} = \left\{\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right| \leq \epsilon\right\}
\]</div>
<p>which is the event that the error is less than or equal to <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<p><strong>Third</strong>, we want to show that <span class="math notranslate nohighlight">\(\forall h_m \in \mathcal{H}\)</span>, the probability of <em><strong>all</strong></em> <span class="math notranslate nohighlight">\(h_1, h_2 \ldots, h_M\)</span> is bounded below by a value of say, <span class="math notranslate nohighlight">\(\phi\)</span>.</p>
<p>In other words, denote the event <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> as the event where <em><strong>all</strong></em> <span class="math notranslate nohighlight">\(h_1, h_2 \ldots, h_M\)</span>
are “good” (none of them are “bad”). The event <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> can be defined as:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{C} = \mathcal{B_1}^{\mathrm{c}} \cap \mathcal{B_2}^{\mathrm{c}} \cap \ldots \cap \mathcal{B_M}^{\mathrm{c}}
\]</div>
<p>which is the event that <em><strong>all</strong></em> <span class="math notranslate nohighlight">\(h_1, h_2 \ldots, h_M\)</span> are “good”. Now, we seek to find
the probability of <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> to be greater than or equal to <span class="math notranslate nohighlight">\(\phi\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}\left(\mathcal{C}\right) &amp;&gt; \phi \\
\end{aligned}
\end{split}\]</div>
<p>For example, if <span class="math notranslate nohighlight">\(\phi = 0.95\)</span>, this means that we can be 95% confident that <em><strong>all</strong></em> <span class="math notranslate nohighlight">\(h_1, h_2 \ldots, h_M\)</span> are “good” (i.e. all <span class="math notranslate nohighlight">\(h_1, h_2, \ldots, h_M\)</span> give a generalization error less than or equal to <span class="math notranslate nohighlight">\(\epsilon\)</span>).</p>
<p>However, to make use of Union Bound (Boole’s Inequality), we need to express the <span class="math notranslate nohighlight">\(h_1, h_2, \ldots, h_M\)</span> as a sequence of logical <strong>or</strong> events. Let’s try to rephrase the event <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> as a sequence of logical <strong>or</strong> events.</p>
<p><strong>Fourth</strong>, let <span class="math notranslate nohighlight">\(\mathcal{C}^{\mathrm{c}}\)</span> be the complement of the event <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{C}^{\mathrm{c}} &amp;= \exists h_m \in \mathcal{H} \quad \text{s.t.} h_m \text{ is a bad} \\
&amp;= \mathcal{B_1} \cup \mathcal{B_2} \cup \ldots \cup \mathcal{B_M} \\
&amp;= h_1 \text{ gives a bad error} \cup h_2 \text{ gives a bad error} \cup \ldots \cup h_M \text{ gives a bad error}
\end{aligned}
\end{split}\]</div>
<p>Then, finding <span class="math notranslate nohighlight">\(\mathbb{P}(\mathcal{C}) &gt; \phi\)</span> is equivalent to finding the following:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\mathbb{P}\left(\mathcal{C}\right) &amp;&gt; \phi \\
\iff &amp;1 - \mathbb{P}\left(\mathcal{C}^{\mathrm{c}}\right) &amp;&gt; \phi \\
\iff &amp;\mathbb{P}\left(\mathcal{C}^{\mathrm{c}}\right) &amp;\leq 1 - \phi \\
\end{aligned}
\end{split}\]</div>
<p>where we invoked that <span class="math notranslate nohighlight">\(\mathcal{C} + \mathcal{C}^{\mathrm{c}} = 1\)</span>. Now, we have turned
the problem of finding <span class="math notranslate nohighlight">\(\mathbb{P}(\mathcal{C}) &gt; \phi\)</span> into finding the probability of
<span class="math notranslate nohighlight">\(\mathcal{C}^{\mathrm{c}}\)</span> to be less than or equal to <span class="math notranslate nohighlight">\(1 - \phi\)</span> (from lower bound to upper bound).</p>
<p><strong>Fifth</strong>, so now we can instead find the equivalent of the Hoeffding Inequality for the event <span class="math notranslate nohighlight">\(\mathcal{C}^{\mathrm{c}}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}\left(\mathcal{C}^{\mathrm{c}}\right) &amp;= \mathbb{P}\left(\mathcal{B_1} \cup \mathcal{B_2} \cup \ldots \cup \mathcal{B_M}\right) \\
&amp;\leq \mathbb{P}\left(\mathcal{B_1}\right) + \mathbb{P}\left(\mathcal{B_2}\right) + \ldots + \mathbb{P}\left(\mathcal{B_M}\right) \\
\end{aligned}
\end{split}\]</div>
<p>where we invoked the Union Bound (Boole’s Inequality).</p>
<p><strong>Last</strong>, in order for the entire hypothesis space to have a generalization gap bigger than <span class="math notranslate nohighlight">\(\epsilon\)</span>, at least one of its hypothesis: <span class="math notranslate nohighlight">\(h_1\)</span> or <span class="math notranslate nohighlight">\(h_2\)</span> or <span class="math notranslate nohighlight">\(h_3\)</span> or … etc should have. This can be expressed formally by stating that:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left[\sup _{h \in \mathcal{H}}\left|\mathcal{R}(h)-\hat{\mathcal{R}}(h)\right|&gt;\epsilon\right]=\mathbb{P}\left[\bigcup_{h \in \mathcal{H}}\left|\mathcal{R}(h)-\hat{\mathcal{R}}(h)\right|&gt;\epsilon\right]
\]</div>
<p>Where <span class="math notranslate nohighlight">\(\bigcup\)</span> denotes the union of the events, which also corresponds to the logical OR operator. Using the union bound inequality, we get:</p>
<div class="math notranslate nohighlight" id="equation-eq-union-bound-1">
<span class="eqno">(12)<a class="headerlink" href="#equation-eq-union-bound-1" title="Link to this equation">#</a></span>\[\begin{split}
\begin{aligned}
\mathbb{P}\left\{\left|\hat{\mathcal{R}}_{\mathcal{D}}(h_S)-\mathcal{R}_{\mathcal{S}}(h_S)\right|&gt;\epsilon\right\} &amp;\stackrel{(a)}{\leq} \mathbb{P}\left[\sup _{h \in \mathcal{H}}\left|\mathcal{R}(h)-\hat{\mathcal{R}}(h)\right|&gt;\epsilon\right] \\
&amp;= \mathbb{P}\left[\bigcup_{h \in \mathcal{H}}\left|\mathcal{R}(h)-\hat{\mathcal{R}}(h)\right|&gt;\epsilon\right]\\
&amp; \stackrel{(b)}{\leq} \sum_{m=1}^{M} \mathbb{P}\left\{\left|\hat{\mathcal{R}}_{\mathcal{D}}\left(h_{m}\right)-\mathcal{R}_{\mathcal{S}}\left(h_{m}\right)\right|&gt;\epsilon\right\} \\
&amp;= \sum_{m=1}^{M} 2 e^{-2 \epsilon^{2} N} \\
&amp;= \left| \mathcal{H} \right| 2 e^{-2 \epsilon^{2} N} \text{. }
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\((a)\)</span> holds because <span class="math notranslate nohighlight">\(\mathbb{P}[A] \leq \mathbb{P}[B]\)</span> if <span class="math notranslate nohighlight">\(A \Rightarrow B\)</span>, and <span class="math notranslate nohighlight">\((b)\)</span> is the Union bound which says <span class="math notranslate nohighlight">\(\mathbb{P}[A\)</span> or <span class="math notranslate nohighlight">\(B] \leq \mathbb{P}[A]+\mathbb{P}[B]\)</span>.</p>
<p>Therefore, if we bound each <span class="math notranslate nohighlight">\(h_{m}\)</span> using the Hoeffding inequality</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left\{\left|\hat{\mathcal{R}}_{\mathcal{S}}\left(h_{m}\right)-\mathcal{R}_{\mathcal{D}}\left(h_{m}\right)\right|&gt;\epsilon\right\} \leq 2 e^{-2 \epsilon^{2} N}
\]</div>
<p>then the overall bound on <span class="math notranslate nohighlight">\(h_S\)</span> is the sum of the <span class="math notranslate nohighlight">\(M\)</span> terms.</p>
<p>To see why <span class="math notranslate nohighlight">\((a)\)</span> holds, consider the following:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\left|\hat{\mathcal{R}}_{\mathcal{D}}(g)-\mathcal{R}_{\mathcal{S}}(g)\right|&gt;\epsilon &amp;\Longrightarrow \left\{\left|\hat{\mathcal{R}}_{\mathcal{D}}\left(h_1\right)-\mathcal{R}_{\mathcal{S}}\left(h_1\right)\right|&gt;\epsilon \text{ or } \left|\hat{\mathcal{R}}_{\mathcal{D}}\left(h_2\right)-\mathcal{R}_{\mathcal{S}}\left(h_2\right)\right|&gt;\epsilon \text{ or } \ldots \text{ or } \left|\hat{\mathcal{R}}_{\mathcal{D}}\left(h_M\right)-\mathcal{R}_{\mathcal{S}}\left(h_M\right)\right|&gt;\epsilon\right\} \\
\end{aligned}
\end{split}\]</div>
<p>The LHS is event <span class="math notranslate nohighlight">\(A\)</span> for example, the RHS is event <span class="math notranslate nohighlight">\(B\)</span>, then since we have <span class="math notranslate nohighlight">\(A \Rightarrow B\)</span>, we have <span class="math notranslate nohighlight">\(\mathbb{P}[A] \leq \mathbb{P}[B]\)</span>.</p>
<p>Thus, we found a bound for the whole hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. Thus our <span class="math notranslate nohighlight">\(1 - \phi\)</span> is actually
<span class="math notranslate nohighlight">\(\left| \mathcal{H} \right| 2 e^{-2 \epsilon^{2} N}\)</span>.</p>
<div class="toggle docutils container">
<p>The below content was what I initially wrote, but the argument is hand-wavy, so I tried to lay
out the argument more formally above. Still quite unsure if the reasoning is correct, but at least
should be along those lines.</p>
<p>If one has <span class="math notranslate nohighlight">\(M\)</span> hypotheses <span class="math notranslate nohighlight">\(h_1, \ldots, h_M\)</span> in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, then what is the probability that
<em><strong>all</strong></em> <span class="math notranslate nohighlight">\(M\)</span> hypotheses satisfy the inequality <span class="math notranslate nohighlight">\(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right| \leq \epsilon\)</span>? So if our probability found is <span class="math notranslate nohighlight">\(95\%\)</span>, this means that
we can be 95% confident that <em><strong>all</strong></em> <span class="math notranslate nohighlight">\(M\)</span> hypotheses satisfy the inequality. This is setting
<span class="math notranslate nohighlight">\(\delta = 0.05\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\mathbb{P}\left(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right| \leq \epsilon\right) \geq 1 - \delta
\end{aligned}
\]</div>
<p>If we can find this <strong>probability</strong>, then this just means that whichever <span class="math notranslate nohighlight">\(h_S\)</span> we learnt by <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>
on <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, will have an error less than or equal to <span class="math notranslate nohighlight">\(\epsilon\)</span> with probability <span class="math notranslate nohighlight">\(95\%\)</span> (similar to
confidence interval).</p>
<p>We are stating the problem by asking the event “all <span class="math notranslate nohighlight">\(M\)</span> hypotheses are good”, now we can
find the complement of “all <span class="math notranslate nohighlight">\(M\)</span> hypotheses are good” to be “at least one <span class="math notranslate nohighlight">\(h_m\)</span> is bad”
so that we can use the union bound easier.</p>
<p>Now, if we go the route of finding complement, then this objective is stated as:</p>
<p>If one has <span class="math notranslate nohighlight">\(M\)</span> hypotheses <span class="math notranslate nohighlight">\(h_1, \ldots, h_M\)</span> in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, then what is the probability that
<em><strong>at least (there exists) at least one</strong></em> <span class="math notranslate nohighlight">\(h_m\)</span> such that <span class="math notranslate nohighlight">\(\left|\mathcal{R}_{\mathcal{D}}(h_m) - \hat{\mathcal{R}}_{\mathcal{S}}(h_m)\right| &gt; \epsilon\)</span>?</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\mathbb{P}\left(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right| &gt; \epsilon\right) \leq \delta
\end{aligned}
\]</div>
<p>These are two equivalent statements, and we can use either one.</p>
<p>Now, we can readily use the union bound since
our expression is now in the form of “at least one <span class="math notranslate nohighlight">\(h_m\)</span> is bad” which translates to a union of
“events” <span class="math notranslate nohighlight">\(h_1\)</span> is bad, <span class="math notranslate nohighlight">\(h_2\)</span> is bad, <span class="math notranslate nohighlight">\(\ldots\)</span>, <span class="math notranslate nohighlight">\(h_M\)</span> is bad.</p>
</div>
</section>
</div><div class="toggle docutils container">
<div class="proof remark admonition" id="prf:remark-major-confusion-alert">
<p class="admonition-title"><span class="caption-number">Remark 19 </span> (Major Confusion Alert)</p>
<section class="remark-content" id="proof-content">
<p>DEFUNCT AS OF 1ST MARCH, 2023, READ WITH CAUTION AS IT IS NOT CORRECT. I AM LEAVING IT HERE FOR HISTORICAL PURPOSES.</p>
<p>What this means is that out of <span class="math notranslate nohighlight">\(M\)</span> hypotheses in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, at least one of them <strong>does satisfy the Hoeffding’s Inequality, but you do not know which <span class="math notranslate nohighlight">\(h\)</span> it is.</strong>
This is because our definition of Hoeffding’s Inequality <strong>requires us to fix a <span class="math notranslate nohighlight">\(h\)</span> prior to generating the dataset</strong>. And therefore this <span class="math notranslate nohighlight">\(h\)</span> we fixed is <strong>not the same as the <span class="math notranslate nohighlight">\(h_S\)</span> we picked after generating the dataset</strong>. So the Hoeffding’s Inequality is no longer valid. It does sound confusing, because one would think that this inequality seems to satify for any <span class="math notranslate nohighlight">\(h\)</span>, but if we follow definition, it is a fixed <span class="math notranslate nohighlight">\(h\)</span>, so now when we get our new <span class="math notranslate nohighlight">\(h_S\)</span>, it is no longer the “same” as the <span class="math notranslate nohighlight">\(h\)</span> we fixed prior.</p>
<p>This is why the question boils down to calculating the following probability:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left[\sup _{h \in \mathcal{H}}\left|\mathcal{R}(h)-\hat{\mathcal{R}}(h)\right|&gt;\epsilon\right]
\]</div>
<p>That is the probability that the least upper bound (that is the supremum <span class="math notranslate nohighlight">\(\sup _{h \in \mathcal{H}}\)</span> ) of the absolute difference between <span class="math notranslate nohighlight">\(\mathcal{R}(h)\)</span> and <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}(h)\)</span> is larger than a very small value <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<p>In more laymen words, every <span class="math notranslate nohighlight">\(h_m \in \mathcal{H}\)</span> induces a difference categorized by say <span class="math notranslate nohighlight">\(\text{in_out_error_diff}_m = \mathcal{R}(h_m)-\hat{\mathcal{R}}(h_m)\)</span>, and this
<span class="math notranslate nohighlight">\(\text{in_out_error_diff}_m\)</span> is a scalar value, say ranging from <span class="math notranslate nohighlight">\(0\)</span> to <span class="math notranslate nohighlight">\(1\)</span>, sometimes, a hypothesis <span class="math notranslate nohighlight">\(h_i\)</span> can induce a difference of say <span class="math notranslate nohighlight">\(0.2\)</span>, and sometimes, another hypothesis <span class="math notranslate nohighlight">\(h_j\)</span> can induce a difference of say <span class="math notranslate nohighlight">\(0.8\)</span>. The supremum of these differences is the <em>nasty and bad</em> hypothesis <span class="math notranslate nohighlight">\(h_{\text{bad}}\)</span> that induces the maximum difference amongst all the <span class="math notranslate nohighlight">\(h_m \in \mathcal{H}\)</span>. BUT IF WE CAN BOUND THE BADDEST AND WORST CASE by a very small value <span class="math notranslate nohighlight">\(\epsilon\)</span>, then we are good. This is exactly what the Hoeffding’s Inequality does. It says that the largest difference between <span class="math notranslate nohighlight">\(\mathcal{R}(h)\)</span> and <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}(h)\)</span> exceeding <span class="math notranslate nohighlight">\(\epsilon\)</span> is lesser
or equals to <span class="math notranslate nohighlight">\(2 e^{-2 \epsilon^{2} N}\)</span>. Note this is not saying that exceeding <span class="math notranslate nohighlight">\(\epsilon\)</span> is impossible, it is saying that the probability of this bad event happening and exceeding <span class="math notranslate nohighlight">\(\epsilon\)</span> is bounded by <span class="math notranslate nohighlight">\(2 e^{-2 \epsilon^{2} N}\)</span>. This is a very important point to note.</p>
</section>
</div></div>
</section>
<section id="framing-learning-theory-with-hoeffding-s-inequality">
<h2><a class="toc-backref" href="#id17" role="doc-backlink">Framing Learning Theory with Hoeffding’s Inequality</a><a class="headerlink" href="#framing-learning-theory-with-hoeffding-s-inequality" title="Link to this heading">#</a></h2>
<div class="proof theorem admonition" id="theorem-learning-theory-1">
<p class="admonition-title"><span class="caption-number">Theorem 6 </span> (Learning Theory)</p>
<section class="theorem-content" id="proof-content">
<p>Consider a dataset <span class="math notranslate nohighlight">\(\mathcal{S} = \left\{\left(\mathbf{x}^{(n)}, y^{(n)}\right)\right\}_{n=1}^N\)</span> drawn i.i.d. from an unknown distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. Let the hypothesis
set <span class="math notranslate nohighlight">\(\mathcal{H} = \left\{h_{1}, \ldots, h_{M}\right\}\)</span> be a finite set of hypotheses. Then, suppose we fix a hypothesis <span class="math notranslate nohighlight">\(h_S\)</span> in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> which is found by the learning
algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>. Then for any <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>, we have the following bound:</p>
<div class="math notranslate nohighlight" id="equation-eq-learning-theory-1">
<span class="eqno">(13)<a class="headerlink" href="#equation-eq-learning-theory-1" title="Link to this equation">#</a></span>\[
\mathbb{P}\left[\left|\mathcal{R}_{\mathcal{D}}(h) - \hat{\mathcal{R}}_{\mathcal{S}}(h)\right|&gt;\epsilon\right] \leq 2\left|\mathcal{H}\right| e^{-2 \epsilon^{2} N} = 2M e^{-2 \epsilon^{2} N} \text{. }
\]</div>
<p>where <span class="math notranslate nohighlight">\(M\)</span> is the number of hypotheses in the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> and <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}\)</span> are the True Risk Function and the Empirical Risk Function respectively.</p>
</section>
</div></section>
<section id="feasibility-from-the-two-view-points">
<h2><a class="toc-backref" href="#id18" role="doc-backlink">Feasibility from the Two View Points</a><a class="headerlink" href="#feasibility-from-the-two-view-points" title="Link to this heading">#</a></h2>
<p>The deterministic analysis shows that learning is infeasible, whereas the
probabilistic analysis shows that learning is feasible. Are they contradictory?
If we look at them closely, we realize that there is in fact no contradiction.
Here are the reasons.</p>
<ol class="arabic">
<li><p>Guarantee and Possibility. If we want a deterministic answer, then the
question we ask is “Can <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> tell us something certain about <span class="math notranslate nohighlight">\(f\)</span>
outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> ?” In this case the answer is no because if we have not
seen the example, there is always uncertainty about the true <span class="math notranslate nohighlight">\(f\)</span>. If we want
a probabilistic answer, then the question we ask is “Can <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> tell
us something possibly about <span class="math notranslate nohighlight">\(f\)</span> outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> ?” In this case the
answer is yes.</p></li>
<li><p>Role of the distribution. There is one common distribution
<span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span> which generates both the in-samples
and the out-samples. Thus, whatever <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span> we use to
generate <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, we must use it to generate the testing samples. The
testing samples are not inside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, but they come from the same
distribution. Also, all samples are generated independently, so that we have
i.i.d. when using the Hoeffding inequality.</p></li>
<li><p>Learning goal. The ultimate goal of learning is to make
<span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S) \approx 0\)</span>. However, in order establish this
result, we need two levels of approximation:<br></p>
<div class="math notranslate nohighlight">
\[
    \mathcal{R}(h_S) \textcolor{red}{\underset{\text{Hoeffding Inequality}}{\approx}} \quad \hat{\mathcal{R}}(h_S) \textcolor{red}{\underset{\text{Training Error}}{\approx}} 0
    \]</div>
<p>The first approximation is made by the Hoeffding inequality, which ensures
that for sufficiently large <span class="math notranslate nohighlight">\(N\)</span>, we can approximate the out-sample error by
the examples in <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. The second approximation is to make the
in-sample error, i.e., the training error, small. This requires a good
hypothesis and a good learning algorithm.</p>
</li>
</ol>
<hr class="docutils" />
<section id="complex-hypothesis-set-and-complex-target-function">
<h3><a class="toc-backref" href="#id19" role="doc-backlink">Complex Hypothesis Set and Complex Target Function</a><a class="headerlink" href="#complex-hypothesis-set-and-complex-target-function" title="Link to this heading">#</a></h3>
<p>The results earlier tells us something about the complexity of the hypothesis
set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> and the target function <span class="math notranslate nohighlight">\(f\)</span>.</p>
<ul>
<li><p><strong>More complex <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>?</strong> If <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is complex with a large
<span class="math notranslate nohighlight">\(M\)</span>, then the approximation by the Hoeffding inequality becomes loose.
Remember, Hoeffing inequality states that</p>
<div class="math notranslate nohighlight">
\[
    \mathbb{P}\left\{\left|\hat{\mathcal{R}}_{\mathcal{S}}(h_S)-\mathcal{R}_{\mathcal{D}}(h_S)\right|&gt;\epsilon\right\} \leq 2 M e^{2 \epsilon^{2} N}
    \]</div>
<p>As <span class="math notranslate nohighlight">\(M\)</span> grows, the upper bound on the right hand side becomes loose, and so
we will run into risk where <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)\)</span> can
deviate from <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S)\)</span>. In other words, if <span class="math notranslate nohighlight">\(M\)</span> is
large, then the right hand side will be very big and therefore the bound
will be meaningless, it is like saying your deviation is less than <span class="math notranslate nohighlight">\(+\infty\)</span>
(an exxageration), which is of course true.</p>
<p>However, if <span class="math notranslate nohighlight">\(M\)</span> is large, we have more candidate hypotheses to choose from
and so the second approximation about the training error will go down. This
gives the following relationship.</p>
<div class="math notranslate nohighlight">
\[
    \mathcal{R}(h_S) \textcolor{red}{\underset{\text{worse if }\mathcal{H} \text{ complex}}{\approx}} \quad \hat{\mathcal{R}}(h_S) \textcolor{red}{\underset{\text{good if }\mathcal{H} \text{ complex}}{\approx}} 0
    \]</div>
<p><strong>Note this is saying that our model is complex!</strong></p>
<p>Where is the optimal trade-off? This requires more investigation.</p>
</li>
<li><p><strong>More complex <span class="math notranslate nohighlight">\(f\)</span>?</strong> If the target function <span class="math notranslate nohighlight">\(f\)</span> is complex, we will suffer
from being not able to push the training error down. This makes
<span class="math notranslate nohighlight">\(E_{\mathrm{in}}(h_S) \approx 0\)</span> difficult. However, since the complexity of
<span class="math notranslate nohighlight">\(f\)</span> has no influence to the Hoeffding inequality, the first approximation
<span class="math notranslate nohighlight">\(E_{\mathrm{in}}(h_S) \approx \mathcal{R}_{\mathcal{D}}(h_S)\)</span> is unaffected.
This gives us</p>
<div class="math notranslate nohighlight">
\[
    \mathcal{R}(h_S) \textcolor{red}{\underset{\text{no effect by } f}{\approx}} \quad \hat{\mathcal{R}}(h_S) \textcolor{red}{\underset{\text{worse if }f \text{ complex}}{\approx}} 0
    \]</div>
<p>Trying to improve the approximation
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S) \approx 0\)</span> by increasing the
complexity of <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> needs to pay a price. If <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> becomes
complex, then the approximation
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S) \approx \mathcal{R}_{\mathcal{D}}(h_S)\)</span>
will be hurt.</p>
<p><strong>Note this is NOT saying that our model is complex! Instead, it is saying
the actual ground truth <span class="math notranslate nohighlight">\(f\)</span> is complex!</strong></p>
</li>
</ul>
<p>To this end, this definitely looks very similar to the bias-variance trade-off,
which is often discussed in many machine learning courses. We will get to that
later!</p>
</section>
</section>
<section id="vc-analysis">
<h2><a class="toc-backref" href="#id20" role="doc-backlink">VC-Analysis</a><a class="headerlink" href="#vc-analysis" title="Link to this heading">#</a></h2>
<p>The objective of this section is go further into the analysis of the Hoeffding
inequality to derive something called the <strong>generalization bound</strong>. There are
two parts of our discussion.</p>
<ol class="arabic simple">
<li><p>The first part is easy, which is to rewrite the Hoeffding inequality into a
form of “confidence interval” or “error bar”. This will allow us interpret
the result better.</p></li>
<li><p>The second part is to replace the constant <span class="math notranslate nohighlight">\(M\)</span> in the Hoeffding inequality by
something smaller. This will allow us derive something more meaningful. Why
do we want to do that? What could go wrong with <span class="math notranslate nohighlight">\(M\)</span> ? Remember that <span class="math notranslate nohighlight">\(M\)</span> is
the number of hypotheses in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. If <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is a finite set,
then everything is fine because the exponential decaying function of the
Hoeffding inequality will override the constant <span class="math notranslate nohighlight">\(M\)</span>. However, for any
practical <span class="math notranslate nohighlight">\(\mathcal{H}, M\)</span> is infinite. Think of a perceptron algorithm. If
we slightly perturb the decision boundary by an infinitesimal translation, we
will get an infinite number of hypotheses, although these hypotheses could be
very similar to each other. If <span class="math notranslate nohighlight">\(M\)</span> is infinite, then the probability bound
offered by the Hoeffding inequality can potentially be bigger than 1 which is
valid but meaningless. To address this issue we need to learn a concept
called the <span class="math notranslate nohighlight">\(\mathbf{V C}\)</span> <strong>dimension</strong>.</p></li>
</ol>
<section id="generalization-bound">
<h3><a class="toc-backref" href="#id21" role="doc-backlink">Generalization Bound</a><a class="headerlink" href="#generalization-bound" title="Link to this heading">#</a></h3>
<p>We first see that the Hoeffding’s and Union bound earlier in
<a class="reference internal" href="#equation-eq-union-bound-1">(12)</a> give us the following result:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}\left\{\underbrace{\left|\hat{\mathcal{R}}_{\mathcal{D}}(h_S)-\mathcal{R}_{\mathcal{S}}(h_S)\right|&gt;\epsilon}_{\text{Bad Event } \mathcal{B}}\right\}
&amp;\leq \sum_{m=1}^{M} 2 e^{-2 \epsilon^{2} N} \\
&amp;= \left| \mathcal{H} \right| 2 e^{-2 \epsilon^{2} N} \text{. }
\end{aligned}
\end{split}\]</div>
<p>Now, we can rewrite the above inequality. We first say that
<span class="math notranslate nohighlight">\(\mathcal{B} = \left|\hat{\mathcal{R}}_{\mathcal{D}}(h_S)-\mathcal{R}_{\mathcal{S}}(h_S)\right|&gt;\epsilon\)</span>
is a <strong>bad event</strong> because the generalization gap is more than <span class="math notranslate nohighlight">\(\epsilon\)</span>. We
then say that the probability <span class="math notranslate nohighlight">\(\mathbb{P}\left[\mathcal{B}\right] \leq \delta\)</span>
for some event <span class="math notranslate nohighlight">\(\mathcal{B}\)</span>, which is equivalent to say that with probability
<span class="math notranslate nohighlight">\(1-\delta\)</span>, the event <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> does not happen.</p>
<p>This means that:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left[\mathcal{B}\right] \leq \delta \Rightarrow \mathbb{P}\left[\mathcal{B}^{\mathrm{c}}\right] \geq 1-\delta
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{B}^{\mathrm{c}}\)</span> is the complement of <span class="math notranslate nohighlight">\(\mathcal{B}\)</span>, which is
the event that <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> does not happen:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{B}^{\mathrm{c}}=\left|\hat{\mathcal{R}}_{\mathcal{D}}(h_S)-\mathcal{R}_{\mathcal{S}}(h_S)\right| \leq \epsilon
\]</div>
<p>We can say that with a confidence <span class="math notranslate nohighlight">\(1-\delta\)</span> :</p>
<div class="math notranslate nohighlight">
\[
\left|\mathcal{R}(h_S)-\hat{\mathcal{R}}(h_S)\right| \leq \epsilon \Rightarrow \hat{\mathcal{R}}(h_S)-\epsilon \leq \mathcal{R}(h_S) \leq \hat{\mathcal{R}}(h_S)+\epsilon
\]</div>
<p>where this is a result of the triangle inequality.</p>
<p>If we can express <span class="math notranslate nohighlight">\(\epsilon\)</span> in terms of <span class="math notranslate nohighlight">\(\delta\)</span>, then we will arrive our goal
of rewriting the Hoeffding inequality. How about we substitute
<span class="math notranslate nohighlight">\(\delta=2 M e^{-2 \epsilon^{2} N}\)</span>, which is the upper bound on the right hand
side. By rearrange the terms, we can show that
<span class="math notranslate nohighlight">\(\epsilon=\sqrt{\frac{1}{2 N} \log \frac{2 M}{\delta}}\)</span>. Therefore, we arrive at
the following inequality.</p>
<div class="proof theorem admonition" id="thm:generalization-bound">
<p class="admonition-title"><span class="caption-number">Theorem 7 </span> (Generalization Bound)</p>
<section class="theorem-content" id="proof-content">
<p>Consider a learning problem where we have a dataset <span class="math notranslate nohighlight">\(\mathcal{S}=\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right\}\)</span>, and a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}=\left\{h_{1}, \ldots, h_{M}\right\}\)</span>. Suppose <span class="math notranslate nohighlight">\(h_S\)</span> is the final hypothesis picked by the learning algorithm. Then, with probability at least <span class="math notranslate nohighlight">\(1-\delta\)</span>,</p>
<div class="math notranslate nohighlight" id="equation-eq-generalization-bound-1">
<span class="eqno">(14)<a class="headerlink" href="#equation-eq-generalization-bound-1" title="Link to this equation">#</a></span>\[
\hat{\mathcal{R}}_{\mathcal{S}}(h_S)-\sqrt{\frac{1}{2 N} \log \frac{2 M}{\delta}} \leq \mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\sqrt{\frac{1}{2 N} \log \frac{2 M}{\delta}} .
\]</div>
</section>
</div><p>The inequality given by <a class="reference internal" href="#equation-eq-generalization-bound-1">(14)</a> is called the
generalization bound, which we can consider it as an “error bar”. There are two
sides of the generalization bound:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\epsilon\)</span>
(Upper Bound). The upper bound gives us a safe-guard of how worse
<span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S)\)</span> can be compared to
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)\)</span>. It says that the unknown quantity
<span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S)\)</span> will not be significantly higher than
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)\)</span>. The amount is specified by
<span class="math notranslate nohighlight">\(\epsilon\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S) \geq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\epsilon\)</span>
(Lower Bound). The lower bound tells us what to expect. It says that the
unknown quantity <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S)\)</span> cannot be better than
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)-\epsilon\)</span>.</p></li>
</ul>
<p>To make sense of the generalization bound, we need to ensure that
<span class="math notranslate nohighlight">\(\epsilon \rightarrow 0\)</span> as <span class="math notranslate nohighlight">\(N \rightarrow \infty\)</span>. In doing so, we need to
assume that <span class="math notranslate nohighlight">\(M\)</span> does not grow exponentially fast, for otherwise term <span class="math notranslate nohighlight">\(\log 2 M\)</span>
will cancel out the effect of <span class="math notranslate nohighlight">\(1 / N\)</span>. However, if <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is an infinite
set, then <span class="math notranslate nohighlight">\(M\)</span> is unavoidably infinite.</p>
<p>To concluse, this is our first generalization bound, it states that the
generalization error is upper bounded by the training error plus a function of
the hypothesis space size and the dataset size. We can also see that the the
bigger the hypothesis space gets, the bigger the generalization error becomes.</p>
<div class="proof remark admonition" id="rmk:infinite-hypothesis-space">
<p class="admonition-title"><span class="caption-number">Remark 20 </span> (What is the Hypothesis Space is Infinite?)</p>
<section class="remark-content" id="proof-content">
<p>For a linear hypothesis of the form <span class="math notranslate nohighlight">\(h(x)=w x+b\)</span>, we also have <span class="math notranslate nohighlight">\(|\mathcal{H}|=\infty\)</span> as there is infinitely many lines that can be drawn. So the generalization error of the linear hypothesis space should be unbounded! If that’s true, how does perceptrons, logistic regression, support vector machines and essentially any ML model that uses a linear hypothesis work with the learning theory bound we just proposed?</p>
<p>There is something missing from the picture. Let’s take a deeper look at the generalization bound.</p>
</section>
</div><p>It is good to stop here and read section <strong>Examining the Independence
Assumption</strong> and <strong>The Symmetrization Lemma</strong> in
<a class="reference external" href="https://mostafa-samir.github.io/ml-theory-pt2/">the post written by Mostafa</a>
before proceeding.</p>
</section>
<section id="the-growth-function">
<h3><a class="toc-backref" href="#id22" role="doc-backlink">The Growth Function</a><a class="headerlink" href="#the-growth-function" title="Link to this heading">#</a></h3>
<p>To resolve the issue of having an infinite <span class="math notranslate nohighlight">\(M\)</span>, we realize that there is a
serious slack caused by the union bound when deriving the Hoeffding inequality.
If we look at the union bound, we notice that for every hypothesis
<span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span> there is an event
<span class="math notranslate nohighlight">\(\mathcal{B}=\left\{\left|\hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}-\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\right|&gt;\epsilon\right\}\)</span>.
If we have <span class="math notranslate nohighlight">\(M\)</span> of these hypotheses, the union bound tells us that</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left[\mathcal{B}_{1} \text { or } \ldots \text { or } \mathcal{B}_{M}\right] \leq \mathbb{P}\left[\mathcal{B}_{1}\right]+\ldots+\mathbb{P}\left[\mathcal{B}_{M}\right]
\]</div>
<p>The union bound is tight ( “ <span class="math notranslate nohighlight">\(\leq\)</span> “ is replaced by “=”) when all the events
<span class="math notranslate nohighlight">\(\mathcal{B}_{1}, \ldots, \mathcal{B}_{M}\)</span> are not overlapping (independent
events). But if the events <span class="math notranslate nohighlight">\(\mathcal{B}_{1}, \ldots, \mathcal{B}_{M}\)</span> are
overlapping (not independent), then the union bound is loose, in fact, very
loose. Having a loose bound does not mean that the bound is wrong. The bound is
still correct, but the right hand side of the inequality will be a severe
overestimate of the left hand side. Will this happen in practice? Unfortunately
many hypotheses are indeed very similar to each other and so the events
<span class="math notranslate nohighlight">\(\mathcal{B}_{1}, \ldots, \mathcal{B}_{M}\)</span> are overlapping. For example, if we
move the decision boundary returned by a perceptron algorithm by an
infinitesimal step then we will have infinitely many hypotheses, and everyone is
highly dependent on each other.</p>
<p>We need some tools to handle the overlapping situation. To do so we introduce
two concepts. The first concept is called the <strong>dichotomy</strong>, and the second
concept is called the <strong>growth function</strong>. Dichotomies will define a growth
function, and the growth function will allow us replace <span class="math notranslate nohighlight">\(M\)</span> by a much smaller
quantity that takes care of the overlapping issue.</p>
<p>Consider a dataset containing <span class="math notranslate nohighlight">\(N\)</span> data points
<span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>. Pick a hypothesis <span class="math notranslate nohighlight">\(h\)</span> from the
hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, and for simplicity assume that the hypothesis is
binary: <span class="math notranslate nohighlight">\(\{+1,-1\}\)</span>. If we apply <span class="math notranslate nohighlight">\(h\)</span> to
<span class="math notranslate nohighlight">\(\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span>, we will get a
<span class="math notranslate nohighlight">\(N\)</span>-tuple
<span class="math notranslate nohighlight">\(\left(h\left(\mathbf{x}^{(1)}\right), \ldots, h\left(\mathbf{x}^{(N)}\right)\right)\)</span>
of <span class="math notranslate nohighlight">\(\pm 1\)</span> ‘s. Each <span class="math notranslate nohighlight">\(N\)</span>-tuple is called a <strong>dichotomy</strong>. The collection of all
possible <span class="math notranslate nohighlight">\(N\)</span>-tuples (by picking all <span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span> ) is defined as
<span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span>. For
example, if <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> contains two hypotheses <span class="math notranslate nohighlight">\(h_{\alpha}\)</span> and <span class="math notranslate nohighlight">\(h_{\beta}\)</span>
such that <span class="math notranslate nohighlight">\(h_{\alpha}\)</span> turns all training samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> to <span class="math notranslate nohighlight">\(+1\)</span> and
<span class="math notranslate nohighlight">\(h_{\beta}\)</span> turns all training samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> to <span class="math notranslate nohighlight">\(-1\)</span>, then we have
two dichotomies and
<span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span> is defined
as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right) &amp; =\left\{\left(h_{\alpha}\left(\mathbf{x}^{(1)}\right), \ldots, h_{\alpha}\left(\mathbf{x}^{(N)}\right)\right),\left(h_{\beta}\left(\mathbf{x}^{(1)}\right), \ldots, h_{\beta}\left(\mathbf{x}^{(N)}\right)\right)\right\} \\
&amp; =\{(+1, \ldots,+1),(-1, \ldots,-1)\}
\end{aligned}
\end{split}\]</div>
<p>More generally, the definition of
<span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span> is as
follows.</p>
<div class="proof definition admonition" id="def:dichotomy">
<p class="admonition-title"><span class="caption-number">Definition 24 </span> (Dichotomy)</p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)} \in \mathcal{X}\)</span>. The dichotomies generated by <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> on these points are</p>
<div class="math notranslate nohighlight" id="equation-eq-dichotomy">
<span class="eqno">(15)<a class="headerlink" href="#equation-eq-dichotomy" title="Link to this equation">#</a></span>\[
\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)=\left\{\left(h\left(\mathbf{x}^{(1)}\right), \ldots, h\left(\mathbf{x}^{(N)}\right)\right) \middle \vert h \in \mathcal{H}\right\}
\]</div>
</section>
</div><p>The above definition suggests that
<span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span> is a
function depending on the training samples
<span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>. Therefore, a different set
(different <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>) of
<span class="math notranslate nohighlight">\(\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right\}\)</span> will give a
different <span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span>.
However, since
<span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span> is a binary
<span class="math notranslate nohighlight">\(N\)</span>-tuple, there will be identical sequences of <span class="math notranslate nohighlight">\(\pm 1\)</span> ‘s in
<span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span>. Let us
look at one example.</p>
<p>Suppose there are <span class="math notranslate nohighlight">\(N=3\)</span> data points in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> so that we have
<span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> (red color is <span class="math notranslate nohighlight">\(+1\)</span> and
blue color is <span class="math notranslate nohighlight">\(-1\)</span>). Use any method to build a linear classifier (could be a
linear regression of a perceptron algorithm). Since there are infinitely many
lines we can draw in the <span class="math notranslate nohighlight">\(2 \mathrm{D}\)</span> plane, the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>
contains infinitely many hypotheses. Now, let us assume that the training data
<span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> are located at position
<span class="math notranslate nohighlight">\(A, B, C\)</span> respectively, as illustrated in <a class="reference internal" href="#ece595-fig4-5"><span class="std std-numref">Fig. 11</span></a>. These
locations are fixed, and the 3 data points
<span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> must stay at these three
locations. For this particular configuration of the locations, we can make as
many as <span class="math notranslate nohighlight">\(2^{3}=8\)</span> dichotomies. Notice that one dichotomy can still have
infinitely many hypotheses. For example in the top left case of
<a class="reference internal" href="#ece595-fig4-5"><span class="std std-numref">Fig. 11</span></a>, we can move the yellow decision boundary up and low
slightly, and we will still get the same dichotomy of <span class="math notranslate nohighlight">\([-1,-1,-1]\)</span>. However, as
we move the decision boundary away by changing the slope and intercept, we will
eventually land on a different dichotomy, e.g., <span class="math notranslate nohighlight">\([-1,+1,-1]\)</span> as shown in the
bottom left of <a class="reference internal" href="#ece595-fig4-5"><span class="std std-numref">Fig. 11</span></a>. As we move around the decision boundary,
we can construct at most 8 dichotomies for
<span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> located at <span class="math notranslate nohighlight">\(A, B\)</span> and
<span class="math notranslate nohighlight">\(C\)</span>.</p>
<p><em>Typo: I think the bottom left <span class="math notranslate nohighlight">\([-1, +1, -1]\)</span> has the linear yellow line drawn
wrongly, it should cut through such that the <span class="math notranslate nohighlight">\(-1\)</span> is on one side, and <span class="math notranslate nohighlight">\(+1\)</span> is on
the other.</em></p>
<p>What if we move <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> to
somewhere else, for example the locations specified by the red part of
<a class="reference internal" href="#ece595-fig4-5"><span class="std std-numref">Fig. 11</span></a> In this case some dichotomies are not allowed, e.g., the
cases of <span class="math notranslate nohighlight">\([+1,-1,+1]\)</span> and <span class="math notranslate nohighlight">\([-1,+1,-1]\)</span> are not allowed because our hypothesis
set contains only linear models and a linear model is not able to cut through 3
data points of alternating classes with a straight line. We can still get the
remaining six configurations, but the total will be less than 8 . The total
number of dichotomies here is 6 .</p>
<figure class="align-default" id="ece595-fig4-5">
<img alt="../../_images/ece595_fig4.5.jpeg" src="../../_images/ece595_fig4.5.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 11 </span><span class="caption-text">For a fixed configuration of <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span>, we can obtain different numbers of dichotomies. Suppose the hypothesis set contains linear models. [Left] There are 8 dichotomies for three data points located not on a line. [Right] When the three data points are located on a line, the number of dichotomies becomes 6.</span><a class="headerlink" href="#ece595-fig4-5" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Now we want to define a quantity that measures the number of dichotomies. This
quantity should be universal for any configuration of
<span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>, and should only be a function of
<span class="math notranslate nohighlight">\(\mathcal{H}\)</span> and <span class="math notranslate nohighlight">\(N\)</span>. If we can obtain such quantity, then we will have a way
to make a better estimate than <span class="math notranslate nohighlight">\(M\)</span>. To eliminate the dependency on
<span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>, we realize that among all the
possible configurations of <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>, there
exists one that can maximize the size of
<span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span>. Define
this maximum as the growth function.</p>
<div class="proof definition admonition" id="ece595_def4.6">
<p class="admonition-title"><span class="caption-number">Definition 25 </span> (Growth Function)</p>
<section class="definition-content" id="proof-content">
<p>The growth function for a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is</p>
<div class="math notranslate nohighlight" id="equation-eq-growth-function">
<span class="eqno">(16)<a class="headerlink" href="#equation-eq-growth-function" title="Link to this equation">#</a></span>\[
m_{\mathcal{H}}(N)=\max _{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)} \in \mathcal{X}}\left|\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\right|
\]</div>
<p>where <span class="math notranslate nohighlight">\(|\cdot|\)</span> denotes the cardinality of a set.</p>
</section>
</div><div class="proof example admonition" id="example_growth_function">
<p class="admonition-title"><span class="caption-number">Example 6 </span> (Example of Growth Function)</p>
<section class="example-content" id="proof-content">
<p>For example, <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)\)</span> of a linear model is 8 , because if we configure <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> like the ones in the green part of <a class="reference internal" href="#ece595-fig4-5"><span class="std std-numref">Fig. 11</span></a>, we will get 8 dichotomies. Of course, if we land on the red case we will get 6 dichotomies only, but the definition of <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)\)</span> asks for the maximum which is 8. How about <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> when <span class="math notranslate nohighlight">\(N=4\)</span> ? It turns out that there are at most 14 dichotomies no matter where we put the four data points <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}, \mathbf{x}^{(4)}\)</span>.</p>
<p>So what is the difference between <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> and <span class="math notranslate nohighlight">\(M\)</span> ? Both are measures of the number of hypotheses. However, <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> is measured from the <span class="math notranslate nohighlight">\(N\)</span> training samples in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> whereas <span class="math notranslate nohighlight">\(M\)</span> is the number of hypotheses we have in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. The latter could be infinite, the former is upper bounded (at most) <span class="math notranslate nohighlight">\(2^{N}\)</span>. Why <span class="math notranslate nohighlight">\(2^{N}\)</span> ? Suppose we have <span class="math notranslate nohighlight">\(N\)</span> data points and the hypothesis is binary. Then the set of all dichotomies <span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span> must be a subset in <span class="math notranslate nohighlight">\(\{+1,-1\}^{N}\)</span>, and hence there are at most <span class="math notranslate nohighlight">\(2^{N}\)</span> dichotomies:</p>
<div class="math notranslate nohighlight">
\[
m_{\mathcal{H}}(N) \leq 2^{N}
\]</div>
<p>If a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is able to generate all <span class="math notranslate nohighlight">\(2^{N}\)</span> dichotomies, then we say that <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> shatter <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>. For example, a <span class="math notranslate nohighlight">\(2 \mathrm{D}\)</span> perceptron algorithm is able to shatter 3 data points because <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)=2^{3}\)</span>. However, the same <span class="math notranslate nohighlight">\(2 \mathrm{D}\)</span> perceptron algorithm is not able to shatter 4 data points because <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(4)=14&lt;2^{4}\)</span></p>
</section>
</div><div class="proof definition admonition" id="restricted_hypothesis_space">
<p class="admonition-title"><span class="caption-number">Definition 26 </span> (Restricted Hypothesis Space)</p>
<section class="definition-content" id="proof-content">
<p>By only choosing the distinct effective hypotheses on the dataset <span class="math notranslate nohighlight">\(S\)</span>, we restrict the hypothesis space <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> to a smaller subspace that depends on the dataset. We call this new hypothesis space a restricted one:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{H}_{\mid S}
\]</div>
</section>
</div><p>Ah, what is a consequence of all this? Can we do better with the generalization
bound <a class="reference internal" href="#equation-eq-generalization-bound-1">(14)</a> defined in
<a class="reference internal" href="#thm:generalization-bound">Theorem 7</a>.</p>
<p>The most straight forward step is to replace <span class="math notranslate nohighlight">\(M\)</span> by <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> :</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathcal{R}}(h_S)-\sqrt{\frac{1}{2 N} \log \frac{2 \textcolor{red}{m_{\mathcal{H}}(N)}}{\delta}} \leq \mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}(h_S)+\sqrt{\frac{1}{2 N} \log \frac{2 \textcolor{red}{m_{\mathcal{H}}(N)}}{\delta}}
\]</div>
<p>Since we know that</p>
<div class="math notranslate nohighlight">
\[
m_{\mathcal{H}}(N) \leq 2^{N}
\]</div>
<p>a natural attempt is to upper bound <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> by <span class="math notranslate nohighlight">\(2^{N}\)</span>.</p>
<p>However, this will not help us because</p>
<div class="math notranslate nohighlight">
\[
\sqrt{\frac{1}{2 N} \log \frac{2 m_{\mathcal{H}}(N)}{\delta}} \leq \sqrt{\frac{1}{2 N} \log \frac{2\left(\textcolor{red}{2^{N}}\right)}{\delta}}=\sqrt{\frac{1}{2 N} \log \frac{2^{N+1}}{\delta}}
\]</div>
<p>For large <span class="math notranslate nohighlight">\(N\)</span> we can approximate <span class="math notranslate nohighlight">\(2^{N+1} \approx 2^{N}\)</span>, and so</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{2 N} \log \frac{2^{N}}{\delta} \approx \frac{N \log 2-\log \delta}{2 N}=\frac{\log 2}{2}-\frac{\log \delta}{2 N} \rightarrow(\log 2) / 2 .
\]</div>
<p>Therefore, as <span class="math notranslate nohighlight">\(N \rightarrow \infty\)</span>, the error bar will never approach zero but
to a constant. This makes the generalization fail.</p>
<p>Furthermore, even though now the restricted hypothesis space
<span class="math notranslate nohighlight">\(\mathcal{H}_{\mid S}\)</span> is “finite”, but <span class="math notranslate nohighlight">\(2^N\)</span> is exponential in terms of <span class="math notranslate nohighlight">\(N\)</span> and
would grow too fast for large datasets, which makes the odds in our inequality
go too bad too fast! Is that the best bound we can get on that growth function?
Can we do better?</p>
</section>
<section id="the-vc-dimension">
<h3><a class="toc-backref" href="#id23" role="doc-backlink">The VC Dimension</a><a class="headerlink" href="#the-vc-dimension" title="Link to this heading">#</a></h3>
<p>Can we find a better upper bound on <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> so that we can send the
error bar to zero as <span class="math notranslate nohighlight">\(N\)</span> grows? Here we introduce some definitions allows us to
characterize the growth function.</p>
<div class="proof definition admonition" id="shatters">
<p class="admonition-title"><span class="caption-number">Definition 27 </span> (Shattering)</p>
<section class="definition-content" id="proof-content">
<p>If a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is able to generate all <span class="math notranslate nohighlight">\(2^N\)</span> dichotomies, then we say that <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> shatter <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>.</p>
<p>In other words, a set of data points <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is shattered by a hypothesis class <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> if there are hypotheses in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> that split <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> in all of the <span class="math notranslate nohighlight">\(2^{\left|\mathcal{S}\right|}\)</span> possible ways; i.e., all possible ways of classifying points in <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> are achievable using concepts in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>.</p>
</section>
</div><div class="proof definition admonition" id="vc_dimension">
<p class="admonition-title"><span class="caption-number">Definition 28 </span> (VC Dimension of <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>)</p>
<section class="definition-content" id="proof-content">
<p>The <strong>Vapnik-Chervonenkis</strong> dimension of a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, denoted by <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span>, is the largest value of <span class="math notranslate nohighlight">\(N\)</span> for which <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)=2^{N}\)</span>.</p>
</section>
</div><div class="proof example admonition" id="vc_dimension_of_a_2d_perceptron">
<p class="admonition-title"><span class="caption-number">Example 7 </span> (VC Dimension of a 2D Perceptron)</p>
<section class="example-content" id="proof-content">
<p>For example, consider the <span class="math notranslate nohighlight">\(2 \mathrm{D}\)</span> perceptron algorithm, which has hypothesis
<span class="math notranslate nohighlight">\(h\)</span> of the following form:</p>
<div class="math notranslate nohighlight">
\[
\operatorname{sign}\left(\left(\mathbf{x}^{(n)}\right)^{T} \mathbf{w}\right) = y^{(n)}
\]</div>
<p>We can start with <span class="math notranslate nohighlight">\(N=3\)</span>, and gradual increase <span class="math notranslate nohighlight">\(N\)</span> until we hit a critical point.</p>
<p>Suppose <span class="math notranslate nohighlight">\(N=3\)</span>. Recall that <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)\)</span> is the maximum number of dichotomies that can be generated by a hypothesis set under <span class="math notranslate nohighlight">\(N=3\)</span> data points. As we have shown earlier, as long as the 3 data points are not on a straight line, it is possible to draw 8 different dichotomies. If the 3 data points are on a straight line, we can only generate 6 dichotomies. However, since <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)\)</span> picks the maximum, we have that <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)=2^{3}\)</span>. Therefore, a 2 D percetpron can shatter 3 data points.</p>
<p>Suppose <span class="math notranslate nohighlight">\(N=4\)</span>. As we have discussed earlier, if we have <span class="math notranslate nohighlight">\(N=4\)</span> data points, there are always 2 dichotomies that cannot be generated by the perceptron algorithm. This implies that the growth function is <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(4)=14&lt;2^{4}\)</span>. Since the perceptron algorithm can shatter <span class="math notranslate nohighlight">\(N=3\)</span> data points but not <span class="math notranslate nohighlight">\(N=4\)</span> data points, the <span class="math notranslate nohighlight">\(\mathrm{VC}\)</span> dimension is <span class="math notranslate nohighlight">\(\mathrm{VCdim}=3\)</span>.</p>
<p>The following animation shows how many ways a linear classifier in 2D can label 3 points (on the left) and 4 points (on the right).</p>
<figure class="align-default" id="shatter">
<img alt="../../_images/shatter.gif" src="../../_images/shatter.gif" />
<figcaption>
<p><span class="caption-number">Fig. 12 </span><span class="caption-text">Image Credit: <a class="reference external" href="https://mostafa-samir.github.io/ml-theory-pt2/">Machine Learning Theory by Mostafa</a>.</span><a class="headerlink" href="#shatter" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Actually, no linear classifier in 2D can shatter any set of 4 points, not just that set; because there will always be two labellings that cannot be produced by a linear classifier. But why? See the image below.</p>
<figure class="align-default" id="impossible-dichotomy">
<img alt="../../_images/impossible-dichotomy.png" src="../../_images/impossible-dichotomy.png" />
<figcaption>
<p><span class="caption-number">Fig. 13 </span><span class="caption-text">Image Credit: <a class="reference external" href="https://mostafa-samir.github.io/ml-theory-pt2/">Machine Learning Theory by Mostafa</a>.</span><a class="headerlink" href="#impossible-dichotomy" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>If we arranged the points in a rectangular way like the one in the image, then let the
blue dot be class <span class="math notranslate nohighlight">\(-1\)</span> and red dot be class <span class="math notranslate nohighlight">\(+1\)</span>, then there exists no way for a
single line (hyperplane if in higher dimensions) to cut the points into two classes.</p>
<p>Moreover, <strong>no matter how you arrange these 4 points, whether be it in a line, a rectangle, S-shape or any
other arrangements, there will always be at least 2 dichotomies that cannot be generated by a linear classifier.
Maybe you could draw some arrangements for yourself and see!</strong> Come to think of it, even if you arrange you 4 points
in a circle or Z-shape, it will always have 4 “corners” which resemble the 4 points in the image above.</p>
<p>We will soon see how this fact of the impossibility of shattering 4 points is related to the VC dimension of a hypothesis set can be scaled to <span class="math notranslate nohighlight">\(N\)</span> data points. And how
this can lead us to finding a better bound!</p>
</section>
</div><p>First, let’s find a general formula for the VC dimension of a perceptron
algorithm.</p>
<div class="proof theorem admonition" id="vc_dimension_of_a_perceptron">
<p class="admonition-title"><span class="caption-number">Theorem 8 </span> (VC Dimension of a Perceptron)</p>
<section class="theorem-content" id="proof-content">
<p>In general, if we have a high-dimensional perceptron algorithm, we can show this:</p>
<p>Consider the input space <span class="math notranslate nohighlight">\(\mathcal{X}=\mathbb{R}^{D} \cup\{1\}\)</span> <span class="math notranslate nohighlight">\(\left(\mathbf{x}=\left[x_{1}, \ldots, x_{D}, 1\right]^{T}\right)\)</span>. The VC dimension of the perceptron algorithm is</p>
<div class="math notranslate nohighlight">
\[
\mathrm{VCdim}=D+1
\]</div>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof. See page 16 of <a class="reference external" href="https://engineering.purdue.edu/ChanGroup/ECE595/files/chapter4.pdf">ECE595: Learning Theory</a></p>
</div>
</section>
<section id="sauers-lemma-and-bounding-the-growth-function">
<h3><a class="toc-backref" href="#id24" role="doc-backlink">Sauer’s Lemma and Bounding the Growth Function</a><a class="headerlink" href="#sauers-lemma-and-bounding-the-growth-function" title="Link to this heading">#</a></h3>
<p>Now that we have the VC dimension, we can bound the growth function. The
following theorem show that <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> is indeed upper bounded by a
polynomial of order no greater than <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span>.</p>
<div class="proof lemma admonition" id="sauer's_lemma">
<p class="admonition-title"><span class="caption-number">Lemma 1 </span> (Sauer’s Lemma)</p>
<section class="lemma-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> be the VC dimension of a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
m_{\mathcal{H}}(N) \leq \sum_{i=0}^{\mathrm{VCdim}}\left(\begin{array}{c}
N \\
i
\end{array}\right)
\end{split}\]</div>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof. Proof can be found in Theorem <span class="math notranslate nohighlight">\(2.4\)</span> of AML’s Learning from Data textbook.</p>
</div>
<p>The bound on the growth function provided by Sauer’s Lemma is indeed much better
than the exponential one we already have because it is actually a polynomial
function.</p>
<p>Using this result, we can show that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
m_{\mathcal{H}}(N) \leq \sum_{i=0}^{\mathrm{VCdim}}\left(\begin{array}{c}
N \\
i
\end{array}\right) \leq \left(\frac{Ne}{\mathrm{VCdim}}\right)^{\mathrm{VCdim}} \leq \mathcal{O}\left(N^{\mathrm{VCdim}}+1\right)
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(e\)</span> is the base of the natural logarithm and <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> is the
<a class="reference external" href="https://en.wikipedia.org/wiki/Big_O_notation">Big-O</a> notation for functions
asymptotic (near the limits) behavior.</p>
<p>If we substitute <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> by this upper bound
<span class="math notranslate nohighlight">\(N^{\mathrm{VCdim}}+1\)</span>, then the generalization bound becomes</p>
<div class="math notranslate nohighlight">
\[
\epsilon=\sqrt{\frac{1}{2 N} \log \frac{2 m_{\mathcal{H}}(N)}{\delta}} \leq \sqrt{\frac{1}{2 N} \log \frac{2\left(\textcolor{red}{N^{\mathrm{VCdim}}+1}\right)}{\delta}} .
\]</div>
<p>How do we interpret the VC dimension? The VC dimension can be informally viewed
as the <strong>effective number of parameters of a model</strong>. Higher VC dimension means
a more complex model, and hence a more diverse hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>.
Well, we have just shown that for a perceptron or linear classifier, the VC
dimension is <span class="math notranslate nohighlight">\(D+1\)</span> where <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the input space. We have seen
that even in 2-dimensional space, if <span class="math notranslate nohighlight">\(N=4\)</span> points, then the linear/percepton
classifier cannot shatter the points. This is because linear models being
linear, cannot model the non-linear decision boundary that can separate the 4
points. However, imagine a complex model like a deep neural network, then you
can easily shatter 4 points in 2D space because the decision boundary can be
very complex. See
<a class="reference external" href="https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py">the moon dataset in scikit-learn</a>
and have a look.</p>
<p>As a result, the growth function <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> will be big. (Think about
the number of dichotomies that can be generated by a complex model versus a
simple model, and hence the overlap we encounter in the union bound.) There are
two scenarios of the VC dimension.</p>
<ol class="arabic">
<li><p><span class="math notranslate nohighlight">\(\mathrm{VCdim}&lt;\infty\)</span>. This implies that the generalization error will go
to zero as <span class="math notranslate nohighlight">\(N\)</span> grows:</p>
<div class="math notranslate nohighlight">
\[
    \epsilon=\sqrt{\frac{1}{2 N} \log \frac{2\left(\textcolor{red}{N^{\mathrm{VCdim}}+1}\right)}{\delta}} \rightarrow 0
    \]</div>
<p>as <span class="math notranslate nohighlight">\(N \rightarrow \infty\)</span> because <span class="math notranslate nohighlight">\((\log N) / N \rightarrow 0\)</span>. If this is
the case, then the final hypothesis <span class="math notranslate nohighlight">\(h_S \in \mathcal{H}\)</span> will generalize.
Such generalization result holds independent of the learning algorithm
<span class="math notranslate nohighlight">\(\mathcal{A}\)</span>, independent of the input distribution
<span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span> and independent of the target function <span class="math notranslate nohighlight">\(f\)</span>. It
only depends on the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> and the training examples
<span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>.</p>
</li>
<li><p><span class="math notranslate nohighlight">\(\mathrm{VCdim}=\infty\)</span>. This means that the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is
as diverse as it can be, and it is not possible to generalize. The
generalization error will never go to zero.</p></li>
</ol>
<p>Are we all set about the generalization bound? It turns out that we need some
additional technical modifications to ensure the validity of the generalization
bound. We shall not go into the details but just state the result.</p>
<div class="proof theorem admonition" id="vc_generalization_bound">
<p class="admonition-title"><span class="caption-number">Theorem 9 </span> (The VC Generalization Bound)</p>
<section class="theorem-content" id="proof-content">
<p>For any tolerance <span class="math notranslate nohighlight">\(\delta&gt;0\)</span></p>
<div class="math notranslate nohighlight" id="equation-eq-vc-generalization-bound">
<span class="eqno">(17)<a class="headerlink" href="#equation-eq-vc-generalization-bound" title="Link to this equation">#</a></span>\[
\mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\sqrt{\frac{\mathscr{8}}{N} \log \frac{\mathscr{4} m_{\mathcal{H}}(\mathscr{2}N)}{\delta}}
\]</div>
<p>with probability at least <span class="math notranslate nohighlight">\(1-\delta\)</span>.</p>
</section>
</div><p>To this end, we have more or less answered the question “Is Learning Feasible?”.</p>
</section>
<section id="interpretating-the-generalization-bound">
<h3><a class="toc-backref" href="#id25" role="doc-backlink">Interpretating the Generalization Bound</a><a class="headerlink" href="#interpretating-the-generalization-bound" title="Link to this heading">#</a></h3>
<p>The VC generalization bound in <a class="reference internal" href="#equation-eq-vc-generalization-bound">(17)</a> is universal in
the sense that it applies to all hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, learning
algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>, input space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, distribution
<span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span>, and <strong>binary</strong> target function <span class="math notranslate nohighlight">\(f\)</span>. So can we use
the VC generalization bound to predict the exact generalization error for any
learning scenario? Unfortunately the answer is no. The VC generalization bound
we derived is a valid upper bound but also a very loose upper bound. The
loose-ness nature of the generalization bound comes from the following reasons
(among others):</p>
<ul class="simple">
<li><p>The Hoeffding inequality has a slack. The inequality works for all values of
<span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span>. However, the behavior of
<span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span> could be very different at different values,
e.g., at 0 or at 0.5. Using one bound to capture both cases will result in
some slack.</p></li>
<li><p>The growth function <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> gives the worst case scenario of
how many dichotomies are there. If we draw the <span class="math notranslate nohighlight">\(N\)</span> data points at random, it
is unlikely that we will land on the worst case, and hence the typical value
of <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> could be far fewer than <span class="math notranslate nohighlight">\(2^{N}\)</span> even if
<span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)=2^{N}\)</span>.</p></li>
<li><p>Bounding <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> by a polynomial introduces further slack.</p></li>
</ul>
<p>Therefore, the VC generalization bound can only be used a rough guideline of
understanding how well the learning algorithm generalize.</p>
</section>
<section id="sample-complexity">
<h3><a class="toc-backref" href="#id26" role="doc-backlink">Sample Complexity</a><a class="headerlink" href="#sample-complexity" title="Link to this heading">#</a></h3>
<p>Sample complexity concerns about the number of training samples <span class="math notranslate nohighlight">\(N\)</span> we need to
achieve the generalization performance. Recall from the generalization bound:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\sqrt{\frac{8}{N} \log \frac{4 m_{\mathcal{H}}(2 N)}{\delta}} .
\]</div>
<p>Fix a <span class="math notranslate nohighlight">\(\delta&gt;0\)</span>, if we want the generalization error to be at most <span class="math notranslate nohighlight">\(\epsilon\)</span>,
we can enforce that</p>
<div class="math notranslate nohighlight">
\[
\sqrt{\frac{8}{N} \log \frac{4 m_{\mathcal{H}}(2 N)}{\delta}} \leq \epsilon
\]</div>
<p>Rearranging the terms yields
<span class="math notranslate nohighlight">\(N \geq \frac{8}{\epsilon^{2}} \log \left(\frac{4 m_{\mathcal{H}}(2 N)}{\delta}\right)\)</span>.
If we replace <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(2 N)\)</span> by the VC dimension, then we obtain a
similar bound</p>
<div class="math notranslate nohighlight">
\[
N \geq \frac{8}{\epsilon^{2}} \log \left(\frac{4(2 N)^{\mathrm{VCdim}}+1}{\delta}\right) .
\]</div>
<div class="proof example admonition" id="sample_complexity_example">
<p class="admonition-title"><span class="caption-number">Example 8 </span> (Sample Complexity)</p>
<section class="example-content" id="proof-content">
<p>Suppose <span class="math notranslate nohighlight">\(\mathrm{VCdim}=3, \epsilon=0.1\)</span> and <span class="math notranslate nohighlight">\(\delta=0.1\)</span> (90% confidence). The number of samples we need satisfies the equation</p>
<div class="math notranslate nohighlight">
\[
N \geq \frac{8}{0.1^{2}} \log \left(\frac{4(2 N)^{3}+4}{0.1}\right) .
\]</div>
<p>If we plug in <span class="math notranslate nohighlight">\(N=1000\)</span> to the right hand side, we will obtain</p>
<div class="math notranslate nohighlight">
\[
N \geq \frac{8}{0.1^{2}} \log \left(\frac{4(2 \times 1000)^{3}+4}{0.1}\right) \approx 21,193 .
\]</div>
<p>If we repeat the calculation by plugging in <span class="math notranslate nohighlight">\(N=21,193\)</span>, obtain a new <span class="math notranslate nohighlight">\(N\)</span>, and iterate, we will eventually obtain <span class="math notranslate nohighlight">\(N \approx 30,000\)</span>. If <span class="math notranslate nohighlight">\(\mathrm{VCdim}=4\)</span>, we obtain <span class="math notranslate nohighlight">\(N \approx 40,000\)</span> samples. This means that every value of <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> corresponds to 10,000 samples. In practice, we may require significantly less number of samples. A typical number of samples is approximately <span class="math notranslate nohighlight">\(10 \times \mathrm{VCdim}\)</span>.</p>
</section>
</div></section>
<section id="model-complexity">
<h3><a class="toc-backref" href="#id27" role="doc-backlink">Model Complexity</a><a class="headerlink" href="#model-complexity" title="Link to this heading">#</a></h3>
<p>The other piece of information that can be obtained from the generalization
bound is how complex the model could be. If we look at the generalization bound,
we realize that the error <span class="math notranslate nohighlight">\(\epsilon\)</span> is a function of <span class="math notranslate nohighlight">\(N, \mathcal{H}\)</span> and
<span class="math notranslate nohighlight">\(\delta\)</span> :</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}(h_S) \leq \hat{\mathcal{R}}(h_S)+\underbrace{\sqrt{\frac{8}{N} \log \frac{4 m_{\mathcal{H}}(2 N)}{\delta}}}_{=\epsilon(N, \mathcal{H}, \delta)}
\]</div>
<p>If we replace <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(2 N)\)</span> by <span class="math notranslate nohighlight">\((2 N)^{\mathrm{VCdim}}+1\)</span>, then we can
write <span class="math notranslate nohighlight">\(\epsilon(N, \mathcal{H}, \delta)\)</span> as</p>
<div class="math notranslate nohighlight">
\[
\epsilon\left(N, \mathrm{VCdim}, \delta\right)=\sqrt{\frac{8}{N} \log \left(\frac{4\left((2 N)^{\mathrm{VCdim}}+1\right)}{\delta}\right)}
\]</div>
<p>The three factors <span class="math notranslate nohighlight">\(N, \mathrm{VCdim}\)</span> and <span class="math notranslate nohighlight">\(\delta\)</span> have different influence on
the error <span class="math notranslate nohighlight">\(\epsilon\)</span> :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> : The VC dimension controls the complexity of the model. As
<span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> grows, the in-sample error <span class="math notranslate nohighlight">\(E_{\mathrm{in}}\)</span> drops because
large <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> implies that we have a more complex model to fit the
training data. However, <span class="math notranslate nohighlight">\(\epsilon\)</span> grows as <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> grows. If we
have a very complex model, then it would be more difficult to generalize to
the out-samples. The trade-off between model complexity and generalization
is shown in <a class="reference internal" href="#ece595-fig4-6"><span class="std std-numref">Fig. 14</span></a>. The blue curve represents the in-sample
error <span class="math notranslate nohighlight">\(E_{\mathrm{in}}\)</span> which drops as <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> increases. The red
curve represents the model complexity which increases as <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span>
increases. The black curve is the out-sample error
<span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span>. There exists an optimal model complexity so
that <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span> is minimized.</p></li>
<li><p><span class="math notranslate nohighlight">\(N\)</span> : A large number of training samples always helps the generalization
bound, as reflected by the fact that
<span class="math notranslate nohighlight">\(\epsilon(N, \mathcal{H}, \delta) \rightarrow 0\)</span> as <span class="math notranslate nohighlight">\(N \rightarrow \infty\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\delta\)</span> : The confidence level tells us how harsh we want the
generalization to be. If we want a very high confidence interval, e.h_S.,
<span class="math notranslate nohighlight">\(99.99 \%\)</span>, then we need a very small <span class="math notranslate nohighlight">\(\delta=0.0001\)</span>. This will in turn
affect the number of training samples <span class="math notranslate nohighlight">\(N\)</span> required to achieve the confidence
level and the desired error bound.</p></li>
</ul>
<figure class="align-default" id="ece595-fig4-6">
<img alt="../../_images/ece595_fig4.6.jpeg" src="../../_images/ece595_fig4.6.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 14 </span><span class="caption-text">The VC generalization bound suggests a trade-off between model complexity and generalization. If we use a more complex model, the in-sample error drops but the out-sample error increases. The optimal model complexity is determined when the out-sample error is minimized.</span><a class="headerlink" href="#ece595-fig4-6" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="testing-data">
<h3><a class="toc-backref" href="#id28" role="doc-backlink">Testing Data</a><a class="headerlink" href="#testing-data" title="Link to this heading">#</a></h3>
<p>The VC analysis provides us a good guideline to train a model. However, the
estimate provided by the <span class="math notranslate nohighlight">\(\mathrm{VC}\)</span> analysis is often too loose to provide
any accurate prediction of <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span>. In practice, no one
really uses <span class="math notranslate nohighlight">\(\mathrm{VC}\)</span> analysis to inform a training process. What is more
often used is a testing dataset. The testing dataset</p>
<div class="math notranslate nohighlight">
\[
\mathcal{S}_{\text {test }}=\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(Q)}\right\}
\]</div>
<p>contains <span class="math notranslate nohighlight">\(Q\)</span> samples drawn from the distribution
<span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>. No testing data <span class="math notranslate nohighlight">\(\mathbf{x}^{(q)}\)</span> can
be in the training dataset <span class="math notranslate nohighlight">\(\mathcal{S}_{\text{train}}\)</span>.</p>
<p>Since in the testing phase the final hypothesis <span class="math notranslate nohighlight">\(h_S\)</span> is already determined, we
will not run into the same trouble in the training phase where we need to use
the Union bound to account for the <span class="math notranslate nohighlight">\(M\)</span> candidate hypotheses in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. As
a result, the Hoeffding inequality simplifies to</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left\{\left|\hat{\mathcal{R}}_{\mathcal{S}}(h_S)-\mathcal{R}_{\mathcal{D}}(h_S)\right|&gt;\epsilon\right\} \leq 2 e^{-2 \epsilon^{2} Q}
\]</div>
<p>and the generalization bound becomes</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\sqrt{\frac{1}{2 Q} \log \frac{2}{\delta}}
\]</div>
<p>Therefore, as the number of testing samples increases, we can certify the
out-sample error by evaluating <span class="math notranslate nohighlight">\(\hat{\mathcal{R}(h_S)}\)</span> using the testing
samples.</p>
<p>There are a few reminders about using the testing data:</p>
<ul class="simple">
<li><p>The common notion of testing accuracy is
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)\)</span>, calculated based on the <span class="math notranslate nohighlight">\(Q\)</span> testing
samples. Therefore, having <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}(h_S)\)</span> does not imply that we
will generalize well. If we change another testing dataset,
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}(h_S)\)</span> will change because it is a numerical value based
on empirical sum. What is guaranteed by the generalization bound is that as
long as <span class="math notranslate nohighlight">\(Q\)</span> is sufficiently large, <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S)\)</span> will
stay close to <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)\)</span> no matter which
particular testing dataset we use. There is a variance associated with
<span class="math notranslate nohighlight">\(\hat{\mathcal{R}}(h_S)\)</span>, and this variance is reflected by
<span class="math notranslate nohighlight">\(\sqrt{\frac{1}{2 Q} \log \frac{2}{\delta}}\)</span>.</p></li>
<li><p>The testing data has to be used after the hypothesis is determined. If we
ever use the testing data as a feedback to re-select the hypothesis, then it
is cheating. For example, we cannot train a SVM, submit to a competition
website, and mark the misclassified samples to re-design the SVM.</p></li>
<li><p>In principle the generalization bound is improved when we have more testing
samples. However, most practical datasets only have training data points and
no testing data points. We can partition the training set into training and
validation. The proportion of training and validation needs to be carefully
chosen. If we allocate too many samples for validation purpose, then we will
loose our ability to training a good classifier.</p></li>
</ul>
</section>
</section>
<section id="why-must-h-be-fixed-and-defined-before-generating-the-dataset-mathcal-s">
<span id="why-must-h-be-fixed"></span><h2><a class="toc-backref" href="#id29" role="doc-backlink">Why must <span class="math notranslate nohighlight">\(h\)</span> be fixed and defined before generating the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>?</a><a class="headerlink" href="#why-must-h-be-fixed-and-defined-before-generating-the-dataset-mathcal-s" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://math.stackexchange.com/questions/2097429/hoeffdings-inequality-and-learning">Question and Answer from MathStackExchange</a>.</p>
<section id="some-intuition-on-the-difference-between-a-priori-and-a-posteriori">
<h3><a class="toc-backref" href="#id30" role="doc-backlink">Some intuition on the difference between <em>a-priori</em> and <em>a-posteriori</em>:</a><a class="headerlink" href="#some-intuition-on-the-difference-between-a-priori-and-a-posteriori" title="Link to this heading">#</a></h3>
<p>Some intuition on the difference between <em>a-priori</em> and <em>a-posteriori</em>: Let
<span class="math notranslate nohighlight">\(\{Y_1, ..., Y_4\}\)</span> be i.i.d. uniform random variables over <span class="math notranslate nohighlight">\([0,1]\)</span>. So for each
<span class="math notranslate nohighlight">\(m \in \{1, ..., 4\}\)</span> we have</p>
<div class="math notranslate nohighlight">
\[
P[Y_m&gt;15/16]=1/16 = 0.0625
\]</div>
<section id="a-priori">
<h4><a class="toc-backref" href="#id31" role="doc-backlink">A-priori:</a><a class="headerlink" href="#a-priori" title="Link to this heading">#</a></h4>
<p>Let’s <em>a-priori</em> pick an index <span class="math notranslate nohighlight">\(K \in \{1, 2, 3, 4\}\)</span>, independent of the <span class="math notranslate nohighlight">\(Y_i\)</span>
variables and before observing these variables. We can use <em>any mass function</em>
<span class="math notranslate nohighlight">\(P[K=m]\)</span> for <span class="math notranslate nohighlight">\(m \in \{1, 2, 3, 4\}\)</span>. What is <span class="math notranslate nohighlight">\(P[Y_K&gt;15/16]\)</span>? It is still <span class="math notranslate nohighlight">\(1/16\)</span>
(regardless of the mass function we use) because, by the law of total
probability:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P[Y_K&gt;15/16] &amp;= \sum_{m=1}^4P[Y_K&gt;15/16|K=m]P[K=m]\\
&amp;=\sum_{m=1}^4\underbrace{P[Y_m&gt;15/16|K=m]}_{P[Y_m&gt;15/16]}P[K=m]  \\
&amp;=\sum_{m=1}^4 (1/16)P[K=m]\\
&amp;=1/16
\end{align}
\end{split}\]</div>
<p>where the equality <span class="math notranslate nohighlight">\(P[Y_m&gt;15/16|K=m]=P[Y_m&gt;15/16]\)</span> holds because <span class="math notranslate nohighlight">\(Y_m\)</span> is
independent of <span class="math notranslate nohighlight">\(K\)</span>.</p>
</section>
<section id="a-posteriori">
<h4><a class="toc-backref" href="#id32" role="doc-backlink">A-posteriori:</a><a class="headerlink" href="#a-posteriori" title="Link to this heading">#</a></h4>
<p>Now let’s <em>a-posteriori</em> pick the index <span class="math notranslate nohighlight">\(K\)</span> associated with the largest <span class="math notranslate nohighlight">\(Y_m\)</span>
value, so <span class="math notranslate nohighlight">\(Y_K = \max[Y_1, Y_2, Y_3, Y_4]\)</span>. This choice of index <span class="math notranslate nohighlight">\(K\)</span> <em>depends on
the observed data</em>. Then:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P[Y_K&gt;15/16] &amp;= 1-P[Y_1\leq 15/16, Y_2\leq 15/16, Y_3\leq 15/16,Y_4\leq 15/16]\\
&amp;=1-(15/16)^4 \\
&amp;\approx 0.2275
\end{align}
\end{split}\]</div>
<p>and so this probability is <em>much larger</em> than 1/16, even though <span class="math notranslate nohighlight">\(Y_K\)</span> is just
one of the <span class="math notranslate nohighlight">\(Y_m\)</span> values and we know <span class="math notranslate nohighlight">\(P[Y_m&gt;15/16]=1/16\)</span> for all
<span class="math notranslate nohighlight">\(m \in \{1, ..., 4\}\)</span>.</p>
<p>On the other hand, we know by the <em>union bound</em> that</p>
<div class="math notranslate nohighlight">
\[
\{Y_K&gt;15/16\} \subseteq \cup_{m=1}^4 \{Y_m&gt;15/16\} \implies P[Y_K&gt;15/16]\leq \sum_{m=1}^4P[Y_m&gt;15/16]=1/4
\]</div>
<p>and indeed <span class="math notranslate nohighlight">\(0.2275 \leq 1/4\)</span>.</p>
</section>
</section>
</section>
<section id="your-specific-setup">
<h2><a class="toc-backref" href="#id33" role="doc-backlink">Your specific setup</a><a class="headerlink" href="#your-specific-setup" title="Link to this heading">#</a></h2>
<p>As in my above comment, I believe we need the following extra assumptions: We
have a finite set <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and an unknown function
<span class="math notranslate nohighlight">\(f:\mathcal{X}\rightarrow\mathbb{R}\)</span>. We are certain that <span class="math notranslate nohighlight">\(f\)</span> is one of the <span class="math notranslate nohighlight">\(M\)</span>
functions in the known set <span class="math notranslate nohighlight">\(\{h_1, ..., h_M\}\)</span>. We have the ability to exactly
evaluate the function <span class="math notranslate nohighlight">\(f\)</span> one step at a time. However, the set <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is
too large so we want to do a probabilistic estimate. Every time step <span class="math notranslate nohighlight">\(i\)</span> we
independently chose <span class="math notranslate nohighlight">\(X_i \in \mathcal{X}\)</span>, uniformly over all points in
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. We then observe the value of <span class="math notranslate nohighlight">\(f(X_i)\)</span> (with no noise).</p>
<p>So for a given function <span class="math notranslate nohighlight">\(h_m\)</span> we define <span class="math notranslate nohighlight">\(\phi_m\)</span> by:</p>
<div class="math notranslate nohighlight">
\[
\phi_m = P[f(X_i) \neq h_m(X_i)] = \frac{\text{number of points } x \in \mathcal{X} \text{ such that } f(x)\neq h_m(x)}{|\mathcal{X}|}
\]</div>
<p>For each <span class="math notranslate nohighlight">\(m \in \{1, ..., M\}\)</span> define the sequence of indicator functions
<span class="math notranslate nohighlight">\(\{I^{(m)}_i\}_{i=1}^{\infty}\)</span> by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
I^{(m)}_i = \left\{ \begin{array}{ll}
1 &amp;\mbox{ if $h_m(X_i) \neq f(X_i)$} \\
0  &amp; \mbox{ otherwise}
\end{array}
\right.
\end{split}\]</div>
<p>For any fixed <span class="math notranslate nohighlight">\(m \in \{1, ..., M\}\)</span> the <span class="math notranslate nohighlight">\(\{I^{(m)}_i\}_{i=1}^{\infty}\)</span>
indicators are i.i.d. so we can apply Hoeffding. Note that for each individual
<span class="math notranslate nohighlight">\(m\)</span>, Hoeffding is a bound on the following <em>a-priori probability</em>:</p>
<div class="math notranslate nohighlight">
\[
P\left[\left|\frac{1}{N}\sum_{i=1}^NI_i^{(m)} - \phi_m\right|&gt;\epsilon\right] \leq 2e^{-2\epsilon^2 N} \quad (Eq. 1)
\]</div>
<p>and it is nice that the bound on the right-hand-side does not depend on the
index <span class="math notranslate nohighlight">\(m\)</span>.</p>
<section id="your-specific-questions">
<h3><a class="toc-backref" href="#id34" role="doc-backlink">Your specific questions</a><a class="headerlink" href="#your-specific-questions" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Your first question asks why Hoeffding requires a fixed function <span class="math notranslate nohighlight">\(h\)</span> rather
than a random function <span class="math notranslate nohighlight">\(H\)</span>. It is because Hoeffding applies to i.i.d. random
variables. If we fix an index <span class="math notranslate nohighlight">\(m \in \{1, .., M\}\)</span> then the indicators
<span class="math notranslate nohighlight">\(\{I^{(m)}_1, I^{(m)}_2, I^{(m)}_3, ...\}\)</span> are i.i.d. over the indices
<span class="math notranslate nohighlight">\(i \in \{1, 2, 3, ...\}\)</span>. If we have a random index <span class="math notranslate nohighlight">\(K\)</span> then the indicators
<span class="math notranslate nohighlight">\(\{I^{(K)}_1, I^{(K)}_2, I^{(K)}_3, ...\}\)</span> are not necessarily independent
because they share a common random index <span class="math notranslate nohighlight">\(K\)</span>.</p></li>
</ol>
<p>2-4) Your remaining questions boil down to the difference between <em>a-priori
probability</em> and <em>a-posteriori probability</em>. The Hoeffding bounds in (Eq. 1) are
a-priori bounds that hold for all <span class="math notranslate nohighlight">\(m \in \{1, ..., M\}\)</span>. They are bounds on the
probability the data behaves in a certain way. That probability (and its bound)
is determined without observing the actual data outcome (in the same way that
the probability of a fair coin flip being heads is 1/2, and this probability is
determined without looking at the outcome of the flip).</p>
<p>If we <em>a-priori</em> pick a random index <span class="math notranslate nohighlight">\(K \in \{1, ..., M\}\)</span> (before observing the
data and independent of the data), then we do not need the union bound:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P\left[\left|\frac{1}{N}\sum_{i=1}^NI_i^{(K)} - \phi_K\right|&gt;\epsilon\right] &amp;= \sum_{m=1}^M P\left[\left|\frac{1}{N}\sum_{i=1}^NI_i^{(K)} - \phi_K\right|&gt;\epsilon | K=m\right]P[K=m] \\
&amp;= \sum_{m=1}^M P\left[\left|\frac{1}{N}\sum_{i=1}^NI_i^{(m)} - \phi_m\right|&gt;\epsilon | K=m \right]P[K=m] \\
&amp;\overset{(a)}{=} \sum_{m=1}^M P\left[\left|\frac{1}{N}\sum_{i=1}^NI_i^{(m)} - \phi_m\right|&gt;\epsilon \right]P[K=m] \\
&amp;\leq \sum_{m=1}^m [2e^{-2\epsilon^2 N}]P[K=m]\\
&amp;= 2e^{-2\epsilon^2 N}
\end{align}
\end{split}\]</div>
<p>where equality (a) holds because the random index <span class="math notranslate nohighlight">\(K\)</span> is independent of the data
<span class="math notranslate nohighlight">\(\{I^{(m)}_i\}_{i=1}^{\infty}\)</span>. So, if we were to <em>a-priori pick</em> a guess
function <span class="math notranslate nohighlight">\(g\)</span>, independent of the data, by just picking a random index, the bound
would indeed be <span class="math notranslate nohighlight">\(2e^{-2\epsilon^2 N}\)</span> rather than <span class="math notranslate nohighlight">\(2M e^{-2\epsilon^2 N}\)</span>.</p>
<p>However, if we observe the results of the data and then <em>a-posteriori</em> pick a
random index <span class="math notranslate nohighlight">\(K \in \{1, ..., M\}\)</span>, the way we choose might lead us to pick an
index that exhibits “atypical” a-posteriori sample paths. So the equality (a) in
the above chain of equalities does not necessarily hold for such picks. We need
to be more careful by using the union bound.</p>
<hr class="docutils" />
<p>Exercise: Code up hoefdding inequality with plot.</p>
</section>
</section>
<section id="further-readings">
<h2><a class="toc-backref" href="#id35" role="doc-backlink">Further Readings</a><a class="headerlink" href="#further-readings" title="Link to this heading">#</a></h2>
<p>This is a difficult topic to learn. I recommend the following resources:</p>
<ul class="simple">
<li><p>Mohri, Mehryar, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of
Machine Learning. MIT press, 2012.</p></li>
<li><p>Shalev-Shwartz, Shai, and Shai Ben-David. Understanding Machine Learning:
From Theory to Algorithms. Cambridge University Press, 2014.</p></li>
<li><p>Abu-Mostafa, Y. S., Magdon-Ismail, M., &amp; Lin, H. (2012). Learning from Data:
A Short Course.</p></li>
<li><p>Mitchell, Tom M. Machine learning. Vol. 1. , bk. 9. : McGraw-hill New
York, 1997.</p></li>
<li><p><a class="reference external" href="https://www.nathanieldake.com/Mathematics/03-Probability-03-Inequalities.html">Nathaniel Dake: Probability Inequalities</a></p></li>
<li><p><a class="reference external" href="https://engineering.purdue.edu/ChanGroup/ECE595/files/chapter4.pdf">ECE595: Learning Theory</a></p></li>
<li><p><a class="reference external" href="https://engineering.purdue.edu/ChanGroup/ECE595/video.html">ECE595: Learning Theory Lectures (Part 3)</a></p></li>
<li><p><a class="reference external" href="https://mostafa-samir.github.io/ml-theory-pt2/">Mostafa Samir: Machine Learning Theory</a></p></li>
<li><p><a class="reference external" href="https://wei2624.github.io/MachineLearning/sv_learning_theory/">Zhang Wei: Learning Theory</a></p></li>
<li><p><a class="reference external" href="https://www.nathanieldake.com/Mathematics/03-Probability-03-Inequalities.html">Nathaniel Dake: Probability Inequalities</a></p></li>
<li><p>Prof chan’s video lectures ECE595: Learning Theory</p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_linear-classification/generalization-classification.html">https://d2l.ai/chapter_linear-classification/generalization-classification.html</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/606895/in-learning-theory-why-cant-we-use-hoeffdings-inequality-as-our-final-bound-i">1. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://math.stackexchange.com/questions/2097429/hoeffdings-inequality-and-learning">2. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/201746/changeing-the-hypothesis-while-generating-samples">3. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/157905/in-learning-theory-why-cant-we-bound-like-pe-ing-e-outg-epsilon">4. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Boole%27s_inequality#Example">Why do we need to use Union Bound?</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Boole%27s_inequality#Example">Union Bound Example</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_linear-classification/generalization-classification.html">Generalization in Classification</a></p></li>
<li><p><a class="reference external" href="http://www.cs.cmu.edu/~ninamf/courses/601sp15/sc-2015.pdf">CMU 10-601: Machine Learning</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/172191/why-is-hoeffdings-inequality-correct-in-machine-learning?">Why is the Hoeffding’s Inequality correct in Machine Learning?</a></p></li>
</ul>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="f-and-c" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Sometimes <span class="math notranslate nohighlight">\(f\)</span> is denoted as <span class="math notranslate nohighlight">\(\mathcal{c}\)</span>, the concept function.</p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./influential/learning_theory"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="01_intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Is The Learning Problem Solvable?</p>
      </div>
    </a>
    <a class="right-next"
       href="../kmeans_clustering/01_intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lloyd’s K-Means Clustering Algorithm</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#some-abuse-of-notations">Some Abuse of Notations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">Problem Statement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#notations">Notations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#is-learning-feasible">Is Learning Feasible?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learing-outside-the-training-set-mathcal-s-deterministic-case">Learing Outside the Training Set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> (Deterministic Case)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#identically-and-independently-distributed-random-variables">Identically and Independently Distributed Random Variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learing-outside-the-training-set-mathcal-s-probabilistic-case">Learing Outside the Training Set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> (Probabilistic Case)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-generalization-gap">The Generalization Gap</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-law-of-large-numbers">The Law of Large Numbers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hoeffding-s-inequality">Hoeffding’s Inequality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-hoeffding-s-inequality-with-the-chebyshev-s-inequality">Comparing Hoeffding’s Inequality with the Chebyshev’s Inequality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-hoeffding-s-inequality-in-classification">Example: Hoeffding’s Inequality in Classification</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pac-framework">PAC Framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hoeffding-inequality-is-invalid-for-h-s-learnt-from-mathcal-s">Hoeffding Inequality is Invalid for <span class="math notranslate nohighlight">\(h_S\)</span> learnt from <span class="math notranslate nohighlight">\(\mathcal{S}\)</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#union-bound">Union Bound</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#framing-learning-theory-with-hoeffding-s-inequality">Framing Learning Theory with Hoeffding’s Inequality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feasibility-from-the-two-view-points">Feasibility from the Two View Points</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complex-hypothesis-set-and-complex-target-function">Complex Hypothesis Set and Complex Target Function</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vc-analysis">VC-Analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generalization-bound">Generalization Bound</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-growth-function">The Growth Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-vc-dimension">The VC Dimension</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sauers-lemma-and-bounding-the-growth-function">Sauer’s Lemma and Bounding the Growth Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretating-the-generalization-bound">Interpretating the Generalization Bound</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-complexity">Sample Complexity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-complexity">Model Complexity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-data">Testing Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-must-h-be-fixed-and-defined-before-generating-the-dataset-mathcal-s">Why must <span class="math notranslate nohighlight">\(h\)</span> be fixed and defined before generating the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#some-intuition-on-the-difference-between-a-priori-and-a-posteriori">Some intuition on the difference between <em>a-priori</em> and <em>a-posteriori</em>:</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#a-priori">A-priori:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#a-posteriori">A-posteriori:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#your-specific-setup">Your specific setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#your-specific-questions">Your specific questions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-readings">Further Readings</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gao Hongnan
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>