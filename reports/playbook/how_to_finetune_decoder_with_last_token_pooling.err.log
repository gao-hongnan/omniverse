Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nbclient/client.py", line 1314, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
from __future__ import annotations

import logging
from collections import Counter, OrderedDict
from typing import Any, Dict, List, Tuple, TypedDict, overload

import numpy as np
import pandas as pd
import psutil
import torch
from datasets import load_dataset
from rich.pretty import pprint
from scipy.special import softmax
from sklearn.metrics import (
    accuracy_score,
    auc,
    average_precision_score,
    confusion_matrix,
    f1_score,
    log_loss,
    precision_recall_curve,
    precision_score,
    recall_score,
    roc_auc_score,
    roc_curve,
)
from torch import nn
from torch.utils.data import DataLoader, Dataset
from tqdm.notebook import tqdm  # Use notebook version for better UI in notebooks
from transformers import (
    DataCollatorWithPadding,
    EvalPrediction,
    GPT2ForSequenceClassification,
    GPT2Tokenizer,
    PreTrainedTokenizer,
    TrainingArguments,
)

from omnivault.transformer.config.decoder import (
    AddNormConfig,
    DecoderBlockConfig,
    DecoderConfig,
    MultiHeadedAttentionConfig,
    PositionwiseFeedForwardConfig,
)
from omnivault.transformer.modules.attention.core import MultiHeadedAttention, ScaledDotProductAttention
from omnivault.transformer.modules.layers.addnorm import AddNorm
from omnivault.transformer.modules.layers.mlp import PositionwiseFeedForward
from omnivault.utils.reproducibility.seed import seed_all

------------------


[0;31m---------------------------------------------------------------------------[0m
[0;31mModuleNotFoundError[0m                       Traceback (most recent call last)
Cell [0;32mIn[1], line 39[0m
[1;32m     29[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtqdm[39;00m[38;5;21;01m.[39;00m[38;5;21;01mnotebook[39;00m [38;5;28;01mimport[39;00m tqdm  [38;5;66;03m# Use notebook version for better UI in notebooks[39;00m
[1;32m     30[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtransformers[39;00m [38;5;28;01mimport[39;00m (
[1;32m     31[0m     DataCollatorWithPadding,
[1;32m     32[0m     EvalPrediction,
[0;32m   (...)[0m
[1;32m     36[0m     TrainingArguments,
[1;32m     37[0m )
[0;32m---> 39[0m [38;5;28;01mfrom[39;00m [38;5;21;01momnivault[39;00m[38;5;21;01m.[39;00m[38;5;21;01mtransformer[39;00m[38;5;21;01m.[39;00m[38;5;21;01mconfig[39;00m[38;5;21;01m.[39;00m[38;5;21;01mdecoder[39;00m [38;5;28;01mimport[39;00m (
[1;32m     40[0m     AddNormConfig,
[1;32m     41[0m     DecoderBlockConfig,
[1;32m     42[0m     DecoderConfig,
[1;32m     43[0m     MultiHeadedAttentionConfig,
[1;32m     44[0m     PositionwiseFeedForwardConfig,
[1;32m     45[0m )
[1;32m     46[0m [38;5;28;01mfrom[39;00m [38;5;21;01momnivault[39;00m[38;5;21;01m.[39;00m[38;5;21;01mtransformer[39;00m[38;5;21;01m.[39;00m[38;5;21;01mmodules[39;00m[38;5;21;01m.[39;00m[38;5;21;01mattention[39;00m[38;5;21;01m.[39;00m[38;5;21;01mcore[39;00m [38;5;28;01mimport[39;00m MultiHeadedAttention, ScaledDotProductAttention
[1;32m     47[0m [38;5;28;01mfrom[39;00m [38;5;21;01momnivault[39;00m[38;5;21;01m.[39;00m[38;5;21;01mtransformer[39;00m[38;5;21;01m.[39;00m[38;5;21;01mmodules[39;00m[38;5;21;01m.[39;00m[38;5;21;01mlayers[39;00m[38;5;21;01m.[39;00m[38;5;21;01maddnorm[39;00m [38;5;28;01mimport[39;00m AddNorm

[0;31mModuleNotFoundError[0m: No module named 'omnivault'

