Search.setIndex({"alltitles": {" (Additivity)": [[79, "how-does-softmax-work-additivity"]], " (Algebraic Definition (Scalar-Vector Multiplication))": [[38, "02-vector-operation-scalar-vector-multiplication-algebraic-definition"]], " (Algebraic Definition (Vector Addition and Subtraction))": [[38, "02-vector-operation-vector-addition-algebraic-definition"]], " (Algebraic Definition of a Vector)": [[37, "01-vector-definition-algebraic-definition"]], " (All Generators are Iterators)": [[80, "software-engineering-concurrency-parallelism-asynchronous-generator-yield-remark"]], " (Amortized Worst-Case Time Complexity)": [[19, "stack-list-amortized-worst-case-time-complexity"]], " (Approximation of GELU)": [[22, "remark-approx-gelu-notation"], [24, "remark-approx-gelu"]], " (Assignment)": [[27, "def:assignment"], [27, "example:assignment"]], " (Attention Scores)": [[24, "decoder-concept-attention-scores"]], " (Attention Scoring Function with Scaling and Softmax)": [[24, "decoder-concept-attention-scoring-function-with-scaling-softmax"]], " (Attention Scoring Function with Scaling)": [[24, "decoder-concept-attention-scoring-function-with-scaling"]], " (Attention Scoring Function)": [[24, "decoder-concept-attention-scoring-function"]], " (Binary Search Pseudocode)": [[16, "875-koko-eating-bananas-binary-search-pseudocode"]], " (Brute Force Search for K-Means)": [[27, "brute-force-search-kmeans"]], " (Centroids)": [[27, "def:centroids"]], " (Coercive and Primitive Types)": [[3, "type-theory-01-subtypes-example-coercive-impl-primitive-types"]], " (Context Vector/Matrix)": [[24, "decoder-concept-context-vector-matrix"]], " (Contravariance)": [[8, "computer-science-type-theory-contravariance"]], " (Correctness of Binary Search Recursive Algorithm)": [[14, "omniverse-dsa-searching-algorithms-binary-search-recursive-algorithm-correctness"]], " (Cosine Annealing With Warmup)": [[25, "why-do-we-use-warmup-cosine-scheduler-definition-duplicate"], [78, "why-do-we-use-warmup-cosine-scheduler-definition"]], " (Cost Function is a Function of Assignment and Centroids)": [[27, "remark:cost-function-is-a-function-of-assignment-and-centroids"]], " (Cost Function is a function of assignments and cluster centers)": [[27, "remark:kmeans-cost-function-is-a-function-of-assignments-and-cluster-centers"]], " (Cost Function of K-Means Monotonically Decreases)": [[27, "kmeans-monotonic-decrease"]], " (Covariance)": [[8, "computer-science-type-theory-covariance"]], " (Dimensionality of the Subspaces)": [[24, "decoder-concept-linear-projections-queries-keys-values-remark"]], " (Distance)": [[39, "03-vector-norm-distance"]], " (Dot Product Example in 3-Dimensional Space)": [[40, "linear-algebra-02-vectors-04-vector-products-dot-product-example-1"]], " (Elbow Method)": [[27, "elbow-method"]], " (Equality of Vectors)": [[37, "01-vector-definition-equality-of-vectors"]], " (Exact Match Scenario)": [[24, "decoder-concept-attention-exact-match-scenario"]], " (Example)": [[22, "gpt-notations-one-hot-example"], [29, "prf:example-bits"], [29, "example-pixels"]], " (Externally Derived Constraints)": [[16, "875-koko-eating-bananas-externally-derived-constraints"]], " (Feasibility Function for Koko Eating Bananas)": [[16, "875-koko-eating-bananas-feasibility-function-for-koko-eating-bananas"]], " (Feasibility Function)": [[16, "875-koko-eating-bananas-feasibility-function"]], " (Field)": [[34, "linear-algebra-01-preliminaries-field"]], " (Fields on the Real Numbers)": [[34, "linear-algebra-preliminaries-fields-on-the-real-numbers"]], " (GELU Activation Function)": [[22, "def-gelu-notation"], [24, "def-gelu"]], " (Generic Divide and Conquer Algorithm)": [[13, "master-theorem-generic-divide-and-conquer-algorithm"]], " (Geometric Definition of a Vector)": [[37, "01-vector-definition-geometric-definition"]], " (Gradient Saturation)": [[24, "decoder-concept-gradient-saturation"]], " (I came all the way just for a Moot Example)": [[6, "computer-science-type-theory-generics-moot-example"]], " (Inclusive Implementations in Object-Oriented Languages)": [[3, "type-theory-01-subtypes-example-inclusive-impl-oop"]], " (Integer Type as a Set)": [[3, "type-theory-01-subtypes-example-int-type-as-set"]], " (Invariance)": [[8, "computer-science-type-theory-invariance"]], " (Jacobian Matrix of Softmax Function)": [[79, "jacobian-softmax"]], " (K-Means Cost Function)": [[27, "def:kmeans-cost"]], " (K-Means Loss Function)": [[27, "def:kmeans-loss"]], " (K-Means Objective Function)": [[27, "def:kmeans-objective"]], " (K-Means Optimal Assignment)": [[27, "criterion:kmeans-optimal-assignment"]], " (K-Means Optimal Cluster Centers)": [[27, "criterion:kmeans-optimal-cluster-centers"]], " (K-Means Voronoi Partition)": [[27, "def:kmeans-voronoi-partition"]], " (K-Means is a Greedy Algorithm)": [[27, "remark-kmeans-greedy"]], " (L2 Norm)": [[39, "03-vector-norm-l2-norm"]], " (L_1 Norm)": [[39, "03-vector-norm-l1-norm"]], " (L_p Norm)": [[39, "03-vector-norm-lp-norm"]], " (Layer Normalization)": [[24, "decoder-layer-normalization"]], " (Linear Projections for Queries, Keys, and Values)": [[24, "decoder-concept-linear-projections-queries-keys-values"]], " (Liskov Substitution Principle)": [[5, "type-theory-liskov-substitution-principle"]], " (Lloyd\u2019s Algorithm (K-Means))": [[27, "lloyd-kmeans-algorithm"]], " (Loop Invariant Theorem)": [[17, "linear-search-loop-invariant-theorem"]], " (Mathematical Representation (Iterative))": [[14, "binary-search-mathematical-representation-iterative"]], " (Mathematical Representation)": [[14, "binary-search-mathematical-representation"]], " (Matrix Formulation)": [[79, "matrix-formulation-softmax"]], " (Minimizing Individual Cluster\u2019s Cost is Equivalent to Minimizing the Objective Function)": [[27, "thm:minimizing-individual-clusters-cost-is-equivalent-to-minimizing-the-objective-function"]], " (Monotone Convergence Theorem)": [[27, "monotone-convergence"]], " (Monotonicity)": [[16, "875-koko-eating-bananas-monotonicity"]], " (Non-Negativity)": [[79, "how-does-softmax-work-non-negativity"]], " (Norm on a Vector Space)": [[39, "03-vector-norm-norm-on-a-vector-space"]], " (Normalization)": [[54, "ml-lifecycle-032-normalization"], [79, "how-does-softmax-work-normalization"]], " (Notation)": [[27, "prf:remark:kmeans-optimal-cluster-centers-notation"]], " (Numerical Stability)": [[24, "decoder-concept-numerical-stability"]], " (Point vs. Position Vector)": [[35, "02-systems-of-linear-equations-point-vs-position-vector"]], " (Position-wise Feedforward Networks)": [[22, "def-positionwise-ffn-notation"], [24, "def-positionwise-ffn"]], " (Positional Encoding)": [[24, "decoder-positional-encoding"]], " (Properties of Transpose)": [[37, "01-vector-definition-properties-of-transpose"]], " (Pseudocode)": [[14, "binary-search-pseudocode-iterative"], [14, "binary-search-pseudocode-recursive"]], " (Query and Key are Independent and Identically Distributed (i.i.d.))": [[24, "decoder-concept-query-key-iid"]], " (Ranking items on a newsfeed)": [[52, "ml-lifecycle-02-ranking-items-newsfeed"]], " (Remark)": [[27, "remark-kmeans-problem-statement"]], " (Scaled Dot-Product Attention)": [[24, "decoder-concept-scaled-dot-product-attention"]], " (Simplification of the Objective Function)": [[23, "decoder-simplified-objective-function"]], " (Softmax Normalization and Attention Weights)": [[24, "decoder-concept-softmax-normalization-attention-weights"]], " (Softmax Output as Vector)": [[79, "softmax-output-vector"]], " (Some Remarks)": [[19, "stack-list-remarks"]], " (Standard Representation of Vectors)": [[37, "01-vector-definition-column-vector-is-the-standard-representation"]], " (Stirling Numbers of the Second Kind)": [[27, "stirling-numbers"]], " (Subtype Criterion)": [[5, "type-theory-subtype-criterion"]], " (Subtype and Type Safety)": [[4, "type-theory-subtype-and-type-safety"]], " (System of Linear Equations (Algebraic Form))": [[35, "02-systems-of-linear-equations-definition-algebraic-form"]], " (Time Complexity)": [[16, "time-complexity"]], " (Transpose of a Vector)": [[37, "01-vector-definition-transpose-of-a-vector"]], " (Unordered Linear Search Mathematical Representation (Iterative))": [[17, "unordered-linear-search-mathematical-representation-iterative"]], " (Unordered Linear Search Pseudocode (Iterative))": [[17, "unordered-linear-search-pseudocode-iterative"]], " (Variance of Dot Product)": [[24, "decoder-concept-variance-dot-product"]], " (Vector Addition)": [[38, "02-vector-operation-vector-addition-example"]], " (Vector Subtraction)": [[38, "02-vector-operation-vector-subtraction-example"]], " (Vector is Invariant under Coordinate Transformation)": [[37, "01-vector-definition-is-invariant-under-coordinate-transformation"]], " (Vector versus Coordinate)": [[37, "01-vector-definition-vector-versus-coordinate"]], " (Voronoi Region)": [[27, "def-voronoi-region"]], " (What if we want to find 39?)": [[14, "binary-search-remark-what-if-we-want-to-find-39"]], " (Why ceiling?)": [[16, "875-koko-eating-bananas-why-ceiling"]], " (Why not just use Any?)": [[6, "computer-science-type-theory-generics-why-use-t"]], " (Yield is an expression and not a statement)": [[80, "software-engineering-concurrency-parallelism-asynchronous-generator-yield-is-an-expression"]], "1. Code versioning": [[60, "code-versioning"]], "1. Review the Configuration File": [[45, "review-the-configuration-file"]], "1. Warmup Phase": [[78, "warmup-phase"]], "2. Cosine Decay Phase": [[78, "cosine-decay-phase"]], "2. Create the Cluster": [[45, "create-the-cluster"]], "2. Data versioning": [[60, "data-versioning"]], "2.1. Tau Fraction": [[78, "tau-fraction"]], "2.1. Training Dataset": [[23, "training-dataset"]], "2.2. Input Representation": [[23, "input-representation"]], "2.2. Learning Rate Multiplier": [[78, "learning-rate-multiplier"]], "2.3. Learning Rate": [[78, "learning-rate"]], "2.3. Model": [[23, "model"]], "3. Model artifacts and metadata": [[60, "model-artifacts-and-metadata"]], "3. Monitor the Cluster Creation": [[45, "monitor-the-cluster-creation"]], "A Caution on Data Leakage": [[62, "a-caution-on-data-leakage"]], "A First Look at Vector Products": [[40, null]], "A Naive Approach": [[16, "a-naive-approach"]], "A Naive DataOps Pipeline": [[56, "a-naive-dataops-pipeline"]], "A Naive Implementation of DataLoader": [[80, "a-naive-implementation-of-dataloader"]], "A Not So Good Example on Implementing Base Estimator": [[9, "a-not-so-good-example-on-implementing-base-estimator"]], "A Note On Cross-validation": [[62, "a-note-on-cross-validation"]], "A Primer on Binary Digits (Bits) and 8-bit Unsigned Integers": [[29, "a-primer-on-binary-digits-bits-and-8-bit-unsigned-integers"]], "A Rudimentary Introduction to Generator and Yield in Python": [[80, null]], "A Smaller Example for Illustration": [[25, "a-smaller-example-for-illustration"]], "A Type Safe Example": [[4, "a-type-safe-example"]], "A Violation of Dependency Inversion Principle": [[85, "a-violation-of-dependency-inversion-principle"]], "A Word on Oscillations": [[25, null], [78, null]], "ACID Properties": [[54, "ml-lifecycle-032-acid-properties"]], "API Reference": [[0, null], [33, null]], "Ablation Studies": [[62, "ablation-studies"]], "Ablations": [[46, null]], "Abstract Overview": [[23, "abstract-overview"]], "Adding a Return Statement": [[80, "adding-a-return-statement"]], "Adding send": [[80, "adding-send"]], "Adding throw and close": [[80, "adding-throw-and-close"]], "Additivity": [[79, "additivity"]], "Advantages": [[54, "advantages"], [65, "advantages"], [65, "id5"], [65, "id9"], [65, "id14"]], "Algebraic Definition": [[37, "algebraic-definition"], [38, "algebraic-definition"], [38, "id1"], [40, "algebraic-definition"]], "Algorithm": [[16, "algorithm"], [27, "algorithm"]], "Algorithm (Iterative + Exact Match)": [[14, "algorithm-iterative-exact-match"]], "Algorithm (Iterative)": [[17, "algorithm-iterative"]], "Algorithm (Recursive + Exact Match)": [[14, "algorithm-recursive-exact-match"]], "Alternative Masking": [[22, null]], "An Example": [[51, "an-example"], [80, "an-example"]], "An Example Of Data Extraction For Collecting Large Volumes Of Text Data": [[55, "an-example-of-data-extraction-for-collecting-large-volumes-of-text-data"]], "An Example On E-commerce Recommendation": [[52, "an-example-on-e-commerce-recommendation"]], "An Example On Medical Diagnosis": [[52, "an-example-on-medical-diagnosis"]], "An Example On Movie Recommendation System": [[51, "an-example-on-movie-recommendation-system"]], "An Example To Illustrate The Notations": [[43, "an-example-to-illustrate-the-notations"]], "An Example Walkthrough": [[78, "an-example-walkthrough"]], "An Example of Batch Extraction": [[57, "an-example-of-batch-extraction"]], "An Example of Positional Encoding": [[24, "an-example-of-positional-encoding"]], "An Example of Real-time Ingestion": [[57, "an-example-of-real-time-ingestion"]], "An Example on Multimodal Data Storage For E-Commerce": [[53, "an-example-on-multimodal-data-storage-for-e-commerce"]], "Analogy: Bakery": [[35, "analogy-bakery"]], "Analogy: Job Scheduling in Data Centers": [[16, "analogy-job-scheduling-in-data-centers"]], "Analogy: The Stack of Plates": [[19, "analogy-the-stack-of-plates"]], "Analytical Processing": [[54, "analytical-processing"]], "Application to Common Algorithms": [[13, "application-to-common-algorithms"]], "Application: Image Compression and Segmentation": [[29, null]], "Applying Compression via K-Means": [[29, "applying-compression-via-k-means"]], "Applying LayerNorm and Residual Connections to Multi-Head Attention Output": [[24, "applying-layernorm-and-residual-connections-to-multi-head-attention-output"]], "Applying LayerNorm and Residual Connections to Positionwise FFN Output": [[24, "applying-layernorm-and-residual-connections-to-positionwise-ffn-output"]], "Architecture": [[56, "architecture"]], "Assignment": [[27, "assignment"]], "Assignments are Equivalent to Clusters": [[27, "assignments-are-equivalent-to-clusters"]], "Assumptions": [[14, "assumptions"], [16, "assumptions"]], "Assumptions and Constraints": [[14, "assumptions-and-constraints"], [16, "assumptions-and-constraints"]], "Asynchronous Data Loading and Prefetching": [[24, "asynchronous-data-loading-and-prefetching"]], "Atomicity, Consistency, Isolation, Durability (ACID)": [[54, "atomicity-consistency-isolation-durability-acid"]], "Attention Heatmap": [[74, "attention-heatmap"]], "Attention Notations": [[22, "attention-notations"]], "Attention Scoring Function": [[24, "attention-scoring-function"]], "Autoregressive Self-Supervised Learning": [[23, "autoregressive-self-supervised-learning"]], "Autoregressive Self-Supervised Learning Paradigm": [[22, "autoregressive-self-supervised-learning-paradigm"]], "Auxiliary Loss Function": [[23, "auxiliary-loss-function"]], "Auxiliary Space Complexity": [[14, "auxiliary-space-complexity"], [14, "id11"], [16, "auxiliary-space-complexity"], [17, "auxiliary-space-complexity"]], "Average Case": [[17, "average-case"]], "Backbone Architecture": [[22, "backbone-architecture"]], "Backend": [[44, "backend"]], "Background": [[17, "background"]], "Barrier": [[46, "barrier"]], "Base Model": [[32, "base-model"]], "Baseline": [[51, "baseline"], [58, "baseline"]], "Basics Of Distributed Data Parallelism": [[44, null]], "Basics of Floating Point Numbers": [[73, "basics-of-floating-point-numbers"]], "Batch Extraction/Ingestion": [[57, "batch-extraction-ingestion"]], "Batch Features, Online Features, and Streaming Features": [[65, "batch-features-online-features-and-streaming-features"]], "Batch Processing does not mean Predicting all Possible Inputs in Advance": [[65, "batch-processing-does-not-mean-predicting-all-possible-inputs-in-advance"]], "Batch Processing vs. Stream Processing": [[55, "batch-processing-vs-stream-processing"]], "Batch Serving/Inference (Asynchronous)": [[65, "batch-serving-inference-asynchronous"]], "Batched": [[22, "batched"]], "Batched Input Sequences": [[22, "batched-input-sequences"]], "Batching": [[24, "batching"]], "Benefit Structure": [[51, "benefit-structure"], [59, "benefit-structure"]], "Best Case": [[17, "best-case"]], "Best, Worst, and Average Case Analysis": [[16, "best-worst-and-average-case-analysis"]], "Best, Worst, and Average Case Analysis of Binary Search": [[14, "binary-search-time-complexity-iterative"], [16, "koko-eating-bananas-best-worst-average-case-analysis-of-binary-search"]], "Best, Worst, and Average Case Analysis of Koko Eating Bananas": [[16, "koko-eating-bananas-best-worst-average-case-analysis-of-koko-eating-bananas"]], "Bias and Variance": [[63, "bias-and-variance"]], "Bibliography": [[1, null]], "Binary Field \\mathbb{F}_2": [[34, "binary-field-mathbb-f-2"]], "Binary Search": [[15, null]], "Binary Search State Table": [[14, "binary-search-state-table-1"], [14, "binary-search-state-table-2"]], "Books and Lectures": [[26, "books-and-lectures"]], "Bound and Constraint in Generics and Type Variables": [[7, null]], "Bound versus Constraints": [[7, "bound-versus-constraints"]], "Boundaries (Linearity)": [[58, "boundaries-linearity"]], "Bounding and Semantic Clarity": [[7, "bounding-and-semantic-clarity"]], "Breaking it Down": [[16, "breaking-it-down"]], "Broadcasting": [[24, null]], "Brute Force Search and Global Minimum": [[27, "brute-force-search-and-global-minimum"]], "Business Problem and Objectives": [[51, "business-problem-and-objectives"]], "Business metrics": [[51, "business-metrics"]], "CI/CD Pipeline": [[56, "ml-lifecycle-03-ci-cd-pipeline"]], "CUDA Memory Allocations": [[71, null]], "Calculating Checkpoint Size and Fluff Ratio": [[73, "calculating-checkpoint-size-and-fluff-ratio"]], "Calculating Expected Value \\mathbb{E}[\\mathcal{T}(N)]": [[17, "calculating-expected-value-mathbb-e-mathcal-t-n"]], "Calibrating Models": [[59, "calibrating-models"]], "Calibration": [[59, "calibration"], [79, "calibration"]], "Calibration and Evaluation (Brier + AUROC combo)": [[59, "calibration-and-evaluation-brier-auroc-combo"]], "Callable Argument Types (Contravariance)": [[8, "callable-argument-types-contravariance"]], "Callable Return Types (Covariance)": [[8, "callable-return-types-covariance"]], "Callback": [[74, "callback"]], "Car Data Model Characteristics": [[54, "ml-lifecycle-032-car-data-model"]], "Case 1": [[13, "case-1"]], "Case 1: Unique Solution": [[35, "case-1-unique-solution"]], "Case 1: i = j": [[79, "case-1-i-j"]], "Case 2": [[13, "case-2"]], "Case 2: Infinite Solutions": [[35, "case-2-infinite-solutions"]], "Case 2: i \\neq j": [[79, "case-2-i-neq-j"]], "Case 3": [[13, "case-3"]], "Case 3: No Solution": [[35, "case-3-no-solution"]], "Cauchy-Schwarz Inequality": [[40, "cauchy-schwarz-inequality"]], "Centroids (Representatives)": [[27, "centroids-representatives"]], "Choose K that Minimizes the Cost Function": [[27, "choose-k-that-minimizes-the-cost-function"]], "Choose Your Metrics Wisely": [[59, "choose-your-metrics-wisely"]], "Choosing The Right Metric": [[59, "choosing-the-right-metric"]], "Choosing the Right Fusion Strategy": [[52, "choosing-the-right-fusion-strategy"]], "Circle as a Subtype of Shape in 2D Euclidean Geometry": [[5, "circle-as-a-subtype-of-shape-in-2d-euclidean-geometry"]], "Circle is a Subtype of Shape": [[5, "circle-is-a-subtype-of-shape"]], "Citations": [[11, "citations"], [21, "citations"], [23, "citations"], [30, "citations"], [78, "citations"], [79, "citations"]], "Clarifying Requirements": [[51, "clarifying-requirements"]], "Clarifying Requirements for an AIOps System": [[51, "clarifying-requirements-aiops-system"]], "Class Imbalance": [[57, "class-imbalance"]], "Classification": [[51, "classification"], [59, "classification"]], "Closing: Relevance of Vector Norms and Distances in Machine Learning and Deep Learning": [[39, "closing-relevance-of-vector-norms-and-distances-in-machine-learning-and-deep-learning"]], "Clustering": [[59, "clustering"]], "Coercive Implementations": [[3, "coercive-implementations"]], "Collating Everything Together": [[24, "collating-everything-together"]], "Column Wise Interpretation": [[40, "column-wise-interpretation"]], "Column-major order": [[53, "column-major-order"]], "Combination of Machine Learning and Deep Learning Tasks": [[52, "combination-of-machine-learning-and-deep-learning-tasks"]], "Command Line Arguments (CPU And Gloo Backend)": [[44, "command-line-arguments-cpu-and-gloo-backend"]], "Common Algorithms": [[13, "master-theorem-application-to-common-algorithms"]], "Common Data Destinations": [[55, "common-data-destinations"]], "Common FAQ": [[26, "common-faq"]], "Common Functions": [[68, "common-functions"], [70, "common-functions"]], "Common Machine Learning Terminologies": [[42, "common-ml-terminologies"]], "Common Terminologies": [[42, "common-terminologies"]], "Comparison between Dynamic and Static Type Checking": [[4, "comparison-between-dynamic-and-static-type-checking"]], "Complexity Analysis": [[12, null], [17, "complexity-analysis"]], "Complexity per Layer": [[24, "complexity-per-layer"]], "Composing the Configurations": [[24, "composing-the-configurations"]], "Composition Of Configurations": [[84, "composition-of-configurations"]], "Composition Order": [[82, "composition-order"]], "Computational Complexity of Self-Attention": [[24, "computational-complexity-of-self-attention"]], "Compute Node": [[45, "compute-node"]], "Computer Science": [[2, "computer-science"], [33, null]], "Concept": [[14, null], [17, null], [19, null], [31, null]], "Concept Drift": [[66, "concept-drift"]], "Concept of Row-major vs Column-major order": [[53, "concept-of-row-major-vs-column-major-order"]], "Concept: K-Means Clustering": [[27, null]], "Conclusion": [[29, "conclusion"]], "Concurrency, Parallelism and Asynchronous Programming": [[81, null]], "Condition 1: The Optimal Assignment": [[27, "condition-1-the-optimal-assignment"]], "Condition 2: The Optimal Cluster Centers (Centroids)": [[27, "condition-2-the-optimal-cluster-centers-centroids"]], "Conditional Entropy": [[23, "conditional-entropy"]], "Conditional Entropy and Perplexity as Loss Function": [[23, "conditional-entropy-and-perplexity-as-loss-function"]], "Conditional on Task": [[23, "conditional-on-task"]], "Config": [[25, "config"]], "Config For Different Stages/Evironments": [[84, "config-for-different-stages-evironments"]], "Configuration Management": [[84, null]], "Configurations, Constants and Enums": [[73, "configurations-constants-and-enums"]], "Configure AWS CLI": [[45, "configure-aws-cli"]], "Configure AWS ParallelCluster": [[45, "configure-aws-parallelcluster"]], "Connection to Liskov Substitution Principle": [[5, "connection-to-liskov-substitution-principle"]], "Cons": [[82, "cons"]], "Consolidated Script": [[45, "consolidated-script"]], "Constraining Type Variable": [[7, "constraining-type-variable"]], "Constraints": [[14, "constraints"], [16, "constraints"], [51, "constraints"]], "Construct Batches, Collate Function and DataLoader": [[25, "construct-batches-collate-function-and-dataloader"]], "Construct Hypothetical Function, Child and Parent Classes": [[76, "construct-hypothetical-function-child-and-parent-classes"]], "Constructing A Reversal Dataset": [[74, "constructing-a-reversal-dataset"]], "Constructing PyTorch Dataset": [[25, "constructing-pytorch-dataset"]], "Construction of Input and Target Sequences": [[24, "construction-of-input-and-target-sequences"]], "Containers are Generics": [[6, "containers-are-generics"]], "Context Length / Block Size": [[24, "context-length-block-size"]], "Context Length and Token Context Window": [[23, "context-length-and-token-context-window"]], "Context Vector/Matrix": [[24, "context-vector-matrix"]], "Contigency Matrix and Purity Score": [[28, "contigency-matrix-and-purity-score"]], "Continuous Training (Dependent on Monitoring of Drifts)": [[62, "continuous-training-dependent-on-monitoring-of-drifts"]], "Contravariance": [[8, "contravariance"], [8, "id2"]], "Contravariant and Callable Types": [[8, "contravariant-and-callable-types"]], "Conventions": [[42, "conventions"]], "Convergence": [[23, "convergence"], [27, "convergence"]], "Corpus and Tokenization": [[22, "corpus-and-tokenization"]], "Correcting the Violation": [[85, "correcting-the-violation"]], "Correctness": [[14, "correctness"], [14, "id5"], [16, "correctness"], [17, "correctness"]], "Cost Function": [[27, "cost-function"]], "Counting FLOPs of Matrix Multiplications": [[73, "counting-flops-of-matrix-multiplications"]], "Covariance": [[8, "covariance"], [8, "id1"]], "Create DataLoader": [[25, "create-dataloader"]], "Create Dataset": [[25, "create-dataset"]], "Create EC2 Key Pair": [[45, "create-ec2-key-pair"]], "Criteria 1: Value Inclusion (Set Membership)": [[5, "criteria-1-value-inclusion-set-membership"]], "Criteria 2: Function Applicability": [[5, "criteria-2-function-applicability"]], "Criteria 3: Property Preservation (Invariant Maintenance)": [[5, "criteria-3-property-preservation-invariant-maintenance"]], "Criterion": [[25, "criterion"]], "Criterion for Subtype Relationships": [[5, "criterion-for-subtype-relationships"]], "Cross-Entropy Loss Function": [[22, "cross-entropy-loss-function"]], "Cross-Validation": [[62, "cross-validation"]], "Data": [[51, "data"]], "Data Augmentation": [[57, "data-augmentation"]], "Data Collator And DataLoader": [[75, "data-collator-and-dataloader"]], "Data Engineering In Machine Learning": [[56, "data-engineering-in-machine-learning"]], "Data Formats": [[53, "data-formats"]], "Data Formats in Machine Learning Systems": [[53, "data-formats-in-machine-learning-systems"]], "Data Lake vs. Data Warehouse": [[55, "data-lake-vs-data-warehouse"]], "Data Lake, Data Warehouse, Data Lakehouse, Delta Lake": [[54, "data-lake-data-warehouse-data-lakehouse-delta-lake"], [54, "ml-lifecycle-032-data-lake-vs-data-warehouse"]], "Data Leakage": [[57, "data-leakage"]], "Data Model": [[54, "data-model"]], "Data Serialization vs Data Deserialization": [[53, "data-serialization-vs-data-deserialization"]], "Data Sources in Machine Learning Systems": [[53, "data-sources-in-machine-learning-systems"]], "Data Storage Engines": [[54, "data-storage-engines"]], "Data Structures and Algorithms": [[33, null]], "Data Types in Machine Learning Systems": [[53, "data-types-in-machine-learning-systems"]], "DataLoaders, Streaming and Lazy Loading": [[80, "dataloaders-streaming-and-lazy-loading"]], "Database Analogy": [[24, "database-analogy"]], "Dataset": [[25, "dataset"], [75, "dataset"], [77, "dataset"]], "Dataset Preparation": [[32, "dataset-preparation"]], "Dataset and Dataloading (Poor Man\u2019s Dataloader)": [[24, "dataset-and-dataloading-poor-man-s-dataloader"]], "Declaration, Compile, and Run Time": [[3, null]], "Decoder": [[24, "decoder"]], "Decoder Blocks": [[24, "decoder-blocks"]], "Decoupling Objectives": [[52, "decoupling-objectives"]], "Deep Learning": [[2, "deep-learning"]], "Deep Learning Tasks": [[52, "deep-learning-tasks"]], "Defining Type Variables with Upper Bounds": [[7, "defining-type-variables-with-upper-bounds"]], "Defining the Random Variable": [[17, "defining-the-random-variable"]], "Definition": [[22, "definition"], [22, "id1"], [22, "id2"], [24, "definition"], [24, "id15"], [24, "id24"], [24, "id32"], [24, "id35"], [25, "definition"], [34, "definition"], [37, "definition"], [40, "definition"], [40, "id3"], [55, "definition"], [55, "id6"], [55, "id10"], [65, "definition"], [65, "id2"], [65, "id7"], [65, "id12"], [78, "definition"], [85, "definition"]], "Definitions": [[16, "definitions"]], "Delete Cluster": [[45, "delete-cluster"]], "Delete Network Resources": [[45, "delete-network-resources"]], "Delete ParallelCluster": [[45, "delete-parallelcluster"]], "Demo Code": [[44, "demo-code"]], "Demonstrating Reflexivity, Transivity and Antisymmetry": [[5, "demonstrating-reflexivity-transivity-and-antisymmetry"]], "Dependencies": [[24, "dependencies"], [32, "dependencies"], [74, "dependencies"], [75, "dependencies"], [77, "dependencies"]], "Dependency Inversion Principle": [[85, null]], "Dependency Inversion Principle and Dependency Injection": [[85, "dependency-inversion-principle-and-dependency-injection"]], "Deployment Testing": [[64, "deployment-testing"]], "Deprecated To Redo": [[25, null]], "Derivative Of Softmax With Respect To Weight Matrix": [[79, "derivative-of-softmax-with-respect-to-weight-matrix"]], "Derivative of the Softmax Function": [[79, "derivative-of-the-softmax-function"]], "Derivatives of the Softmax Function": [[79, "derivatives-of-the-softmax-function"]], "Design Patterns": [[86, null]], "Dimensionality": [[58, "dimensionality"]], "Dimensions": [[22, "dimensions"]], "Dimensions and Indexing": [[22, "dimensions-and-indexing"]], "Direct Sum Notation Is Concatenation": [[22, null]], "Disadvantages": [[54, "disadvantages"], [65, "disadvantages"], [65, "id6"], [65, "id10"], [65, "id15"]], "Distance": [[39, "distance"]], "Distributed Data Parallelism And Data Sharding": [[53, "distributed-data-parallelism-and-data-sharding"]], "Distributed Information": [[44, "distributed-information"]], "Distributed Systems": [[47, null]], "Document Model": [[54, "document-model"]], "Document Model Characteristics": [[54, "ml-lifecycle-032-document-model"]], "Dot Product": [[40, "dot-product"]], "Drawing Some Connection to Ordinary Functions": [[8, "drawing-some-connection-to-ordinary-functions"]], "Drift madewithml": [[66, "drift-madewithml"]], "Dropout And Elementwise Operation": [[22, null]], "Dry Run": [[75, "dry-run"]], "Dynamic Type Checking": [[4, "dynamic-type-checking"]], "ELT (Extract, Load, Transform)": [[55, "elt-extract-load-transform"]], "ELTL (Extract, Load, Transform, Load)": [[55, "eltl-extract-load-transform-load"]], "ETL (Extract, Transform, Load)": [[55, "etl-extract-transform-load"]], "Early Fusion": [[52, "early-fusion"]], "Edge Cases": [[14, "edge-cases"], [16, "edge-cases"]], "Elbow Method": [[27, "elbow-method"]], "Elementwise and Vectorwise Operations": [[22, "elementwise-and-vectorwise-operations"]], "Encoding Strategy Overview": [[25, "encoding-strategy-overview"]], "Enough is Enough": [[79, null]], "Ensembling": [[58, "ensembling"]], "Equality of Vectors": [[37, "equality-of-vectors"]], "Estimating FLOPs for a Single Forward Pass": [[73, "estimating-flops-for-a-single-forward-pass"]], "Estimating FLOPs for a Single Forward Pass of GPT-2": [[73, "estimating-flops-for-a-single-forward-pass-of-gpt-2"]], "Estimation of the Conditional Probability Distribution": [[23, "estimation-of-the-conditional-probability-distribution"]], "Evaluate With Pretrained Model": [[32, "evaluate-with-pretrained-model"]], "Evaluation (Performance Metrics)": [[28, "evaluation-performance-metrics"]], "Example": [[14, "example"], [16, "example"], [19, "example"], [29, "example"], [54, "example"], [59, "example"], [65, "example"], [65, "id4"], [65, "id8"], [65, "id13"], [78, "example"]], "Example 1: Iterative Approach": [[16, "example-1-iterative-approach"]], "Example 2: Pigeonhole Principle": [[16, "example-2-pigeonhole-principle"]], "Example is not a Proof": [[34, null]], "Example of a Data Model": [[54, "example-of-a-data-model"]], "Example: Ensuring Type Safety with Sized": [[7, "example-ensuring-type-safety-with-sized"]], "Example: Personal Protective Equipment (PPE) Detection": [[52, "example-personal-protective-equipment-ppe-detection"]], "Examples": [[13, "examples"], [34, "examples"], [54, "examples"], [66, "examples"]], "Examples in code (Python) of Row-major vs Column-major order and its effect on performance": [[53, "examples-in-code-python-of-row-major-vs-column-major-order-and-its-effect-on-performance"]], "Examples of Deep Learning Tasks": [[52, "examples-of-deep-learning-tasks"]], "Examples of Machine Learning Tasks": [[52, "examples-of-machine-learning-tasks"]], "Examples of Row-major vs Column-major order": [[53, "examples-of-row-major-vs-column-major-order"]], "Expected Outcome": [[17, "expected-outcome"]], "Experiment Tracking": [[60, "experiment-tracking"]], "Explanation": [[14, "explanation"]], "Extensions": [[17, "extensions"]], "FLOPS Per Second in GPUs": [[73, "flops-per-second-in-gpus"]], "Feasibility Function": [[16, "feasibility-function"]], "Feature Characteristics": [[58, "feature-characteristics"]], "Feature Engineering": [[57, "feature-engineering"]], "Features": [[51, "features"]], "Features (Inputs)": [[52, "features-inputs"]], "Features of a Cancer Diagnosis System": [[51, "features-cancer-diagnosis"]], "Features, Labels and Outputs (Inputs/Outputs)": [[52, "features-labels-and-outputs-inputs-outputs"]], "Feedback Loop": [[56, "feedback-loop"]], "Field Axioms": [[34, "linear-algebra-preliminaries-definition-of-a-field"]], "Fields": [[34, null], [34, "id2"]], "Final Model Training": [[62, "final-model-training"]], "Find the Instance ID": [[45, "find-the-instance-id"]], "Finding and Removing Reference Cycles": [[71, "finding-and-removing-reference-cycles"]], "Finite vs. Unbounded Feature Space, Precurser to Deployment Strategies": [[65, "finite-vs-unbounded-feature-space-precurser-to-deployment-strategies"]], "First Decoder Block (\\ell = 1)": [[22, "first-decoder-block-ell-1"]], "First Sample First Token": [[25, "first-sample-first-token"]], "First Sample Fourth Token": [[25, "first-sample-fourth-token"]], "Floating Point Operations (FLOPs)": [[73, "floating-point-operations-flops"]], "Floating Point Operations Per Second (FLOPS)": [[73, "floating-point-operations-per-second-flops"]], "Formal Notation of Time Complexity": [[14, null]], "Frame a Business Problem as an Machine Learning Task": [[52, "frame-a-business-problem-as-an-machine-learning-task"]], "Framing the Problem as a Sorted Boolean Array": [[16, "framing-the-problem-as-a-sorted-boolean-array"]], "From Batch Prediction to Online Prediction": [[65, "from-batch-prediction-to-online-prediction"]], "From Business Metrics to Machine Learning Metrics": [[51, "from-business-metrics-to-machine-learning-metrics"]], "From Causal Mask To Cross-Attention Mask": [[74, "from-causal-mask-to-cross-attention-mask"]], "From GPT-1 to GPT-2": [[23, "from-gpt-1-to-gpt-2"]], "Fulfilling the Subtype Criterion": [[5, "fulfilling-the-subtype-criterion"]], "Function Overloading": [[9, null], [9, "id1"]], "Function Overloading and Single/Dynamic Dispatch": [[9, "function-overloading-and-single-dynamic-dispatch"]], "Function feasible": [[16, "function-feasible"]], "Function minEatingSpeed": [[16, "function-mineatingspeed"]], "Function total_hours_to_finish_eating": [[16, "function-total-hours-to-finish-eating"]], "Functional Form of f": [[79, "functional-form-of-f"]], "Further Add a Singleton Dimension in Target Masks": [[25, "further-add-a-singleton-dimension-in-target-masks"]], "Further Processing": [[52, "further-processing"]], "Further Readings": [[42, "further-readings"]], "Further Violation of Type Safety": [[4, "further-violation-of-type-safety"]], "Future Mask": [[25, "future-mask"]], "GPT Example": [[25, "gpt-example"]], "GPT is a Autoregressive Self-Supervised Learning Model": [[23, "gpt-is-a-autoregressive-self-supervised-learning-model"]], "GPT-2 Family": [[23, "decoder-concept-gpt-2-family"], [24, "decoder-concept-gpt-2-family-duplicate"]], "GPT-2 Model Architecture (HuggingFace)": [[24, "gpt-2-model-architecture-huggingface"]], "GPT-2 Paper Key Ideas": [[23, "gpt-2-paper-key-ideas"]], "GPT-2 Variants": [[23, "gpt-2-variants"], [24, "gpt-2-variants"]], "GPT-2 is a Continuation of GPT-1 with Self-Attention Mechanisms": [[24, "gpt-2-is-a-continuation-of-gpt-1-with-self-attention-mechanisms"]], "GPU Memory Footprint of Loading Model and Optimizer": [[73, "gpu-memory-footprint-of-loading-model-and-optimizer"]], "Gaussian Error Linear Unit (GELU)": [[22, "gaussian-error-linear-unit-gelu"], [24, "gaussian-error-linear-unit-gelu"]], "General Attention Mechanism": [[22, "general-attention-mechanism"]], "General Form of Linear Equations": [[35, "general-form-of-linear-equations"]], "General Notations": [[22, "general-notations"]], "Generalization of the Pythagorean Theorem to D Dimensions": [[39, "generalization-of-the-pythagorean-theorem-to-d-dimensions"], [39, "vector-norm-pythagorean-theorem-d-dimensions"]], "Generation": [[25, "generation"]], "Generative Pre-trained Transformer (GPT)": [[24, "generative-pre-trained-transformer-gpt"]], "Generative Pre-trained Transformers": [[21, null]], "Generator Expression": [[80, "generator-expression"]], "Generators and Streaming Data": [[80, "generators-and-streaming-data"]], "Generic Form": [[13, "generic-form"]], "Generic Functions": [[6, "generic-functions"]], "Generic Methods": [[6, "generic-methods"]], "Generics": [[6, "generics"]], "Generics and Type Variables": [[6, null], [6, "id2"]], "Geometric Definition": [[37, "geometric-definition"]], "Geometric Interpretation": [[38, "geometric-interpretation"]], "Geometric definition": [[40, "geometric-definition"]], "Geometrical Definition": [[38, "geometrical-definition"]], "Get Class and Instance Attributes": [[76, "get-class-and-instance-attributes"]], "Get Signature and Type Annotations of a Function": [[76, "get-signature-and-type-annotations-of-a-function"]], "Global Rank And World Size": [[44, "global-rank-and-world-size"]], "Gradient, Jacobian, and Hessian of Softmax": [[79, "gradient-jacobian-and-hessian-of-softmax"]], "Graph Model": [[54, "graph-model"]], "Head": [[22, "head"]], "Heatmap": [[24, "heatmap"]], "Hessian Matrix": [[79, "hessian-matrix"]], "How About We Use Back Causal Attention Mask?": [[74, "how-about-we-use-back-causal-attention-mask"]], "How Many GPUs?": [[45, "how-many-gpus"]], "How To Do Teacher-Student Knowledge Distillation?": [[77, null]], "How To Fine-Tune Decoder-Only Models For Sequence Classification Using Last Token Pooling?": [[75, null]], "How To Fine-Tune Decoder-Only Models For Sequence Classification With Cross-Attention?": [[74, null]], "How do I access and extract the data?": [[55, "how-do-i-access-and-extract-the-data"]], "How do I access the data?": [[55, "how-do-i-access-the-data"]], "How do I load the extracted data into the destination storage?": [[55, "how-do-i-load-the-extracted-data-into-the-destination-storage"]], "How does Generator Work?": [[80, "how-does-generator-work"]], "How to Calculate the Number of FLOPs in Transformer Based Models?": [[73, null]], "How to Implement Nominal Subtyping?": [[3, "how-to-implement-nominal-subtyping"]], "How to Implement Structural Subtyping?": [[3, "how-to-implement-structural-subtyping"]], "How to Inspect Function and Class Signatures in Python?": [[76, null]], "How to Setup SLURM and ParallelCluster in AWS": [[45, null]], "How to find K?": [[27, "how-to-find-k"]], "Hybrid Fusion": [[52, "hybrid-fusion"]], "Hybrid Serving": [[65, "hybrid-serving"]], "Hydra": [[82, "hydra"]], "Hyperparameter Tuning": [[60, "hyperparameter-tuning"], [62, "hyperparameter-tuning"]], "Hypothesis Space": [[27, "hypothesis-space"]], "IEEE (Style) Citations": [[2, null]], "Identical Application": [[22, "identical-application"], [24, "identical-application"]], "Identify and Scope the Data Source": [[53, "identify-and-scope-the-data-source"]], "Identify the Business Problem": [[51, "identify-the-business-problem"]], "Identifying the Type of Machine Learning Task": [[52, "identifying-the-type-of-machine-learning-task"]], "Image Compression with K-Means": [[29, "image-compression-with-k-means"]], "Image Segmentation": [[29, "image-segmentation"]], "Imperative vs Declarative": [[54, "imperative-vs-declarative"]], "Implementation": [[14, "implementation"], [14, "id6"], [16, "implementation"], [17, "implementation"], [17, "id2"], [19, "implementation"], [23, null], [24, "implementation"], [24, "id11"], [24, "id16"], [24, "id28"], [24, "id33"], [24, "id37"], [25, "implementation"], [28, "implementation"], [32, null], [78, "implementation"], [79, "implementation"]], "Implementation of Residual Block and AddNorm": [[24, "implementation-of-residual-block-and-addnorm"]], "Implementation of the Jacobian Matrix": [[79, "implementation-of-the-jacobian-matrix"]], "Implementation: K-Means (Lloyd)": [[28, null]], "Implementations": [[26, "implementations"]], "Imports and Dependencies": [[28, "imports-and-dependencies"]], "Inadmissble Equations": [[13, "inadmissble-equations"]], "Inclusive Implementations": [[3, "inclusive-implementations"]], "Inclusive vs. Coercive Implementations": [[3, "inclusive-vs-coercive-implementations"]], "Independence of Normal Vector from Plane Vectors\u2019 Position": [[35, "independence-of-normal-vector-from-plane-vectors-position"]], "Independent Processing": [[22, "independent-processing"], [24, "independent-processing"]], "Independent and Identically Distributed (IID)": [[58, "independent-and-identically-distributed-iid"]], "Index-to-String Mapping": [[22, "index-to-string-mapping"]], "Influential Ideas and Papers": [[33, null]], "Initial Book Relation": [[54, "ml-lifecycle-032-initial-book-relation"]], "Initial Condition of Conditional Probability Distribution": [[23, "initial-condition-of-conditional-probability-distribution"]], "Initializing Criterion With Composer": [[25, "initializing-criterion-with-composer"]], "Input Sequence": [[22, "input-sequence"]], "Input Space Complexity": [[14, "input-space-complexity"], [14, "id10"], [16, "input-space-complexity"], [17, "input-space-complexity"]], "Input and Target": [[25, "input-and-target"]], "Inputs and Labels": [[52, "inputs-and-labels"]], "Inputs and Targets": [[25, "inputs-and-targets"]], "Inspect All Members": [[76, "inspect-all-members"]], "Instantiating": [[82, "instantiating"]], "Integers as a Subtype of Real Numbers": [[5, "integers-as-a-subtype-of-real-numbers"]], "Interpretability vs. Accuracy": [[58, "interpretability-vs-accuracy"]], "Interpreting Dot Product as Matrix Multiplication": [[40, "interpreting-dot-product-as-matrix-multiplication"]], "Introduction": [[13, "introduction"], [14, "introduction"], [16, "introduction"], [17, "introduction"], [19, "introduction"], [23, "introduction"], [34, "introduction"], [51, "introduction"], [52, "introduction"]], "Intuition": [[14, "intuition"], [17, "intuition"], [19, "intuition"], [24, "intuition"], [27, "intuition"], [55, "intuition"], [55, "id5"], [55, "id9"], [66, "intuition"]], "Intuition (What comes before Data Extraction?)": [[53, "intuition-what-comes-before-data-extraction"]], "Intuition of Attention Mechanism": [[24, "intuition-of-attention-mechanism"]], "Invariance": [[8, "invariance"], [8, "id3"]], "Invariance, Covariance and Contravariance": [[8, null]], "Iterative Process Through L Decoder Blocks": [[22, "iterative-process-through-l-decoder-blocks"]], "JSON": [[53, "json"]], "K-Means": [[26, null], [28, null], [29, "k-means"]], "K-Means Algorithm on IRIS": [[28, "k-means-algorithm-on-iris"]], "K-Means Algorithm on MNIST": [[28, "k-means-algorithm-on-mnist"]], "K-Means Converges in Finite Steps": [[27, "k-means-converges-in-finite-steps"]], "K-Means++": [[27, "k-means"]], "K-Medoids": [[27, "k-medoids"]], "Key 1. Byte Pair Encoding (BPE) (1,2,3)": [[23, "key-1-byte-pair-encoding-bpe-1-2-3"]], "Key 1. Competent Generalists over Narrow Experts (1)": [[23, "key-1-competent-generalists-over-narrow-experts-1"]], "Key 1. GPT-2 is a Continuation of GPT-1 with Self-Attention Mechanisms (1)": [[23, "key-1-gpt-2-is-a-continuation-of-gpt-1-with-self-attention-mechanisms-1"]], "Key 1. Modeling Language Models over Joint Probability Distributions (1)": [[23, "key-1-modeling-language-models-over-joint-probability-distributions-1"]], "Key 1. Rejection of CommonCrawl (1,2)": [[23, "key-1-rejection-of-commoncrawl-1-2"]], "Key 2. Construction of WebText Dataset": [[23, "key-2-construction-of-webtext-dataset"]], "Key 2. Decompose Joint Distributions as Conditional Distributions via Chain Rule (2)": [[23, "key-2-decompose-joint-distributions-as-conditional-distributions-via-chain-rule-2"]], "Key 2. IID Assumption Fails in Real World (2, 3)": [[23, "key-2-iid-assumption-fails-in-real-world-2-3"]], "Key 2. Modifications from GPT-1 and Model Stability (1)": [[23, "key-2-modifications-from-gpt-1-and-model-stability-1"]], "Key 3. Conditional on Task (3)": [[23, "key-3-conditional-on-task-3"]], "Key 3. Multi-Task Learning is Nacent (4)": [[23, "key-3-multi-task-learning-is-nacent-4"]], "Key 4. From Word Embeddings to Contextual Embeddings (5,6)": [[23, "key-4-from-word-embeddings-to-contextual-embeddings-5-6"]], "Key 4. Optimizing Unsupervised is the same as Optimizing Supervised (4)": [[23, "key-4-optimizing-unsupervised-is-the-same-as-optimizing-supervised-4"]], "Key 5. Large Language Models has Capacity to Infer and Generalize (5)": [[23, "key-5-large-language-models-has-capacity-to-infer-and-generalize-5"]], "Key 5. Zero Shot Learning and Zero Shot Transfer (7)": [[23, "key-5-zero-shot-learning-and-zero-shot-transfer-7"]], "Key Components": [[52, "key-components"]], "Key Components of Framing a Machine Learning Problem": [[52, "ml-lifecycle-02-project-scoping-key-components"]], "Key Differences Between Structured And Unstructured Data": [[54, "ml-lifecycle-032-structured-vs-unstructured-data"]], "Koko Eating Bananas": [[16, null]], "Kronecker Delta": [[79, "kronecker-delta"]], "L^{p} Norm": [[39, "l-p-norm"]], "L_1 Norm (Manhattan Norm)": [[39, "l-1-norm-manhattan-norm"]], "L_2 Norm (Euclidean Norm)": [[39, "l-2-norm-euclidean-norm"]], "Labeling": [[57, "labeling"]], "Labels": [[52, "labels"]], "Last Token has Full Context": [[24, "last-token-has-full-context"]], "Late Fusion": [[52, "late-fusion"]], "Layer Norm Stabilises Activation Distributions": [[24, "layer-norm-stabilises-activation-distributions"]], "Layer Normalization": [[22, "layer-normalization"], [24, "layer-normalization"]], "Layer Normalization Before Projection": [[22, "layer-normalization-before-projection"]], "LayerNorm and Residual Connection": [[24, "layernorm-and-residual-connection"]], "Learnable Affine Transformation": [[24, "learnable-affine-transformation"]], "Learning Curves": [[62, "learning-curves"]], "Learning Objectives": [[16, "learning-objectives"], [19, "learning-objectives"], [34, "learning-objectives"], [37, "learning-objectives"], [38, "learning-objectives"]], "Learning Problem (Conditional Maximum Likelihood Estimation)": [[42, "learning-problem-conditional-maximum-likelihood-estimation"]], "Learning Rate Scheduler": [[25, "learning-rate-scheduler"]], "Lemma 1: Stirling Numbers of the Second Kind": [[27, "lemma-1-stirling-numbers-of-the-second-kind"]], "Lemma 2: Cost Function of K-Means Monotonically Decreases": [[27, "lemma-2-cost-function-of-k-means-monotonically-decreases"]], "Lemma 3: Monotone Convergence Theorem": [[27, "lemma-3-monotone-convergence-theorem"]], "Linear Algebra": [[33, null]], "Linear Projections": [[24, "linear-projections"]], "Linear Search": [[18, null]], "Linking Plane and Hyperplane Equations to Linear Regression": [[35, "linking-plane-and-hyperplane-equations-to-linear-regression"]], "Liskov Substitution Principle": [[5, "liskov-substitution-principle"]], "List is Invariant": [[8, "list-is-invariant"]], "List vs Immutable List": [[8, "list-vs-immutable-list"]], "Lloyd\u2019s Algorithm": [[27, "lloyds-algorithm"]], "LoRA Implementation": [[32, "lora-implementation"]], "Load and Read the Image": [[29, "load-and-read-the-image"]], "Local And Global Rank": [[43, "local-and-global-rank"]], "Local And Global World Size": [[43, "local-and-global-world-size"]], "Local Minima": [[27, "local-minima"]], "Logging into the Head Node": [[45, "logging-into-the-head-node"]], "Lookup": [[22, "lookup"]], "Lookup Operation": [[24, "lookup-operation"]], "Loop Invariant": [[17, "loop-invariant"]], "Loop Invariant and Induction": [[17, "loop-invariant-and-induction"]], "Loss Computation": [[25, "loss-computation"]], "Loss Function": [[23, "loss-function"], [27, "loss-function"]], "Loss, Cost, Objective and Performance Metrics": [[52, "loss-cost-objective-and-performance-metrics"]], "Low Level and High Level Modules": [[85, "low-level-and-high-level-modules"]], "Low-Rank Adaptation Of Large Language Models": [[30, null]], "MY OLD EXAMPLE TO REFINE": [[66, "my-old-example-to-refine"]], "Machine Learning Notations": [[42, null], [42, "id2"]], "Machine Learning Objective (Establishing Metrics)": [[52, "machine-learning-objective-establishing-metrics"]], "Machine Learning Tasks": [[52, "machine-learning-tasks"]], "Machine Learning on the Cloud and on the Edge": [[65, "machine-learning-on-the-cloud-and-on-the-edge"]], "Main Profiling Code": [[68, "main-profiling-code"], [70, "main-profiling-code"]], "Markov Assumption": [[23, "markov-assumption"]], "Masked Multi-Head Attention for Decoder Layer \\ell": [[22, "masked-multi-head-attention-for-decoder-layer-ell"]], "Masked/Causal Self-Attention": [[24, "masked-causal-self-attention"]], "Masking and Ignore Index": [[25, "masking-and-ignore-index"]], "Master Port and Master Address": [[44, "master-port-and-master-address"]], "Master Theorem": [[14, "master-theorem"]], "Master Theorem 1": [[13, null]], "Master Theorem Case 2 Extensions": [[13, "master-theorem-case-2-extensions"]], "Master Theorem Cases": [[13, "master-theorem-cases"], [24, "self-attention-complexity"]], "Mathematical Formulation": [[16, "mathematical-formulation"]], "Mathematical Induction": [[17, "mathematical-induction"]], "Mathematical Intuition": [[78, "mathematical-intuition"]], "Mathematical Notations": [[42, "mathematical-notations"]], "Mathematical Representation": [[16, "mathematical-representation"], [17, "mathematical-representation"]], "Mathematical Representation (Iterative)": [[14, "mathematical-representation-iterative"]], "Mathematical Representation (Recursive)": [[14, "mathematical-representation-recursive"]], "Matrix Multiplication Primer": [[22, "matrix-multiplication-primer"]], "Maximum Path Length": [[24, "maximum-path-length"]], "Measuring Success": [[51, "measuring-success"]], "Medical Diagnosis Favours Recall": [[51, null]], "Memory Efficiency": [[80, "memory-efficiency"]], "Memory Mapping": [[24, "memory-mapping"]], "Merge - No Additional Inference Latency": [[31, "merge-no-additional-inference-latency"]], "Merge And Quantize": [[32, "merge-and-quantize"]], "Merge And Unload": [[32, "merge-and-unload"]], "Merge Padding and Future Masks": [[25, "merge-padding-and-future-masks"]], "Mermaid Diagram Of Deep Learning Tasks": [[52, null]], "Mermaid Diagram Of Machine Learning Tasks": [[52, null]], "Metadata Management": [[83, "metadata-management"]], "Method Resolution Order": [[76, "method-resolution-order"]], "Metric Selection": [[59, "metric-selection"]], "Metrics": [[32, "metrics"]], "Miniconda": [[45, "miniconda"]], "Minimum Viable Product (MVP)": [[52, "minimum-viable-product-mvp"]], "Missing": [[10, "missing"]], "Model": [[25, "model"]], "Model Architecture": [[75, "model-architecture"]], "Model Calibration": [[63, "model-calibration"]], "Model Compression": [[65, "model-compression"]], "Model FLOPs Utilization (MFU)": [[73, "model-flops-utilization-mfu"]], "Model Fitting": [[27, "model-fitting"]], "Model Inference": [[27, "model-inference"]], "Model Promotion": [[64, "model-promotion"]], "Model Registry and Promotion (MLOps)": [[64, "model-registry-and-promotion-mlops"]], "Model Selection": [[58, "model-selection"]], "Model Versioning, Code Versioning, and Data Versioning": [[60, "model-versioning-code-versioning-and-data-versioning"]], "Modern Row and Columnar Formats": [[53, "modern-row-and-columnar-formats"]], "Modifications from GPT-1 and Model Stability": [[24, "modifications-from-gpt-1-and-model-stability"]], "Modifying GPT-2 Head For Classification": [[74, "modifying-gpt-2-head-for-classification"]], "Monitor 2": [[66, "monitor-2"]], "Monitoring and Alerting": [[56, "monitoring-and-alerting"]], "Monitoring and Optimizing": [[55, "monitoring-and-optimizing"]], "Monotonicity": [[16, "monotonicity"]], "More Intuition in Andrej Karpathy\u2019s Video": [[24, null]], "More Intuition on Positional Encodings (Pretty bad analogy, to revise)": [[24, "more-intuition-on-positional-encodings-pretty-bad-analogy-to-revise"]], "Motivation": [[9, "motivation"], [10, "motivation"], [23, "motivation"], [25, "motivation"], [25, "id4"], [31, "motivation"], [35, "motivation"], [76, "motivation"], [78, "motivation"]], "Multi-Head Attention": [[24, "multi-head-attention"]], "Multi-Head Attention for Layer \\ell": [[22, "multi-head-attention-for-layer-ell"]], "Multi-Node Setup With CUDA": [[44, "multi-node-setup-with-cuda"]], "Multi-Stage and Multi-Modal Paradigms": [[52, null]], "Multimodal Deep Learning (Yes ChatGPT Is Multimodal)": [[52, "multimodal-deep-learning-yes-chatgpt-is-multimodal"]], "Naive Way To Handle Future Mask": [[24, null]], "Narrowing Values, Widening Functions": [[5, "narrowing-values-widening-functions"]], "Negative Scaling": [[38, "negative-scaling"]], "Next Method": [[80, "next-method"]], "No Distributed Barrier": [[46, "no-distributed-barrier"]], "No Free Lunch Theorem": [[58, "no-free-lunch-theorem"]], "NoSQL": [[54, "nosql"]], "Nodes": [[43, "nodes"]], "Nominal Subtyping - Class Hierarchy Determines Subtypes": [[3, "nominal-subtyping-class-hierarchy-determines-subtypes"]], "Nominal vs. Structural Subtyping": [[3, "nominal-vs-structural-subtyping"]], "Non-Fields": [[34, "non-fields"]], "Non-Functional Metrics": [[52, "non-functional-metrics"]], "Non-Negativity": [[79, "non-negativity"]], "Norm": [[39, "norm"]], "Normalization": [[54, "normalization"], [79, "normalization"]], "NotGiven": [[10, "notgiven"]], "NotGiven vs. MISSING": [[10, "notgiven-vs-missing"]], "Notation": [[24, "notation"]], "Notation Abuse": [[22, null]], "Notation, Context Length, Shuffling and Batching": [[24, "notation-context-length-shuffling-and-batching"]], "Notations": [[22, null], [33, null], [43, null]], "Notebooks": [[26, "notebooks"]], "Number of Bits needed for a Positive Integer": [[29, "number-of-bits-needed-for-a-positive-integer"]], "Number of items left after k-th comparison": [[14, "items-left-binary-search"]], "Numerical Instability of the Softmax Function": [[79, "numerical-instability-of-the-softmax-function"]], "Numerical Stability and Gradient Saturation": [[24, "numerical-stability-and-gradient-saturation"]], "Objective": [[17, "objective"]], "Objective Function": [[27, "objective-function"]], "Objective Function Re-defined": [[27, "objective-function-re-defined"]], "Objective Function for Fine-Tuning": [[23, "objective-function-for-fine-tuning"]], "Offline Metrics": [[52, "offline-metrics"]], "Offline Validation": [[64, "offline-validation"]], "Offline Validation Steps": [[64, "offline-validation-steps"]], "On Dynamic vs Static Type Checking": [[4, "on-dynamic-vs-static-type-checking"]], "On-Device Inference": [[65, "on-device-inference"]], "One-Hot Encoding Process": [[22, "one-hot-encoding-process"]], "One-Hot Encoding and Embedding Matrix": [[24, "one-hot-encoding-and-embedding-matrix"]], "One-Hot Representation of Input Sequence \\mathbf{x}": [[22, "one-hot-representation-of-input-sequence-mathbf-x"]], "Online Metrics": [[52, "online-metrics"]], "Online Resources": [[26, "online-resources"]], "Online Validation": [[64, "online-validation"]], "Online Validation Techniques": [[64, "online-validation-techniques"]], "Operations": [[19, "operations"], [33, null]], "Optimizer": [[25, "optimizer"]], "Optimizing Unsupervised is the same as Optimizing Supervised": [[23, "optimizing-unsupervised-is-the-same-as-optimizing-supervised"]], "Ordered Linear Search: Efficiency in Sorted Arrays": [[17, "ordered-linear-search-efficiency-in-sorted-arrays"]], "Ordered and Probabilistic Linear Search": [[17, "ordered-and-probabilistic-linear-search"]], "Other Methods": [[27, "other-methods"]], "Outer Product": [[40, "outer-product"]], "Outputs": [[52, "outputs"]], "Outputs (Predictions)": [[52, "outputs-predictions"]], "Overloading with Container": [[9, "overloading-with-container"]], "PE: Positional Encoding Layer": [[22, "pe-positional-encoding-layer"]], "Pair Problem Revisited": [[6, "pair-problem-revisited"]], "Parameters Reduction In LoRA": [[31, "parameters-reduction-in-lora"]], "Parametric Equation of a Plane": [[35, "parametric-equation-of-a-plane"]], "Partition and Voronoi Regions": [[27, "partition-and-voronoi-regions"]], "Patch Composer Configuration with Model Config": [[24, "patch-composer-configuration-with-model-config"]], "Performance": [[51, "performance"]], "Permutation Invariance": [[24, "permutation-invariance"]], "Perplexity": [[23, "perplexity"]], "Plane Equation in Normal Form (Vector Form)": [[35, "plane-equation-in-normal-form-vector-form"]], "Planes": [[35, "planes"]], "Plane\u2019s Equations": [[35, "plane-s-equations"]], "Playbook": [[33, null]], "Positional Embeddings": [[24, "positional-embeddings"]], "Positional Encoding for p = 1 (\u2018priest\u2019)": [[24, "positional-encoding-for-p-1-priest"]], "Positional Encoding for p = 2 (\u2018and\u2019)": [[24, "positional-encoding-for-p-2-and"]], "Positional Encoding for p = 3 (\u2018clerk?\u2019)": [[24, "positional-encoding-for-p-3-clerk"]], "Positional Encodings via Embeddings": [[24, "positional-encodings-via-embeddings"]], "Positionwise Feed-Forward Networks": [[22, "positionwise-feed-forward-networks"], [24, "positionwise-feed-forward-networks"]], "Positive Scaling": [[38, "positive-scaling"]], "Preliminaries": [[36, null]], "Probabilistic Interpretation": [[79, "probabilistic-interpretation"]], "Probabilistic Search: Harnessing Data to Optimize Searches": [[17, "probabilistic-search-harnessing-data-to-optimize-searches"]], "Problem Formulation": [[27, "problem-formulation"], [79, "problem-formulation"]], "Problem Intuition": [[16, "problem-intuition"]], "Problem Scenario: Optimized Product Search in an Online Store": [[17, "problem-scenario-optimized-product-search-in-an-online-store"]], "Problem Statement": [[16, "problem-statement"], [29, "problem-statement"]], "Process": [[43, "process"]], "Process Group Initialization": [[44, "process-group-initialization"]], "Production Layer": [[56, "production-layer"]], "Profile GPT Small Time And Memory": [[70, null]], "Profiling": [[72, null]], "Profiling Code With Timeit": [[68, null]], "Profiling Generator Performance": [[80, "profiling-generator-performance"]], "Profiling Square Operation": [[69, "profiling-square-operation"]], "Projection to a Higher Dimension Space": [[22, "projection-to-a-higher-dimension-space"], [24, "projection-to-a-higher-dimension-space"]], "Projections Lead to Dynamic Context Vectors": [[24, "projections-lead-to-dynamic-context-vectors"]], "Proof": [[16, null]], "Proof of Algebraic and Geometric Equivalence of Dot Product": [[40, "proof-of-algebraic-and-geometric-equivalence-of-dot-product"]], "Proof of Geometric Definition and The Law of Cosines": [[40, "proof-of-geometric-definition-and-the-law-of-cosines"]], "Properties of 2D-Planes": [[35, "properties-of-2d-planes"]], "Properties of Dot Product": [[40, "properties-of-dot-product"]], "Properties of Transpose": [[37, "properties-of-transpose"]], "Pros": [[82, "pros"], [82, "id1"]], "Pros and Cons of Nominal and Structural Subtyping": [[3, "pros-and-cons-of-nominal-and-structural-subtyping"]], "Pros and cons of Row-major vs Column-major order": [[53, "pros-and-cons-of-row-major-vs-column-major-order"]], "Pseudocode": [[14, "pseudocode"], [14, "id4"], [16, "pseudocode"], [17, "pseudocode"]], "Publisher Relation": [[54, "ml-lifecycle-032-publisher-relation"]], "Purpose and Behavior": [[10, "purpose-and-behavior"], [10, "id1"]], "Putting it all Together to form the GPT": [[24, "putting-it-all-together-to-form-the-gpt"]], "PyTorch\u2019s CosineAnnealingLR vs. Composer\u2019s CosineAnnealingScheduler": [[78, "pytorch-s-cosineannealinglr-vs-composer-s-cosineannealingscheduler"]], "PyTorch\u2019s Event And Profiler": [[69, null]], "Pydantic": [[82, "pydantic"]], "Pydantic And Hydra": [[82, null]], "Pydantic Schema": [[82, "pydantic-schema"]], "Pydra": [[82, "pydra"]], "Queries, Keys, and Values": [[24, "queries-keys-and-values"]], "Queries, Keys, and Values in Attention Mechanism": [[24, "queries-keys-and-values-in-attention-mechanism"]], "Query, Key and Values": [[22, "query-key-and-values"]], "RNG Module": [[0, "rng-module"]], "Rank And Low-Rank Decomposition Via Matrix Factorization": [[31, "rank-and-low-rank-decomposition-via-matrix-factorization"]], "Ranking, Detection, Pairwise, Retrieval And Other Metrics": [[59, "ranking-detection-pairwise-retrieval-and-other-metrics"]], "Reading Large Files, Generator vs Iterator": [[80, "reading-large-files-generator-vs-iterator"]], "Reading a Big File into a List": [[80, "reading-a-big-file-into-a-list"]], "Real World Examples of Covariance and Contravariance": [[8, "real-world-examples-of-covariance-and-contravariance"]], "Real-Time Prediction And Computational Resources": [[58, "real-time-prediction-and-computational-resources"]], "Real-Time Serving/Inference (Online with only Batch Features)": [[65, "real-time-serving-inference-online-with-only-batch-features"]], "Real-World Use Case": [[19, "real-world-use-case"]], "Real-time Ingestion (Stream Ingestion)": [[57, "real-time-ingestion-stream-ingestion"]], "Reconstruction": [[29, "reconstruction"]], "Recovering a run": [[60, "recovering-a-run"]], "Recursive Method Overview": [[17, "recursive-method-overview"]], "Reducing the Search Space": [[16, "reducing-the-search-space"]], "Reduction": [[25, "reduction"]], "References": [[3, null], [22, null], [22, "references"], [23, null], [23, null], [23, null], [23, null], [23, null], [23, null], [23, null], [23, null], [23, null], [24, null], [24, null], [24, null], [24, null], [24, null], [25, null], [30, "references"], [45, "references"], [78, null]], "References And Further Readings": [[31, "references-and-further-readings"], [68, "references-and-further-readings"], [69, "references-and-further-readings"], [70, "references-and-further-readings"], [77, "references-and-further-readings"], [84, "references-and-further-readings"]], "References and Further Readings": [[3, "references-and-further-readings"], [4, "references-and-further-readings"], [5, "references-and-further-readings"], [6, "references-and-further-readings"], [7, "references-and-further-readings"], [8, "references-and-further-readings"], [9, "references-and-further-readings"], [10, "references-and-further-readings"], [12, "references-and-further-readings"], [13, "references-and-further-readings"], [14, "references-and-further-readings"], [15, "references-and-further-readings"], [16, "references-and-further-readings"], [17, "references-and-further-readings"], [18, "references-and-further-readings"], [19, "references-and-further-readings"], [20, "references-and-further-readings"], [23, "references-and-further-readings"], [24, "references-and-further-readings"], [25, "references-and-further-readings"], [26, "references-and-further-readings"], [27, "references-and-further-readings"], [28, "references-and-further-readings"], [29, "references-and-further-readings"], [34, "references-and-further-readings"], [35, "references-and-further-readings"], [36, "references-and-further-readings"], [37, "references-and-further-readings"], [38, "references-and-further-readings"], [39, "references-and-further-readings"], [40, "references-and-further-readings"], [41, "references-and-further-readings"], [43, "references-and-further-readings"], [44, "references-and-further-readings"], [47, "references-and-further-readings"], [48, "references-and-further-readings"], [51, "references-and-further-readings"], [52, "references-and-further-readings"], [53, "references-and-further-readings"], [54, "references-and-further-readings"], [55, "references-and-further-readings"], [56, "references-and-further-readings"], [57, "references-and-further-readings"], [58, "references-and-further-readings"], [60, "references-and-further-readings"], [61, "references-and-further-readings"], [62, "references-and-further-readings"], [63, "references-and-further-readings"], [65, "references-and-further-readings"], [71, "references-and-further-readings"], [72, "references-and-further-readings"], [73, "references-and-further-readings"], [76, "references-and-further-readings"], [78, "references-and-further-readings"], [79, "references-and-further-readings"], [80, "references-and-further-readings"], [82, "references-and-further-readings"], [83, "references-and-further-readings"], [85, "references-and-further-readings"]], "References, Resources and Roadmap": [[33, null]], "Reflexivity, Transivity and Antisymmetry": [[5, "reflexivity-transivity-and-antisymmetry"]], "Regression": [[59, "regression"]], "Relation of MFU and TFLOPS": [[73, "relation-of-mfu-and-tflops"]], "Relational Model": [[54, "relational-model"]], "Relationship to Business Objectives": [[52, "relationship-to-business-objectives"]], "Repeated Substitution": [[14, "repeated-substitution"]], "Representation Mapping": [[24, "representation-mapping"]], "Representing Derivative of Softmax as a Jacobian Matrix": [[79, "representing-derivative-of-softmax-as-a-jacobian-matrix"]], "Reproducibility": [[24, "reproducibility"], [25, "reproducibility"], [31, "reproducibility"], [60, "reproducibility"], [74, "reproducibility"]], "Residual Connection": [[24, "residual-connection"]], "Retrieve All Methods of a Class": [[76, "retrieve-all-methods-of-a-class"]], "Revisiting Add Example": [[7, "revisiting-add-example"]], "Row Wise Interpretation": [[40, "row-wise-interpretation"]], "Row and Columnar Formats": [[53, "row-and-columnar-formats"]], "Row-major order": [[53, "row-major-order"]], "Runtime Behavior": [[9, "runtime-behavior"]], "SLURM Status": [[45, "slurm-status"]], "Sales Data and Probabilities": [[17, "sales-data-and-probabilities"]], "Sample Run": [[45, "sample-run"]], "Sampling": [[57, "sampling"]], "Sampling from the Softmax Distribution": [[79, "sampling-from-the-softmax-distribution"]], "Sanity Check": [[28, "sanity-check"]], "Sanity Check with Palm Paper\u2019s FLOPs Calculation": [[73, "sanity-check-with-palm-paper-s-flops-calculation"]], "Satisfies Narrowing Values, Widening Functions": [[5, "satisfies-narrowing-values-widening-functions"]], "Scalar projections": [[40, "scalar-projections"]], "Scalar-Product Equation of a Plane": [[35, "scalar-product-equation-of-a-plane"]], "Scalar-Vector Multiplication": [[38, "scalar-vector-multiplication"]], "Scale": [[51, "scale"]], "Scaled Dot-Product Attention": [[24, "scaled-dot-product-attention"]], "Scaling Down the Dot Product of Query and Key Vectors": [[24, "scaling-down-the-dot-product-of-query-and-key-vectors"]], "Scope of Generic Methods and Functions": [[6, "scope-of-generic-methods-and-functions"]], "Search Algorithm Implementation": [[17, "search-algorithm-implementation"]], "Section 2. Approach": [[23, "section-2-approach"]], "See Also": [[54, null], [59, null], [59, null], [62, null]], "Seed Module": [[0, "seed-module"]], "Seeding": [[60, "seeding"]], "Self-Attention": [[24, "self-attention"]], "Self-Attention Enables Parallelism": [[24, "self-attention-enables-parallelism"]], "Semantic Representation": [[22, "semantic-representation"]], "Sentinel Types": [[10, null]], "Sequential Operations": [[24, "sequential-operations"]], "Service Locator And Dependency Injection": [[84, "service-locator-and-dependency-injection"]], "Serving Strategies": [[65, "serving-strategies"]], "Set CUDA Device": [[44, "set-cuda-device"]], "Setting Up": [[32, "setting-up"], [44, "setting-up"], [75, "setting-up"], [77, "setting-up"]], "Setting Up Identity and Access Management (IAM) Role": [[45, "setting-up-identity-and-access-management-iam-role"]], "Setting up a Batch Serving System": [[65, "setting-up-a-batch-serving-system"]], "Setup Python Environment": [[45, "setup-python-environment"]], "Shared File System": [[45, "shared-file-system"]], "Sharpening and Dampening the Softmax Distribution": [[79, "sharpening-and-dampening-the-softmax-distribution"]], "Shuffling and Discrete Uniform Sampling": [[24, "shuffling-and-discrete-uniform-sampling"]], "Sign of the Dot Product is Determined by the Angle in between Two Vectors": [[40, "sign-of-the-dot-product-is-determined-by-the-angle-in-between-two-vectors"]], "Simple Binary Classification Example": [[25, "simple-binary-classification-example"]], "Single Dispatch": [[9, "single-dispatch"]], "Singularity": [[45, "singularity"]], "Size of the Image": [[29, "size-of-the-image"]], "Slurm Commands": [[45, "slurm-commands"]], "Smoothness (Chaoticity)": [[58, "smoothness-chaoticity"]], "Softmax": [[24, "softmax"]], "Softmax Function": [[79, "softmax-function"]], "Softmax Function via Exponential Family": [[79, "softmax-function-via-exponential-family"]], "Softmax Head": [[24, "softmax-head"]], "Softmax Is Not Invariant Under Scaling": [[79, "softmax-is-not-invariant-under-scaling"]], "Softmax Is Smooth, Continuous and Differentiable": [[79, "softmax-is-smooth-continuous-and-differentiable"]], "Softmax Is Translation Invariance": [[79, "softmax-is-translation-invariance"]], "Softmax Layer": [[22, "softmax-layer"]], "Softmax Obeys The Three Axioms of Probability (Kolmogorov Axioms)": [[79, "softmax-obeys-the-three-axioms-of-probability-kolmogorov-axioms"]], "Softmax Preserves Order (Monotonicity)": [[79, "softmax-preserves-order-monotonicity"]], "Softmax Preserves Order, Is Translation Invariant But Not Invariant Under Scaling.": [[79, null]], "Softmax as a Vector Function": [[79, "softmax-as-a-vector-function"]], "Software Engineering": [[33, null]], "Solution Intuition": [[16, "solution-intuition"]], "Solution Space in 2D (Lines)": [[35, "solution-space-in-2d-lines"]], "Solution Space in 3D (Planes)": [[35, "solution-space-in-3d-planes"]], "Solution: Binary Search": [[16, "solution-binary-search"]], "Some Common Metrics to Track in Experiment Tracking": [[60, "ml-lifecycle-experiment-tracking-metrics"]], "Some Derivatives Tips So Far\u2026": [[79, null]], "Some Key Stages In Model Development and Training": [[62, "ml-lifecycle-model-development-training-some-key-stages"]], "Some Practical Considerations for FLOPs in Deep Learning": [[73, "some-practical-considerations-for-flops-in-deep-learning"]], "Some Useful Commands": [[45, "some-useful-commands"]], "Space Complexity": [[14, "space-complexity"], [14, "id9"], [16, "space-complexity"], [17, "space-complexity"], [19, "space-complexity"]], "Space Complexity of K-Means": [[27, "space-complexity-kmeans"]], "Space-Time Tradeoff": [[16, "space-time-tradeoff"]], "Split to Train-Valid-Test": [[25, "split-to-train-valid-test"]], "Stack": [[20, null]], "Stack List Dunder Methods": [[19, "stack-list-dunder-methods"]], "Stack List Operations": [[19, "stack-list-operations"]], "Stack List Time Complexity": [[19, "stack-list-time-complexity"]], "Stack with List as Underlying Data Structure": [[19, "stack-with-list-as-underlying-data-structure"]], "Stage 1. Problem Formulation": [[51, null]], "Stage 10. Continuous Integration, Deployment, Learning and Training (DevOps, DataOps, MLOps)": [[49, null]], "Stage 11. Infrastructure and Tooling for MLOps": [[50, null]], "Stage 2. Project Scoping And Framing The Problem": [[52, null]], "Stage 3. Data Pipeline (Data Engineering and DataOps)": [[56, null]], "Stage 3.1. Data Source and Formats": [[53, null]], "Stage 3.2. Data Model and Storage": [[54, null]], "Stage 3.3. Extract, Transform, Load (ETL)": [[55, null]], "Stage 4. Data Extraction (MLOps), Data Analysis (Data Science), Data Preparation (Data Science)": [[57, null]], "Stage 4.1. Data Extraction (MLOps)": [[57, "stage-4-1-data-extraction-mlops"]], "Stage 4.2. Data Analysis (Data Science)": [[57, "stage-4-2-data-analysis-data-science"]], "Stage 4.3. Data Preparation (MLOps)": [[57, "stage-4-3-data-preparation-mlops"]], "Stage 5. Model Development and Training (MLOps)": [[62, null]], "Stage 5.1. Model Selection": [[58, null]], "Stage 5.2. Metric Selection": [[59, null]], "Stage 5.3. Experiment Tracking And Versioning": [[60, null]], "Stage 5.4. Model Testing": [[61, null]], "Stage 6. Model Evaluation (MLOps)": [[63, null]], "Stage 7. Model Validation, Registry and Pushing Model to Production (MLOps)": [[64, null]], "Stage 8. Model Serving (MLOps)": [[65, null]], "Stage 9. Model Monitoring (MLOps)": [[66, null]], "Staging/Experiment/Development": [[56, "staging-experiment-development"]], "Standard Cases": [[16, "standard-cases"]], "Standard Test Cases": [[14, "standard-test-cases"]], "State": [[25, "state"]], "State And Metadata Management": [[83, null]], "State Management": [[83, "state-management"]], "Static Type Checking": [[4, "static-type-checking"]], "Step 0. Project Scope": [[55, "step-0-project-scope"]], "Step 1.": [[29, "step-1"]], "Step 1. Corpus": [[22, null]], "Step 1. Data Extraction": [[56, "step-1-data-extraction"]], "Step 1. Extract (Data Extraction and Defining the Data Source)": [[55, "step-1-extract-data-extraction-and-defining-the-data-source"]], "Step 1. Triggering the Production Deployment Pipeline": [[56, "step-1-triggering-the-production-deployment-pipeline"]], "Step 10. Deploy the DAG (Staging Environment)": [[56, "step-10-deploy-the-dag-staging-environment"]], "Step 10. Layer Normalization Before Projection": [[22, null]], "Step 10. Position-wise Feed-Forward Network": [[22, null]], "Step 11. Residual Connection": [[22, null]], "Step 11. Trigger the DAG as part of a CI/CD pipeline": [[56, "step-11-trigger-the-dag-as-part-of-a-ci-cd-pipeline"]], "Step 1: Derivative of \\mathcal{L} with respect to \\mathbf{z}": [[79, "step-1-derivative-of-mathcal-l-with-respect-to-mathbf-z"]], "Step 2.": [[29, "step-2"]], "Step 2. CI/CD: Deploy Image to Production Environment": [[56, "step-2-ci-cd-deploy-image-to-production-environment"]], "Step 2. Data Loading to Staging Lake": [[56, "step-2-data-loading-to-staging-lake"]], "Step 2. Load (Data Ingestion and Destination)": [[55, "step-2-load-data-ingestion-and-destination"]], "Step 2. Vocabulary and Tokenization": [[22, null]], "Step 2: Derivative of \\mathbf{z} with respect to \\boldsymbol{\\theta}": [[79, "step-2-derivative-of-mathbf-z-with-respect-to-boldsymbol-theta"]], "Step 3.": [[29, "step-3"]], "Step 3. Loading Data to Staging Warehouse": [[56, "step-3-loading-data-to-staging-warehouse"]], "Step 3. One Hot Encoding": [[22, null]], "Step 3. Transform (Data Processing and Transformation)": [[55, "step-3-transform-data-processing-and-transformation"]], "Step 3: Derivative of \\mathcal{L} with respect to \\boldsymbol{\\theta}": [[79, "step-3-derivative-of-mathcal-l-with-respect-to-boldsymbol-theta"]], "Step 4. Data Validation After Extraction and Load": [[56, "step-4-data-validation-after-extraction-and-load"]], "Step 4. Token Embedding": [[22, null]], "Step 5. Data Transformation": [[56, "step-5-data-transformation"]], "Step 5. Positional Embedding": [[22, null]], "Step 6. Data Validation After Transformation": [[56, "step-6-data-validation-after-transformation"]], "Step 6. Pre-Layer Normalization For Masked Multi-Head Attention": [[22, null]], "Step 7. Load Transformed Data to Staging GCS and BigQuery": [[56, "step-7-load-transformed-data-to-staging-gcs-and-bigquery"]], "Step 7. Masked Multi-Head Self-Attention": [[22, null]], "Step 7.1. Linear Projections, Query, Key, and Value Matrices": [[22, null]], "Step 7.2. Reshaping and Transposing Query, Key, and Value Matrices": [[22, null]], "Step 7.3. Scaled Dot-Product Attention and Masking": [[22, null]], "Step 7.4. Concatenation and Projection": [[22, null]], "Step 8. (Optional) Writing a DAG to Automate the Pipeline": [[56, "step-8-optional-writing-a-dag-to-automate-the-pipeline"]], "Step 8. Residual Connection": [[22, null]], "Step 9. Containerize the DAG": [[56, "step-9-containerize-the-dag"]], "Step 9. Pre-Layer Normalization For Position-wise Feed-Forward Network": [[22, null]], "Step-By-Step Code Implementation": [[29, "step-by-step-code-implementation"]], "Steps to Compress an Image": [[29, "steps-to-compress-an-image"]], "Steps to Identify and Scope the Data Source": [[53, "steps-to-identify-and-scope-the-data-source"]], "Stop EC2 Instances": [[45, "stop-ec2-instances"]], "Strategy Pattern": [[87, null]], "Streaming Inference": [[65, "streaming-inference"]], "String-to-Index Mapping": [[22, "string-to-index-mapping"]], "Structural Subtyping": [[3, "structural-subtyping"]], "Structured Config": [[82, "structured-config"]], "Structured vs Unstructured Data": [[54, "structured-vs-unstructured-data"]], "Subsequent Decoder Blocks (\\ell > 1)": [[22, "subsequent-decoder-blocks-ell-1"]], "Subsumption": [[5, null], [5, "id1"]], "Subtypes": [[3, null]], "Summary": [[17, "summary"], [34, "summary"], [56, "summary"]], "Supervised Fine-Tuning": [[23, "supervised-fine-tuning"]], "Synchronize CUDA To Time CUDA Operations": [[67, null]], "System Health": [[66, "system-health"]], "System Health Dashboard": [[66, "system-health-dashboard"]], "System of Linear Equations (Algebraic Form)": [[35, "system-of-linear-equations-algebraic-form"]], "System of Linear Equations (Geometric Interpretation)": [[35, "system-of-linear-equations-geometric-interpretation"]], "Systems of Linear Equations": [[35, null]], "Table of Contents": [[11, "table-of-contents"], [12, "table-of-contents"], [15, "table-of-contents"], [18, "table-of-contents"], [20, "table-of-contents"], [21, "table-of-contents"], [26, "table-of-contents"], [36, "table-of-contents"], [41, "table-of-contents"], [47, "table-of-contents"], [48, "table-of-contents"], [72, "table-of-contents"], [81, "table-of-contents"], [86, "table-of-contents"]], "Table of Notations": [[22, "table-of-notations"]], "Table of Steps to Identify and Scope the Data Source": [[53, "ml-lifecycle-03-steps-identify-scope-data-source"]], "Target Padding Mask": [[25, "target-padding-mask"]], "Task Specific Fine-Tuning": [[31, "task-specific-fine-tuning"]], "Temperature": [[79, "temperature"]], "Template": [[55, "template"], [55, "id7"], [55, "id11"]], "Test Cases": [[14, "test-cases"], [16, "test-cases"]], "Tests": [[14, "tests"], [14, "id7"], [16, "tests"], [17, "tests"], [17, "id3"]], "Text vs Binary Formats": [[53, "text-vs-binary-formats"]], "The Autoregressive Self-Supervised Learning Paradigm": [[23, "the-autoregressive-self-supervised-learning-paradigm"], [31, "the-autoregressive-self-supervised-learning-paradigm"]], "The Concept of Generative Pre-trained Transformers (GPT)": [[23, null]], "The Connection of Mutability and Variance": [[8, "the-connection-of-mutability-and-variance"]], "The Definitions": [[8, "the-definitions"]], "The Distinction Between Finite and Unbounded Feature Space": [[65, "the-distinction-between-finite-and-unbounded-feature-space"]], "The ETL/ELT Framework": [[55, "the-etl-elt-framework"]], "The Estimator Function is Smooth with Respect to the Parameters": [[23, "the-estimator-function-is-smooth-with-respect-to-the-parameters"]], "The Evolution of Data Engineering (Don\u2019t Quote Me On This!)": [[55, "the-evolution-of-data-engineering-don-t-quote-me-on-this"]], "The Hypothesis Space": [[27, "the-hypothesis-space"]], "The Implementation of Generative Pre-trained Transformers (GPT)": [[24, null]], "The Importance of Generic Types": [[19, "the-importance-of-generic-types"]], "The Importance of a Field in Vector Spaces and Deep Learning": [[34, "the-importance-of-a-field-in-vector-spaces-and-deep-learning"]], "The Jacobian Matrix of Softmax": [[79, "the-jacobian-matrix-of-softmax"]], "The Lifecycle of an AIOps System": [[48, null]], "The Loss/Cost/Objective Function": [[27, "the-loss-cost-objective-function"]], "The Low-Rank Adaptation (LoRA) Algorithm": [[31, "the-low-rank-adaptation-lora-algorithm"]], "The Model, Loss and Data Paradigm": [[62, "the-model-loss-and-data-paradigm"]], "The Motivation": [[6, "the-motivation"], [8, "the-motivation"]], "The Necessary Conditions to Minimize the Objective Function": [[27, "the-necessary-conditions-to-minimize-the-objective-function"]], "The Notion of Similarity and Closeness": [[27, "the-notion-of-similarity-and-closeness"]], "The Precondition for Binary Search": [[16, "the-precondition-for-binary-search"]], "The Recursive Counterpart": [[17, "the-recursive-counterpart"]], "The Training Phase": [[22, "the-training-phase"]], "The Update Weights Of Fine-Tuning Has A Low Intrinsic Rank": [[31, "the-update-weights-of-fine-tuning-has-a-low-intrinsic-rank"]], "The yield Statement": [[80, "the-yield-statement"]], "Theoretical Best Space Complexity": [[16, "theoretical-best-space-complexity"]], "Theoretical Best Time Complexity": [[16, "theoretical-best-time-complexity"]], "Theoretical Best Time/Space Complexity and Space-Time Tradeoff": [[16, "theoretical-best-time-space-complexity-and-space-time-tradeoff"]], "Theoretical FLOPs in Transformer Models": [[73, "theoretical-flops-in-transformer-models"]], "Theoretical Foundations and Practical Implications": [[16, "theoretical-foundations-and-practical-implications"]], "Theoretical Model FLOPs Utilization (MFU) Indicates a Rough Benchmark of Efficiency": [[73, "theoretical-model-flops-utilization-mfu-indicates-a-rough-benchmark-of-efficiency"]], "Tikz Code": [[17, null], [19, null]], "Time Complexity": [[14, "time-complexity"], [14, "id8"], [16, "time-complexity"], [17, "time-complexity"], [19, "time-complexity"]], "Time Complexity Table": [[17, "time-complexity-table"], [17, "id4"]], "Time Complexity Using Big O Notation \\mathcal{O}(g(N))": [[17, "time-complexity-using-big-o-notation-mathcal-o-g-n"]], "Time Complexity of K-Means": [[27, "time-complexity-kmeans"]], "Time Complexity of Linear Search": [[17, "linear-search-time-complexity-linear-search-iterative"]], "Time Complexity of Linear Search (Recursive)": [[17, "linear-search-time-complexity-recursive"]], "Time Efficiency": [[80, "time-efficiency"]], "Time and Space Complexity": [[27, "time-and-space-complexity"]], "Timeit Profiler": [[68, "timeit-profiler"]], "Token Embedding Matrix": [[24, "token-embedding-matrix"]], "Token Embedding and Positional Encoding": [[22, "token-embedding-and-positional-encoding"]], "Token Embedding and Vector Representation Process": [[24, "token-embedding-and-vector-representation-process"]], "Token Embeddings": [[24, "token-embeddings"]], "Token to Index, and Index to Token Mappings": [[22, "token-to-index-and-index-to-token-mappings"]], "Tokenization": [[25, "tokenization"]], "Tokenization and Vocabulary": [[24, "tokenization-and-vocabulary"]], "Tokenizer": [[75, "tokenizer"]], "Torch Cuda Event": [[69, "torch-cuda-event"]], "Torch Profiler": [[69, "torch-profiler"]], "Total Space Complexity": [[14, "total-space-complexity"], [14, "id12"], [16, "total-space-complexity"], [17, "total-space-complexity"]], "Total Trainable Parameters": [[73, "total-trainable-parameters"]], "Trace": [[69, "trace"]], "Tractability": [[58, "tractability"]], "Train LoRA": [[32, "train-lora"]], "Trained Attention Heatmaps": [[25, "trained-attention-heatmaps"]], "Trainer": [[25, "trainer"]], "Training": [[74, "training"], [75, "training"]], "Training Chronicles": [[62, "training-chronicles"]], "Training Paradigm": [[25, "training-paradigm"]], "Training a Mini-GPT to Learn Two-Digit Addition": [[25, null]], "Transactional And Analytical Processing Databases": [[54, "transactional-and-analytical-processing-databases"]], "Transactional Databases Are Row-Major": [[54, "transactional-databases-are-row-major"]], "Transactional Processing": [[54, "transactional-processing"]], "Translating to a First True in a Sorted Boolean Array Problem": [[16, "translating-to-a-first-true-in-a-sorted-boolean-array-problem"]], "Transpose Property": [[40, "transpose-property"]], "Transpose of a Vector": [[37, "transpose-of-a-vector"]], "Troubleshooting": [[45, "troubleshooting"]], "Type Argument": [[6, "type-argument"]], "Type Safety": [[4, null], [4, "id1"]], "Type Theory, A Very Rudimentary Introduction": [[11, null]], "Type Variable and Type Parameter": [[6, "type-variable-and-type-parameter"]], "Types Of Data Analysis": [[57, "ml-lifecycle-04-data-analysis"]], "Types are Sets": [[3, "types-are-sets"]], "Types of Data Inputs for Machine Learning": [[52, "ml-lifecycle-02-types-of-data-inputs"]], "Types of Inputs": [[52, "types-of-inputs"]], "Understanding GPU Memory 1: Visualizing All Allocations over Time": [[71, "understanding-gpu-memory-1-visualizing-all-allocations-over-time"]], "Understanding Model And Data Assumptions": [[58, "understanding-model-and-data-assumptions"]], "Understanding the Connection: Business Goals and Corresponding Machine Learning Tasks": [[52, "understanding-the-connection-business-goals-and-corresponding-machine-learning-tasks"]], "Uniform Distribution of X": [[17, "uniform-distribution-of-x"]], "Unifying Batch Pipeline and Streaming Pipeline": [[65, "unifying-batch-pipeline-and-streaming-pipeline"]], "Union Type versus Constrained Type Variable": [[7, "union-type-versus-constrained-type-variable"]], "Unnormalized Logits": [[79, "unnormalized-logits"]], "Unordered Sequential Search": [[17, "unordered-sequential-search"]], "Unsafe Overloading Variants": [[9, "unsafe-overloading-variants"]], "Updated Book Relation": [[54, "ml-lifecycle-032-updated-book-relation"]], "Updated Matrix Description Table with Batch and Head Dimensions": [[22, "updated-matrix-description-table-with-batch-and-head-dimensions"]], "Upper Bounding Type Variables": [[7, "upper-bounding-type-variables"]], "Use Case 1. Timeouts in HTTP Requests": [[10, "use-case-1-timeouts-in-http-requests"]], "Using HuggingFace": [[75, "using-huggingface"]], "Using PyTorch\u2019s Dataset and Dataloader": [[24, "using-pytorch-s-dataset-and-dataloader"]], "Using __dict__": [[76, "using-dict"]], "Using a Generator Function": [[80, "using-a-generator-function"]], "Using dir": [[76, "using-dir"]], "Using inspect.getmembers": [[76, "using-inspect-getmembers"]], "Using vars": [[76, "using-vars"]], "Utilities": [[24, "utilities"]], "Vector Addition and Subtraction": [[38, "vector-addition-and-subtraction"]], "Vector Addition is Commutative": [[38, "vector-addition-is-commutative"]], "Vector Database (A High-dimensional Playground for Large Language Models)": [[54, "vector-database-a-high-dimensional-playground-for-large-language-models"]], "Vector Norm and Distance": [[39, null]], "Vector Orientation": [[37, "vector-orientation"]], "Vector Quantization": [[29, "vector-quantization"]], "Vector and Its Definition": [[37, null]], "Vector and Its Operations": [[38, null]], "Vector is Invariant under Coordinate Transformation": [[37, "vector-is-invariant-under-coordinate-transformation"]], "Vector-Scalar Multiplication is Commutative": [[38, "vector-scalar-multiplication-is-commutative"]], "Vector-Scalar Multiplication is Invariant under Rotation": [[38, "vector-scalar-multiplication-is-invariant-under-rotation"]], "Vectors": [[41, null]], "Violating Type Safety": [[4, "violating-type-safety"]], "Virtual Environment": [[45, "virtual-environment"]], "Visualising Positional Encodings": [[24, "visualising-positional-encodings"]], "Visualization": [[14, "visualization"], [16, "visualization"], [65, "visualization"]], "Visualization (Batch Features only)": [[65, "visualization-batch-features-only"], [65, "id3"]], "Visualization (Online Features)": [[65, "visualization-online-features"]], "Visualizing Variance of Dot Product": [[24, "visualizing-variance-of-dot-product"]], "Vocabulary": [[22, "vocabulary"], [25, "vocabulary"]], "Warmup": [[25, "warmup"], [78, "warmup"]], "Weight Sharing": [[22, null]], "Weights And Embeddings": [[22, "weights-and-embeddings"]], "What (raw) data do I need to extract (relevant to my project)?": [[55, "what-raw-data-do-i-need-to-extract-relevant-to-my-project"], [55, "id1"]], "What are my budget constraints?": [[55, "what-are-my-budget-constraints"]], "What are my project requirements?": [[55, "what-are-my-project-requirements"], [55, "id12"]], "What are the data processing techniques and tools I should use?": [[55, "what-are-the-data-processing-techniques-and-tools-i-should-use"]], "What are the data security and compliance requirements?": [[55, "what-are-the-data-security-and-compliance-requirements"]], "What are the performance requirements?": [[55, "what-are-the-performance-requirements"], [55, "id14"]], "What are the scalability and flexibility requirements?": [[55, "what-are-the-scalability-and-flexibility-requirements"], [55, "id15"]], "What considerations should I keep in mind when loading the data?": [[55, "what-considerations-should-i-keep-in-mind-when-loading-the-data"]], "What format is the data in? Is it in a format that I can use?": [[55, "what-format-is-the-data-in-is-it-in-a-format-that-i-can-use"], [55, "id3"]], "What is Nominal Subtyping?": [[3, "what-is-nominal-subtyping"]], "What is Structural Subtyping?": [[3, "what-is-structural-subtyping"]], "What tools do I need to extract the data?": [[55, "what-tools-do-i-need-to-extract-the-data"], [55, "id4"]], "What type of data am I dealing with?": [[55, "what-type-of-data-am-i-dealing-with"], [55, "id13"]], "When can K-Means Fail?": [[27, "when-can-k-means-fail"]], "When to Use K-Means?": [[27, "when-to-use-k-means"]], "Where Is The MLOps?": [[62, "where-is-the-mlops"]], "Where can I find this data? This means finding all potential data sources": [[55, "where-can-i-find-this-data-this-means-finding-all-potential-data-sources"], [55, "id2"]], "Where should I store the extracted data?": [[55, "where-should-i-store-the-extracted-data"]], "Whiteboarding": [[16, "whiteboarding"]], "Why DAG?": [[56, "ml-lifecycle-03-why-dag"]], "Why Does Calibration Matter?": [[59, "why-does-calibration-matter"]], "Why Does Cosine Annealing With Warmup Stabilize Training?": [[78, null]], "Why Left + Right // 2 May Cause Overflow?": [[14, "why-left-right-2-may-cause-overflow"]], "Why Nominal Subtyping?": [[3, "why-nominal-subtyping"]], "Why Structural Subtyping?": [[3, "why-structural-subtyping"]], "Why Use a List for Stack Implementation?": [[19, "why-use-a-list-for-stack-implementation"]], "Why mask our target in Adder?": [[25, "why-mask-our-target-in-adder"]], "With Distributed Barrier": [[46, "with-distributed-barrier"]], "Workflow": [[53, "workflow"], [55, "workflow"], [55, "id8"], [55, "id16"]], "Worst Case": [[17, "worst-case"]], "YAML Driven Configuration": [[82, "yaml-driven-configuration"]], "Yield": [[80, "yield"]], "\\mathbf{W}_{e}: Embedding Matrix": [[22, "mathbf-w-e-embedding-matrix"]], "\\mathbf{X}: Output of the Embedding Layer": [[22, "mathbf-x-output-of-the-embedding-layer"]], "\\tilde{\\mathbf{X}}: Output of the Positional Encoding Layer": [[22, "tilde-mathbf-x-output-of-the-positional-encoding-layer"]], "failureCode is HeadNodeBootstrapFailure with failureReason Cluster creation timed out": [[45, "failurecode-is-headnodebootstrapfailure-with-failurereason-cluster-creation-timed-out"]], "\ud83c\udf0c Omniverse: A Journey Through Knowledge": [[33, null]]}, "docnames": ["api/reproducibility", "bibliography", "citations", "computer_science/type_theory/01-subtypes", "computer_science/type_theory/02-type-safety", "computer_science/type_theory/03-subsumption", "computer_science/type_theory/04-generics", "computer_science/type_theory/05-typevar-bound-constraints", "computer_science/type_theory/06-invariance-covariance-contravariance", "computer_science/type_theory/07-pep-3124-overloading", "computer_science/type_theory/08-pep-661-sentinel-values", "computer_science/type_theory/intro", "dsa/complexity_analysis/intro", "dsa/complexity_analysis/master_theorem", "dsa/searching_algorithms/binary_search/concept", "dsa/searching_algorithms/binary_search/intro", "dsa/searching_algorithms/binary_search/problems/875-koko-eating-bananas", "dsa/searching_algorithms/linear_search/concept", "dsa/searching_algorithms/linear_search/intro", "dsa/stack/concept", "dsa/stack/intro", "influential/generative_pretrained_transformer/01_intro", "influential/generative_pretrained_transformer/02_notations", "influential/generative_pretrained_transformer/03_concept", "influential/generative_pretrained_transformer/04_implementation", "influential/generative_pretrained_transformer/05_adder", "influential/kmeans_clustering/01_intro", "influential/kmeans_clustering/02_concept", "influential/kmeans_clustering/03_implementation", "influential/kmeans_clustering/04_image_segmentation", "influential/low_rank_adaptation/01_intro", "influential/low_rank_adaptation/02_concept", "influential/low_rank_adaptation/03_implementation", "intro", "linear_algebra/01_preliminaries/01-fields", "linear_algebra/01_preliminaries/02-systems-of-linear-equations", "linear_algebra/01_preliminaries/intro", "linear_algebra/02_vectors/01-vector-definition", "linear_algebra/02_vectors/02-vector-operation", "linear_algebra/02_vectors/03-vector-norm", "linear_algebra/02_vectors/04-vector-products", "linear_algebra/02_vectors/intro", "notations/machine_learning", "operations/distributed/01_notations", "operations/distributed/02_basics", "operations/distributed/03_how_to_setup_slurm_in_aws", "operations/distributed/04_ablation", "operations/distributed/intro", "operations/machine_learning_lifecycle/00_intro", "operations/machine_learning_lifecycle/010_continuous_integration_deployment_learning_and_training", "operations/machine_learning_lifecycle/011_infrastructure_and_tooling_for_mlops", "operations/machine_learning_lifecycle/01_problem_formulation", "operations/machine_learning_lifecycle/02_project_scoping", "operations/machine_learning_lifecycle/03_dataops_pipeline/031_data_source_and_format", "operations/machine_learning_lifecycle/03_dataops_pipeline/032_data_model_and_storage", "operations/machine_learning_lifecycle/03_dataops_pipeline/033_etl", "operations/machine_learning_lifecycle/03_dataops_pipeline/03_dataops_pipeline", "operations/machine_learning_lifecycle/04_mlops_data_pipeline", "operations/machine_learning_lifecycle/05_model_development_selection_and_training/051_model_selection", "operations/machine_learning_lifecycle/05_model_development_selection_and_training/052_metric_selection", "operations/machine_learning_lifecycle/05_model_development_selection_and_training/053_experiment_tracking", "operations/machine_learning_lifecycle/05_model_development_selection_and_training/054_model_testing", "operations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline", "operations/machine_learning_lifecycle/06_model_evaluation", "operations/machine_learning_lifecycle/07_model_validation_registry_and_pushing_model_to_production", "operations/machine_learning_lifecycle/08_model_deployment_and_serving", "operations/machine_learning_lifecycle/09_model_monitoring", "operations/profiling/01_synchronize", "operations/profiling/02_timeit", "operations/profiling/03_time_profiler", "operations/profiling/04_small_gpt_profile", "operations/profiling/05_memory_leak", "operations/profiling/intro", "playbook/how_to_calculate_flops_in_transformer_based_models", "playbook/how_to_finetune_decoder_with_cross_attention", "playbook/how_to_finetune_decoder_with_last_token_pooling", "playbook/how_to_inspect_function_and_class_signatures", "playbook/how_to_teacher_student_knowledge_distillation", "playbook/why_cosine_annealing_warmup_stabilize_training", "playbook/why_softmax_preserves_order_translation_invariant_not_invariant_scaling", "software_engineering/concurrency_parallelism_asynchronous/generator_yield", "software_engineering/concurrency_parallelism_asynchronous/intro", "software_engineering/config_management/01-pydra", "software_engineering/config_management/02-state", "software_engineering/config_management/concept", "software_engineering/design_patterns/dependency-inversion-principle", "software_engineering/design_patterns/intro", "software_engineering/design_patterns/strategy"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["api/reproducibility.rst", "bibliography.md", "citations.md", "computer_science/type_theory/01-subtypes.md", "computer_science/type_theory/02-type-safety.md", "computer_science/type_theory/03-subsumption.md", "computer_science/type_theory/04-generics.md", "computer_science/type_theory/05-typevar-bound-constraints.md", "computer_science/type_theory/06-invariance-covariance-contravariance.md", "computer_science/type_theory/07-pep-3124-overloading.md", "computer_science/type_theory/08-pep-661-sentinel-values.md", "computer_science/type_theory/intro.md", "dsa/complexity_analysis/intro.md", "dsa/complexity_analysis/master_theorem.md", "dsa/searching_algorithms/binary_search/concept.md", "dsa/searching_algorithms/binary_search/intro.md", "dsa/searching_algorithms/binary_search/problems/875-koko-eating-bananas.md", "dsa/searching_algorithms/linear_search/concept.md", "dsa/searching_algorithms/linear_search/intro.md", "dsa/stack/concept.md", "dsa/stack/intro.md", "influential/generative_pretrained_transformer/01_intro.md", "influential/generative_pretrained_transformer/02_notations.md", "influential/generative_pretrained_transformer/03_concept.md", "influential/generative_pretrained_transformer/04_implementation.ipynb", "influential/generative_pretrained_transformer/05_adder.ipynb", "influential/kmeans_clustering/01_intro.md", "influential/kmeans_clustering/02_concept.md", "influential/kmeans_clustering/03_implementation.ipynb", "influential/kmeans_clustering/04_image_segmentation.ipynb", "influential/low_rank_adaptation/01_intro.md", "influential/low_rank_adaptation/02_concept.md", "influential/low_rank_adaptation/03_implementation.ipynb", "intro.md", "linear_algebra/01_preliminaries/01-fields.md", "linear_algebra/01_preliminaries/02-systems-of-linear-equations.md", "linear_algebra/01_preliminaries/intro.md", "linear_algebra/02_vectors/01-vector-definition.md", "linear_algebra/02_vectors/02-vector-operation.md", "linear_algebra/02_vectors/03-vector-norm.md", "linear_algebra/02_vectors/04-vector-products.md", "linear_algebra/02_vectors/intro.md", "notations/machine_learning.md", "operations/distributed/01_notations.md", "operations/distributed/02_basics.md", "operations/distributed/03_how_to_setup_slurm_in_aws.md", "operations/distributed/04_ablation.md", "operations/distributed/intro.md", "operations/machine_learning_lifecycle/00_intro.md", "operations/machine_learning_lifecycle/010_continuous_integration_deployment_learning_and_training.md", "operations/machine_learning_lifecycle/011_infrastructure_and_tooling_for_mlops.md", "operations/machine_learning_lifecycle/01_problem_formulation.md", "operations/machine_learning_lifecycle/02_project_scoping.md", "operations/machine_learning_lifecycle/03_dataops_pipeline/031_data_source_and_format.md", "operations/machine_learning_lifecycle/03_dataops_pipeline/032_data_model_and_storage.md", "operations/machine_learning_lifecycle/03_dataops_pipeline/033_etl.md", "operations/machine_learning_lifecycle/03_dataops_pipeline/03_dataops_pipeline.md", "operations/machine_learning_lifecycle/04_mlops_data_pipeline.md", "operations/machine_learning_lifecycle/05_model_development_selection_and_training/051_model_selection.md", "operations/machine_learning_lifecycle/05_model_development_selection_and_training/052_metric_selection.md", "operations/machine_learning_lifecycle/05_model_development_selection_and_training/053_experiment_tracking.md", "operations/machine_learning_lifecycle/05_model_development_selection_and_training/054_model_testing.md", "operations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline.md", "operations/machine_learning_lifecycle/06_model_evaluation.md", "operations/machine_learning_lifecycle/07_model_validation_registry_and_pushing_model_to_production.md", "operations/machine_learning_lifecycle/08_model_deployment_and_serving.md", "operations/machine_learning_lifecycle/09_model_monitoring.md", "operations/profiling/01_synchronize.ipynb", "operations/profiling/02_timeit.ipynb", "operations/profiling/03_time_profiler.ipynb", "operations/profiling/04_small_gpt_profile.ipynb", "operations/profiling/05_memory_leak.ipynb", "operations/profiling/intro.md", "playbook/how_to_calculate_flops_in_transformer_based_models.ipynb", "playbook/how_to_finetune_decoder_with_cross_attention.ipynb", "playbook/how_to_finetune_decoder_with_last_token_pooling.ipynb", "playbook/how_to_inspect_function_and_class_signatures.ipynb", "playbook/how_to_teacher_student_knowledge_distillation.ipynb", "playbook/why_cosine_annealing_warmup_stabilize_training.md", "playbook/why_softmax_preserves_order_translation_invariant_not_invariant_scaling.md", "software_engineering/concurrency_parallelism_asynchronous/generator_yield.md", "software_engineering/concurrency_parallelism_asynchronous/intro.md", "software_engineering/config_management/01-pydra.md", "software_engineering/config_management/02-state.md", "software_engineering/config_management/concept.md", "software_engineering/design_patterns/dependency-inversion-principle.md", "software_engineering/design_patterns/intro.md", "software_engineering/design_patterns/strategy.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 19, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 77, 79, 80, 82, 83, 84, 85], "0": [3, 8, 9, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 53, 54, 57, 58, 59, 63, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 87], "00": [24, 25, 28, 45, 68, 69, 70, 82], "000": [24, 25, 29, 31, 42, 53, 71, 80], "0000": [24, 29], "00000001": 82, "000001": 82, "00002296180803007320": 25, "000022962": 25, "0000230073928833": 24, "000045924": 25, "000056": 68, "00005645197712961995": 68, "000068885": 25, "00007591251522123026": 68, "000076": 68, "000091847": 25, "0000e": 24, "0001": 29, "000108": 68, "00010837518017815013": 68, "000114809": 25, "000117": 68, "00011720387667794871": 68, "00011999999999999999": 78, "000137771": 25, "00013780312900865102": 68, "000138": 68, "00014655353377531386": 68, "000147": 68, "00015573308791388857": 68, "000156": 68, "000160733": 25, "00017999999999999998": 78, "000183694": 25, "000201": 68, "00020125986010833822": 68, "000206656": 25, "000229618": 25, "00023999999999999998": 78, "00024817627457812105": 78, "000252580": 25, "00025268062760848447": 68, "000253": 68, "0002690838939219355": 78, "000275542": 25, "000278": 68, "0002783071457913188": 68, "00028567627457812104": 78, "0002963292387221365": 78, "000298504": 25, "0003": [67, 78, 82], "000321465": 25, "0003337215379814711": 68, "000344427": 25, "000367389": 25, "000390351": 25, "0003956739992645453": 67, "000413313": 25, "000436274": 25, "000459236": 25, "000482198": 25, "000505160": 25, "000528122": 25, "000551083": 25, "000574045": 25, "000597007": 25, "0006117052461950424": 68, "000612": 68, "0006176728557486812": 73, "000619969": 25, "000642931": 25, "000665892": 25, "00066589243287212298": 25, "000686556815682806": 68, "000687": 68, "000688854": 25, "000711816": 25, "000734778": 25, "000757740": 25, "000773": 68, "000773164099660496": 68, "000780701": 25, "000803663": 25, "000826625": 25, "000849587": 25, "000872549": 25, "0008809659262803036": 68, "000881": 68, "000895511": 25, "000918472": 25, "000941434": 25, "000964396": 25, "000987358": 25, "000u": [69, 70], "001": [25, 68, 69, 70, 72, 79, 80, 82], "0010": 29, "001010320": 25, "001033281": 25, "001036": 68, "0010361814617577633": 68, "0010535790334329838": 68, "001054": 68, "001056243": 25, "001079205": 25, "001102167": 25, "001113589": 25, "001115805": 25, "001118034": 25, "001120277": 25, "001122533": 25, "001124803": 25, "001125129": 25, "001127087": 25, "001129385": 25, "001131697": 25, "001134023": 25, "001136364": 25, "001138719": 25, "001141089": 25, "001143473": 25, "001145873": 25, "001148090": 25, "001148288": 25, "001150718": 25, "001153164": 25, "001155625": 25, "001158103": 25, "001160596": 25, "001163105": 25, "001165631": 25, "001168173": 25, "001170732": 25, "001171052": 25, "001173308": 25, "001175901": 25, "001178511": 25, "00117851130197757937": 25, "001181139": 25, "001183784": 25, "001186447": 25, "001189129": 25, "001191828": 25, "001194014": 25, "001194546": 25, "001197283": 25, "001200038": 25, "001202813": 25, "001205607": 25, "001208421": 25, "001211254": 25, "001214107": 25, "001216976": 25, "001216981": 25, "001219875": 25, "001222790": 25, "001225726": 25, "001228683": 25, "001231662": 25, "001234662": 25, "001237684": 25, "001239938": 25, "001240729": 25, "001243796": 25, "001246887": 25, "001250000": 25, "001253137": 25, "001256297": 25, "00125948180464969628": 25, "001259482": 25, "001262691": 25, "001262899": 25, "001265924": 25, "001269183": 25, "001272466": 25, "001275776": 25, "001279111": 25, "001282473": 25, "001285861": 25, "001289277": 25, "001292719": 25, "001296190": 25, "001299688": 25, "001303215": 25, "001306771": 25, "001308823": 25, "00130882305771417282": 25, "001310356": 25, "001313971": 25, "001317616": 25, "001321291": 25, "0013218201389535288": 68, "001322": 68, "001324997": 25, "001328735": 25, "001331785": 25, "001332504": 25, "001336306": 25, "001340141": 25, "001344008": 25, "001347910": 25, "001351845": 25, "001354747": 25, "001355815": 25, "00135982073305105332": 25, "001359821": 25, "001363862": 25, "001367939": 25, "001372053": 25, "001376205": 25, "001377708": 25, "001380394": 25, "001384622": 25, "001388889": 25, "001393196": 25, "001397542": 25, "001400670": 25, "001401930": 25, "001406360": 25, "001410832": 25, "001415346": 25, "001419905": 25, "001423632": 25, "001424507": 25, "001429155": 25, "001433848": 25, "001435": 68, "001435256951747305": 68, "001438588": 25, "001443376": 25, "001446594": 25, "001448211": 25, "001453095": 25, "001458030": 25, "001463014": 25, "001468051": 25, "001469556": 25, "001473139": 25, "001474": 68, "0014744814187987805": 68, "001478281": 25, "001483477": 25, "001488728": 25, "00148872833543853430": 25, "001492518": 25, "001494036": 25, "001499400": 25, "001504823": 25, "001510305": 25, "001515479": 25, "001515848": 25, "001521452": 25, "001527118": 25, "001532848": 25, "001538441": 25, "001538644": 25, "001544505": 25, "001550434": 25, "001556432": 25, "001561403": 25, "001562500": 25, "001568640": 25, "001574852": 25, "001581139": 25, "001584365": 25, "001587502": 25, "001593942": 25, "001600461": 25, "001607061": 25, "001607327": 25, "001610": 68, "0016100557130809725": 68, "001613743": 25, "001620509": 25, "001627361": 25, "001630288": 25, "001634301": 25, "001641330": 25, "001648451": 25, "001653250": 25, "001655665": 25, "001662975": 25, "00166297526309434830": 25, "001670383": 25, "001676212": 25, "001677890": 25, "001685500": 25, "001693214": 25, "001699174": 25, "001701035": 25, "001708965": 25, "001717007": 25, "001722136": 25, "001725164": 25, "001733438": 25, "001741833": 25, "001745097": 25, "001750350": 25, "001758994": 25, "001767767": 25, "001768059": 25, "001776673": 25, "001785714": 25, "001791021": 25, "001794895": 25, "0018": 79, "001804220": 25, "001813691": 25, "001813983": 25, "001823312": 25, "001833089": 25, "001836945": 25, "001843024": 25, "001853123": 25, "001859906": 25, "001863390": 25, "001873829": 25, "001882868": 25, "001884446": 25, "001895245": 25, "001905830": 25, "001906232": 25, "001917412": 25, "00191741247211842623": 25, "001928792": 25, "002": [25, 79], "002163735205972857": 68, "002164": 68, "0022265049091528": 68, "002227": 68, "0029": 79, "002m": 70, "003": 25, "0032607856453568743": 68, "003261": 68, "00360": 25, "0037": 79, "004": [25, 74], "0048": 75, "005": 25, "00504": 25, "0053": 24, "0057": 24, "006": 25, "00635da5926ac5242": 45, "007": 25, "007358": 68, "007358246850183679": 68, "0078": 25, "0079": [75, 79], "008": [25, 80], "009": 25, "00it": 25, "01": [4, 24, 25, 31, 32, 37, 68, 69, 70, 75, 79, 82], "010": 25, "0100": 24, "0102": 79, "01034": 25, "0105": 25, "0106": 24, "01073": 25, "011": 25, "01100100": 29, "01154": 25, "0117": [25, 75, 79], "0117797851562": 24, "01190": 25, "012": 25, "0123": 75, "013": 25, "01348": 73, "0139": 24, "014": 25, "01414": 25, "0143": 79, "015": 25, "016": [24, 25], "0167": 24, "017": 25, "0172": 79, "018": 25, "01813": 25, "0185": 79, "0186": 79, "019": 25, "0190": 79, "01903": 25, "0192": 79, "01_demo_start_mast": 44, "01_demo_start_work": 44, "01it": 25, "02": [24, 25, 32, 38, 68, 69, 70, 74, 75], "020": [2, 11, 25], "0200": 24, "0201": 24, "020m": 70, "021": 25, "0212": 24, "0213": 24, "0216": 25, "021837805972314456": 32, "021837813003862862": 32, "021838": 32, "021u": 70, "022": 25, "0220": 75, "02212": 25, "0225": 24, "022951": 32, "023": 25, "0230": 24, "02311": 73, "02348": 25, "0237": 75, "023u": 70, "024": 25, "024319": 32, "0249": 79, "025": 25, "02531": 77, "0256": 79, "026": 25, "0260": 24, "02634": 25, "026965": 32, "027": 25, "02727": 25, "0273": 25, "0275": 24, "027700": 32, "028": 25, "02804": 25, "02820": 25, "0287": 75, "029": 25, "0293": 79, "029624": 75, "02978723": 28, "02982": 25, "02cc9a3a21eecdc77": 45, "02it": 25, "03": [4, 25, 44, 68, 69, 70, 75], "030": 25, "0300": [24, 79], "0302": [24, 79], "030300": 32, "030542": 32, "031": 25, "03102": 25, "031093": 75, "0312": 75, "0317": 79, "032": 25, "0320": 24, "03265": [1, 2, 21, 23, 78], "0329": 24, "032m": 70, "033": 25, "0332": 24, "03320": 25, "033271": 75, "03368": 25, "034": 25, "03400": 1, "0344": 75, "035": 25, "0352": 25, "036": [25, 80], "03639": 25, "0365": 75, "0369": [24, 75], "037": 25, "03762": 1, "038": [25, 80], "038522": 75, "0387310738": 1, "039": [25, 68], "0391": 79, "0398": 24, "03983": [1, 2, 78], "03_12": 25, "03it": 25, "04": [25, 29, 46, 69, 70, 75], "040": 25, "0400": 24, "04005": 25, "04029": 25, "040u": 70, "041": [25, 68], "04108": 25, "0417": 79, "04199": 25, "042": [25, 68], "04238": 25, "042384711361475": 73, "042m": 70, "042u": 70, "043": [25, 68], "0430": 25, "0431": 25, "0432": 24, "04374": 25, "044": [25, 68], "04407": 25, "044715": [22, 24], "045": [25, 68], "04541": 25, "04557": 25, "0457": 79, "04572": 25, "04581": 25, "04588": 25, "046": [25, 68, 80], "04615385": 28, "0462": 24, "04650": 25, "0469": 25, "047": 25, "0473": 1, "0478": 24, "047m": 70, "048": 25, "048m": 70, "049": 25, "0491": 79, "05": [17, 24, 25, 28, 44, 45, 46, 67, 68, 69, 70, 71, 74, 75, 76, 78, 79, 82], "050": 25, "0500": 24, "05012": 25, "05029": 25, "0505": 79, "0506": 24, "05074": 25, "0508": 25, "050m": 70, "051": 25, "05101": [1, 2, 21, 23], "05111": 25, "05137": 1, "0517": 25, "052": 25, "05235": 25, "05295": 25, "053": 25, "0536": 24, "054": 25, "0542": 24, "055": 25, "056": 25, "05611": 25, "05660": 25, "0569": 24, "057": 25, "0570": 79, "0576": 24, "057m": 70, "058": [25, 75], "05893": 25, "059": [24, 25], "05930": 25, "0596": 24, "05it": 25, "05t07": 45, "06": [25, 32, 68, 70, 75, 82], "060": 25, "0600": 24, "06027": 25, "06064": 25, "06065": 25, "061": 25, "0611e": [24, 79], "06183": 25, "061u": 70, "062": 25, "0623": 24, "06291": 25, "062u": 70, "063": 25, "0631": 25, "06352": 25, "0636": 79, "06375": 25, "064": 25, "064411": 32, "064466": 32, "065": 25, "06506": 25, "0654": 79, "065888": 32, "066": 25, "067": 25, "0674": 75, "068": 25, "069": 25, "0690": 25, "06934": 25, "0699": 24, "07": [25, 32, 67, 68, 70, 71, 74, 75], "070": [25, 68], "0703": 25, "0704": 79, "07043": 25, "0709589389998655": 68, "070959": 68, "070m": 70, "071": [25, 68], "07112360400060425": 68, "071131": 68, "07113105599910341": 68, "07117068199986534": 68, "071171": 68, "07128997600011644": 68, "0713498349996371": 68, "071350": 68, "07186": 25, "07193": 25, "072": [25, 68], "07201": 25, "07217": 25, "072292": 68, "07229203399947437": 68, "07290069700047752": 68, "073": [25, 68], "07313682499989227": 68, "073137": 68, "07318": 25, "07319": 25, "0732": 75, "07369880799979": 68, "073699": 68, "07376415900034772": 68, "0737714920005601": 68, "07379378780005937": 68, "073794": 68, "0738": 68, "07382289199995284": 68, "073823": 68, "07382382700052403": 68, "073859": 68, "07385925299968221": 68, "074": 25, "074113": 68, "07411301600022853": 68, "07416": 25, "07425473500006774": 68, "074255": 68, "07425991700074519": 68, "0744": 79, "074693272212485": 73, "075": [25, 68], "075171": 68, "07517127899973275": 68, "0756": 24, "076": 25, "077": [25, 68], "0770235424421242": 68, "077u": 70, "078": [25, 68], "0783": 79, "07837": 25, "07841499799997109": 68, "07844": 25, "078464": 68, "07846403200073837": 68, "0785": 24, "07899": 25, "079": [25, 68], "079124": 68, "07912403600003018": 68, "07924": 25, "07965": 25, "07it": 25, "08": [24, 25, 29, 38, 46, 67, 68, 69, 70, 71, 76, 82], "080": 25, "0801": 24, "080725": 32, "081": 25, "0819": 79, "082": 25, "082m": 70, "083": 25, "083u": 70, "084": 25, "08465": 25, "085": 25, "0850": 24, "0852": 79, "08556": 25, "086": 25, "0861": 79, "087": 25, "08730": 1, "087u": 70, "088": 25, "089": 25, "0896": 24, "08966": 25, "0898": 25, "08d41f68bf12ca54b": 45, "08it": 25, "09": [24, 25, 67, 68, 70, 74, 79, 82], "090": 25, "091": 25, "0915": 25, "0917": 24, "092": 25, "09206": 25, "09214": 25, "093": 25, "09336": 25, "093519": 68, "0935192509996341": 68, "0938": 25, "0939": 79, "094": 25, "0940": 79, "095": 25, "0957": 24, "096": 25, "096400": 32, "09685": [1, 30, 31], "097": 25, "098": 25, "099": 25, "0998": 24, "0a0": 70, "0b3": 56, "0d": 35, "0d3": 25, "0e": 82, "0m": 70, "0mnote": 70, "0pt": 17, "0x29a6b1430": 29, "0x56501f5ee590": 76, "0x56501f8d70a0": 76, "0x565020e85f50": 76, "0x7f2b1d202a00": 25, "0x7f2b1d202c70": 25, "0x7f2bfdf34730": 25, "0x7f5686d00040": 76, "0x7f5686d000d0": 76, "0x7f5686d00160": 76, "0x7f5686d001f0": 76, "0x7f5686d00280": 76, "0x7f5686d00310": 76, "0x7f5686d003a0": 76, "0x7f5686d00430": 76, "0x7f5686d004c0": 76, "0x7f5686d00550": 76, "0x7f5686d005e0": 76, "0x7f5686d00670": 76, "0x7f5686d00700": 76, "0x7f5686d00790": 76, "0x7f5686d00820": 76, "0x7f5686d008b0": 76, "0x7f5686d00940": 76, "0x7f5686d009d0": 76, "0x7f5686d00a60": 76, "0x7f5686d00af0": 76, "0x7f5686d00b80": 76, "0x7f5686d00c10": 76, "0x7f5686d00ca0": 76, "0x7f5686d00d30": 76, "0x7f5686d00dc0": 76, "0x7f5686d00e50": 76, "0x7f5686d00ee0": 76, "0x7f5686d00f70": 76, "0x7f5686d06a60": 76, "0x7f5686d06af0": 76, "0x7f5686d06b80": 76, "0x7f5686d06c10": 76, "0x7f5686d06ca0": 76, "0x7f5686d06d30": 76, "0x7f5686d06dc0": 76, "0x7f5686d06e50": 76, "0x7f5686d06ee0": 76, "0x7f5686d06f70": 76, "0x7f5686d08040": 76, "0x7f5686d080d0": 76, "0x7f5686d08160": 76, "0x7f5686d081f0": 76, "0x7f5686d08280": 76, "0x7f5686d08310": 76, "0x7f5686d083a0": 76, "0x7f5686d084c0": 76, "0x7f5686d08550": 76, "0x7f5686d08700": 76, "0x7f5686d08790": 76, "0x7f5686d088b0": 76, "0x7f5686d089d0": 76, "0x7f5686d08a60": 76, "0x7f5686d09a80": 76, "0x7f5686d0b040": 76, "0x7f5686d0b0d0": 76, "0x7f5686d0b160": 76, "0x7f5686d0b1f0": 76, "0x7f5686d0b280": 76, "0x7f5686d0b310": 76, "0x7f5686d0b3a0": 76, "0x7f5686d0b430": 76, "0x7f5686d0b4c0": 76, "0x7f5686d0b550": 76, "0x7f5686d0b5e0": 76, "0x7f5686d0b670": 76, "0x7f5686d0b700": 76, "0x7f5686d0b790": 76, "0x7f5686d0b820": 76, "0x7f5686d0b8b0": 76, "0x7f5686d0b940": 76, "0x7f5686d0b9d0": 76, "0x7f5686d0ba60": 76, "0x7f5686d0baf0": 76, "0x7f5686d0bb80": 76, "0x7f5686d0bc10": 76, "0x7f5686d0bca0": 76, "0x7f5686d0bd30": 76, "0x7f5686d0bdc0": 76, "0x7f5686d0be50": 76, "0x7f5686d0bee0": 76, "0x7f5686d0bf70": 76, "0x7f5686d1a550": 76, "0x7f5686d1a5b0": 76, "0x7f5686ee0520": 76, "0x7f5686ee0a30": 76, "0x7f568c4d9790": 76, "0x7f568c589040": 76, "0x7f568d411bd0": 76, "0x7f56a3fc8820": 76, "0x7f56a3fcf0d0": 76, "0x7f56a3fcf160": 76, "0x7f56a3fcf1f0": 76, "0x7f56a3fcf280": 76, "0x7f56a42c7040": 76, "0x7f56a42c70d0": 76, "0x7f56a42c71f0": 76, "0x7f56a42c7280": 76, "0x7f56a42c7310": 76, "0x7f56a42c73a0": 76, "0x7f56a42c7430": 76, "0x7f56a42c7550": 76, "0x7f56a42f7820": 76, "0x7f56a46c0700": 76, "0x7f56a46c0790": 76, "0x7f56a46c0820": 76, "0x7f56a46c08b0": 76, "0x7f56a46c0940": 76, "0x7f56a46c09d0": 76, "0x7f56a46c0a60": 76, "0x7f56a46c0af0": 76, "0x7f56a46c0b80": 76, "0x7f56a46f09d0": 76, "0x7f56a46f0a60": 76, "0x7f56a46f0af0": 76, "0x7f56a46f0b80": 76, "0x7f56a46f0c10": 76, "0x7f56a46f0dc0": 76, "0x7f56a46f0e50": 76, "0x7f56a46f0ee0": 76, "0x7f56a46f0f70": 76, "0x7f56a46f2040": 76, "0x7f56a46f20d0": 76, "0x7f56a46f2160": 76, "0x7f56a46f21f0": 76, "0x7f56a46f2430": 76, "0x7f56a46f24c0": 76, "0x7f56a46f2550": 76, "0x7f56a46f29d0": 76, "0x7f56a46f2a60": 76, "0x7f56a46f2af0": 76, "0x7f56a46f2b80": 76, "0x7f56a46f2d30": 76, "0x7f56a46f2dc0": 76, "0x7f56a46f2e50": 76, "0x7f56a46f2ee0": 76, "0x7f56a46f2f70": 76, "0x7f56a46f4040": 76, "0x7f56a46f40d0": 76, "0x7f56a46f4160": 76, "0x7f56a46f41f0": 76, "0x7f56a46f4280": 76, "0x7f56a46f4310": 76, "0x7f56a46f43a0": 76, "0x7f56a46f4430": 76, "0x7f56a46f44c0": 76, "0x7f56a46f4550": 76, "0x7f56a46f45e0": 76, "0x7f56a46f4670": 76, "0x7f56a46f4790": 76, "0x7f56a46f48b0": 76, "0x7f56a46f4940": 76, "0x7f56a46f49d0": 76, "0x7f56a46f4a60": 76, "0x7f56a46f4af0": 76, "0x7f56a46f4ca0": 76, "0x7f56a46f4d30": 76, "0x7f56a46f4e50": 76, "0x7f56a46f4ee0": 76, "0x7f56a46f4f70": 76, "0x7f56a4731dc0": 76, "0x7f56a4731e50": 76, "0x7f56a4731ee0": 76, "0x7f56a4731f70": 76, "0x7f56a4738040": 76, "0x7f56a47380d0": 76, "0x7f56a4738160": 76, "0x7f56a47381f0": 76, "0x7f56a4738280": 76, "0x7f56a47383a0": 76, "0x7f56a4738430": 76, "0x7f56a47384c0": 76, "0x7f56a4738550": 76, "0x7f56a47385e0": 76, "0x7f56a4738670": 76, "0x7f56a4738700": 76, "0x7f56a4738790": 76, "0x7f56a4738820": 76, "0x7f56a47388b0": 76, "0x7f56a47389d0": 76, "0x7f56a4738af0": 76, "0x7f56a4738b80": 76, "0x7f56a4738c10": 76, "0x7f56a4738ca0": 76, "0x7f56a4738d30": 76, "0x7f56a4738dc0": 76, "0x7f56a4738e50": 76, "0x7f56a4738ee0": 76, "0x7f56a4738f70": 76, "0x7f56a66f9550": 76, "0x7f56a69264c0": 76, "0x7f56a6926550": 76, "0x7f56a69265e0": 76, "0x7f576006e0d0": 76, "0x7f576006e1f0": 76, "0x7f576006e280": 76, "0x7f576006e3a0": 76, "0x7f576006e430": 76, "0x7f576006e4c0": 76, "0x7f576006e550": 76, "0x7f576006e5e0": 76, "0x7f576006e670": 76, "0x7f576006e700": 76, "0x7f576006e790": 76, "0x7f576006e820": 76, "0x7f576006e8b0": 76, "0x7f576006e940": 76, "0x7f576006e9d0": 76, "0x7f576006ea60": 76, "0x7f576006eaf0": 76, "0x7f576006eb80": 76, "0x7f576006ec10": 76, "0x7f576006eca0": 76, "0x7f576006ed30": 76, "0x7f576006edc0": 76, "0x7f576006ee50": 76, "0x7f576006eee0": 76, "0x7f576006ef70": 76, "0x7f5760071040": 76, "0x7f57600710d0": 76, "0x7f5760071160": 76, "0x7f57600711f0": 76, "0x7f5760071280": 76, "0x7f5760071310": 76, "0x7f57600713a0": 76, "0x7f5760071430": 76, "0x7f57600714c0": 76, "0x7f5760071550": 76, "0x7f57600715e0": 76, "0x7f5760071670": 76, "0x7f5760071700": 76, "0x7f5760071790": 76, "0x7f5760071820": 76, "0x7f57600718b0": 76, "0x7f5760071940": 76, "0x7f57600719d0": 76, "0x7f5760071a60": 76, "0x7f5760071af0": 76, "0x7f5760071b80": 76, "0x7f5760071c10": 76, "0x7f57600f1700": 76, "0x7f57600f1790": 76, "0x7f57600f1820": 76, "0x7f57600f18b0": 76, "0x7f57600f1940": 76, "0x7f57600f19d0": 76, "0x7f57600f1a60": 76, "0x7f57600f1af0": 76, "0x7f57600f1b80": 76, "0x7f57600f1c10": 76, "0x7f57600f1ca0": 76, "0x7f57600f1dc0": 76, "0x7f57600f1e50": 76, "0x7f57600f1ee0": 76, "0x7f57600f1f70": 76, "0x7f5788148160": 76, "0x7f5788952dc0": 76, "0x7f5788966700": 76, "0x7f578eb98b80": 76, "0x7f578ee32550": 76, "0x7f578ee49ee0": 76, "0x7f5790f16ca0": 76, "0x7f5790f180d0": 76, "0x7f5791765960": 76, "0x7f5791770840": 76, "1": [1, 2, 3, 4, 6, 7, 8, 9, 11, 14, 17, 19, 21, 25, 26, 28, 30, 31, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 46, 48, 52, 54, 59, 62, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 80, 82, 83, 84, 85, 87], "10": [1, 2, 5, 6, 9, 11, 13, 14, 16, 17, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 38, 40, 42, 44, 45, 48, 50, 51, 53, 54, 59, 62, 64, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82], "100": [4, 9, 16, 24, 25, 28, 29, 32, 35, 51, 53, 54, 59, 69, 70, 71, 73, 74, 78, 79, 80], "1000": [13, 25, 28, 32, 53, 59, 73, 75, 78, 79, 82], "10000": [14, 22, 24, 25, 28, 68, 69, 74], "100000": [71, 73, 80], "1000000": 53, "100001": 80, "100005": 80, "1001": 13, "100253": 70, "10029": 77, "100m": 70, "100th": 60, "101": [6, 25, 70], "1010": 29, "101200": 75, "1016": [2, 11], "10165": [2, 79], "101694": 68, "1016942249998465": 68, "102": [25, 70], "1020": 70, "1024": [23, 24, 32, 68, 71, 73, 75], "1024568889997681": 68, "102457": 68, "1025": 24, "102m": 70, "103": [25, 73], "1033": 24, "1033807330004493": 68, "10341": 25, "10368073345018": 73, "1037": 24, "104": 25, "10464": 25, "105": [25, 28, 70], "1054": 24, "1055": [24, 25], "1059": 79, "106": [25, 70], "1061": 24, "107": [25, 70], "108": [25, 70], "10895": 25, "108m": 70, "109": 25, "1095": 70, "10_000": [68, 70], "10it": 25, "10pt": [17, 19], "11": [1, 2, 14, 16, 21, 23, 24, 25, 27, 28, 32, 33, 35, 38, 48, 67, 68, 69, 70, 73, 75, 78, 80], "110": [25, 28, 70], "1100": 24, "1102": 24, "1103": 24, "11047": 25, "1109": 25, "111": [25, 28, 38, 69, 70], "1110": 24, "1111": 29, "1114": 79, "112": [25, 70, 80], "1122": 79, "113": 25, "11305118925439782": 32, "113055": 68, "1130551600008403": 68, "1134": 28, "11340": 25, "113814": 75, "113m": 70, "114": [25, 70], "115": 25, "1150": [24, 73], "11503": 24, "11511": 25, "11518": 25, "1159": 77, "115902369059602": 73, "116": 25, "1160": 24, "11627": 25, "11678": 25, "117": [25, 28], "11706": 25, "11721": 25, "11764": 77, "11777": 25, "117m": [23, 24], "118": 25, "11842": 25, "1184635700001309": 68, "118464": 68, "1185": 24, "11855": 25, "119": [25, 28, 70], "1190": 24, "11it": 25, "12": [1, 2, 7, 14, 19, 22, 23, 24, 25, 26, 27, 28, 32, 35, 37, 38, 39, 40, 42, 68, 69, 70, 71, 73, 75, 78, 79, 80, 82], "120": [25, 54, 59, 70], "12008": 25, "12032": 25, "1205213247": 25, "1207959552": 73, "121": [25, 68, 69, 70], "121601": 68, "1216013510002085": 68, "121720": 68, "1217202600000746": 68, "1218": 24, "12196": 25, "122": [24, 25, 28, 32, 70], "12200": 25, "122484": 24, "1229": 24, "123": [6, 25, 28, 53, 68], "12330": 25, "1234": 24, "12345": 6, "1234567890abcdef0": 45, "123m": 70, "124": [24, 25, 68, 75], "12418": 25, "1243": 24, "12430": 25, "124337664": 73, "12435": 25, "124439808": 73, "124m": 73, "125": [25, 28, 68, 70, 75], "12500": 25, "12571": 25, "12580756501576662": 32, "126": [25, 70], "1261": 24, "126720": 25, "127": [23, 25], "1275": 75, "1277": [32, 79], "1277818483567122": 32, "1279": 79, "128": [24, 25, 29, 32, 68, 70, 74, 80], "1280": [23, 24, 73], "1285": 75, "1286": 24, "1287": 24, "1289": 24, "129": [25, 28], "1292": 79, "12926": 25, "12938": 25, "12943": 25, "12971": 25, "12it": 25, "12lhq": 73, "12xlarg": 45, "13": [1, 2, 17, 24, 25, 28, 29, 32, 35, 42, 46, 68, 70, 74, 80], "130": 25, "13059": 25, "131": [25, 68], "13190": 25, "132": [25, 32, 70, 73], "13254": 25, "133": [25, 70, 75], "1335": 69, "1337": 25, "133m": 70, "134": [25, 70, 75], "134256": 32, "135": [25, 29, 32, 75], "13523": 25, "13551": 25, "13594": 25, "136": [24, 25, 32, 70], "1363": 24, "1365": 70, "136885": 32, "136m": 70, "137": [25, 70, 75], "137562": 29, "137634": 29, "1377": 69, "138": [25, 28, 32], "13818": 25, "13878": 25, "139": [25, 69], "139018": 32, "13901817798614502": 32, "13901824007066116": 32, "139018252491951": 32, "13901830174555815": 32, "1391": 75, "13917": 25, "13992": 25, "13it": 25, "14": [1, 2, 6, 8, 14, 21, 23, 24, 25, 26, 27, 28, 32, 68, 70, 73, 78, 80], "140": [25, 28, 32], "140150035": 25, "1409": 1, "14096916299559473": 32, "141": [25, 29], "1411": 24, "1412": [1, 2, 21, 23], "14173": 25, "142": 25, "1420": 70, "142m": 70, "143": [25, 69], "14383": 25, "144": [25, 29, 70], "14464": 25, "1447": 24, "145": [25, 70], "1453": 24, "146": 25, "14697": 25, "147": 25, "1470": 24, "1471": 24, "1473": 69, "1474": 69, "147786": 68, "14778646800004935": 68, "14790": 25, "148": [25, 28], "1481": 24, "14855": 24, "14864": 25, "14886": 25, "1489": 24, "149": 25, "1490": 24, "14902": 25, "14906": 25, "1492051968": 73, "14932": 25, "1494": 32, "14943": 25, "14960491599958914": 68, "149605": 68, "14981": 25, "14986462840006426": 68, "149865": 68, "14995777100011765": 68, "149958": 68, "14it": 25, "15": [1, 14, 16, 17, 24, 25, 26, 27, 28, 29, 32, 38, 54, 68, 70, 75, 80, 82], "150": [6, 25, 28, 59, 70], "15001": 25, "15016293000007863": 68, "15019284299978608": 68, "150193": 68, "15019696000035765": 68, "150206": 68, "15020622800057026": 68, "15025364100001753": 68, "150254": 68, "1503": 77, "15043866700034414": 68, "15047101199979807": 68, "1505": 79, "15051599399976112": 68, "150516": 68, "150662": 68, "1506624739995459": 68, "1507": 24, "151": [25, 28, 70], "151141": 68, "15114111419989057": 68, "151385": 68, "15138537599978008": 68, "15140369100026874": 68, "151430": 68, "15143018500020844": 68, "15144059900012508": 68, "151467": 68, "15146724180012824": 68, "151482": 68, "15148220399987622": 68, "15148427300027834": 68, "1515": 32, "151533": 70, "15155341100035002": 68, "15156354600003397": 68, "151564": 68, "15169357899958413": 68, "151694": 68, "151936": 32, "152": 25, "1524": [24, 79], "1525": 75, "15265": 25, "153": 25, "15334": 25, "15369": 25, "154": 25, "15412": 25, "1542470366": 73, "15429": 25, "1542m": [23, 24], "1547": 24, "154u": 70, "155": 25, "1558m": 73, "156": [25, 70], "157": 25, "1570": 79, "15709": 25, "15721": 25, "15797": 25, "158": 25, "158000": 75, "1581": 79, "15832": 25, "159": [25, 68, 70], "15967": 25, "15it": 25, "15mm": 17, "16": [1, 6, 14, 23, 24, 25, 27, 28, 29, 30, 31, 32, 37, 38, 39, 40, 46, 59, 68, 70, 73, 74, 75, 80], "160": [25, 32], "1600": [23, 24, 73], "1601": [75, 77], "16025": 25, "1604": 79, "160583": 32, "1608": [1, 2, 78], "161": [25, 28, 68, 70], "1610612736": 73, "16112": 25, "1614": 24, "162": [25, 68, 70], "1623": 24, "16246": 77, "16299": 25, "163": [25, 68], "16319": 25, "16337": 25, "16345": 25, "1639": 24, "163u": 70, "164": [6, 25], "164500": 32, "16458": 25, "16492": 25, "165": 25, "1650744": 29, "16515": 25, "16573": 25, "1659": 24, "16593": 25, "166": [25, 28, 70], "16641": 25, "16663": 25, "167": [25, 28], "16703": 25, "1674": 24, "16749": 25, "16789": 25, "16791": 25, "167u": 70, "168": 25, "16825": 25, "169": 25, "16967": 25, "16e9": 73, "16gb": 77, "16it": 25, "17": [1, 6, 17, 22, 24, 25, 27, 28, 29, 30, 31, 32, 34, 54, 68, 69, 70, 74, 80], "170": [25, 69], "1702": 24, "1703": 1, "1706": 1, "170m": 70, "171": [25, 69], "17104": 25, "1711": [1, 2, 21, 23], "17113": 25, "1715": 24, "172": 25, "17233": 25, "173": [25, 69], "1730": 24, "17312": 25, "173m": 70, "174": [25, 70], "1740": 24, "1743": 24, "1744": 24, "17467": 25, "17470": 25, "17483": 25, "175": [25, 31, 70], "175000000000": 31, "17553": 25, "17554": 25, "17592": 25, "175_000_000_000": 31, "175b": 31, "176": 25, "17649": 25, "17669": 25, "17684": 25, "1769472": 73, "177": 25, "17716740096": 73, "17726": 25, "17748": 25, "1775": 44, "17750": 25, "17756": 25, "1776": 24, "17774": 25, "178": [25, 28], "17812": 25, "1785": 75, "1786": 24, "17890": 25, "179": [25, 75], "1790": 24, "17940": 25, "1797": 28, "179m": [69, 70], "17_21": 74, "17a": [26, 27], "17it": 25, "18": [1, 2, 6, 11, 24, 25, 28, 32, 34, 38, 39, 40, 44, 54, 68, 70, 79, 80], "180": [25, 38, 40, 59, 70, 79], "1800": 76, "18049": 25, "1806": 1, "18084": 25, "18091": 25, "180m": 70, "181": [25, 70], "18105": 25, "18127": 25, "1813": 24, "181376": 32, "18142": 25, "1815": 24, "182": 25, "18216": 25, "1822": 24, "1826": 24, "18280": 25, "18283": 25, "183": 25, "18325": 25, "184": [25, 70, 79], "1841": 24, "1844": 24, "18446": 25, "1845": 24, "1846": 24, "18472": 25, "185": 25, "18510": 25, "185m": 70, "186": 25, "18672": 25, "18694": 25, "186m": 70, "187": 25, "18728": 25, "18750": 25, "18799": 25, "188": 25, "18800": 25, "18810": 25, "18864": 25, "18872": 25, "189": [25, 28], "1891": 24, "18926": 25, "18988": 25, "189m": 69, "18it": 25, "19": [1, 17, 24, 25, 27, 28, 32, 35, 68, 69, 70, 73, 76, 78, 80], "190": 25, "1908": [1, 2, 21, 23, 78], "19086": 25, "191": [25, 29], "19145": 25, "19173": 25, "19176": 25, "19188": 25, "19189": 25, "192": [25, 32, 69], "19235": 25, "19277": 25, "19299": 25, "193": 25, "19314": 25, "19326": 25, "19327": 25, "19344": 25, "19359": 25, "19368": 25, "193m": 70, "194": 25, "19402": 25, "19415": 25, "19451": 25, "195": 25, "1950": 79, "19511": 25, "1953": 24, "19542": 25, "196": [24, 25], "19606": 25, "19611": 25, "19634": 25, "19635": 25, "196406": 24, "19650": 25, "19657": 25, "19677": 25, "19680": 25, "1969": 79, "197": [25, 70], "1970": [24, 54], "19712": 25, "19767": 25, "198": [24, 25], "1980": 13, "19802": 25, "19833": 25, "19841": 25, "1987": 24, "19892": 25, "198m": 70, "199": 25, "1992": [24, 25, 28, 31, 60, 82], "1997": [37, 38], "19981": 25, "199m": 70, "19it": 25, "19th": 11, "1_000_000": [70, 73], "1_loss": 63, "1cm": [17, 19], "1d": [24, 28, 29, 35], "1e": [24, 25, 28, 68, 70, 71, 74, 75, 76, 79], "1e6": 75, "1j": 22, "1k": 27, "1n": [22, 35, 73], "1p": [22, 73], "1st": [24, 74], "1x7": 25, "1x7x18": 25, "2": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 17, 19, 21, 25, 26, 28, 30, 31, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 46, 48, 51, 53, 58, 67, 68, 69, 70, 71, 72, 75, 76, 77, 80, 82, 85, 87], "20": [1, 6, 16, 17, 23, 24, 25, 28, 29, 32, 35, 38, 40, 44, 45, 54, 59, 68, 69, 70, 73, 74, 75, 79, 80], "200": [25, 28, 51, 52, 59, 73, 78], "2000": [25, 42, 74, 79], "20000": [14, 67], "20003": 25, "2001": [26, 27], "20030": 25, "2006": [2, 79], "2007": [1, 2, 11, 79], "20071": 25, "20095": 25, "200u": 70, "201": [25, 70], "2010": 24, "2012": [2, 11], "2013": [2, 11], "2014": [1, 2, 21, 23, 24, 25, 39], "2015": 77, "2016": [1, 2, 25, 26, 27, 29, 78, 79], "20162": 25, "20167": 25, "2017": [1, 2, 21, 22, 23, 24, 25, 26, 27, 30, 31, 48, 51, 53, 54, 56], "2018": [1, 23, 42], "2019": [1, 2, 21, 22, 23, 24, 25, 31, 78], "202": [25, 28], "2020": [1, 23, 24, 34, 35, 39], "2021": [1, 2, 21, 23, 30, 31, 77, 78, 79], "20216": 25, "2022": [1, 17, 26, 27, 29, 42, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 65, 73, 82], "20221": 25, "2023": [1, 2, 14, 21, 23, 24, 25, 26, 27, 28, 29, 42, 70, 78, 79], "20230310": [68, 70], "2024": [24, 25, 28, 32, 44, 45, 46, 67, 68, 69, 70, 71, 74, 75, 77, 82], "20240509_155331": 82, "20255": 25, "2029": 24, "203": 25, "20334": 25, "20363": 25, "20368": 25, "204": 25, "20437": 25, "2049": 24, "204m": 70, "205": [25, 28, 29, 70], "20529": 25, "2055": 79, "20556": 25, "20597": 25, "206": 25, "206343": 29, "20641": 25, "20647": 46, "206487": 29, "20682": 25, "20696": 25, "207": [25, 70], "20785": 25, "208": 25, "2080": 24, "20811": 25, "2083": 77, "209": 25, "2092": 24, "20924": 25, "20950": 25, "20952": 25, "20it": 25, "21": [1, 14, 24, 25, 26, 27, 28, 29, 32, 35, 68, 70, 73, 75, 80], "210": [25, 28], "2100": 24, "21026": 25, "2103": 24, "2106": [1, 2, 30, 31, 79], "211": 25, "21100": 25, "21120": 24, "212": [25, 28], "21214": 25, "2122": 24, "212272604": 31, "21260": 25, "212600881152": 73, "212625": 75, "212800": 75, "213": [21, 23, 25, 70], "21306": 25, "21339": 25, "21360": 25, "21371": 25, "21373": 25, "21375": 25, "2139551385": 76, "214": [25, 70], "2140": 24, "21412": 25, "21428": 25, "215": [25, 28, 68], "21544": 25, "21582": 25, "215m": 70, "216": 25, "21637": 25, "21644": 25, "21660": 25, "21666": 25, "2168": 25, "21694": 25, "216m": 70, "217": [25, 68], "21747": 25, "2175": 24, "21750": 25, "21789": 25, "217m": 70, "218": [25, 44, 68], "21822": 25, "21832664599969576": 68, "218327": 68, "21856": 25, "2188": 25, "21898": 25, "219": [25, 68, 70], "219012": 75, "21922": 25, "21946": 25, "2198": 79, "21it": 25, "22": [1, 2, 14, 21, 23, 24, 25, 28, 32, 35, 68, 70, 73, 80], "220": 25, "22008085299967206": 68, "22015970299980836": 68, "220160": 68, "22016962399993645": 68, "2202": 24, "22020937799970852": 68, "220236": 68, "22023602300032508": 68, "2203388449999693": 68, "220339": 68, "2204": 73, "2204785499998252": 68, "220479": 68, "22048294700016413": 68, "220491": 68, "22049137779995362": 68, "22050": 25, "22057815300013317": 68, "22060177200000908": 68, "2206222049999269": 68, "22067": 25, "22067614660008986": 68, "22077888900003018": 68, "22078104100000928": 68, "220830": 68, "22083036900039588": 68, "22087210900008358": 68, "22097": 25, "221": 25, "22100": 25, "22108890900017286": 68, "221089": 75, "22120609100056754": 68, "22177": 25, "221m": 70, "222": [25, 70], "22226": 25, "22227": 25, "22234672700051306": 68, "222347": 68, "22247255000002042": 68, "222473": 68, "22247573399999965": 68, "222476": 68, "22253749899937247": 68, "22256": 25, "22256395700060239": 68, "222564": 68, "22257933899982163": 68, "222611": 68, "22261103200016805": 68, "22269292600049084": 68, "222693": 68, "2227": 1, "22273382500043226": 68, "222744": 68, "2227441450004335": 68, "22283626599983108": 68, "223": [2, 11, 25, 28], "22307": 24, "22339": 25, "22344": 25, "22360": 25, "22369271400002616": 68, "223693": 68, "224": [25, 71, 82], "22404": 25, "224073": 68, "22407326100073988": 68, "22411": 25, "22419899699980306": 68, "224199": 68, "22421371400014323": 68, "22424623200004135": 68, "224320": 68, "2243202702000417": 68, "224344": 68, "22434405200001492": 68, "2243646639999497": 68, "224365": 68, "224382": 68, "22438234299988835": 68, "224439366000297": 68, "22444049899968377": 68, "22447669499979384": 68, "224477": 68, "22448583999994298": 68, "224486": 68, "2245766099995308": 68, "224577": 68, "225": [25, 82], "2252": 24, "2255": 24, "2255011379993448": 68, "22584": 25, "22588": 25, "226": 25, "2264": 75, "22681": 25, "227": [25, 29], "22734": 25, "2274": 79, "227551": 75, "2279": 75, "228": 25, "228008": 68, "22800831199947424": 68, "22808": 25, "229": [25, 82], "2291029060015717": 68, "229103": 68, "22934": 25, "23": [1, 13, 14, 16, 24, 25, 28, 32, 35, 44, 68, 69, 70, 80], "230": 25, "2301": 24, "2305": 25, "23076": 25, "231": [25, 32, 70], "23103": 25, "23106": 25, "2314": 75, "2315": 24, "231u": 70, "232": [25, 69], "23207": 25, "23274": 25, "233": 25, "23306": 25, "234": 25, "2341": 79, "23415": 25, "2345": 25, "234u": 70, "235": [25, 28], "2359296": 73, "236": 25, "2360064": 73, "23606797749979": 37, "2366": 24, "237": [25, 70], "23729": 25, "23749": 25, "238": [25, 29], "2383": 24, "23831": 25, "239": [25, 70], "2399": 75, "23it": 25, "24": [2, 23, 24, 25, 28, 29, 32, 68, 70, 73, 79, 80], "240": [25, 29], "2403": 24, "2407": [24, 77], "241": [14, 21, 23, 25], "24115": 25, "2415": [25, 79], "24164": 25, "2419": 24, "242": [25, 69], "2425508965889174": 73, "24296": 25, "243": [25, 69], "24302": 25, "2435": 24, "244": [25, 70], "244672": 68, "24467239400019025": 68, "24475": 25, "2447970040002474": 68, "244915": 68, "24491532199990615": 68, "24495568000020285": 68, "244956": 68, "244981": 68, "2449814139999944": 68, "245": 25, "24501344400050584": 68, "24505015699924115": 68, "24507564099985757": 68, "245076": 68, "245088": 68, "2450883880001129": 68, "2451": 1, "24528420900060155": 68, "24582058120031433": 68, "245821": 68, "24588": 25, "246": [25, 28], "24691": 25, "247": [25, 70], "24723": 25, "24732": 25, "24759": 25, "24788": 25, "248": [25, 32], "2486": 79, "24876": 25, "248761": 68, "24876118500014854": 68, "24884": 25, "24893": 25, "249": 25, "24it": 25, "24n": 29, "25": [17, 23, 24, 25, 28, 29, 32, 35, 54, 59, 69, 70, 71, 73, 75, 80], "250": [25, 28, 73], "25016": 25, "250u": 70, "251": [25, 70, 75], "2518": 24, "25193": 25, "252": 25, "2522": 24, "25269": 25, "253": 25, "2530": 24, "25315": 25, "2535": 24, "2539": 24, "25394": 25, "254": [25, 70], "25471": 25, "25473": 25, "255": [25, 28, 29, 80], "255440": 29, "255488": 29, "25557": 25, "2558": 79, "256": [24, 25, 71, 74, 82], "25602": 25, "2561": 69, "25618": 25, "2562": 69, "2563": 69, "25658": 25, "257": [23, 24], "2576": 24, "2577": 24, "25818": 25, "2586": 24, "2594": 75, "259m": 70, "259u": 70, "25it": 25, "26": [1, 2, 21, 23, 24, 25, 28, 32, 35, 68, 69, 70, 71, 78, 80], "260": 25, "26029": 25, "2604872299998533": 68, "26100": 31, "26121": 25, "26123": 25, "26145": 31, "26158": 25, "2616": 24, "2618": 24, "26188": 25, "26188341": 28, "261m": 70, "262": [25, 75, 77], "264": 28, "26452": 25, "265": 70, "26580": 25, "265m": 69, "266": 25, "267": 25, "2672": 25, "2673": 24, "26785": 25, "267u": 70, "26828": 25, "268u": 70, "269": [25, 70], "26camp": 1, "26creativ": 1, "26creativeasin": 1, "26it": 25, "26linkcod": 1, "26tag": 1, "27": [6, 16, 24, 25, 28, 32, 35, 69, 70, 73, 75, 80], "270": 25, "2702": 24, "270226": 25, "2707": 24, "27081": 25, "2717": 24, "272": 25, "27247": 25, "27272": 25, "272m": 70, "273": [28, 70], "27317": 25, "27339": 25, "2735": 24, "27352": 25, "27398": 25, "274": 25, "2740": 24, "274u": 70, "275": [28, 77], "275124": 29, "2753": 24, "275508": 29, "27568": 25, "275u": 70, "276": [25, 70], "27622": 25, "2764": 24, "27652": 25, "277": 25, "27705": 25, "278": [28, 69], "27832": 25, "2784": 77, "27874": 25, "279": 45, "2794": 24, "27940": 25, "27it": 25, "28": [6, 24, 25, 28, 37, 46, 75, 80], "280": [28, 31], "28029": 25, "280302738926063": 32, "280u": 70, "2816": [24, 25, 32], "2816445108714582": 32, "282": 25, "2822": 24, "28266": 25, "28294": 25, "2837": 24, "2839": 24, "284": 70, "2840": 24, "28423": 25, "28427": 25, "2843": 24, "28463": 25, "285": [25, 70], "2852": 25, "28551": 25, "28583": 25, "2864": 24, "28650": 25, "287": 69, "288": 70, "2887": 24, "28872": 25, "289": 25, "2890644827": 25, "28985": 25, "2899": 75, "289u": 70, "29": [24, 25, 28, 35, 38, 46, 68, 69, 70, 80], "290": [24, 25, 70], "29009": 25, "2907": 24, "291": 24, "29109": 25, "29119": 25, "2912": 24, "291648307200": 73, "29178": 25, "292": [25, 28], "29251": 25, "292u": 70, "293": 25, "2935": 24, "294": [25, 75], "2940": 75, "2943": 24, "29448": 24, "29479": 25, "29500": [25, 44, 45, 46, 74], "29504": 25, "29527": 25, "2961808030073203e": 25, "2969": 25, "29692": 25, "297": 70, "29716": 25, "29746": 25, "29809": 25, "2985": 24, "299": [25, 28], "2993": 24, "29it": 25, "2a": 13, "2b": 13, "2c": 13, "2cm": 19, "2d": [24, 28, 29, 38, 39], "2e": [75, 77], "2f": [29, 73], "2j": 22, "2k": 27, "2n": [13, 17, 25, 35, 73], "2nd": [24, 71], "2p": 73, "2t": 73, "2x": [8, 35, 53], "2x_1": 8, "2x_2": 8, "2y": 35, "3": [1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 16, 17, 19, 21, 25, 26, 28, 31, 32, 33, 34, 37, 38, 39, 42, 43, 44, 46, 48, 59, 68, 69, 70, 71, 73, 74, 75, 76, 77, 80, 82, 84, 85, 87], "30": [2, 4, 10, 16, 17, 19, 21, 23, 24, 25, 28, 29, 35, 38, 53, 54, 59, 68, 69, 70, 73, 75, 79, 80], "300": [29, 70, 73], "3000": 79, "30000": [14, 71], "3000285877644368": 32, "30005": 25, "30046": 25, "3006": 79, "300b": 73, "300e9": 73, "300m": 70, "301": [24, 25], "3017": 75, "3019": 24, "301966": 24, "3024361499992665": 68, "30280": 25, "30291978655031": 28, "303": [29, 75], "304": [25, 28], "30400": 25, "305": 25, "30570": 25, "305m": 70, "30607": 25, "30609": 25, "3064": 24, "307": 25, "3072": [23, 24, 73], "3077": 24, "308": [25, 28], "308m": 70, "308u": 70, "309": 25, "3097": 25, "309715571000197": 68, "309716": 68, "309u": 70, "30d963e": [68, 70], "30it": 25, "31": [14, 24, 25, 28, 35, 39, 54, 73, 80, 82], "310": 70, "31064": 25, "311": 75, "31121": 25, "312": [69, 70, 71, 73], "31202": 25, "31219": 25, "3124": 9, "3126": 24, "31261": 25, "312e12": 73, "313": [25, 28], "3132": 24, "3134690575704466": 73, "31353": 25, "313600": 32, "31369": 25, "31384": 25, "314": [25, 28], "31429": 25, "31459": 25, "3146": 24, "315": [25, 27], "31519": 25, "3154": 24, "316": 25, "3167": 24, "3169": 25, "316u": 70, "317": 25, "31783": 25, "318": [69, 70, 71], "31853": 25, "31859": 25, "31884": [25, 75, 77], "3190": 24, "31908": 25, "31966": 25, "31it": 25, "31m": 70, "31merror": 70, "32": [14, 17, 21, 23, 24, 25, 28, 29, 32, 35, 39, 45, 46, 53, 69, 70, 73, 74, 75, 77, 80, 82], "320": 53, "3203": 24, "32090": 25, "321066": 68, "3210660050017395": 68, "322": [69, 70, 71], "3223057644110276": 32, "32292": 25, "32313": 25, "3237": 24, "3237948": 29, "323m": 69, "324": 25, "3244176": 28, "32450061149613": 73, "325": [25, 70], "326": [24, 25], "3262": [24, 79], "327": 25, "32703": 25, "328": [25, 70], "3285": 24, "32874": 25, "32879": 25, "32e9": 73, "33": [6, 24, 25, 28, 35, 70, 80], "330": 31, "3306": 79, "3309": 25, "331": [25, 70], "33166": 25, "33167": 25, "3322": 79, "3325": 24, "332666429276160": 75, "3327": 77, "3328": 24, "33333": 25, "33375": 25, "333u": 70, "334": [25, 28], "3340": 69, "33472": 25, "3350": 24, "33504": 25, "3354": 79, "335m": 69, "336": 70, "33623": 25, "33759": 25, "338": 25, "33837": 25, "339": 71, "3390": 1, "33947": 25, "339u": 70, "33it": 25, "34": [24, 25, 28, 35, 46, 54, 69, 70, 71, 75, 80], "34011": 25, "340m": 69, "3422": 24, "3424": 24, "3429": 24, "3433": 24, "34349": 25, "34355": 25, "3440": 28, "34409": 25, "34425": 25, "345m": [23, 24, 69], "346": 25, "34602": 25, "34643": 25, "34842": 25, "34847": 25, "3488": 32, "34882": 25, "348m": 69, "34902": 25, "34997": 25, "35": [24, 25, 28, 68, 70, 80], "350": 25, "3504": 28, "350m": 73, "351": [28, 75], "35146": 25, "35289": 25, "353": [28, 70], "35333": 25, "35407": 25, "35433": 25, "35457": 25, "355": 70, "35534": 25, "35534775": 28, "35546": 25, "355853": 68, "3558534099993267": 68, "3559": 25, "35592011": 28, "356": 24, "35605": 25, "357": 25, "3571": 24, "35754": 25, "35758": 25, "358": 68, "3581": 77, "358m": 70, "359": [25, 68], "35914": 25, "3596197342614926": 32, "35it": 25, "36": [23, 24, 25, 28, 46, 68, 70, 73, 80], "360": [68, 70], "3600": 73, "36034": 25, "361": [68, 70], "36132": 25, "36171": 25, "362": [24, 28, 68], "3623878656": 73, "36270": 25, "363": 68, "363u": 70, "364": 68, "36462": 25, "365": [68, 70], "36506": 25, "36552": 25, "36594": 25, "366": 68, "36618": 25, "36660": 25, "367": 68, "3672": 79, "36730": 25, "368": 24, "3684": 24, "36868": 25, "3689689390002968": 68, "368969": 68, "369": 25, "36981": 25, "369m": 70, "36it": 25, "37": [24, 25, 28, 38, 44, 70, 73, 75, 80], "370565": 68, "37056508000114263": 68, "370740459995136": 32, "370u": 70, "37132": 25, "37148195211411106": 73, "37177": 25, "372": [25, 28], "37216339": 28, "37286": 24, "37288": 25, "373": 24, "3730": 24, "3732": 75, "3737": 24, "374": 28, "37414": 25, "37434": 25, "37436": 25, "3744": 79, "375": [28, 68], "37519": 25, "376": [24, 28], "3761": 69, "3765": 24, "376m": 70, "377": 68, "37764": 25, "377m": 70, "378": 68, "3785": 24, "379": [25, 68], "3791314968461": 73, "37943855": 29, "379456": 75, "3797": 24, "37988": 25, "37it": 25, "38": [14, 24, 25, 28, 39, 69, 70, 80], "380": 25, "38012": 25, "381": [25, 75], "38107": 25, "38136": 25, "38145": 25, "382": 25, "38225": 25, "38226": 25, "38357": 25, "38366": 25, "38393": 25, "384": [25, 29], "385": 25, "3853": 24, "3854": 24, "38549307": 28, "38597376": 73, "38599": 25, "386": 25, "38622": 25, "38643": 25, "387": [25, 67], "3870": 24, "38728": 25, "38753": 25, "388": 70, "38808": 25, "389": [24, 67], "389420": 28, "389m": 70, "38it": 25, "39": [24, 25, 28, 68, 70, 80], "390332": 28, "39087": 25, "390m": 70, "391m": 70, "392m": 70, "393": 25, "39328": 25, "39383808": 73, "39394": 25, "394": 25, "39417": 25, "394u": 70, "395": 25, "395620": 68, "39562018000015087": 68, "3957": 25, "39607": 25, "3965": 69, "397": 70, "3974": 69, "39757": 25, "39770": 25, "3979669969222125": 75, "39799": 25, "39838": 25, "39869": 25, "3987": 24, "39940": 25, "39983": 25, "39it": 25, "3d": [29, 38, 39], "3d0387310738": 1, "3d13ct5cvb80yfwjepws02": 1, "3d165953": 1, "3d2025": 1, "3dw": 1, "3dxm2": 1, "3e": [25, 78, 79, 82], "3f": 79, "3fsubscriptionid": 1, "3n": 16, "3rd": [2, 21, 23, 24, 79], "3x2": 53, "4": [1, 2, 3, 6, 7, 13, 14, 16, 17, 19, 21, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 38, 39, 40, 42, 43, 44, 45, 46, 48, 52, 53, 54, 59, 62, 68, 69, 70, 71, 73, 74, 75, 76, 78, 79, 80, 82, 85, 87], "40": [9, 17, 24, 25, 28, 29, 59, 69, 70, 73, 80], "4000": 79, "40000": 14, "40053": 25, "40157": 25, "4016": 24, "40178591009753": 32, "40225": 25, "40265": 25, "403": 28, "4034": 24, "40348": 25, "40420": 25, "40443": 25, "4051": 24, "40536": 25, "406": [24, 82], "4061": 79, "4071274942": 28, "408": 32, "4089": [24, 79], "4096": [23, 24, 31, 60], "4099": 24, "409m": 70, "40e9": 73, "40gb": [23, 73], "40it": 25, "41": [24, 25, 32, 35, 69, 70, 80], "410": [28, 68], "41076": 25, "41085": 25, "411": [25, 68], "4113": 75, "411400": 32, "41144": 25, "411u": 70, "412": 28, "41208": 25, "412m": 69, "412u": 70, "413": 68, "41332": 25, "41341": 25, "41369606": 28, "41381": 25, "4141": 24, "41418363219630583": 73, "4144910469995011": 68, "4156278679993193": 68, "415628": 68, "4161": 24, "4164": 24, "41648": 25, "41672": 25, "41683": 25, "41768": 25, "418": [28, 31], "4184": 24, "418m": 70, "419": [25, 28, 70], "4190616449996014": 68, "419062": 68, "419068941002479": 68, "419069": 68, "4195425559992145": 68, "419543": 68, "41986": 25, "419u": 70, "41it": 25, "42": [2, 9, 11, 17, 24, 25, 28, 29, 32, 68, 69, 70, 71, 74, 75, 76, 77, 80], "420": 70, "4210": 24, "42113": 25, "4217562": 29, "422": 25, "4224": 25, "42258": 25, "42261": 25, "42285238": 28, "4229": 24, "423": 25, "4231182596449616": 73, "42318": 25, "42328": 25, "423m": 69, "424": 28, "4243": 75, "42434": 25, "42485": 25, "425": 70, "42522": 25, "42526": 25, "4257": 75, "425m": 70, "42604197": 29, "42669": 25, "42671": 25, "42683": 25, "427": 70, "42703": 25, "4276138693308093": 74, "42768": 25, "428587": 32, "42860": 25, "42945": 25, "42it": 25, "43": [24, 25, 28, 32, 39, 69, 70, 80], "430": [6, 70], "43008": 25, "431": 28, "431046962738037": 32, "43123": 25, "43130": 25, "43146": 25, "432": [24, 70], "43277": 25, "432m": 70, "433": [25, 70], "43312883": 28, "43378": 25, "43382": 25, "435": 28, "43536": 25, "43546": 25, "43602": 25, "438": 70, "4383": 24, "43856": 25, "439": 24, "43978": 25, "43it": 25, "44": [24, 25, 28, 32, 38, 69, 70, 80], "440": [25, 70], "441": 28, "4412": 69, "44139": 25, "4414": 25, "44140": 25, "4416": 24, "44187": 25, "442": [25, 70], "442112": 75, "4423": 69, "44242": 25, "442u": 70, "443": 25, "44347": 25, "44477": 25, "445": 25, "44500": 25, "44511": 25, "44528": 25, "44693": 25, "446u": 70, "448": 32, "4483": 75, "4485": 24, "4490": 24, "44910": 25, "44934": 25, "4499": 24, "449m": 70, "44it": 25, "45": [19, 23, 24, 25, 28, 39, 46, 59, 68, 69, 75, 77, 80], "450": 25, "45009": 25, "45026": 25, "45029": 25, "4503311258278": 73, "4512": 24, "45132940": 24, "452473": 24, "45398": 25, "454": 25, "45402": 25, "454m": 69, "455431": 68, "4554312190002747": 68, "456": 82, "4571": 24, "45728": 25, "458": [25, 68, 70], "458u": 70, "459": 68, "4598": 44, "45it": 25, "46": [24, 25, 28, 32, 68, 70, 73, 75, 80], "460": 68, "4602": 24, "460m": 70, "461": [24, 68], "46192": 25, "461943": 68, "4619431142000394": 68, "4620": 44, "46246": 25, "462u": 70, "463": [32, 68], "46323080499951175": 68, "46335": 25, "463462": 68, "4634621249997508": 68, "46350148": 28, "463649": 68, "46364944700053456": 68, "4636755310002627": 68, "4636971440004345": 68, "46372856899961334": 68, "463729": 68, "463939": 68, "46393922600054793": 68, "464": [32, 69, 70], "4640383700007078": 68, "464213": 68, "4642132010003479": 68, "465": 69, "4653": 24, "46557": 25, "46559": 25, "465929": 68, "4659291400002985": 68, "4665": 75, "46661": 25, "46671": 25, "466m": 70, "467": 25, "46804": 25, "46812": 25, "46843": 25, "46844444": 28, "46848": 25, "46967": 25, "469u": 70, "47": [24, 25, 28, 44, 69, 70, 75, 80], "470u": 70, "4710": 24, "47107": 25, "47117": 75, "47172": 25, "4719360": 73, "4720": 24, "4721": 24, "47276": 25, "4728": 24, "47295": 25, "473": [28, 70], "4730964467005076": 32, "47334": 25, "4734": 75, "47415": 25, "47437275321498723": 73, "474m": [69, 70], "47612": 25, "47626": 25, "47681": 25, "476m": 69, "47736": 25, "47777": 25, "477m": 69, "478300": 75, "479": 25, "47971": 25, "47it": 25, "48": [9, 23, 24, 25, 28, 29, 44, 68, 70, 73, 80], "480336": 68, "4803364019999208": 68, "480672001838684": 69, "48071": 25, "481": 25, "482": 25, "48205128": 28, "4828": 24, "483": [4, 5, 6, 8, 11, 25], "48312557359986386": 68, "483126": 68, "48316": 25, "4831838208": 73, "48341351999988547": 68, "483475": 68, "4834751440002947": 68, "48351270700004534": 68, "483513": 68, "48362178600018524": 68, "483791": 68, "48379133800062846": 68, "483812": 68, "48381232899992027": 68, "48389172999941366": 68, "484": [6, 8, 24, 25, 28, 68], "48418703799961804": 68, "4842157639996003": 68, "484216": 68, "484244": 68, "4842440839993287": 68, "48476": 25, "485": [28, 70, 82], "4850": 24, "486": 77, "48624": 25, "4864": 24, "4873": 25, "48736": 25, "488": 28, "48827": 25, "48850": 77, "48873": 25, "489": [25, 68], "48925": 25, "48979592": 28, "48987": 25, "48it": 25, "49": [25, 28, 39, 68, 69, 70, 80], "491": 68, "49158": 25, "49179": 25, "492": 68, "492051968": 73, "4922": 25, "4923": 24, "49292": 25, "49296": 25, "49298": 25, "493": 68, "4934": 25, "49372": 25, "494": 28, "49428": 25, "49447": 25, "49505": 25, "49576": 25, "49703": 25, "49705": 25, "4973": 24, "4973441634": 28, "49829": 25, "4986": 24, "49860": 25, "49895": 25, "499": 28, "4995": 28, "49it": 25, "4c0333854cb905966f8cc4e9a74068c1e507c7b7": 32, "4cm": 19, "4d": [25, 35], "4e": 74, "4f": [28, 53, 73, 75, 77], "4n": 73, "4th": 25, "4x": 35, "4xlarg": 43, "4y": 35, "5": [1, 2, 3, 4, 5, 6, 7, 8, 13, 14, 16, 17, 19, 21, 24, 25, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 43, 44, 48, 51, 53, 57, 64, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 87], "50": [17, 23, 24, 25, 28, 35, 44, 59, 68, 69, 70, 75, 80], "500": [25, 28, 53, 76], "5000": [53, 79], "50000": [28, 74], "500u": [69, 70], "50115": 25, "5017": 25, "50186": 25, "502": 24, "5025": 24, "50256": [24, 75], "50257": [24, 73, 75], "50316": 25, "50370": 25, "50377": 25, "504": [25, 70], "50491": 25, "5068": 24, "507": [28, 70], "5071": 75, "5074": 24, "5075": 24, "50796": 25, "507m": 69, "508": 68, "5083": 75, "50961": 25, "509m": 70, "51": [25, 28, 32, 34, 69, 70, 75, 80], "510": [68, 70], "510880": 29, "510952": 29, "511": [68, 70], "51113": 25, "512": [23, 24, 68, 73], "5120": [23, 24], "5124": 24, "512m": 70, "513": 70, "51407": 25, "515": 25, "5150": 24, "5154": 24, "51553": 25, "51582": 25, "516": 70, "51642": 25, "51661": 25, "5174": 77, "51752": 25, "51771": 25, "5181": 24, "51940": 25, "51it": 25, "52": [25, 32, 67, 68, 69, 70, 80], "520": 26, "52016": 25, "52034": 25, "521": 70, "5214": 24, "522": 25, "5221": 24, "5225": 24, "52291": 25, "5232": 25, "52357": 25, "5236": 24, "52363": 25, "5248": 24, "525": 28, "5252": 79, "52557": 25, "52605": 25, "5262": 24, "52657": 25, "527": 28, "5271": 24, "52777778": 28, "5281": 24, "52858": 25, "52941176": 28, "5296": 24, "52it": 25, "53": [25, 32, 69, 70, 80, 82], "530": 25, "5304": 24, "53091": 25, "53166227": 28, "53183": 25, "5319": 79, "53197": 25, "5319817168701279": 32, "53270": 25, "532m": 69, "532u": 70, "5331": 24, "5333": 24, "53345": 25, "533m": 70, "5345": 24, "534m": 69, "534u": 70, "536": 24, "53617": 25, "5378": 79, "5383": 24, "5391": 24, "53925": 25, "5398e": [24, 79], "53it": 25, "54": [25, 69, 70, 80], "54003": 25, "54022": 25, "5403": 24, "54178": 25, "542470366": 73, "542u": 70, "543": 25, "5436": 24, "544": [3, 70], "544u": 70, "545": 68, "54518": 25, "54578": 25, "54592": 25, "5463": 24, "54678": 25, "547m": 70, "54965": 25, "54976875": 74, "549u": 70, "54it": 25, "55": [25, 32, 46, 67, 69, 70, 74, 80], "55048": 25, "551": [70, 75], "55185": 25, "552": 25, "5522448429284077": 73, "55409": 25, "5547": 25, "55473": 25, "555": 70, "55591": 25, "555m": 70, "55610225252113": 32, "55620": 25, "55758": 25, "5580": 24, "55890": 25, "55921": 25, "55933": 25, "5599587203302373": 32, "56": [14, 25, 28, 67, 68, 70, 80], "5607": 24, "5611": 75, "56111": 25, "56120": 25, "56174": 25, "56177": 25, "5623": 24, "5628899835796387": 32, "56350": 25, "5639": 24, "5645": 24, "56535": 25, "565u": 70, "566": 25, "5670": 77, "56744": 25, "56823": 25, "56857": 25, "56889605": 28, "569": 28, "5698": 24, "57": [25, 32, 68, 70, 80], "570": 75, "5715": 24, "57245": 25, "574": 28, "57499": 25, "575435": 75, "576": 70, "57636": 25, "57706": 25, "5778": 24, "5786": 28, "57947": 25, "58": [25, 28, 45, 68, 70, 80], "580": [25, 32], "581": 25, "58105": 25, "58128": 25, "582": 25, "5821": 75, "5823": 24, "58239": 25, "5827": 24, "583": 25, "583296614400": 73, "5835": 24, "583k": 25, "5847": 75, "584k": 25, "584m": 70, "585": 77, "5865": 24, "588": 70, "58801": 25, "58844": 25, "5886": [24, 77], "589": 70, "58919": 25, "58920": 25, "5893": 77, "58960": 25, "589824": [32, 73], "589m": 70, "58it": 25, "59": [21, 23, 25, 28, 45, 68, 80], "590m": 69, "591m": 70, "592": 32, "5920": 25, "5925": 77, "59447": 25, "59473": 25, "5949": 24, "5960": 24, "5962": 24, "596449": 75, "597": [24, 25], "59749": 25, "59851": 25, "5988": 28, "5998": [2, 21, 23, 30, 31], "599999": 75, "59it": 25, "5b": 32, "5cm": 19, "5e": 76, "5e12": 73, "5f": 73, "5mm": 17, "6": [1, 2, 6, 7, 8, 14, 16, 17, 19, 21, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 38, 39, 40, 43, 48, 53, 58, 59, 60, 62, 68, 69, 70, 71, 73, 74, 75, 78, 79, 80, 87], "60": [17, 25, 28, 59, 69, 70, 78, 80], "600": 45, "6000": 67, "60000": 28, "60037": 25, "6008": [2, 21, 23, 30, 31], "600m": 70, "60138": 25, "601m": 70, "6022": 24, "603": [28, 75], "60395": 25, "603u": 70, "6047": 25, "60471": 25, "6063": 75, "60693": 25, "607": 32, "6077": 24, "608": [28, 32], "60857": 25, "608643": 75, "608m": 70, "60981": 25, "60it": 25, "61": [25, 70, 80], "6116": 75, "6119": 24, "612724": 75, "612m": 70, "61301": 25, "6130560": 29, "613m": 70, "61472122": 24, "61567": 25, "61576": 25, "615u": 70, "6167": 77, "616u": 70, "617": 25, "61806": 25, "61858": 25, "618m": 70, "619": 70, "61903": 25, "61969": 25, "61it": 25, "62": [25, 67, 69, 70, 80], "6207": 24, "6216": 25, "62181": 25, "623": 69, "62352941": 28, "62402": 25, "62428": 25, "62466": 25, "625829189863": 31, "62689": 25, "627m": 70, "62801": 25, "62823": 25, "6285": [24, 75], "62865": 25, "628m": 70, "62914": 25, "62it": 25, "63": [25, 28, 68, 69, 70, 71, 75, 77, 80], "630194235588974": 28, "6302": 75, "63084": 25, "63124": 25, "63179": 25, "632": 70, "6324970042866496": 73, "63403": 25, "6340956189978897": 68, "634096": 68, "6349": 77, "635": 68, "6364": 79, "63667": 25, "637": 68, "6379": 24, "638": [28, 68], "63888889": 28, "639": 25, "63996": 25, "63it": 25, "64": [13, 14, 24, 25, 28, 29, 32, 70, 74, 75, 77, 80], "6400": [23, 24], "6400553": 29, "640220": 68, "6402201920000152": 68, "64037": 25, "64146": 25, "64169": 25, "6428": 77, "643": 70, "64347": 25, "6435": 77, "644": 28, "64465": 25, "64480": 25, "644u": 70, "6451": 24, "6459": 24, "64694": 25, "6478": 24, "647m": 69, "648": 69, "649": 70, "6492525648321494": 32, "64966443": 28, "65": [25, 28, 46, 59, 69, 70, 80], "650": 29, "6501": 24, "650u": 70, "65115": 25, "65208": 25, "6523": 24, "6536": 24, "6541": 24, "65422": 25, "654800": 75, "654u": 70, "65535": 44, "65536": [25, 74], "65563": 25, "656": 70, "6567345287852233": 73, "6570": 24, "65714286": 28, "65759": 25, "6594": 24, "65957447": 28, "66": [25, 28, 32, 69, 70, 73, 75, 80], "661": 10, "6619": 24, "662": 25, "66206": 25, "6622": 24, "662u": 70, "663": 28, "665": 25, "66529492": 28, "66589": 25, "66644": 25, "6666666666666666": 28, "6667": 16, "66689": 25, "667": 25, "6674": 24, "667u": 70, "668": 25, "6681": 24, "669": 25, "6693280": 31, "66970": 25, "66it": 25, "67": [25, 70, 80], "6702": 24, "67047": 25, "6706": 24, "670m": 69, "67117": 25, "6713": 24, "672": 68, "67292": 25, "673m": 70, "674": 68, "674881715648123": 73, "674m": 69, "675": [32, 68], "67510": 25, "6756": 24, "676": 68, "6784": 25, "6799": 24, "68": [25, 28, 70, 73, 80], "680": 75, "6803": 24, "68127": 25, "682084": 68, "6820840510008566": 68, "68255": 25, "683": 25, "68339": 68, "683391": 68, "6833910059995105": 68, "6835393290002685": 68, "6835425659992325": 68, "683543": 68, "6837199530000362": 68, "6838137882004958": 68, "683814": 68, "68381571899954": 68, "6839085111998429": 68, "683909": 68, "683922": 68, "6839223050010332": 68, "684": 25, "684006079000028": 68, "68421053": 28, "68450": 25, "6847": 24, "684m": 70, "685": 25, "6852539360006631": 68, "685254": 68, "68529412": 28, "6853": 68, "6853365530005249": 68, "685337": 68, "68538": 25, "68581": 25, "6866": 25, "6868": 75, "68693": 25, "68761": 25, "68781": 29, "688": 70, "68804": 25, "68815": 25, "68826": 25, "68829": 29, "68877005": 28, "6898": 24, "68it": 25, "69": [25, 70, 80], "69078947": 28, "691": 70, "69163": 25, "69168": 25, "692": 28, "69247": 25, "692u": 70, "693": 31, "6935": 75, "6937": [24, 77], "693708384291344": 73, "695": 25, "695558": 32, "69589": 25, "6964": 24, "6966": 75, "696m": 69, "698": 32, "6980": [1, 2, 21, 23], "69830": 25, "69895": 25, "698m": 70, "69it": 25, "6e": 32, "6lhq": 73, "6n": 73, "6nd": 73, "6x": 53, "7": [1, 2, 3, 7, 14, 16, 17, 21, 24, 25, 27, 28, 29, 32, 33, 34, 38, 40, 43, 44, 48, 53, 59, 65, 68, 69, 70, 74, 78, 80, 87], "70": [17, 25, 28, 46, 59, 69, 70, 80], "700": 23, "7000": 25, "7009": 24, "700m": 70, "70135": 25, "702005": 32, "702m": 70, "703m": 70, "706": 28, "7063": [24, 75], "707": [25, 28], "70788": 25, "7079424": 73, "708": 25, "70854": 25, "7086": 24, "71": [25, 70, 80], "71012": 25, "712": 25, "713": [25, 82], "7139": 24, "714": 25, "7140": 24, "71423": 25, "715": 82, "71552": 25, "716": 25, "71604": 25, "7162": 24, "71638": 25, "71657": 25, "7167": 32, "7168": 24, "71696": 25, "7176": 24, "718m": 70, "71907": 25, "7193": 77, "7196": 75, "71it": 25, "72": [14, 25, 29, 70, 73, 80], "720": 25, "72008": 25, "72041": 44, "72042": 44, "72043": 44, "72044": 44, "7205": 77, "72062": 25, "720m": 70, "72105": 25, "722": 24, "72219": 25, "72236": 25, "72283": 25, "722m": 70, "723": 70, "7233": 24, "725": 25, "7253e": 24, "7257": 75, "726": [68, 70], "726191": 68, "7261910039997019": 68, "7264139199996862": 68, "7264165149990731": 68, "726417": 68, "726529": 68, "7265293540003768": 68, "7266": 68, "7266143320002811": 68, "72670": 25, "726819": 68, "7268191237995779": 68, "72687": 25, "727": 25, "727164707999691": 68, "727165": 68, "7272930130002351": 68, "72772": 25, "727781": 68, "7277811669991934": 68, "727m": 69, "728044": 68, "7280440384000031": 68, "729": 25, "7294365609996021": 68, "7295": 24, "729m": 70, "729u": 70, "72it": 25, "73": [25, 70, 73, 80], "730": 25, "73022": 25, "7304": 24, "730475": 68, "7304752370000642": 68, "731": 25, "732": 69, "7320": 77, "7327": 24, "733": 25, "7333": 24, "735m": 70, "7363": 24, "7376": 24, "737m": 70, "73815": 25, "739": 25, "7390": 1, "73940": 25, "7398": 24, "739m": 70, "74": [25, 69, 70, 80], "740088": 75, "74036": 25, "74083": 25, "7421": 24, "74243": 25, "744": 29, "74403": 25, "7444": 24, "7457": 25, "74644": 25, "747": 25, "7472": 77, "74875": 25, "749323": 68, "7493231420003212": 68, "74990": 25, "74it": 25, "75": [25, 70, 80], "7500": 25, "75073": 25, "750u": 70, "751268": 68, "7512682050000876": 68, "75277": 25, "752m": 70, "75311": 25, "75372": 25, "75378": 25, "7539": 24, "753u": 70, "75435": 25, "755": 73, "7557055709994529": 68, "755706": 68, "756": 32, "7560": 24, "7568": 24, "7569": 24, "757": 70, "757336": 68, "7573362090006412": 68, "75778": 25, "7578": 25, "758m": 69, "759u": 70, "75it": 25, "76": [25, 69, 70, 80], "76046437346437": 28, "760u": 70, "7612242146420387": 73, "761m": 69, "762": 25, "762m": [23, 24], "76402": 25, "76483": 25, "76484561": 28, "76494": 25, "76514": 25, "76575": 25, "766320": 29, "766464": 29, "766m": 70, "767m": 70, "768": [23, 24, 68, 70, 73], "7680": 70, "7694444444444445": 28, "769u": 70, "76it": 25, "77": [25, 69, 70, 80], "77026": 25, "77051": 25, "7712": 24, "77149": 25, "77249": 25, "77260": 25, "77303": 25, "77357": 25, "774m": 73, "77565": 25, "775m": 70, "77689": 25, "777": 45, "77700": 25, "77726": 25, "7773": 25, "7779": 24, "778": 28, "77818": 25, "77846": 25, "77971": 25, "77991": 25, "78": [25, 28, 70, 80], "78079": 25, "78082": 25, "781": 28, "78149": 25, "7824": 24, "78287": 25, "78299": 25, "783": 70, "78328": 25, "784": [28, 32], "7841": 75, "7845": 25, "78469": 25, "785": 25, "78539": 25, "786": 24, "786432": 73, "78699": 25, "788": 24, "78832": 25, "78847": 25, "788u": 70, "78952": 25, "78it": 25, "79": [25, 70, 80], "79013": 25, "79047426048": 73, "79083": 25, "791": 25, "7911": 24, "792": 70, "79201": 25, "7930": [25, 75], "79352": 25, "79370": 25, "79396": 25, "79465": 25, "795599698575646": 73, "796": 25, "797": 25, "7973": 75, "7974": 75, "798": 28, "79853": 25, "79982": 25, "8": [1, 2, 13, 14, 16, 17, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 48, 59, 60, 68, 70, 73, 74, 75, 76, 77, 78, 79, 80, 87], "80": [17, 24, 25, 59, 70, 80], "80015": 25, "80057": 25, "8008": 25, "800984": 80, "800u": 70, "8018": 77, "803": 25, "8033": 24, "8034": 25, "8038": 24, "803m": 70, "804": 70, "805": 25, "80527": 25, "8053063680": 73, "80536": 25, "80544": 25, "805m": 70, "805u": 70, "806": 25, "8061": 24, "8065": 24, "807": 25, "80716": 25, "807u": 70, "808": 24, "81": [25, 59, 69, 70, 75, 80], "81116": 25, "811883582334536": 28, "81213": 25, "81233": 25, "81266": 25, "813": 68, "81303": 25, "81348": 25, "8145": 24, "815": [25, 68], "8150": 77, "8156": 77, "816": [28, 68], "81609": 25, "8165": 24, "817": 25, "818": 25, "8182": 24, "819": [25, 32], "8192": 24, "81940": 25, "81it": 25, "82": [25, 70, 80], "820": 28, "820m": 70, "82129": 25, "823": 28, "8230": 24, "8238": 77, "82396": 25, "823m": 69, "824": 67, "82437": 25, "825284": 75, "825m": 70, "82608": 25, "82648": 25, "82721": 25, "8286": 25, "828u": 70, "82903": 25, "82it": 25, "83": [25, 29, 69, 70, 80], "83003": 25, "83064": 25, "83208": 25, "83311": 25, "83459": 25, "83595": 25, "83777": 25, "83780": 25, "83783784": 28, "8387": 24, "83981": 25, "83it": 25, "84": [25, 70, 80], "8410": 24, "84106": 25, "8415": 24, "8419": 24, "841m": 70, "8421": 24, "842u": 70, "8437": 24, "84455": 25, "845": 68, "84502": 25, "84571": 25, "845815": 32, "846u": 70, "847": 68, "84766": 25, "84767": 25, "8478": 24, "848": 68, "84814": 25, "84828": 25, "84833": 25, "848750": 32, "849": 68, "84953088": 73, "84it": 25, "85": [25, 69, 70, 80], "8501": 32, "85167": 25, "85178": 25, "85190": 25, "851m": 70, "854553600": 73, "85474": 25, "85542": 25, "85636": 25, "85712": 25, "85750": 25, "85777": 25, "858": 68, "85830": 25, "858u": 70, "8590": 24, "85905225": 28, "8592": 24, "85922": 25, "8594": 25, "85981": 25, "85it": 25, "86": [25, 69, 70, 80], "860": 28, "860237": 75, "86075": 25, "86082": 25, "86100": 25, "86145": 25, "8615": 24, "8616": 24, "86281": 25, "864": 70, "86438": 25, "86508": 25, "86610": 25, "867": 70, "86705": 25, "867180": 32, "86825596": 28, "86860": 25, "86864": 25, "8688": 77, "87": [25, 70, 80], "87166": 25, "87216": 25, "8722": 75, "87294": 25, "873m": 70, "87433": 25, "8744": 24, "87445": 25, "87446": 25, "87479": 25, "874944921600": 73, "874m": 70, "875062886400": 73, "87506288640000": 73, "87517": 25, "87537": 25, "87599": 25, "876099": 75, "87619": 25, "877m": 69, "8780": 24, "87807": 25, "8784": 24, "8789": 25, "87898": 25, "8793": 25, "87943": 25, "8796": 24, "87it": 25, "88": [25, 70, 80], "880": [24, 70], "88089": 25, "880m": 70, "880u": 70, "88121": 25, "881m": 70, "882": 70, "883": 25, "8830": 25, "8833333333333333": 28, "88388": 25, "884": 25, "88485": 25, "886": [25, 68], "88602": 25, "88653": 25, "88654": 25, "887": 28, "8874175820001255": 67, "88789": 25, "888": 68, "88840": 25, "88879": 25, "889m": 70, "88it": 25, "89": [25, 70, 80], "890": 68, "89017341": 28, "89074": 25, "890u": 70, "891": 28, "89162011": 28, "89257": 25, "89285714": 28, "89395": 25, "89429": 25, "8943": 75, "8955": 75, "89572": 25, "895753": 32, "89585889": 29, "896": 32, "89631926654981": 73, "89655": 25, "897": 28, "897491012859949": 73, "898": 28, "8981086857156975": 73, "89it": 25, "8xa100": 73, "9": [1, 2, 3, 4, 7, 8, 14, 16, 19, 21, 23, 24, 25, 26, 27, 28, 29, 32, 33, 37, 38, 39, 44, 45, 48, 49, 57, 59, 68, 69, 70, 71, 73, 74, 75, 76, 78, 79, 80, 82, 87], "90": [17, 25, 40, 52, 59, 69, 70, 80], "9000": 28, "9007": 25, "90081522": 28, "90094": 25, "901044": 75, "9015": 24, "902": 25, "903": 25, "9031": 75, "90319": 25, "903625": 75, "903m": 70, "90443": 25, "904508": 78, "90469": 25, "9047619": 28, "9049": 24, "905": [25, 28], "90561": 25, "906788": 75, "90697": 25, "908": 68, "90804": 25, "9086": 24, "909": 68, "9093": 24, "909526": 75, "909733": 32, "90it": 25, "91": [14, 25, 70, 80], "910": 68, "9101": 24, "91018": 25, "910443": 32, "9116": 75, "91183": 25, "91210": 25, "912348": 32, "91241": 25, "91357": 25, "913684": 32, "9137": 32, "91378": 25, "914": 28, "91408": 25, "91431": 25, "91459": 25, "914779": 75, "915999": 75, "916m": 70, "9173": 24, "91756": 25, "917u": 70, "91843": 25, "9186": 24, "91it": 25, "92": [24, 25, 28, 70, 80], "920098": 28, "92018": 25, "920468": 32, "920626": 32, "921": 70, "92107": 25, "92125": 25, "921905": 75, "92289442": 28, "923062": 75, "92335": 25, "923m": 70, "923u": 70, "924": [28, 69], "92402": 25, "924157": 32, "92473": 25, "925": 70, "9258": 25, "9261": 32, "92679": 25, "92686": 25, "9269": 25, "92700": 25, "92714": 25, "927157": 32, "92760181": 28, "927814": 75, "92808": 25, "9293": 77, "929515": 75, "92967186547287": 28, "92it": 25, "93": [25, 45, 80], "9305": 24, "93065": 25, "930785": 75, "93115": 25, "9315789473684211": 32, "931579": 32, "93181818": 28, "932": 28, "93217": 25, "933540": 75, "933m": 70, "933u": 70, "934": 68, "934282": 32, "935": 67, "93542": 25, "935628": 75, "936": [25, 68], "9360": 24, "936106": 32, "936106070735046": 32, "93650": 25, "937": [25, 28, 68], "93793": 25, "938": [25, 68], "938326": 75, "93879": 25, "939": 25, "93969849": 28, "93990": 25, "93it": 25, "94": [25, 69, 70, 80], "94008": 25, "941042": 32, "941155": 32, "9411551411551411": 32, "94206": 25, "942398": 75, "942731": [32, 75], "942775": 75, "94284": 25, "94439": 25, "9445": 75, "944779": 75, "945m": 70, "94623": 25, "94638": 25, "94681": 25, "9471012658228": 28, "947137": 32, "94740": 25, "94758": 25, "947m": 70, "949": 25, "949336": 75, "949m": 70, "95": [25, 28, 32, 59, 69, 70, 80], "950": [25, 59], "951": 25, "95125": 25, "951m": 69, "952": 25, "952219": 32, "952987": 75, "953": 25, "95306": 25, "954": 28, "95474": 25, "954921": 32, "954u": 70, "955": 68, "95540": 25, "955947": 32, "955u": 70, "95612": 25, "95613": 25, "957": 68, "9573": 24, "958": 68, "95841": 25, "9589": 24, "959318": 75, "95995": 25, "959u": 70, "95it": 25, "96": [24, 25, 32, 69, 70, 80], "960": 25, "960062": 75, "9602": 24, "960352": 32, "960352422907489": 32, "96057": 25, "9606": 24, "9607": 75, "961": 25, "96152": 25, "9617": 24, "961750": 75, "961793": 75, "962": 25, "962396": 75, "9626068376068373": 73, "963399": 75, "96424": 25, "96524": 25, "966": 24, "96622": 25, "96631": 25, "9663676416": 73, "96647": 25, "96766": 25, "967851": 32, "9692": 77, "96949": 25, "9696603103": 28, "97": [25, 28, 69, 70, 80], "970182": 32, "9704": 24, "97076": 25, "971857": 32, "971m": 70, "9720": 24, "97209": 25, "972136": 75, "97321": 25, "9747298715068023": 32, "974730": 32, "975164": 32, "97534": 25, "975445": 78, "976": 28, "97672": 25, "976m": 70, "9771": 24, "977165": 32, "97742": 25, "977606": 75, "977963": 32, "97948": 25, "979735": 75, "97k": 25, "98": [25, 69, 74, 80], "9802e": 24, "980495": 75, "981": 70, "9812046605398257": 32, "981205": 32, "98225": 25, "982279": 32, "98277": 25, "983": 25, "983136": 32, "984": 70, "984542": 32, "9848": 24, "985105": 32, "9851052470652112": 32, "98513": 25, "98538": 25, "985478": 32, "9863": 24, "986326": 75, "98659": 25, "98677": 25, "98748": 25, "987603": 75, "988262": 32, "989": 68, "989035": 75, "989355": 32, "989370": 32, "98it": 25, "99": [7, 25, 31, 57, 59, 69, 70, 80], "990": [32, 59], "9900": 24, "990026": 75, "99042": 25, "990476": 32, "990863": 32, "990918": 32, "991": 68, "991196": 75, "991540": 75, "992": 68, "992234": 32, "992m": 70, "993": 68, "9930856553147576": 32, "993086": 32, "993103": 75, "993395": 32, "9936": 75, "993630": 32, "993739": 75, "99375": 25, "994530": 32, "9947": 24, "994745": 75, "994755": 75, "994777": 32, "994828": 75, "995271": 75, "995431": 32, "9954314720812182": 32, "995570": 32, "9955702958862339": 32, "996": 53, "9961": 75, "996175": 31, "996349": 32, "996470": 32, "996582": 75, "996616": 32, "996647": 75, "996782": 32, "996798": 32, "997": 79, "9972": 24, "997293": 32, "9976": 24, "997859": 32, "997951": 32, "9981937602627258": 32, "998194": 32, "9982": 24, "99832": 25, "998358": 32, "99851": 25, "998522": 32, "9988": 24, "9988615953476088": 32, "998862": 32, "998957": 32, "999": [76, 82], "999064": 32, "9992": 24, "99951": 25, "9995e": [24, 79], "9996": 24, "9998": 24, "9999": 24, "99995": 79, "9999999999999995e": 78, "999m": 70, "99it": 25, "A": [1, 2, 3, 5, 6, 7, 8, 14, 17, 19, 21, 22, 23, 24, 26, 27, 28, 30, 32, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 51, 52, 53, 55, 57, 58, 59, 61, 64, 65, 66, 71, 73, 76, 79, 81, 82, 83, 84], "AND": [25, 32, 78], "And": [6, 7, 8, 9, 14, 17, 23, 24, 25, 27, 29, 33, 35, 39, 45, 48, 51, 56, 61, 62, 72, 73, 74, 76, 79], "As": [6, 7, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 38, 39, 42, 51, 53, 54, 55, 56, 57, 58, 60, 71, 73, 76, 78, 79, 82, 85], "At": [14, 16, 17, 19, 21, 22, 27, 37, 52, 56, 57, 62, 65, 79, 80, 83, 84], "BY": 54, "Be": 19, "Being": 17, "But": [4, 6, 8, 9, 10, 14, 16, 23, 24, 25, 31, 32, 33, 35, 40, 44, 45, 52, 53, 59, 61, 62, 65, 66, 71, 76, 82, 85], "By": [3, 4, 5, 6, 10, 14, 16, 22, 23, 24, 25, 27, 35, 37, 38, 40, 42, 48, 51, 52, 53, 54, 56, 59, 60, 62, 63, 65, 76, 78, 79, 82, 84, 85], "FOR": 46, "For": [3, 4, 5, 6, 7, 8, 9, 10, 14, 16, 17, 19, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 71, 73, 76, 77, 78, 79, 80, 82, 83, 85], "IN": 24, "If": [3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 40, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 73, 74, 75, 76, 78, 79, 82, 83], "In": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87], "Into": [2, 23, 24, 78, 79], "It": [3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 64, 65, 66, 71, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 87], "Its": [2, 11, 13, 17, 33, 40, 41, 85], "NO": [44, 46], "NOT": [28, 32], "No": [3, 8, 25, 40, 51, 54, 59, 78, 80, 82], "Not": [10, 13, 14, 27, 33, 40, 54, 71], "OF": [25, 78], "ON": [25, 78], "OR": 44, "Of": [23, 25, 28, 33, 42, 47, 72, 76], "On": [1, 2, 3, 6, 8, 14, 16, 17, 21, 23, 24, 27, 28, 54, 58, 73, 78, 79, 80], "One": [1, 8, 14, 16, 23, 27, 29, 31, 35, 38, 39, 44, 52, 54, 56, 57, 58, 59, 62, 65, 66, 67, 71, 79, 82], "Or": [40, 45, 65, 74], "Such": [6, 22, 23, 31, 43], "THE": [25, 78], "TO": 46, "That": [4, 16, 24, 31, 40, 79], "The": [1, 2, 3, 4, 5, 7, 9, 10, 11, 13, 14, 15, 20, 21, 25, 26, 28, 29, 32, 33, 35, 37, 38, 39, 42, 44, 45, 51, 53, 54, 56, 57, 58, 60, 61, 63, 64, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 82, 83, 84, 85, 87], "Their": [35, 39], "Then": [4, 7, 8, 14, 16, 22, 23, 24, 25, 27, 28, 29, 31, 39, 40, 45, 52, 55, 56, 59, 62, 73, 80, 82, 85], "There": [7, 14, 16, 24, 25, 27, 28, 29, 34, 35, 39, 44, 52, 54, 56, 57, 58, 59, 60, 62, 65, 76, 77, 82], "These": [5, 6, 9, 11, 14, 16, 21, 22, 23, 24, 25, 32, 34, 35, 37, 39, 40, 44, 51, 52, 54, 55, 56, 57, 59, 60, 63, 64, 65, 66, 71, 72, 73, 85], "To": [3, 6, 14, 16, 17, 19, 21, 22, 23, 27, 29, 31, 33, 34, 35, 37, 38, 42, 44, 45, 46, 52, 55, 57, 60, 66, 71, 72, 76, 78, 80, 82, 83, 85], "WITH": 24, "Will": [53, 55, 76], "With": [7, 14, 16, 23, 24, 26, 27, 29, 33, 35, 39, 40, 48, 52, 53, 54, 55, 57, 69, 72, 84], "_": [3, 4, 7, 8, 13, 14, 16, 17, 23, 24, 25, 27, 28, 29, 31, 32, 37, 40, 42, 53, 58, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80], "_0": [14, 17, 35], "_1": [5, 14, 17, 22, 24, 27, 29, 35, 37, 39, 40, 42, 52, 73, 79], "_2": [5, 13, 22, 24, 27, 29, 35, 37, 39, 40, 42, 52, 73, 79], "_3": [22, 24, 27, 35, 37], "_4": 22, "_5": 22, "_6": 24, "__": [8, 76], "___": 76, "__add__": [6, 7, 8], "__all__": 31, "__annotations__": 76, "__args__": 76, "__bases__": 76, "__bool__": [10, 24], "__builtin__": 76, "__builtins__": 76, "__call__": [76, 77, 79], "__class__": [3, 4, 5, 10, 24, 76, 85], "__class_getitem__": 8, "__closure__": 76, "__code__": 76, "__constants__": 24, "__contains__": [6, 8], "__defaults__": 76, "__delattr__": [10, 24, 76], "__delitem__": 8, "__dict__": [3, 24], "__dir__": 76, "__doc__": 76, "__eq__": [8, 76, 83], "__format__": 76, "__future__": [4, 24, 25, 28, 29, 31, 32, 44, 46, 67, 68, 70, 71, 74, 75, 77, 78, 82, 83, 84], "__ge__": [8, 76], "__get__": 76, "__getattr__": 76, "__getattribute__": 76, "__getitem__": [8, 9, 74, 75, 77, 80, 85], "__getstate__": 76, "__globals__": 76, "__gt__": [8, 76], "__hash__": [8, 76], "__i": 8, "__iadd__": 8, "__imul__": 8, "__index": 8, "__init__": [3, 5, 6, 8, 9, 24, 28, 32, 56, 68, 70, 71, 73, 74, 75, 76, 77, 79, 80, 84, 85, 87], "__init_subclass__": 76, "__item": 8, "__iter": 8, "__iter__": [8, 19], "__kei": 8, "__kwdefaults__": 76, "__le__": [8, 76], "__len__": [3, 8, 9, 19, 32, 74, 75, 77, 80], "__loader__": 76, "__lt__": [8, 76], "__main__": [44, 46, 67, 68, 69, 71, 75, 76, 82, 85, 87], "__module__": 76, "__mro__": [3, 76], "__mul__": 8, "__name__": [3, 4, 5, 10, 24, 44, 46, 53, 67, 68, 69, 70, 71, 75, 76, 77, 82, 85, 87], "__ne__": 76, "__new__": [10, 24, 76], "__next__": 80, "__object": 8, "__origin__": 76, "__package__": 76, "__post_init__": [73, 82], "__private_attr": 76, "__qualname__": 76, "__reduce__": 76, "__reduce_ex__": 76, "__reference__": [68, 70], "__repr__": [9, 10, 24, 76], "__reversed__": 8, "__rmul__": 8, "__setattr__": [10, 24, 76], "__setitem__": 8, "__setstate__": 76, "__sizeof__": 76, "__slots__": [3, 24], "__spec__": 76, "__start": 8, "__stop": 8, "__str__": [6, 76], "__subclasshook__": [3, 76], "__tagged__": [68, 70], "__valu": 8, "__weakref__": 76, "_activ": [68, 70], "_activate_neftun": 76, "_add_positional_encod": 24, "_add_sm_patterns_to_gitignor": 76, "_alia": 25, "_annot": 76, "_appli": 76, "_assign_sampl": 28, "_autoset_attn_implement": 76, "_b": [13, 22], "_backward_compatibility_gradient_checkpoint": 76, "_c": [28, 44, 70], "_call_impl": 76, "_callback": 71, "_centroid": 28, "_check_and_enable_flash_attn_2": 76, "_check_and_enable_sdpa": 76, "_check_method": 3, "_childclass__private_attr": 76, "_compute_argmin_assign": 28, "_contain": 6, "_convert_head_mask_to_5d": 76, "_copy_lm_head_original_to_res": 76, "_create_repo": 76, "_cycl": 71, "_d": [28, 40], "_deactivate_neftun": 76, "_default": 76, "_devic": [24, 71], "_dh": 76, "_dispatch_accelerate_model": 76, "_distributed_c10d": 44, "_dtype": 24, "_dump_snapshot": [70, 71], "_e": 22, "_empti": 76, "_expand_inputs_for_gener": 76, "_experimentalconfig": 70, "_extract_past_from_model_output": 76, "_f": 31, "_fig": 28, "_finish_current_push": 76, "_foreach_sqrt": 70, "_from_config": 76, "_gather_and_numpifi": 76, "_gener": 19, "_genericalia": 76, "_get_backward_hook": 76, "_get_backward_pre_hook": 76, "_get_candidate_gener": 76, "_get_collator_with_removed_column": 76, "_get_cosine_schedule_with_warmup_lr_lambda": [25, 78], "_get_decoder_start_token_id": 76, "_get_distance_metr": 28, "_get_div_term_vector": 24, "_get_eval_sampl": 76, "_get_files_timestamp": 76, "_get_generation_mod": 76, "_get_learning_r": 76, "_get_logits_processor": 76, "_get_logits_warp": 76, "_get_nam": 76, "_get_no_split_modul": 76, "_get_output_dir": 76, "_get_position_vector": 24, "_get_resized_embed": 76, "_get_resized_lm_head": 76, "_get_stopping_criteria": 76, "_get_train_sampl": 76, "_h": [22, 24], "_has_converg": 28, "_hook_rss_memory_post_forward": 76, "_hook_rss_memory_pre_forward": 76, "_hp_search_setup": 76, "_i": [22, 76, 77, 79], "_i1": 76, "_i2": 76, "_i3": 76, "_i4": 76, "_i5": 76, "_i6": 76, "_ih": 76, "_ii": 76, "_iii": 76, "_inertia": 28, "_init_centroid": 28, "_init_positional_encod": 24, "_init_weight": [24, 32, 68, 70, 74, 75, 76], "_initialize_weight": 76, "_inner_training_loop": 76, "_instanc": [10, 24], "_intern": 82, "_issue_warnings_after_load": 76, "_j": [22, 27, 79], "_k": [27, 28, 29, 79], "_kind": 76, "_label": 28, "_load_best_model": 76, "_load_from_checkpoint": 76, "_load_from_state_dict": 76, "_load_optimizer_and_schedul": 76, "_load_pretrained_model": 76, "_load_pretrained_model_low_mem": 76, "_load_rng_stat": 76, "_lora_a_init_param": 32, "_lora_b_init_param": 32, "_lrschedul": [25, 75, 78], "_lsprof": 80, "_m": [14, 24, 73], "_maybe_initialize_input_ids_for_gener": 76, "_maybe_log_save_evalu": 76, "_maybe_warn_non_full_backward_hook": 76, "_mean": 28, "_memory_profil": 70, "_merg": 32, "_merge_criteria_processor_list": 76, "_method": 28, "_miss": [10, 25], "_modul": 32, "_move_model_to_devic": 76, "_n": [17, 22, 23, 28, 42, 76], "_name": 76, "_name_or_path": 24, "_named_memb": 76, "_nested_gath": 76, "_notgiven": [10, 24], "_oh": 76, "_p": 39, "_paramet": 25, "_prepare_attention_mask_for_gener": 76, "_prepare_decoder_input_ids_for_gener": 76, "_prepare_encoder_decoder_kwargs_for_gener": 76, "_prepare_input": 76, "_prepare_model_input": 76, "_private_instance_attr": 76, "_profil": 70, "_protected_attr": 76, "_push_from_checkpoint": 76, "_qkv_same_embed_dim": 24, "_record_memory_histori": [70, 71], "_register_load_state_dict_pre_hook": 76, "_register_state_dict_hook": 76, "_remove_unused_column": 76, "_reorder_cach": 76, "_replicate_for_data_parallel": 76, "_report_to_hp_search": 76, "_reset_clust": 28, "_reset_inertia": 28, "_reset_label": 28, "_resize_token_embed": 76, "_rotate_checkpoint": 76, "_save": 76, "_save_checkpoint": 76, "_save_optimizer_and_schedul": 76, "_save_rng_st": 76, "_save_to_state_dict": 76, "_save_tpu": 76, "_self_": 82, "_set_default_torch_dtyp": 76, "_set_gradient_checkpoint": 76, "_set_signature_columns_if_need": 76, "_slow_forward": 76, "_sorted_checkpoint": 76, "_stack_item": 19, "_strategi": 87, "_t": [8, 22, 24, 79], "_t_co": 8, "_target_": 82, "_temporary_reorder_cach": 76, "_tensor": 71, "_tensor_await": 71, "_tensor_s": 71, "_tie_encoder_decoder_weight": 76, "_tie_or_clone_weight": 76, "_to_copi": 69, "_trained_st": [25, 74], "_tune_save_checkpoint": 76, "_type": [19, 25], "_update_centroid": 28, "_update_model_kwargs_for_gener": 76, "_upload_modified_fil": 76, "_validate_generated_length": 76, "_validate_model_class": 76, "_validate_model_kwarg": 76, "_view_dim": 71, "_w": 22, "_wrap": 44, "_wrap_model": 76, "_wrapped_call_impl": 76, "a100": 73, "a100_40gb": 73, "a100_bfloat16_flops_promis": 73, "a100_bfloat16_promised_flop": 73, "a_": [14, 17, 22, 35, 73], "a_0": [14, 17], "a_1": [14, 17, 39, 40, 79], "a_2": [39, 40, 79], "a_3": 39, "a_bas": [44, 46], "a_bhl": 24, "a_d": [39, 40], "a_i": 79, "a_list": 24, "a_n": 79, "a_setup": [44, 46], "a_tensor": 71, "aaron": 1, "ab": [1, 2, 22, 30, 31, 32, 34, 40, 73, 77, 78], "abandon": 52, "abbeel": 1, "abbreiv": 24, "abbrevi": 42, "abc": [5, 9, 24, 56, 85, 87], "abcdef1234567890": 45, "abcedf": 6, "abcmeta": 3, "abid": [6, 7], "abil": [8, 16, 23, 24, 42, 54, 59, 62, 63, 64, 65], "abl": [4, 6, 8, 9, 14, 16, 19, 23, 24, 25, 31, 32, 45, 51, 52, 56, 57, 58, 65, 75, 76, 77, 80, 82], "ablat": [33, 47], "about": [6, 7, 8, 9, 10, 14, 16, 17, 22, 23, 24, 25, 27, 34, 35, 37, 38, 39, 44, 45, 46, 52, 54, 55, 56, 57, 58, 60, 62, 64, 65, 66, 71, 73, 79, 82, 85, 87], "abov": [3, 4, 6, 7, 8, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 31, 34, 40, 43, 44, 52, 65, 66, 73, 74, 76, 79, 84], "abrupt": 58, "absenc": [10, 14, 17, 24], "absent": 10, "absolut": [23, 25, 39, 40, 59, 62, 63, 66, 69, 78], "abstract": [4, 5, 6, 16, 19, 20, 24, 34, 37, 39, 56, 76, 80, 82, 85], "abstractmethod": [3, 5, 9, 24, 56, 85, 87], "abund": 52, "abus": [14, 16, 42], "ac": 40, "academ": [53, 65], "academi": [1, 14, 17, 18, 19, 20], "acceler": [23, 24], "accelerator_config": 76, "accept": [4, 6, 8, 9, 16, 19, 62, 65, 76, 80], "access": [17, 19, 24, 27, 31, 42, 51, 53, 54, 56, 78, 80, 82, 83, 85], "accid": [57, 65], "accident": 6, "accommod": [6, 23, 73], "accomplish": [24, 29, 52], "accord": [3, 5, 9, 14, 24, 25, 27, 32, 42, 51, 60, 76, 78], "accordingli": [24, 25, 54], "account": [17, 23, 24, 25, 29, 40, 42, 45, 52, 54, 59, 66, 70, 73, 74, 76], "acculum": [23, 24], "accumul": [23, 24, 25, 28, 71, 73], "accur": [22, 23, 25, 42, 45, 51, 55, 57, 59, 66, 68, 76, 79], "accuraci": [25, 27, 32, 51, 52, 54, 55, 56, 57, 59, 62, 63, 64, 65, 66, 74, 75, 77], "accuracy_scor": [32, 75, 77], "accustom": 65, "achiev": [16, 17, 19, 24, 25, 29, 31, 32, 51, 52, 54, 58, 59, 62, 63, 73, 76, 79, 80, 85], "acknowledg": [31, 38], "acronym": 73, "across": [5, 6, 11, 16, 19, 22, 23, 24, 25, 27, 31, 35, 42, 43, 44, 52, 53, 54, 56, 62, 63, 64, 65, 68, 69, 71, 78, 84], "act": [6, 16, 19, 22, 23, 24, 44, 46, 53, 54, 55, 56, 57, 60], "act_fn": 32, "action": [14, 19, 24, 27, 35, 38, 43, 44, 46, 52, 53, 56, 57, 66, 68, 71, 80], "activ": [16, 23, 25, 31, 44, 45, 54, 57, 60, 62, 65, 68, 69, 70, 71, 73, 74, 75, 78, 79], "activation_funct": 24, "activation_nam": [68, 70], "active_adapt": 76, "activityprofilercontrol": [69, 70, 71], "actual": [3, 4, 6, 8, 9, 16, 23, 24, 25, 27, 30, 31, 35, 40, 44, 45, 52, 56, 57, 58, 59, 61, 63, 66, 67, 73, 74, 75, 76, 78, 80, 82, 85], "actual_timeout": 10, "acut": 40, "acycl": 56, "ad": [3, 4, 6, 7, 8, 13, 14, 19, 22, 23, 24, 25, 29, 31, 32, 35, 53, 56, 57, 65, 71, 73, 78, 79, 83], "adafactor": 76, "adam": [1, 2, 9, 21, 23, 25, 31, 74, 78], "adam_beta1": 76, "adam_beta2": 76, "adam_epsilon": 76, "adamconfig": [25, 74], "adamw": [25, 70, 73, 75, 76, 77, 82], "adamw_torch": [32, 75, 76], "adapt": [1, 2, 3, 6, 9, 17, 21, 23, 24, 25, 27, 29, 32, 33, 54, 56, 57, 65, 73, 78, 80], "add": [3, 6, 8, 14, 17, 19, 22, 24, 27, 28, 32, 37, 38, 44, 45, 46, 52, 54, 56, 60, 65, 70, 71, 73, 76, 78, 79, 80, 82, 83, 87], "add1": 4, "add_adapt": 76, "add_argu": [44, 46, 71], "add_callback": [25, 74, 76], "add_int_and_float": 7, "add_int_and_ndarrai": 7, "add_memory_hook": 76, "add_model_tag": 76, "add_modul": 76, "add_new_employee_using_list": 8, "add_norm_1": [24, 25, 74, 75], "add_norm_2": [24, 25, 74, 75], "add_norm_config_1": [24, 25, 74], "add_norm_config_2": [24, 25, 74], "add_subplot": 38, "add_text": 37, "add_text_annot": [38, 39, 40], "add_two_int": 7, "add_vector": 37, "add_vectors_to_plott": [38, 39, 40], "addbackward0": 24, "added_tokens_decod": 75, "addedtoken": 75, "addend": 25, "adder_dataset": 25, "adderdataset": 25, "addertoken": 25, "addervocabulari": 25, "addhandl": [75, 77], "addit": [3, 5, 6, 9, 14, 16, 17, 21, 22, 23, 24, 27, 32, 33, 34, 37, 40, 45, 48, 51, 53, 54, 56, 57, 60, 64, 73, 78, 83], "addition": [23, 24, 35, 42, 44, 51, 56], "additional_metadata": [53, 60], "addnorm": [25, 74, 75, 77], "addnormconfig": [24, 25, 74, 75, 77], "address": [6, 14, 17, 24, 25, 45, 51, 53, 54, 55, 62, 64, 82], "adept": [23, 52], "adeptli": 23, "adequ": 48, "adher": [3, 5, 7, 8, 16, 17, 19, 25, 34, 37, 39, 53, 54, 55, 56, 57, 85], "adjac": 54, "adjust": [14, 16, 22, 23, 24, 25, 31, 40, 45, 51, 55, 59, 62, 73, 78], "administratoraccess": 45, "adopt": [17, 31, 55, 60, 79, 83], "advanc": [2, 3, 15, 16, 17, 21, 23, 25, 30, 31, 40, 54, 56, 62, 71, 72, 80], "advantag": [6, 17, 19, 24, 27, 31, 51, 53, 55, 80], "advent": 57, "adversari": 52, "advic": 58, "advoc": [10, 85], "aerospac": [2, 11], "affect": [3, 5, 8, 14, 17, 24, 25, 31, 38, 43, 51, 53, 56, 58, 64, 73, 79, 85], "affili": 71, "affin": 22, "affirm": 16, "afford": 51, "afforement": [25, 78], "aforement": [24, 56, 82], "afshi": 42, "after": [9, 11, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 40, 44, 45, 46, 52, 54, 55, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 73, 75, 78, 79, 80, 82, 83, 85], "ag": [35, 42, 52, 53, 54, 66], "again": [6, 7, 14, 16, 22, 24, 25, 27, 31, 39, 45, 52, 54, 56, 76, 77, 78, 79, 80], "against": [24, 27, 51, 52, 56, 57, 61, 64, 85], "agenc": 54, "agent": [55, 76], "aggreg": [6, 22, 24, 25, 52, 54, 55, 56, 65, 79], "aggregate_data": 56, "aggregated_data": 56, "aggregation_funct": 56, "aggres": 60, "agi": 52, "agil": 55, "agnost": [1, 23, 31, 55, 57, 85], "agreement": [16, 64], "ah": 25, "ahead": [24, 25, 39, 40], "ai": [1, 21, 23, 24, 30, 39, 48, 51, 57, 62, 63, 65, 73], "aid": [23, 24], "aidan": 1, "aim": [14, 16, 22, 23, 24, 25, 27, 29, 31, 35, 42, 51, 52, 79, 84], "aiop": [33, 52], "airbyt": 56, "airflow": 56, "airplan": 3, "ajax": 55, "aka": 24, "akin": [7, 14, 16, 19, 37, 80], "akra": 13, "al": [17, 22, 23, 24, 25, 31, 34, 35, 39, 78, 79], "alammar": [23, 24], "aldo": 1, "alec": 1, "alert": [52, 55, 64, 65, 66], "alex": 24, "alexand": [1, 26, 27, 42], "algebra": [1, 24, 30, 31, 34, 39, 53, 79], "algo": [15, 16], "algomonst": 14, "algorist": [15, 16], "algorithm": [1, 11, 19, 20, 22, 23, 24, 25, 26, 29, 34, 39, 40, 42, 43, 48, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 78, 79, 87], "ali": 52, "alia": [24, 68, 70], "alic": [6, 54], "align": [1, 3, 5, 6, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 31, 34, 35, 37, 39, 40, 42, 51, 52, 53, 58, 59, 64, 65, 78, 79], "alignat": 27, "all": [1, 2, 3, 4, 5, 7, 8, 9, 10, 13, 14, 16, 17, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 42, 44, 45, 46, 52, 53, 54, 56, 57, 58, 59, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 79, 82, 83, 84, 87], "all_arg": 76, "all_config": 68, "all_pr": 63, "all_reduc": 44, "allclos": [24, 28], "allen": [1, 30, 31], "aller": 23, "allevi": [23, 24], "alloc": [14, 16, 19, 33, 72, 80], "allot": 16, "allow": [3, 4, 6, 7, 8, 9, 10, 13, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 38, 51, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 69, 73, 78, 80, 82, 83, 84, 85], "almost": [3, 13, 24, 42, 79], "alon": [52, 59], "along": [17, 19, 22, 23, 24, 27, 32, 35, 38, 40, 51, 52, 54, 55, 59, 62, 64, 65, 71, 76, 82], "alongsid": [23, 62, 65], "alpha": [22, 23, 24, 25, 28, 30, 31, 32, 38, 52, 58, 77, 78, 79], "alpha_": [25, 78], "alpha_1": 78, "alpha_2": 78, "alpha_3": 78, "alpha_4": 78, "alpha_5": 78, "alpha_6": 78, "alpha_7": 78, "alpha_f": [25, 78], "alpha_t": 78, "alphabet": 17, "alphago": 52, "alreadi": [3, 14, 16, 17, 22, 24, 25, 27, 28, 32, 51, 52, 56, 57, 60, 62, 74, 80], "also": [3, 4, 5, 6, 7, 8, 9, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 52, 53, 55, 56, 57, 58, 60, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 87], "alter": [5, 8, 14, 24, 31, 38, 79, 80], "altern": [6, 14, 17, 24, 27, 38, 45, 52, 54, 55], "although": [9, 11, 14, 17, 19, 22, 23, 24, 25, 27, 29, 31, 52, 54, 62, 78], "altogeth": 14, "alwai": [5, 13, 14, 16, 17, 22, 23, 24, 25, 29, 39, 40, 43, 46, 51, 55, 57, 58, 59, 60, 61, 62, 65, 73, 76, 79], "am": [24, 25, 28, 56, 67, 69, 74], "am_i_in_jupyt": 24, "aman": [23, 24], "amax": 28, "amazon": [1, 53, 54, 55, 65], "ambient": 35, "ambigu": 24, "ameet": 42, "amen": 24, "ami": [45, 59], "aminian": 52, "amodei": [1, 2, 21, 23], "among": [22, 24, 27, 31, 35, 44, 63, 79], "amongst": [19, 52], "amount": [13, 14, 16, 19, 23, 29, 35, 51, 52, 56, 57, 65, 69, 71, 73, 79], "amp": 25, "amplif": 31, "amplifi": [23, 24, 31, 59, 79], "amplitud": 78, "amsgrad": [25, 82], "an": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 19, 22, 23, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37, 39, 40, 42, 44, 45, 46, 49, 50, 54, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 71, 73, 76, 77, 79, 82, 83, 84, 85, 87], "anaconda": 45, "analog": [17, 19, 54], "analogi": 8, "analogu": 35, "analys": 57, "analysi": [1, 6, 11, 13, 19, 22, 23, 24, 25, 26, 27, 28, 31, 33, 35, 39, 40, 48, 51, 52, 54, 55, 56, 59, 60, 64, 65, 73, 79], "analyt": [39, 40, 48, 55, 56, 57], "analyz": [14, 16, 24, 51, 52, 54, 55, 57, 64, 65], "andrej": [23, 73], "andrew": 42, "angl": 24, "ani": [3, 4, 5, 7, 8, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 64, 65, 66, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85], "anim": [3, 4, 5, 7, 23, 52, 54], "animaltyp": 7, "anneal": 33, "annot": [4, 23, 24, 25, 28, 29, 31, 32, 37, 44, 46, 67, 68, 70, 71, 74, 75, 77, 78, 82, 83, 84], "annotation_text": 37, "announc": 24, "anomali": [39, 48, 55, 57, 65, 66], "anoth": [3, 4, 6, 7, 9, 10, 16, 17, 23, 24, 25, 28, 31, 34, 40, 43, 44, 52, 54, 56, 59, 62, 65, 72, 75, 76, 79, 82], "answer": [1, 6, 16, 23, 24, 25, 27, 52, 57], "anthoni": 6, "anti": 5, "anticip": [51, 53], "anymor": [25, 27], "anyon": 39, "anyth": [13, 25, 54, 57, 74, 82, 85], "anywai": 25, "ap": 45, "apach": [54, 55, 56, 70], "apart": [24, 27, 28, 32, 80], "api": [10, 48, 53, 54, 55, 56, 64, 65, 69], "app": [51, 52, 56, 65], "app_config_group": 82, "app_nam": 82, "appar": [25, 27, 40, 57, 67], "appear": [13, 24, 37, 52, 53, 62, 65, 80], "appeas": 25, "append": [6, 8, 19, 24, 25, 28, 29, 44, 46, 56, 68, 73, 74, 76, 78, 79, 80, 82], "append_and_return_list": 6, "append_int_and_return_list": 6, "append_int_to_stack": 19, "append_pi": 8, "append_str_and_return_list": 6, "append_str_to_stack": 19, "append_to_stack": 19, "appendix": 73, "appl": 53, "appli": [3, 5, 6, 8, 13, 14, 16, 17, 22, 23, 25, 27, 30, 31, 32, 34, 35, 38, 39, 42, 51, 55, 56, 57, 68, 69, 70, 71, 74, 75, 76, 78, 79, 80, 82, 85], "applic": [2, 3, 8, 11, 14, 16, 17, 19, 23, 25, 26, 27, 31, 33, 34, 35, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 82, 84, 85], "apply_lora_to_base_model": 32, "apply_transform": 85, "apply_weight_decay_to_different_param_group": [25, 74], "appreci": [6, 29, 42], "apprehend": 16, "approach": [3, 6, 10, 13, 14, 17, 21, 24, 25, 27, 31, 35, 38, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 64, 65, 66, 78, 79, 80, 85], "appropri": [5, 16, 22, 23, 24, 25, 27, 29, 31, 32, 45, 51, 52, 54, 55, 56, 57, 59, 62, 63, 65, 79, 85, 87], "approv": [56, 64], "approx": [22, 23, 24, 31, 39, 68, 70, 73], "approxim": [4, 14, 19, 23, 25, 27, 30, 31, 35, 58, 59, 68, 70, 73, 74, 75, 79], "apr": [2, 11], "apt": [45, 56], "aptli": 7, "ar": [1, 2, 4, 5, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 21, 22, 23, 25, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 52, 53, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85], "arang": [24, 68, 70], "arbitrari": [17, 22, 24, 34, 65, 78], "arbitrarili": 35, "arbitrary_types_allow": [24, 83], "arcfac": 42, "architect": 66, "architectur": [21, 23, 25, 31, 32, 52, 53, 60, 62, 65, 73, 76], "archiv": 64, "arctan": 39, "arctang": 39, "area": [5, 16, 24, 39, 42, 52, 55, 56, 59, 65, 73], "aren": [8, 65], "arg": [4, 6, 7, 8, 9, 16, 19, 24, 25, 29, 32, 44, 46, 53, 56, 68, 71, 74, 75, 76], "arg1": 7, "arg2": 7, "argmax": [22, 23, 25, 31, 32, 74, 75, 79], "argmin": [22, 23, 24, 27, 28, 31], "argpars": [44, 46, 71], "args_list": 25, "argu": [5, 10, 28, 31, 56, 57], "argument": [4, 7, 9, 10, 19, 24, 25, 29, 75, 76, 80, 82], "argumentpars": [44, 71], "ari": 59, "aris": [3, 6, 14, 16, 19, 22, 25, 39, 42, 46, 52, 56, 65], "arithmet": [5, 25, 73, 79], "arjancod": 85, "around": [8, 10, 17, 24, 25, 32, 51, 54, 65, 67, 79, 82, 83], "arr": 29, "arrai": [6, 7, 8, 14, 19, 22, 23, 24, 28, 29, 31, 37, 39, 52, 53, 54, 56, 66, 79], "arrang": [14, 17, 27, 73], "arraylik": 24, "arriv": [16, 22, 24, 54, 65], "arrow": [17, 19, 40], "arrow_length_ratio": 38, "art": 23, "arthur": 27, "articl": [4, 6, 14, 24, 26, 27, 29, 31, 48, 52, 54, 55, 61, 65, 77], "artifact": [32, 56, 62, 75, 82, 83], "artifact_uri": 83, "artifici": 48, "arxiv": [1, 2, 21, 23, 24, 30, 31, 73, 77, 78, 79], "as_datafram": 28, "as_tensor": 24, "ascend": [14, 17, 25, 55, 68, 69, 78], "asctim": [67, 68, 69, 70, 71, 75, 77, 82], "ashish": 1, "asian": 55, "asid": 23, "ask": [8, 14, 24, 25, 31, 52, 53, 82], "aspect": [3, 10, 14, 17, 21, 35, 37, 39, 40, 48, 51, 52, 59, 60, 66], "assert": [3, 5, 9, 10, 14, 24, 25, 28, 44, 68, 69, 70, 71, 73, 74, 75, 76, 78, 82, 83], "assert_allclos": 28, "assert_array_equ": 28, "assert_clos": [22, 24, 25, 79], "assert_equ": [14, 16, 17], "assess": [3, 5, 16, 23, 29, 48, 51, 52, 53, 62, 64, 73], "asset": [14, 25, 29, 37, 38, 65, 80], "assets_dir": 29, "assign": [4, 6, 8, 9, 10, 17, 22, 24, 25, 28, 29, 39, 43, 51, 53, 54, 57, 59, 68, 70, 73, 75, 79, 82], "assign_project": 8, "assignment1": [68, 70], "assignment2": [68, 70, 72], "assimil": 23, "assist": 65, "assisted_decod": 76, "associ": [5, 17, 24, 27, 32, 34, 35, 38, 40, 43, 45, 51, 59, 60, 64, 65, 79], "assum": [4, 5, 6, 7, 8, 13, 14, 16, 17, 22, 23, 24, 25, 27, 29, 31, 32, 35, 37, 40, 42, 43, 44, 51, 54, 56, 58, 59, 73, 74, 78, 79], "assumed_mfu": 73, "assumpt": [6, 17, 24, 26, 51, 75, 79], "assur": [17, 55], "aston": [1, 24], "astyp": [24, 28, 29], "asymptot": [13, 16], "async": 71, "async_op": 44, "asynchrn": 67, "asynchron": [33, 46, 67, 68, 69], "asyncio": 71, "ate": 24, "aten": [69, 70], "atm": 53, "atol": [24, 28, 79], "attach": [45, 76], "attachment_id": 45, "attachmentid": 45, "attain": 23, "attempt": [6, 16, 24, 32, 66, 76, 80], "attend": [22, 23, 24, 25, 74], "attent": [1, 2, 21, 27, 28, 30, 31, 32, 33, 34, 53, 68, 70, 73, 75, 77], "attention_mask": [32, 74, 75, 77], "attention_matrix": [25, 74], "attention_scor": [22, 24, 68, 70, 73, 74], "attention_weight": [22, 24, 25, 68, 70, 74], "attention_weights_summed_over_sequ": 24, "attn": [22, 24, 68, 70], "attn_pdrop": [24, 68, 70], "attr": [24, 25, 68, 70], "attract": 52, "attribut": [3, 4, 6, 8, 23, 25, 28, 35, 39, 51, 53, 54, 55, 68, 70, 71, 79, 83], "attributeerror": [4, 6, 8, 10, 24, 25], "au": 23, "auc": [32, 59, 63, 64, 66, 75, 77], "audio": [52, 53, 54, 55], "audit": [55, 64], "aug": [1, 2, 21, 23, 78, 79], "augment": [13, 80, 82], "auroc": [51, 52], "authent": [23, 53, 55], "author": [8, 11, 22, 23, 24, 25, 31, 45, 48, 54, 55, 56, 57, 71, 78], "auto": [22, 25, 28, 29, 32, 44, 68, 71, 75, 76, 87], "auto_find_batch_s": 76, "autocal": 76, "autocast": [68, 70], "autocast_config": [25, 74], "autocast_smart_context_manag": 76, "autocomplet": [51, 65], "autoencod": [39, 52], "autofil": 52, "autograd": [44, 70, 71, 79], "autom": [48, 55, 57, 60, 62, 64, 66, 76], "automat": [3, 6, 9, 10, 19, 44, 52, 53, 56, 60, 62, 76], "autonom": [51, 52, 65], "autoregress": [1, 24, 25, 75], "avail": [4, 6, 9, 10, 14, 16, 23, 30, 31, 35, 44, 45, 51, 52, 53, 54, 55, 60, 62, 65, 67, 69, 77, 79, 80], "avenu": 5, "averag": [19, 24, 25, 27, 28, 29, 32, 42, 51, 52, 54, 55, 56, 58, 59, 62, 63, 75, 78, 82], "average_batch_loss": 25, "average_batch_perplex": 25, "average_precision_scor": [32, 75, 77], "avg": [25, 69, 70, 82, 84], "avg_bia": 83, "avg_expected_loss": 83, "avg_loss": [75, 77], "avg_val_loss": 75, "avg_vari": 83, "avoid": [3, 11, 14, 16, 24, 31, 32, 42, 57, 58, 59, 66, 76, 79, 83, 84], "avro": 53, "aw": [33, 43, 47, 52, 53, 55, 65], "awai": [16, 23, 24, 42], "await": [10, 71], "awaitable_leak": 71, "awaitabletensor": 71, "awaitabletensorwithviewcallback": 71, "awar": [19, 22, 53, 75], "awk": 44, "aws_access_kei": 45, "aws_secret_kei": 45, "awscli": 45, "awsec2": 45, "ax": [24, 25, 28, 29, 35, 37, 38, 39, 40, 78, 79], "ax_0": 35, "ax_kwarg": [37, 38, 39, 40], "axesimag": 29, "axi": [22, 24, 25, 27, 28, 29, 32, 37, 38, 39, 40, 59, 62, 66, 71, 75], "axiom": [16, 39], "axler": [37, 38], "azur": [48, 53, 54, 55], "b": [2, 3, 5, 7, 8, 13, 14, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 57, 59, 64, 66, 68, 70, 71, 73, 74, 75, 76, 79, 82, 85], "b_": [22, 70, 71, 73], "b_1": [35, 40], "b_2": [35, 40], "b_3": 35, "b_d": 40, "b_demo": 44, "b_i": 35, "b_m": 35, "b_n": 35, "ba": [1, 2, 21, 23, 25, 34], "back": [8, 11, 14, 16, 19, 22, 23, 24, 25, 27, 29, 32, 35, 45, 51, 54, 56, 60, 65, 68, 70, 78, 80, 82], "backbon": [23, 24, 29, 31, 55, 68, 70, 74, 75], "backbone_last_layer_hidden_st": 75, "backdrop": 3, "backend": [24, 25, 31, 46, 60, 74], "background": [3, 23, 24, 65], "backoff": 56, "backoff_factor": [25, 74], "backpropag": [24, 25, 31, 39, 73, 79], "backtick": 8, "backtrack": 62, "backup": [55, 56], "backward": [8, 24, 44, 68, 70, 71, 73, 75, 77, 82], "backward_pass": 70, "backward_tot": 73, "bad": [6, 25, 28, 31, 56, 59, 74], "bag": [57, 58], "baguett": 35, "bahdanau": [1, 24, 73], "bake": 35, "balanc": [23, 24, 25, 51, 54, 57, 63, 65, 77], "ball": [3, 4, 5], "banach": [1, 39], "banana": [15, 33, 54], "bandwidth": [16, 29], "bank": [23, 24, 53, 54], "bar": [25, 79, 82], "barbara": 5, "bare": 83, "barrier": 44, "base": [3, 6, 8, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 33, 35, 37, 38, 39, 40, 42, 45, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 74, 76, 78, 79, 80, 82, 84, 85], "base_class": 76, "base_config": 82, "base_model": [32, 74, 75], "base_model_merged_and_unload": 32, "base_model_total_train": 32, "base_model_with_adapt": 32, "base_model_with_adapter_total_train": 32, "basedecod": 24, "baseestim": [9, 28], "baselin": [23, 48, 52, 59, 62, 64], "basemodel": [24, 32, 44, 56, 68, 70, 73, 76, 82, 83, 84], "bash": [45, 56], "bashrc": 45, "basi": [4, 23, 35, 37, 57], "basic": [1, 3, 5, 11, 13, 17, 22, 24, 25, 26, 27, 31, 32, 33, 42, 47, 52, 55, 56, 62, 68, 72, 74, 75, 76, 78, 79, 80, 82], "basic_launch": 82, "basic_sweep": 82, "basicconfig": [67, 68, 69, 70, 71], "basiclaunch": 82, "basicsweep": 82, "batch": [23, 31, 32, 48, 54, 62, 68, 70, 73, 74, 75, 76, 77, 80, 82, 83], "batch_decode_equ": 25, "batch_first": [25, 74], "batch_index": [25, 74], "batch_siz": [24, 25, 32, 68, 70, 73, 74, 75, 77, 80, 82, 84], "batchmean": 77, "batchnorm": 25, "bathroom": 42, "bay": 79, "bayesian": [60, 62, 79], "bazzi": 13, "bbb": 22, "bc": 34, "beam": 70, "beam_sampl": 76, "beam_search": 76, "bear": 54, "beast": 56, "beat": 17, "beatrix": 70, "beauti": 55, "becaus": [3, 4, 5, 6, 7, 8, 9, 10, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 44, 45, 46, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 65, 66, 67, 69, 71, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85], "becom": [3, 5, 6, 14, 16, 19, 22, 23, 24, 25, 29, 31, 34, 35, 38, 51, 52, 54, 55, 56, 60, 62, 65, 66, 69, 78, 79, 80, 85, 87], "bedrock": 17, "bedroom": 42, "been": [6, 10, 14, 16, 17, 21, 24, 27, 32, 39, 40, 42, 43, 45, 55, 56, 57, 59, 63, 64, 66, 76, 80, 83], "befor": [3, 4, 8, 10, 11, 14, 16, 17, 19, 23, 24, 25, 27, 29, 31, 32, 35, 38, 40, 44, 45, 46, 51, 52, 54, 56, 57, 58, 59, 62, 64, 65, 66, 67, 68, 71, 73, 75, 76, 78, 79, 80, 82, 83], "beforehand": [25, 27], "begin": [13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 34, 35, 37, 38, 39, 40, 42, 52, 53, 56, 59, 62, 66, 73, 78, 79], "beginn": [25, 58, 62, 77], "behalf": 45, "behav": [3, 5, 7, 8, 35], "behavior": [3, 4, 5, 8, 16, 17, 19, 24, 25, 31, 42, 48, 51, 52, 57, 58, 59, 62, 65, 66, 75, 77, 78, 80, 82, 84], "behaviour": [8, 10, 24, 25, 70], "behind": [14, 16, 19, 22, 24, 25, 27, 38, 56, 78], "beij": [48, 51, 53, 54, 56], "being": [3, 5, 7, 8, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 34, 35, 39, 46, 51, 52, 54, 55, 57, 65, 73, 75, 78, 79, 80, 84], "believ": [23, 24, 52], "bell": [54, 76], "belong": [3, 22, 27, 28, 37, 59, 62, 79], "below": [3, 4, 6, 7, 8, 9, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 32, 34, 35, 39, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 57, 60, 62, 69, 71, 73, 74, 75, 78, 79, 82, 83, 85], "benchmark": [23, 24, 31, 51, 52, 58, 60, 62, 64, 70, 72], "bend": [17, 19], "benderski": 79, "benefici": [6, 17, 22, 23, 24, 25, 39, 57, 58, 66, 83, 84], "benefit": [17, 23, 24, 56, 75, 80], "bengio": [1, 2, 79], "benign": 59, "bentlei": 13, "bernoulli": 22, "bert": 52, "besid": [10, 24, 34, 83], "best": [24, 25, 27, 28, 29, 35, 42, 48, 52, 53, 54, 55, 57, 58, 62, 65, 67, 83], "bet": 24, "beta": [22, 24, 25, 35, 52, 74, 79, 82], "beta_1": 25, "beta_2": 25, "beta_d": [22, 24], "better": [4, 16, 22, 23, 24, 25, 27, 28, 29, 35, 42, 48, 51, 52, 53, 54, 57, 58, 60, 62, 64, 66, 72, 74, 75, 77, 78, 82], "better_knowledge_distil": 77, "between": [3, 6, 7, 8, 9, 10, 13, 14, 16, 17, 22, 23, 24, 25, 27, 28, 29, 31, 34, 35, 37, 38, 39, 42, 51, 52, 53, 56, 57, 58, 59, 60, 62, 63, 66, 73, 74, 77, 78, 79, 80, 83, 84, 85], "beyond": [1, 2, 14, 16, 21, 23, 25, 51, 58, 59, 60, 62, 64, 76, 78], "bf16": [73, 76], "bf16_full_ev": 76, "bfloat16": [68, 70, 73, 76], "bi": [23, 54], "bia": [22, 24, 25, 32, 42, 62, 64, 68, 70, 73, 74, 75, 77, 78, 79], "bias": [22, 23, 24, 25, 57, 60, 66, 73], "bibliographi": 33, "bidirect": [21, 23, 24], "big": [13, 16, 25, 30, 31, 51, 56, 82], "bigcup_": 22, "bigger": 6, "biggest": 58, "bigoplus_": 22, "bigqueri": [52, 54, 55], "bigsqcup_": [27, 79], "biject": [22, 74], "bike": 57, "bilinear": 40, "billion": 31, "bin": [24, 44, 45, 56, 59], "binari": [13, 17, 22, 24, 33, 51, 52, 54, 55, 58, 59, 62, 64, 71], "binary_search": 14, "binary_search_it": 14, "binary_search_recurs": 14, "binary_search_recursive_help": 14, "bincount": 79, "bind": [6, 85], "biomark": 51, "bird": [3, 4], "bisect": 14, "bishop": [1, 2, 26, 27, 29, 79], "bit": [14, 17, 23, 24, 30, 44, 52, 53, 61, 62, 73, 78, 82], "bitcoin": 66, "bitshift": 5, "bla": 53, "blabber": 79, "black": [24, 28, 52, 63, 72], "blacklist": 25, "blacklist_weight_modul": 25, "blob": [32, 53, 55, 68, 70], "block": [23, 25, 40, 46, 53, 67, 68, 69, 70, 73, 80], "block_siz": [24, 73], "blog": [14, 17, 23, 24, 27, 30, 45, 55, 58, 71, 73], "blood": 52, "blostein": 13, "blue": [19, 22, 29, 35, 38, 39, 40, 64], "blur": [23, 25], "bmatrix": [22, 24, 27, 29, 35, 37, 38, 39, 40, 42, 53, 73, 79], "bmm": 70, "bmmbackward0": 70, "bmp": 29, "bmw": 53, "bo": [22, 25], "board": 68, "bob": [6, 54], "bodi": [9, 17, 80], "bold": 37, "boldsymbol": [22, 23, 24, 25, 27, 29, 31, 42, 53, 78], "book": [1, 19, 24, 35, 42, 52, 58, 62, 65, 87], "bool": [3, 6, 8, 16, 17, 19, 24, 25, 28, 29, 31, 56, 60, 67, 68, 70, 71, 73, 74, 75, 76, 78, 82, 83, 84], "boolean": [6, 10, 17, 24, 29, 53], "booleanpair": 6, "booltensor": [24, 25, 68, 70, 74, 75], "boost": [52, 58, 87], "bootstrap": 63, "border": [17, 19], "born": [6, 11, 54], "born_in": 54, "bos_token": 75, "bos_token_id": 24, "boss": 59, "boston": [26, 27], "bot": 24, "both": [3, 4, 5, 6, 7, 8, 9, 10, 16, 17, 19, 22, 23, 24, 25, 27, 28, 31, 34, 35, 37, 38, 39, 40, 44, 45, 51, 52, 53, 54, 56, 57, 60, 62, 64, 65, 66, 73, 74, 75, 79, 80, 83, 84, 85], "boto3": 55, "bottleneck": [55, 56, 73], "bottom": [37, 38, 39, 40, 79], "bound": [6, 10, 11, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 33, 40, 52, 58, 76, 78, 80], "boundari": [7, 14, 16, 51, 57, 79], "bounded": [22, 24], "bow": 57, "box": [17, 19, 52, 63, 65, 72, 82], "box1": 17, "box7": 17, "bpe": 24, "branch": 4, "brandon": [23, 24], "breach": 64, "bread": 35, "break": [3, 8, 14, 17, 24, 25, 28, 31, 32, 45, 52, 56, 74, 75, 77, 78], "breakdown": 80, "breakthrough": 21, "breath": 16, "brent": 24, "bridg": [34, 53], "brief": [4, 30, 31, 52, 53, 58], "briefli": [14, 17, 24, 25, 79], "brier": [32, 75], "brier_scor": [32, 75], "brier_score_loss": [32, 75, 77], "bring": [31, 54], "broad": [23, 56, 65, 76], "broadcast": [7, 22, 25, 74, 75], "broader": [6, 8, 16, 25, 38, 55, 65], "broadli": 6, "broken": [16, 23, 52], "broker": 53, "brows": [52, 65], "browser": [19, 53], "brute": 17, "bryan": 1, "bson": 54, "bst": 14, "bt": 24, "bubbl": 14, "budget": [51, 53], "buffer": [44, 68, 70, 71, 73, 76], "bug": [4, 6, 14, 56, 83], "bui": [17, 54], "build": [4, 8, 22, 23, 24, 25, 35, 40, 51, 52, 54, 55, 56, 57, 59, 62, 63, 74], "builder": 56, "built": [9, 19, 24, 25, 31, 53, 54, 55, 56, 60, 64, 69, 76, 80, 82], "builtin": [6, 9, 76, 80], "bunch": 73, "burden": [22, 23], "burst": 45, "busi": [54, 55, 56, 57, 59, 62, 64, 65, 82], "buster": 56, "butter": 35, "button": 19, "buyer": 54, "bwd": 73, "bxc": 73, "bxd": 73, "bxt": 25, "by_0": 35, "bypass": [6, 14], "byte": [24, 53, 73, 80], "byteunit": 73, "c": [1, 2, 3, 4, 5, 8, 9, 11, 13, 14, 16, 17, 21, 22, 23, 24, 25, 27, 28, 31, 34, 35, 37, 38, 39, 40, 42, 53, 58, 69, 71, 73, 74, 75, 76, 78, 79, 82], "c10d": [44, 45], "c408": [68, 70], "c416": 25, "c_": [13, 14, 22, 23, 28, 73], "c_1": [27, 28], "c_2": [27, 28], "c_k": [27, 28], "c_proj": 24, "cach": [32, 53, 56, 65, 68, 76, 77], "cache_en": [25, 74], "caim": 1, "caiu": 24, "calcul": [5, 8, 14, 16, 22, 23, 24, 25, 28, 29, 31, 33, 35, 39, 40, 42, 54, 56, 62, 63, 65, 66, 71], "calculate_al": 8, "calculate_checkpoint_s": 73, "calculate_fluff_ratio": 73, "calculate_memory_ratio": 73, "calculate_num_bit": 29, "calculu": [52, 73, 79], "calibr": [23, 52, 62], "call": [3, 4, 6, 8, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 34, 35, 39, 40, 43, 44, 46, 53, 54, 56, 66, 67, 69, 70, 71, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85, 87], "call_model_init": 76, "callabl": [3, 24, 25, 28, 53, 69, 71, 76, 85], "callback": [25, 71, 73, 76, 82, 84], "caller": [8, 80, 85], "cam": 58, "cambridg": [1, 2, 21, 23, 34, 35, 39, 78, 79], "came": [23, 24, 25], "camera": [17, 52, 57, 65], "campaign": 65, "can": [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 22, 23, 24, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87], "can_gener": 76, "can_we_fli": [3, 4], "canari": 64, "cancel": [40, 51, 73], "cancer": [52, 59, 62], "candid": [16, 64], "cannot": [3, 4, 5, 7, 8, 13, 14, 16, 17, 19, 23, 24, 25, 27, 31, 35, 39, 40, 52, 54, 74, 76, 82, 85], "canon": 82, "cap": 23, "capabl": [3, 6, 8, 23, 24, 53, 55, 56, 65, 73, 76], "capac": [19, 22, 24, 42, 51, 55, 61, 62, 73], "capit": [54, 65], "captcha": 55, "caption": 52, "captiv": 16, "captur": [9, 16, 22, 23, 24, 25, 31, 48, 52, 55, 57, 65, 66, 71, 79], "car": [3, 4, 7, 53, 57], "card": [52, 53, 65], "cardin": 27, "care": [5, 6, 25, 28, 56, 62], "carefulli": [22, 45, 51, 52, 57, 83], "carelessli": 24, "carol": 54, "carri": [22, 23, 24, 52, 56], "cart": 65, "cartesian": [23, 35], "case": [3, 5, 6, 8, 9, 22, 23, 25, 27, 28, 29, 31, 32, 38, 39, 40, 42, 43, 44, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 66, 67, 73, 74, 75, 76, 78, 82], "caskroom": 28, "cassandra": [53, 55], "cast": [6, 24, 25, 68, 70, 77], "cat": [3, 4, 7, 22, 23, 24, 42, 44, 45, 52, 53, 54, 77], "catalog": [17, 51, 53], "catch": [4, 6, 80], "categor": [25, 27, 37, 52, 53, 57, 58, 59], "categori": [3, 23, 24, 25, 31, 51, 52, 53, 60, 65], "caught": [4, 6, 80], "caus": [4, 6, 23, 24, 25, 28, 29, 31, 54, 60, 68, 70, 79, 80, 82], "causal": [21, 68, 70, 75, 77], "causal_attent": 24, "causal_mask": [68, 70, 75], "causal_mha": 24, "causalmultiheadselfattent": [68, 70], "cc": [32, 82], "cccc": 22, "cd": [45, 55, 62, 64], "cdf": [22, 24], "cdot": [14, 16, 17, 22, 23, 24, 25, 27, 29, 31, 35, 37, 38, 39, 40, 42, 73, 77, 79], "ce": 77, "ce_loss": 77, "ceil": [14, 29], "cell": [27, 28, 32], "censu": 53, "center": [10, 17, 19, 24, 28, 42, 79], "central": [8, 35, 37, 38, 54, 55, 56, 60, 62, 64, 84], "centroid": [28, 29], "centroids_s": 29, "centuri": 11, "ceo": 8, "certain": [3, 7, 16, 17, 22, 23, 24, 25, 27, 34, 35, 38, 48, 52, 54, 56, 57, 59, 61, 62, 65, 78, 79, 82], "certainti": [34, 52, 59], "cfg": [25, 56, 82], "cfn": 45, "chadha": [23, 24], "chain": [5, 22, 31, 52, 79, 82], "challeng": [16, 23, 24, 25, 27, 31, 51, 52, 65], "chanc": [17, 24, 59, 64], "chang": [3, 4, 7, 8, 14, 17, 23, 24, 25, 27, 28, 31, 37, 38, 45, 48, 51, 54, 55, 56, 57, 58, 60, 62, 65, 66, 74, 76, 78, 79, 82, 83, 84, 85, 87], "changer": 17, "channel": 29, "chaotic": 62, "chapter": [17, 21, 23, 24, 26, 27, 29, 35, 37, 38, 39, 42, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 65, 78, 79], "char": 24, "charact": [22, 23, 24, 25, 52, 53, 54], "character": [14, 19, 23, 38, 42, 43], "characterist": [3, 17, 24, 25, 35, 51, 53, 57, 59, 62, 79], "charger": 17, "charl": 1, "charli": 6, "chart": 66, "chase": [16, 22], "chatbot": [51, 65], "chatgpt": [23, 24, 55], "chdir": 82, "cheap": [45, 53], "check": [3, 5, 6, 9, 10, 11, 14, 16, 17, 19, 24, 32, 45, 54, 55, 56, 60, 61, 62, 64, 66, 75, 77, 80, 82, 83], "check_output": 60, "checker": [3, 4, 5, 6, 7, 8, 19], "checklist": 64, "checkout": 60, "checkpoint": [23, 24, 25, 32, 46, 56, 74, 75, 77, 83], "checkpoint_s": 73, "chees": 22, "chef": 45, "chelsea": 1, "chen": [1, 2, 21, 23, 30, 31, 35, 78], "cheng": 1, "chervonenki": 42, "chess": 16, "chicken": 24, "chief": 24, "child": [1, 2, 13, 21, 23], "child_class_methods_using_dict": 76, "child_class_methods_using_dir": 76, "child_class_methods_using_getmemb": 76, "child_class_methods_using_var": 76, "childclass": 76, "children": [13, 32, 76], "chip": [26, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 65], "chloe": 54, "chmod": [45, 56], "cho": 1, "choic": [16, 17, 22, 24, 25, 27, 28, 35, 37, 39, 51, 52, 53, 54, 55, 58, 59, 60, 62, 65, 78, 79, 82], "choo": 35, "choos": [9, 13, 16, 17, 22, 25, 42, 53, 55, 58, 62, 65, 73, 74, 76, 79], "chose": [24, 71], "chosen": [14, 16, 22, 24, 27, 32, 35, 37, 53, 57, 60, 62, 65], "christian": [69, 70, 72], "christianjmil": 68, "christoph": [1, 26, 27, 29, 79], "chromadb": 8, "chrome": 69, "chronolog": 17, "chunk": [24, 25], "chunk_siz": 24, "churn": [51, 52], "ci": [26, 55, 62, 64], "cifar10": 82, "cine": 23, "cinema": 23, "circl": [23, 27], "circular": 5, "citat": 33, "cite": [23, 73], "citi": [24, 54, 57], "citizen": [8, 24], "civitai": 30, "ck": 40, "ckpt": 73, "cl": [3, 8, 10, 22, 24, 75, 76, 82, 83, 84], "cl100k_base": 24, "claim": [16, 25, 27, 78], "clarifi": [65, 80], "clariti": [3, 5, 6, 10, 14, 19, 25, 38, 40, 44], "class": [4, 5, 6, 7, 8, 9, 10, 14, 16, 19, 23, 24, 25, 27, 28, 32, 33, 42, 44, 51, 52, 56, 58, 59, 62, 68, 70, 71, 73, 74, 75, 77, 79, 80, 82, 83, 84, 85, 87], "class_annot": 76, "class_attr": 76, "class_child": 76, "class_child_all_memb": 76, "class_field": 76, "class_idx": 28, "class_index": [32, 75], "class_method": 76, "class_par": 76, "classcastexcept": 6, "classes_to_inspect": 76, "classic": [8, 19, 35, 52, 57, 58, 65, 71], "classif": [23, 27, 30, 32, 33, 42, 52, 53, 57, 58, 62, 63, 66, 77, 79, 85], "classifi": [3, 23, 27, 42, 52, 58, 59, 74, 77], "classmethod": [3, 76, 82, 83, 84], "classvar": 8, "claus": [54, 80], "clean": [23, 55, 56, 57], "clean_data": 56, "clean_up_tokenization_spac": [75, 77], "cleaner": 84, "cleanup": [68, 80], "clear": [5, 6, 7, 9, 10, 13, 19, 22, 23, 24, 25, 27, 28, 31, 42, 51, 54, 64, 71, 74, 80, 85], "clear_output": 74, "clearer": [10, 24, 69], "clearli": [3, 16, 23, 24, 29, 51, 54, 74], "click": [17, 19, 44, 51, 52, 65, 66], "client": [16, 45, 53, 87], "clifford": 1, "clinic": 51, "clinician": 51, "clip_grad_norm": [25, 74], "clock": 16, "clone": [24, 25, 45, 70], "close": [5, 6, 10, 14, 16, 22, 23, 24, 28, 45, 52, 59, 64, 66, 73, 79], "closer": [22, 24, 25, 27, 39, 40, 52, 65, 79], "closest": [27, 28, 29, 65], "closur": 34, "cloud": [16, 45, 53, 55, 56, 66], "clr": 17, "cls_index": 24, "cluster": [26, 28, 29, 33, 39, 42, 43, 44, 52, 55, 56, 57, 58, 62], "cluster_1": 28, "cluster_2": 28, "cluster_3": 28, "cluster_assign": 28, "cluster_centers_": 29, "cluster_idx": 28, "cluster_nam": 45, "cluster_std": 28, "clustermgtd": 45, "clusterstatusmgtd": 45, "cmap": [24, 25, 28, 74], "cmd": 56, "cmu": 27, "cnn": [52, 54, 58], "co": [13, 22, 24, 25, 32, 40, 77, 78], "coars": 29, "cockroachdb": 54, "codd": 54, "code": [3, 4, 5, 6, 7, 8, 9, 10, 16, 22, 23, 24, 25, 27, 28, 33, 38, 43, 45, 46, 54, 55, 56, 61, 67, 69, 71, 72, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85, 87], "codebas": [60, 76, 82, 83, 84], "codebook": 29, "codomain": 22, "coeffici": [35, 59], "coerc": [3, 6], "coercion": [9, 24, 82], "coerciv": [2, 11], "coexist": 6, "coher": [23, 24, 29], "cohes": [9, 53, 56], "coincid": [24, 25, 27, 29, 35, 73, 78, 79, 83], "col": [37, 53, 68], "col_idx": 53, "col_v": 37, "colab": [23, 24], "cold": 68, "collabor": [55, 56, 60, 64, 66], "collaps": 43, "collat": 77, "collate_fn": [25, 74, 75, 77], "collate_fn_config": 25, "collate_for_birect": 74, "collate_for_unidirect": [74, 75], "collated_batch": 74, "collect": [3, 7, 8, 9, 19, 22, 23, 27, 28, 31, 34, 37, 42, 43, 44, 51, 52, 53, 54, 56, 57, 58, 62, 63, 65, 68, 69, 70, 71, 75, 77, 79, 80], "colleg": 40, "collinear": 40, "colon": 34, "color": [22, 24, 28, 29, 35, 37, 38, 39, 40, 54, 57, 71], "color_bgr2rgb": 29, "colorbar": 24, "colored_imag": 29, "columbia": 17, "column": [22, 24, 25, 28, 31, 37, 38, 42, 52, 54, 63, 68, 69, 76, 79], "com": [1, 24, 25, 29, 31, 32, 45, 68, 70, 75, 77], "combin": [6, 9, 13, 17, 22, 23, 24, 25, 27, 34, 38, 42, 44, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 77, 78, 82], "combinatori": [16, 23, 27], "come": [3, 4, 6, 8, 9, 14, 16, 19, 22, 24, 25, 27, 29, 31, 32, 35, 39, 51, 52, 54, 55, 56, 60, 62, 65, 73, 78, 79, 80, 82, 83], "comm": 44, "command": [31, 65, 73, 82], "commenc": 78, "comment": [13, 42, 52, 57, 75], "commerc": 65, "commerci": 53, "commit": [14, 51, 54, 56, 60], "commit_hash": 60, "common": [3, 4, 9, 10, 16, 17, 22, 23, 24, 25, 27, 31, 35, 37, 39, 40, 44, 52, 54, 56, 57, 58, 59, 61, 62, 63, 65, 73, 79, 83, 85], "common_ax_kwarg": 40, "common_issu": 8, "commonli": [17, 22, 23, 24, 25, 31, 35, 42, 52, 57, 73], "commonsens": 23, "commun": [23, 24, 43, 44, 51], "commut": [5, 34, 40], "compact": [53, 79], "compactli": 22, "compani": [31, 35, 51, 52, 54, 65], "compar": [7, 13, 14, 16, 17, 22, 23, 24, 25, 27, 28, 29, 39, 43, 51, 52, 53, 54, 55, 59, 60, 61, 62, 63, 64, 66, 73, 78, 79, 80, 83], "compare_model": 83, "comparison": [7, 17, 58, 59, 62, 71, 73, 79], "comparison_msg": 73, "comparison_result": 73, "compass": 16, "compat": [3, 4, 5, 8, 9, 24, 25, 52, 53, 55, 56, 64], "compens": 31, "competit": 58, "compil": [4, 6, 9, 11, 23, 25, 59, 68, 76, 82], "complain": [9, 24, 82], "complaint": 82, "complement": 55, "complet": [14, 16, 17, 21, 22, 23, 24, 25, 27, 35, 38, 40, 54, 56, 59, 60, 63, 64, 67, 69, 70, 71, 73, 76, 78, 80], "completion_statu": 80, "complex": [3, 6, 8, 10, 13, 22, 23, 25, 26, 28, 31, 33, 34, 37, 39, 40, 42, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 65, 73, 76, 82], "compli": 13, "complianc": [52, 53, 64], "complic": 76, "compon": [16, 22, 24, 25, 31, 37, 38, 39, 40, 42, 45, 56, 57, 60, 62, 66, 73, 79, 83, 84], "compos": [73, 74, 82, 83, 84], "composer_block_s": 24, "comprehend": [19, 34, 37, 38], "comprehens": [10, 17, 23, 24, 31, 34, 40, 45, 52, 56, 59, 62, 64, 79, 80], "compress": [24, 25, 26, 31, 33, 38, 55, 75], "compress_imag": 29, "compressed_imag": 29, "compressed_image_s": 29, "compressed_ratio": 29, "compressed_s": 29, "compression_ratio": 29, "compris": [23, 29, 35], "compromis": [5, 8, 23], "comput": [5, 8, 11, 14, 16, 17, 19, 22, 23, 26, 27, 28, 29, 31, 34, 35, 37, 39, 40, 42, 43, 44, 46, 51, 52, 53, 54, 55, 56, 57, 60, 65, 66, 68, 71, 73, 76, 77, 78, 79, 80], "computation": [16, 24, 27, 31, 51, 52, 54, 62, 65], "compute_lora_paramet": 31, "compute_loss": 76, "compute_loss_context_manag": 76, "compute_metr": [32, 75, 76], "compute_metrics_for_single_label_classif": [32, 75], "compute_transition_scor": 76, "computed_field": 24, "computeresourc": 45, "con": 65, "conan": 54, "concat": [22, 24, 25], "concaten": [4, 24, 25, 52], "concav": 79, "concentr": [16, 23, 65, 79], "concept": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 18, 20, 21, 24, 25, 26, 29, 30, 33, 34, 35, 37, 38, 39, 40, 42, 43, 52, 54, 58, 62, 63, 65, 69, 78, 85], "conceptu": [3, 14, 17, 22, 23, 25, 38, 80], "concern": [3, 23, 35, 52, 53, 76, 85], "concis": [16, 40, 54, 60], "conclud": [14, 16, 17, 79], "conclus": [6, 14, 17, 25, 39, 59, 78], "concret": [3, 6, 8, 16, 22, 23, 24, 25, 27, 29, 31, 35, 38, 42, 43, 45, 51, 65, 66, 71, 75, 78, 79, 80, 85, 87], "concurr": [23, 33, 46, 54, 55], "conda": [32, 45, 71, 75, 77], "condens": 3, "condit": [5, 8, 10, 13, 14, 16, 17, 22, 24, 25, 31, 32, 40, 46, 54, 55, 58, 62, 64, 73, 74, 78, 79, 80], "condition": 23, "conduct": [54, 56, 57, 60, 62, 64, 66], "conf": [56, 82], "confid": [52, 66], "config": [10, 32, 44, 45, 46, 56, 60, 68, 70, 74, 75, 76, 77, 83], "config_arg": 73, "config_class_str": 76, "config_dict": [82, 84], "config_manag": [25, 82], "config_nam": [68, 82], "config_obj": 82, "config_path": 82, "config_pydant": 82, "config_sourc": 82, "config_stor": 82, "configclass": 76, "configer": 71, "configstor": 82, "configur": [10, 25, 31, 33, 43, 44, 53, 55, 56, 60, 62, 68, 78, 83], "configure_deterministic_mod": [24, 31, 60], "configure_logg": 44, "confirm": [5, 13, 16, 17, 24, 35, 48, 56, 73], "conflict": [52, 70], "conform": [5, 56, 57, 80], "confus": [10, 16, 22, 23, 24, 25, 27, 28, 31, 32, 35, 39, 42, 65, 73, 75, 78], "confusion_matrix": [32, 75, 77], "congest": 57, "conjectur": [23, 24], "conjunct": 62, "connect": [10, 11, 14, 16, 17, 27, 44, 54, 55, 56, 65, 79, 84], "connector": 55, "conquer": 14, "consecut": [9, 53, 74], "consequ": [3, 4, 6, 7, 8, 9, 14, 16, 17, 23, 24, 25, 27, 29, 35, 37, 39, 40, 43, 44, 46, 52, 57, 59, 73, 75, 78, 79, 80], "conserv": 4, "consid": [3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 35, 37, 38, 39, 40, 42, 43, 44, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 73, 74, 75, 78, 79, 80], "consider": [14, 16, 25, 51, 58, 78, 79], "consist": [5, 6, 14, 16, 17, 19, 22, 23, 24, 31, 34, 35, 37, 39, 40, 42, 55, 56, 59, 64, 73, 74, 79], "consol": [17, 25, 45, 74, 82], "constaint": 14, "constant": [13, 14, 16, 17, 19, 22, 24, 25, 27, 31, 35, 58, 59, 65, 68, 74, 78, 79], "constant_": 24, "constantli": [52, 59, 62, 65], "constitut": [16, 29, 65], "constrain": [58, 82], "constrained_beam_search": 76, "constraint": [6, 8, 11, 23, 24, 25, 33, 35, 54, 58, 60, 78, 82], "construct": [3, 6, 16, 22, 27, 51, 52, 59, 62, 70, 71, 79], "construct_dummy_batch_causal_mask": 75, "construct_dummy_batch_cross_attention_mask": 74, "construct_dummy_batch_future_mask": [24, 25, 74], "construct_dummy_batch_target_padding_mask": [24, 25, 74], "construct_target_tensor": 25, "constructor": [6, 8, 56, 76, 84, 85], "consult": 10, "consum": [8, 16, 25, 31, 53, 54, 55, 56, 65, 73, 80], "consumpt": [31, 35], "contain": [3, 4, 8, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 35, 42, 53, 54, 55, 56, 62, 65, 73, 75, 76, 79, 80, 82, 84, 85], "contend": 23, "content": [3, 14, 23, 24, 31, 34, 52, 53, 55, 57, 65, 80, 82], "context": [3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 21, 22, 25, 29, 31, 34, 35, 37, 38, 39, 40, 42, 43, 44, 51, 52, 55, 56, 57, 58, 59, 62, 65, 66, 68, 70, 73, 74, 75, 79, 80, 83, 84, 85, 87], "context_dir": 56, "context_fc": [24, 25, 68, 70, 74, 75], "context_length": [24, 25, 68, 70, 73, 74, 75], "context_project": [22, 24, 25, 68, 70, 74, 75], "context_vector": [22, 24, 25, 68, 70, 74], "context_vector_concat": 24, "contextlib": [68, 70], "contextu": [22, 24, 31, 34, 54, 65, 74], "contigu": [17, 22, 24, 25, 53, 68, 70, 74, 75], "conting": [23, 28, 34], "contingency_matrix": 28, "contingency_matrix_": 28, "continu": [14, 22, 25, 28, 33, 46, 48, 51, 52, 53, 55, 56, 57, 58, 59, 65, 66, 67, 73, 76, 78, 80], "contra": 8, "contract": [6, 7, 85], "contradict": 8, "contrari": 27, "contrarili": 8, "contrast": [3, 16, 23, 24, 34, 51, 53, 55, 61, 65, 79], "contrastive_search": 76, "contravari": [11, 17, 33], "contribut": [14, 23, 24, 25, 28, 31, 39, 73, 77, 78], "contributor": [24, 55], "control": [3, 10, 14, 24, 55, 56, 58, 60, 62, 66, 76, 77, 80, 82, 84, 85], "conundrum": 16, "conv1d": 32, "conveni": [16, 23, 24, 25, 27, 39, 44, 45, 58, 68, 70, 76], "convent": [22, 23, 24, 25, 35, 37, 54, 74, 79, 85], "convention": [9, 37], "converg": [16, 22, 24, 25, 26, 28, 29, 31, 78, 79], "convers": [3, 6, 8, 14, 16, 17, 21, 31, 35, 38, 51, 55, 56, 65, 79], "convert": [3, 6, 13, 22, 24, 25, 29, 37, 52, 53, 54, 55, 57, 73, 76, 77, 82], "convex": [24, 27, 79], "convinc": 83, "convolut": [24, 52, 54, 58, 71], "cookbook": 24, "cooki": 55, "coordin": [28, 35, 44, 79], "coordinat": 35, "copi": [8, 13, 19, 24, 28, 32, 45, 53, 55, 56, 73, 78, 83], "copy_": 69, "coqa": 23, "core": [3, 10, 14, 16, 17, 19, 21, 24, 25, 28, 39, 43, 44, 46, 73, 74, 75, 76, 77, 80, 82], "core_plugin": 82, "cormen": [1, 13, 17], "cornerston": 21, "coroutin": 80, "corpu": [23, 24, 25, 31, 73], "corr": [1, 2, 78], "correct": [3, 5, 7, 8, 9, 23, 24, 25, 27, 42, 56, 59, 74, 78, 79], "correct_predict": [75, 77], "correctli": [5, 6, 7, 14, 16, 17, 25, 42, 51, 56, 59, 65], "correl": [31, 52, 56, 57], "correspond": [3, 5, 8, 13, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 35, 37, 38, 42, 43, 44, 51, 53, 65, 74, 75, 79], "correspondingli": 74, "cosin": [24, 32, 33, 65, 75], "cosineannealinglr": [25, 74, 75], "cosineannealinglrconfig": 74, "cosineannealingwithwarmupschedul": [25, 78], "cosinedecaywithwarmupschedul": 78, "cost": [14, 16, 19, 23, 24, 28, 29, 31, 42, 51, 53, 54, 55, 56, 59, 73], "costli": [52, 53], "couchbas": 55, "could": [4, 5, 6, 7, 8, 9, 10, 16, 23, 24, 25, 35, 37, 42, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 69, 73, 78, 79, 83], "count": [8, 16, 17, 19, 25, 35, 45, 52, 55, 59, 69, 76, 80], "count_label": 75, "count_up_to": 80, "countabl": 79, "counter": [16, 25, 28, 75, 77, 80], "counterintuit": [8, 25], "counterpart": 23, "countri": [52, 54], "coupl": [3, 24, 25, 62, 78, 80, 85], "cours": [6, 14, 16, 23, 24, 25, 26, 27, 28, 32, 35, 42, 44, 52, 53, 65, 72, 76], "courvil": [1, 2, 79], "covari": [11, 17, 23, 24, 27, 33, 80], "cover": [5, 14, 24, 25, 27, 29, 54, 56, 58, 78, 82], "cpp": [69, 70, 71], "cprofil": 80, "cpu": [24, 25, 31, 32, 43, 45, 46, 53, 60, 64, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 82], "cpu_children": 69, "cpu_count": [32, 75], "cpu_par": 69, "cpu_time_tot": [69, 70], "craft": [6, 52, 61], "crash": [6, 9, 54], "crawl": 55, "creat": [5, 6, 13, 14, 19, 22, 24, 28, 32, 38, 40, 44, 52, 53, 54, 55, 56, 57, 58, 60, 64, 66, 69, 71, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85], "create_accelerator_and_postprocess": 76, "create_add_dataset": 25, "create_attention_mask": 77, "create_config_class_str": 76, "create_directori": 25, "create_extended_attention_mask_for_decod": 76, "create_incorrect_pair": 6, "create_inst": [25, 74], "create_load": 25, "create_misleading_pair": 6, "create_model_card": 76, "create_optim": 76, "create_optimizer_and_schedul": 76, "create_profile_config": 68, "create_schedul": 76, "create_silent_error_pair": 6, "create_tabbed_svg_view": 14, "create_target_mask": [24, 25], "created_at": 56, "creation": [6, 44, 64, 84, 85], "creativ": 21, "creator": 82, "credenti": [45, 55, 84], "credit": [13, 23, 24, 25, 31, 39, 40, 48, 51, 52, 53, 54, 56, 59, 62, 65, 71, 78], "crimin": 54, "crit": [13, 14], "criteria": [3, 4, 51, 54, 55, 64], "criterion": [4, 8, 16, 24, 27, 68, 70, 74, 75, 83], "criterion_config_cl": [25, 74], "criterion_pydantic_config": [25, 74], "criterion_registri": [25, 74], "critic": [4, 13, 14, 21, 24, 25, 51, 52, 53, 56, 57, 59, 60, 64, 66], "croissant": 35, "cronjob": 56, "crop": [24, 68, 70], "crop_context_length": [68, 70], "cross": [23, 24, 25, 27, 33, 38, 40, 52, 57, 58, 63, 64, 75, 77, 79], "cross_attention_mask": 74, "crossentropyloss": [24, 25, 68, 70, 71, 74, 75, 77, 82], "crossentropylossconfig": 74, "crowdsourc": 53, "crucial": [3, 5, 6, 13, 17, 19, 24, 34, 35, 37, 39, 40, 51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66], "crud": 54, "crux": [16, 23], "cry": 32, "crystallographi": 27, "cs170": 14, "cs2030": [4, 5, 6, 8], "cs211": 14, "cs2112": 14, "cs324": [23, 24], "cs336": [43, 44, 68, 70], "csc412": [23, 24], "cse": 14, "cse241": 14, "css": 55, "csv": [52, 53, 54, 55, 65], "ct": [53, 54], "ctr": [51, 52], "cubinlink": 70, "cubla": [25, 31, 32], "cublas_workspace_config": [24, 31, 60], "cublasapi_reproduc": 31, "cuda": [23, 24, 25, 31, 32, 33, 53, 60, 68, 70, 72, 75, 76, 77], "cuda11x": 70, "cuda_bla": 32, "cuda_dnn": 32, "cuda_fft": 32, "cuda_memory_usag": [69, 70], "cuda_time_tot": [69, 70], "cuda_visible_devic": 44, "cudadevicesynchron": [69, 70], "cudalaunchkernel": [69, 70], "cudamemcpyasync": 69, "cudastreamsynchron": 69, "cudf": 70, "cudnn": [24, 31, 32, 60], "cufft": 32, "cultiv": 23, "cuml": 70, "cumsum": 24, "cumtim": 80, "cumul": [22, 24, 66], "cumulative_prob": 24, "cup": [23, 27], "cupi": 70, "curat": 23, "curr": 6, "current": [3, 14, 16, 17, 22, 23, 24, 25, 28, 29, 32, 44, 45, 58, 64, 65, 66, 70, 73, 75, 76, 78, 80, 82, 83, 85], "current_file_path": 25, "current_path": [25, 28, 29], "current_step": [25, 78], "curs": [57, 58], "curv": [25, 27, 42, 59, 78], "curvatur": 79, "custom": [6, 9, 17, 24, 25, 28, 51, 52, 54, 55, 56, 65, 66, 73, 74, 76, 80, 82, 85], "customari": [23, 27], "customdataset": 85, "cut": [16, 44, 52], "cv": 52, "cv2": 29, "cvtcolor": 29, "cwd": [25, 28, 29, 82], "cxd": 73, "cycl": [25, 27, 69, 78, 80], "cyclic": [25, 78], "cz": 35, "cz_0": 35, "d": [2, 14, 21, 22, 23, 25, 27, 28, 29, 30, 31, 34, 35, 37, 38, 40, 42, 44, 45, 54, 58, 62, 68, 70, 71, 73, 74, 75, 76, 79, 82], "d1": [25, 32], "d2": [25, 32], "d2l": 1, "d3": 25, "d_": [22, 24, 70, 71, 82], "d_1": 25, "d_2": 25, "d_ablat": 46, "d_ff": [23, 24, 25, 68, 70, 74, 75], "d_k": [22, 24, 25, 73], "d_model": [23, 24, 25, 68, 70, 73, 74, 75], "d_q": [22, 24, 68, 70, 73, 74], "d_qkv": 24, "d_v": [22, 24, 68, 70, 73, 74], "daemon": [44, 46], "dai": [16, 35, 52, 57, 59, 65, 73], "daili": [30, 57, 66], "dake": [26, 27, 28], "dall": 16, "danger": 9, "daniela": [26, 27], "dario": 1, "dark": 3, "dashboard": [56, 57], "dask": [55, 70], "data": [1, 3, 4, 6, 9, 10, 14, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 35, 39, 40, 42, 43, 45, 47, 48, 59, 61, 63, 64, 65, 66, 68, 73, 74, 76, 77, 79, 82, 83, 85], "data1": [56, 85], "data2": [56, 85], "data3": 85, "data4": 85, "data5": 85, "data_col": [32, 75, 76], "data_config": 25, "data_dir": [82, 84], "data_dtyp": 24, "data_fold": 24, "data_se": [32, 75, 76], "data_shap": 24, "databas": [14, 52, 53, 55, 56, 65, 84], "databrick": [30, 54, 55], "dataclass": [6, 10, 24, 25, 38, 73, 76, 82, 83], "datacol": 76, "datacollatorwithpad": [32, 75, 76, 77], "dataconfig": [25, 74, 82, 84], "datadog": 66, "datafram": [28, 53, 68, 69, 73, 75], "dataload": [8, 60, 74, 77, 82, 84], "dataloader_drop_last": 76, "dataloader_num_work": 76, "dataloader_persistent_work": 76, "dataloader_pin_memori": 76, "dataloader_prefetch_factor": 76, "datamodul": [82, 84], "dataop": [33, 48, 55, 57], "dataset": [3, 14, 16, 17, 27, 28, 29, 31, 35, 42, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 73, 76, 78, 79, 80, 82, 85], "dataset_dir": [25, 74], "dataset_nam": [24, 25, 74], "dataset_path": [25, 74], "dataset_s": [25, 74], "dataset_str": 25, "dataset_tensor": 25, "dataset_test": 85, "dataset_train": 85, "dataset_url": [25, 74], "dataset_vers": 83, "datasheet": 73, "datatyp": 3, "date": [55, 56, 62, 64], "datefmt": 71, "datetim": [45, 70, 71], "dation": 65, "daum\u00e9": [26, 27], "david": 1, "davison": 23, "db": 56, "dd": [56, 82], "ddot": [22, 24, 40, 73, 79], "ddp": [43, 44, 45, 53, 73], "ddp_backend": 76, "ddp_broadcast_buff": 76, "ddp_bucket_cap_mb": 76, "ddp_find_unused_paramet": 76, "ddp_timeout": 76, "ddp_tutori": 47, "de": [23, 24, 25, 55, 78], "deadlin": 16, "deadlock": 75, "deal": [8, 14, 24, 25, 39, 53, 54, 56, 57, 62, 65], "dean": 77, "deberta": [32, 77], "debertav2forsequenceclassif": 77, "debertav2token": 77, "debug": [24, 25, 60, 61, 62, 64, 71, 74, 76, 82, 84], "debug_sampl": [25, 74], "debug_util": 76, "debugopt": 76, "dec": [1, 2, 21, 23], "decai": [1, 2, 21, 23, 25], "decathlon": [1, 23], "decemb": 23, "decent": 75, "decid": [4, 16, 24, 35, 51, 52, 53, 54, 57, 62, 63, 65, 66], "decim": 8, "decis": [9, 10, 14, 16, 17, 23, 35, 42, 51, 52, 53, 57, 58, 59, 60, 62, 63, 64, 65, 70, 74, 79, 87], "decision_tre": 87, "decisiontreestrategi": 87, "declar": [6, 7, 9, 28], "decod": [21, 23, 25, 29, 33, 60, 73, 77], "decode_batch": 25, "decode_equ": 25, "decoded_equ": 25, "decoded_input": 25, "decoded_sent": 25, "decoded_target": 25, "decoder_block": [23, 24, 25, 74, 75], "decoder_block_config": [24, 25, 74], "decoderblock": 23, "decoderblockconfig": [24, 25, 74, 75, 77], "decoderconfig": [24, 25, 74, 75, 77], "decoderforsequenceclassificationconfig": [74, 75], "decomp": 63, "decompos": [22, 24, 27, 31], "decomposit": [22, 23, 30], "decor": [3, 9, 53, 82], "decoupl": [1, 2, 21, 23, 25, 56, 82, 84, 85], "decoupledadamw": 25, "decreas": [8, 16, 23, 25, 28, 31, 51, 59, 61, 66, 78, 79], "decrement": 28, "dedic": [56, 73], "deduc": [5, 27, 40], "deduct": 54, "deem": [4, 23, 24, 25, 56], "deep": [1, 11, 21, 22, 23, 24, 25, 29, 31, 32, 37, 40, 43, 51, 54, 57, 58, 60, 62, 63, 67, 71, 72, 78, 79, 80, 83, 84], "deepak": [48, 56], "deepcopi": 32, "deeper": [10, 17, 24, 35, 52, 57, 78], "deeplearningbook": 1, "deepli": [37, 39], "deepspe": 76, "def": [3, 4, 5, 6, 7, 8, 9, 10, 14, 16, 17, 19, 22, 24, 25, 28, 29, 31, 32, 44, 46, 53, 54, 56, 60, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87], "default": [10, 24, 25, 28, 29, 31, 32, 44, 45, 53, 62, 67, 69, 71, 73, 75, 76, 77, 79, 80, 82, 83], "default_data_col": 76, "default_factori": 76, "default_repr": 76, "default_rng": [24, 60], "default_square_trac": 69, "default_tim": [67, 68], "default_valu": 76, "defaultdict": 79, "defer": 6, "defin": [3, 4, 5, 6, 9, 10, 14, 16, 19, 22, 23, 24, 25, 28, 29, 31, 34, 35, 37, 38, 39, 40, 42, 43, 44, 48, 51, 52, 53, 54, 56, 58, 59, 62, 64, 65, 66, 68, 70, 73, 74, 76, 77, 78, 79, 80, 82, 84, 85], "definit": [5, 6, 7, 9, 10, 17, 23, 27, 29, 31, 33, 35, 39, 41, 42, 43, 44, 54, 57, 58, 62, 68, 70, 76, 77, 79, 80, 84], "degener": 16, "degrad": [23, 31, 62, 64, 66], "degre": [24, 31, 38, 40, 58], "deisenroth": [1, 34, 35, 39], "del": [68, 71, 77], "delai": [14, 51, 59], "deleg": 87, "delet": [54, 68, 71, 77], "deliber": 23, "deliv": [42, 65], "deliveri": [48, 62], "delta": [31, 55], "delta_": 79, "demand": [19, 51, 55, 73], "demo": 52, "demograph": [52, 53, 64, 65], "demonstr": [3, 8, 16, 17, 19, 23, 24, 25, 28, 39, 44, 71, 79, 80, 87], "demonstrate_multinomial_sampling_effect": 79, "denomin": [24, 73, 79], "denot": [4, 5, 6, 8, 13, 14, 16, 17, 22, 23, 24, 25, 27, 28, 29, 31, 34, 35, 37, 38, 39, 40, 42, 43, 44, 54, 73, 77, 78, 79], "dens": [22, 23, 24, 73, 77], "densiti": [42, 79], "deparallel": 76, "depart": 31, "depend": [6, 9, 13, 14, 16, 17, 19, 22, 23, 25, 27, 29, 31, 33, 38, 40, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 65, 66, 70, 73, 78, 79, 82, 86], "dependencie": 23, "depict": [16, 24], "deploi": [25, 31, 45, 48, 51, 52, 55, 62, 64, 65, 66, 84], "deploy": [33, 48, 51, 52, 55, 84], "depract": [75, 77], "deprec": [24, 32, 73, 75, 78], "depth": [11, 14, 17, 23, 24, 29, 51, 56, 62, 64], "deriv": [6, 8, 14, 17, 22, 23, 24, 25, 27, 31, 35, 40, 44, 51, 56, 58, 65], "desc": [54, 68, 74, 75, 77, 82], "descend": [17, 24, 55, 78, 79], "descent": [1, 2, 25, 34, 39, 78], "describ": [3, 4, 5, 8, 13, 14, 16, 17, 23, 24, 25, 27, 31, 35, 37, 45, 51, 52, 53, 54, 55, 78, 79, 84], "describe_anim": 4, "descript": [13, 14, 16, 17, 19, 24, 31, 32, 34, 42, 44, 51, 52, 53, 54, 55, 56, 57, 60, 62, 66, 68, 71, 79, 83], "deseri": 82, "deserv": 37, "design": [3, 5, 6, 7, 8, 10, 16, 17, 19, 22, 23, 24, 25, 33, 42, 44, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 75, 78, 83, 84, 85, 87], "desir": [5, 17, 22, 23, 24, 45, 52, 53, 54, 55, 58, 60, 64, 66, 73, 76, 78, 79, 82, 87], "despit": [3, 9, 24, 37, 53, 62], "dest_fold": 24, "dest_folder_path": 24, "destin": 56, "destruct": 19, "det": 40, "detach": [24, 25, 45, 74, 75], "detail": [3, 4, 10, 14, 16, 17, 19, 23, 24, 25, 27, 31, 34, 35, 37, 45, 51, 52, 53, 54, 56, 60, 64, 65, 73, 75, 76, 77, 78, 82, 85], "detect": [6, 11, 32, 39, 48, 51, 54, 55, 56, 57, 62, 65, 66, 71], "detector": 71, "determin": [4, 6, 9, 14, 16, 17, 24, 25, 27, 29, 35, 39, 44, 51, 52, 53, 55, 57, 59, 60, 62, 65, 66, 78, 79], "determinist": [14, 24, 25, 31, 60, 61, 62, 66, 79], "detour": 23, "dev": [25, 56], "develop": [3, 4, 10, 11, 16, 21, 23, 24, 33, 48, 51, 52, 54, 57, 58, 59, 60, 63, 64, 65, 66, 72, 84, 85], "deviat": [22, 24, 54, 59, 66, 68], "devic": [24, 25, 32, 48, 51, 52, 53, 55, 67, 68, 69, 70, 71, 74, 75, 76, 77, 82, 83, 84], "device_": 69, "device_count": 44, "device_t": 69, "device_typ": [24, 69], "devicetyp": 69, "devop": [33, 48, 57], "df": [28, 53, 68, 69, 73, 75], "df_by_mean": 68, "df_np": 53, "df_np_col": 53, "dfrac": [14, 22, 24, 27], "di": 85, "diag": 79, "diag_": 79, "diag_emb": 79, "diagnos": [51, 60, 62], "diagnosi": [59, 62], "diagnost": [51, 59], "diagon": [22, 24, 25, 27, 31, 39, 59, 68, 70, 74, 75, 79], "diagram": [19, 26, 27, 28, 38, 40, 56, 59, 65, 85], "dichotim": 59, "dichotom": 29, "dict": [6, 24, 25, 28, 29, 32, 38, 54, 56, 68, 70, 73, 75, 76, 77, 79, 82, 83, 84], "dictat": [16, 24, 25, 38, 52, 85], "dictconfig": 82, "dictionari": [6, 7, 10, 27, 29, 53, 76, 79, 82, 83, 84], "did": [8, 9, 14, 23, 24, 27, 29, 39, 56, 62, 68, 69, 70, 74, 75, 76, 80], "die": 24, "diederik": 1, "differ": [3, 4, 6, 7, 8, 9, 10, 13, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 42, 44, 48, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 73, 76, 77, 78, 79, 80, 82, 83, 85, 87], "differenti": [10, 22, 23, 24, 25, 29, 37, 40, 52, 58], "difficult": [6, 24, 44, 52, 54, 57, 65, 73], "difficulti": [16, 23, 27], "dig": [56, 69, 78], "digit": [21, 28, 33, 34, 51, 52, 74], "dii": 85, "dilemma": 23, "dill": 70, "dim": [22, 24, 25, 31, 32, 68, 70, 74, 75, 77, 79], "dim0": [22, 24, 68, 70, 73, 74], "dim1": [22, 24, 68, 70, 73, 74], "dimens": [17, 27, 31, 32, 34, 35, 37, 38, 40, 42, 52, 62, 73, 74, 75, 79], "dimension": [5, 22, 23, 25, 27, 28, 29, 31, 34, 35, 37, 38, 39, 42, 52, 53, 57, 65, 79], "dimensionality_reduct": 52, "diminish": [23, 24], "dip": 85, "dir": [56, 82], "direct": [3, 8, 16, 19, 23, 24, 25, 27, 31, 35, 37, 38, 39, 40, 51, 53, 56, 58, 59, 69, 78, 79, 85], "directli": [3, 13, 16, 17, 19, 22, 23, 24, 25, 27, 28, 39, 43, 45, 51, 52, 53, 54, 55, 79, 80, 82, 85], "directori": [25, 28, 29, 44, 45, 56, 60, 76, 82], "disabl": [6, 10, 22, 28, 31, 80, 82], "disable_adapt": 76, "disable_existing_logg": 82, "disable_input_require_grad": 76, "disable_tqdm": 76, "disadvantag": 55, "disappear": 13, "discard": [14, 16], "discern": 16, "disclaim": 25, "discontinu": 51, "discount": 55, "discourag": 25, "discours": 24, "discov": [38, 51, 62], "discoveri": 17, "discrep": [3, 6, 59, 64, 66, 79], "discret": [23, 29, 39, 42, 52, 53, 79], "discrimin": [23, 25, 57, 59, 78, 79], "discuss": [3, 4, 5, 7, 10, 14, 16, 17, 21, 22, 23, 24, 25, 29, 34, 35, 37, 39, 40, 42, 46, 51, 52, 53, 56, 73, 78, 79], "diseas": [51, 52, 59, 62], "disinguish": 10, "disjoint": [27, 79], "disk": [29, 83], "dislik": 51, "dispar": [54, 64], "dispatch_batch": 76, "dispers": 24, "displai": [14, 28, 29, 38, 40, 68, 74, 79], "display_contingency_and_pur": 28, "display_result": 28, "disrupt": 56, "dissatisfact": 51, "dissect": [24, 85], "dissimilar": [22, 39], "dist_info": 44, "dist_info_per_process": [44, 46], "dist_tuto": 47, "distanc": [24, 27, 28, 29, 33, 40, 41, 42, 53, 54], "distil": [33, 52, 58], "distillation_loss": 77, "distinct": [3, 5, 6, 10, 23, 24, 25, 27, 29, 35, 37, 54, 80, 84], "distinctli": 28, "distinfoperprocess": 44, "distinguish": [10, 17, 23, 24, 34, 59, 84], "distort": [28, 29], "distribut": [16, 22, 25, 26, 27, 29, 31, 33, 34, 40, 42, 43, 45, 48, 51, 55, 56, 57, 60, 62, 65, 66, 73, 74, 76, 77, 82], "distributedconfig": [25, 74], "distributeddataparallel": [44, 76], "disturb": 19, "div": 70, "div_term": 24, "divbackward0": [70, 79], "dive": [1, 2, 10, 11, 17, 21, 23, 24, 35, 37, 38, 56, 57, 78, 79], "diverg": [21, 25, 60, 77, 78], "divers": [17, 23, 31, 53, 54, 55, 57, 64, 65, 79], "divid": [9, 14, 17, 24, 25, 28, 29, 42, 73, 79], "divis": [5, 9, 16, 24, 34, 73, 79], "divisor": 24, "dk": [25, 27], "dl": 52, "dload": 25, "dn": 45, "dna": 53, "do": [3, 4, 5, 6, 7, 8, 9, 13, 14, 16, 17, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 37, 39, 40, 42, 44, 45, 46, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 65, 66, 68, 69, 70, 72, 73, 75, 76, 78, 79, 80, 82, 83], "do_division_on_int": 9, "do_ev": [32, 75, 76], "do_predict": [32, 75, 76], "do_sampl": 24, "do_train": [32, 75, 76], "doc": [6, 31, 32, 53, 77], "docker": 56, "dockerfil": 56, "docstr": 76, "doctor": 54, "document": [9, 17, 19, 23, 24, 28, 29, 44, 45, 48, 52, 53, 57, 62, 82], "documentari": 66, "documentclass": [17, 19], "doe": [3, 4, 5, 6, 8, 10, 13, 14, 16, 17, 19, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 42, 44, 46, 51, 52, 53, 54, 55, 57, 58, 62, 67, 69, 70, 71, 74, 76, 79, 83, 84, 85, 87], "doesn": [3, 8, 13, 14, 16, 19, 25, 26, 53, 54, 57, 58, 65, 70, 71, 78, 79, 80, 87], "doesnt": 4, "dog": [3, 4, 5, 7, 22, 42, 52], "doi": [1, 2, 11], "dollar": [23, 24, 51, 54], "domain": [16, 17, 22, 23, 31, 39, 51, 54, 55, 64, 79], "domin": [13, 14, 16, 24, 25, 27, 79], "don": [3, 9, 14, 16, 24, 25, 28, 31, 43, 44, 45, 52, 54, 56, 57, 61, 62, 65, 66, 68, 78, 79, 83, 84], "done": [3, 7, 13, 14, 16, 17, 19, 23, 24, 25, 27, 31, 37, 38, 44, 45, 54, 55, 56, 59, 60, 69, 73, 74, 75, 80, 84, 85], "dorothea": 13, "dose": 30, "dot": [5, 25, 27, 35, 38, 73, 74, 82], "doubl": [8, 9, 19, 37, 45, 73, 76], "double_int_or_int": 9, "double_scalar": 28, "doublepair": 6, "douglasorr": 77, "down": [6, 14, 17, 22, 23, 25, 32, 37, 45, 52, 54, 65, 75, 77, 78, 79], "down_proj": 32, "downarrow": 22, "download": [24, 55, 73, 82], "download_fil": 25, "downsid": 54, "downstream": [8, 23, 31, 54, 55, 56, 57, 64], "downtim": [48, 64], "doyl": 54, "dp": 1, "dpi": 29, "drastic": [24, 25, 31, 58, 59, 78], "draw": [6, 17, 19, 23, 24, 38, 56, 57, 63], "drawback": [6, 27, 31, 53, 80], "drawn": [23, 42, 58, 63, 79], "drif": 66, "drift": [48, 52, 56, 64], "drill": 64, "drive": [3, 4, 35, 51, 52, 83], "driven": [51, 55, 57], "driver": [54, 55], "drone": 17, "drop": [22, 62, 66], "drop_last": [25, 74], "dropout": [24, 25, 32, 68, 70, 74, 75, 76], "drown": 59, "dry_run_backbon": 75, "dry_run_backbone_last_layer_hidden_st": 75, "dry_run_model": 75, "dry_run_model_config": 75, "dry_run_pool": 75, "dry_run_pooler_output": 75, "dtype": [24, 25, 28, 29, 67, 68, 70, 74, 75, 77, 79], "dub": 23, "duck": 3, "dude": 46, "due": [3, 14, 16, 17, 19, 23, 24, 28, 31, 32, 52, 53, 54, 55, 57, 62, 64, 65, 71, 73, 74, 76, 79, 83], "dummi": [24, 58, 62, 74, 85], "dummy_data": 85, "dummy_model": [25, 78], "dump": [55, 82], "duo": 6, "duplic": [17, 23, 54, 55, 56, 76], "durat": [25, 51, 55, 57, 78], "dure": [3, 4, 6, 9, 14, 16, 17, 22, 23, 24, 25, 28, 31, 32, 44, 45, 52, 53, 57, 60, 61, 62, 63, 65, 71, 73, 78, 82, 83], "dvc": [56, 60], "dwarf": 13, "dxd": 24, "dynam": [3, 6, 14, 16, 19, 66, 80, 83], "dzmitri": [1, 73], "e": [1, 3, 4, 5, 7, 8, 9, 10, 13, 14, 16, 19, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 37, 39, 40, 42, 43, 46, 51, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 71, 73, 74, 76, 78, 79, 80, 82, 84, 85], "e731": 25, "e_": 24, "each": [3, 5, 6, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 71, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85], "earli": [17, 25, 51, 59, 74, 78], "earlier": [3, 4, 6, 8, 14, 16, 17, 22, 23, 24, 25, 27, 28, 29, 31, 35, 45, 56, 58, 62, 65, 69, 73, 74, 75, 80, 82], "eas": [22, 31, 52, 53, 85], "easi": [8, 24, 25, 27, 53, 54, 56, 57, 64, 71, 73, 79, 80, 82], "easier": [3, 24, 25, 28, 54, 55, 56, 58, 60, 65, 76, 83, 85], "easili": [6, 16, 22, 24, 25, 27, 31, 39, 52, 53, 55, 56, 60, 65, 66, 73, 82, 83, 84, 85, 87], "east": 55, "eat": [15, 19, 22, 24, 33], "eaten": 16, "ec2": 43, "echo": [44, 45], "econom": [51, 53], "ecosystem": [56, 67], "ed": [2, 21, 23], "eda": 57, "edg": [48, 53, 54], "edgar": 54, "edgecolor": 28, "edit": 1, "editori": 16, "educ": [23, 27, 29, 45, 53], "edunita": [3, 4, 5], "edward": 1, "ef": [45, 55], "efa": 45, "effect": [3, 5, 6, 14, 16, 17, 19, 22, 23, 24, 25, 29, 31, 34, 37, 44, 51, 52, 54, 55, 56, 57, 58, 60, 64, 73, 76, 78, 79], "effective_batch_s": 73, "effective_batch_size_per_it": 73, "effective_flops_per_second": 73, "effici": [4, 14, 16, 19, 22, 24, 25, 30, 31, 35, 43, 48, 51, 52, 53, 54, 55, 56, 57, 58, 62, 65, 66, 76, 78], "effort": [16, 23, 56, 84], "efsset": 45, "eigen": 53, "eigendecomposit": 38, "eigenvalu": 38, "eigenvector": 38, "eighth": 25, "einsum": 22, "either": [4, 5, 9, 14, 16, 17, 22, 24, 25, 27, 28, 29, 31, 32, 35, 38, 40, 54, 55, 56, 59, 62, 69, 76, 78, 79, 80, 82, 85], "elabor": 52, "elaps": [25, 78], "elapsed_tim": [53, 69], "elbow": 28, "elbow_method": 28, "electr": 16, "electron": [17, 53], "eleg": [6, 10], "element": [3, 6, 8, 9, 14, 16, 17, 19, 22, 23, 24, 25, 26, 27, 28, 31, 34, 37, 40, 42, 51, 53, 56, 69, 73, 74, 76, 79, 82], "element1": 19, "element2a": 19, "element2b": 19, "element3a": 19, "element3b": 19, "element3c": 19, "element4a": 19, "element4b": 19, "elementwis": 69, "elementwise_affin": [22, 24, 25, 74, 75], "eli": 79, "elif": [9, 10, 14, 25, 28, 68, 71, 76, 85, 87], "elimin": [4, 14, 35, 46, 56], "ell": [14, 23, 25, 42], "ellipsi": [6, 9, 76], "ellipt": 27, "els": [3, 4, 7, 9, 10, 13, 14, 16, 22, 24, 25, 28, 29, 32, 44, 46, 56, 68, 70, 71, 73, 74, 75, 76, 77, 78, 80, 83, 85, 87], "elsewher": [6, 22, 24, 35], "elt": 53, "elucid": [17, 35], "elus": 16, "em": 26, "email": [51, 52, 65], "eman": 35, "emb": 24, "embd_pdrop": 24, "embed": [17, 25, 32, 34, 35, 37, 39, 40, 42, 48, 52, 53, 54, 55, 57, 60, 65, 68, 70, 73, 75], "embed_token": 32, "embedd": 8, "embedding_backward": 70, "embedding_dense_backward": 70, "embedding_dim": [24, 68, 70], "embedding_matrix": 24, "embeddingbackwa": 70, "embeddingbackward0": [24, 70], "embodi": 54, "emerg": 48, "emit": 24, "emoji": [23, 24], "empahsi": [23, 24], "emphas": [5, 22, 24, 25, 34, 37, 54, 55, 58, 77, 78], "emphasi": [23, 37], "emphasis": 31, "empir": [25, 27, 31, 42, 62, 78], "empirc": [25, 78], "emploi": [16, 19, 23, 25, 39, 51, 62, 64, 66, 78], "employe": [6, 8], "empow": [23, 24, 54], "empti": [9, 14, 17, 19, 24, 27, 28, 35, 69, 70, 76, 77], "empty_cach": [68, 71, 77], "empty_lik": [24, 70], "empty_strid": [69, 70], "emptyset": [14, 27], "en": [1, 8, 25, 32, 71, 77, 78], "enabl": [3, 4, 6, 9, 16, 17, 19, 21, 22, 23, 25, 31, 45, 48, 53, 54, 56, 58, 60, 64, 65, 67, 70, 71, 74, 79, 80, 84], "enable_adapt": 76, "enable_backward": 70, "enable_input_require_grad": 76, "enable_optim": 70, "enable_tim": 69, "enc": 24, "encapsul": [6, 23, 24, 34, 35, 40, 53, 56, 83, 87], "encod": [21, 29, 31, 32, 34, 52, 54, 55, 57, 75, 76, 77, 79, 80], "encode_batch": 25, "encode_equ": 25, "encode_ordinari": 24, "encoded_sent": 25, "encoder_hidden_st": 24, "encoder_hidden_states_mask": 24, "encoding_nam": 24, "encompass": [6, 9, 14, 17, 51, 54, 55], "encount": [9, 16, 17, 25, 28, 56, 65, 80, 85], "encourag": [10, 25, 39, 52], "encrypt": 55, "end": [3, 4, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 51, 52, 53, 56, 57, 58, 59, 62, 65, 66, 67, 68, 69, 73, 78, 79, 80, 82, 83], "end_tim": [53, 67, 83], "endeavor": 16, "endoftext": 75, "endpoint": [44, 65], "endswith": [24, 25, 68, 70, 74, 75], "enemi": 24, "enforc": [6, 7, 19, 54, 56], "engag": [51, 52, 57], "engagement_loss": 52, "engagement_predict": 52, "engin": [17, 25, 48, 51, 52, 53, 58, 64, 65, 66, 70], "english": [23, 24, 52], "enhanc": [4, 17, 22, 23, 24, 51, 52, 55, 56, 57, 62, 65, 80, 84, 85], "enjoi": 51, "enjoy": 52, "enlighten": 16, "enorm": [57, 80], "enough": [7, 14, 19, 23, 28, 29, 31, 35, 45, 46, 52, 53, 55, 71, 74, 75, 80, 82], "enrich": 55, "ensembl": 62, "ensur": [3, 4, 5, 6, 8, 10, 14, 16, 17, 19, 22, 23, 24, 25, 28, 29, 31, 32, 34, 39, 43, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 68, 70, 73, 74, 76, 78, 79], "entail": [23, 55, 57, 74, 75], "enter": 28, "enterpris": 56, "entertain": 23, "entir": [13, 14, 16, 17, 22, 23, 24, 25, 42, 53, 54, 55, 56, 62, 63, 73, 75, 78, 80], "entireti": [6, 23], "entiti": [3, 4, 6, 23, 24, 35, 37, 38, 39, 46, 53, 54, 66], "entri": [37, 40, 52, 62, 82], "entropi": [25, 27, 52, 77, 79], "entrypoint": [56, 82], "enum": 87, "enumer": [23, 24, 28, 29, 42, 65, 74, 75], "env": [24, 25, 28, 31, 44, 45, 46, 56, 60, 74, 82], "env_copi": 82, "env_set": 82, "environ": [3, 4, 19, 24, 25, 28, 31, 44, 46, 48, 51, 52, 53, 55, 57, 60, 64, 65, 76, 84], "environment": 65, "envis": 52, "eo": [22, 24, 25], "eos_token": [75, 77], "eos_token_id": [24, 75, 77], "eosin": 29, "ep": [22, 24, 25, 68, 70, 74, 75, 82], "ephemeral_gc": 71, "epoch": [25, 32, 60, 61, 62, 74, 75, 76, 77, 78, 82, 83], "epoch_index": [25, 83], "epperli": 30, "epsilon": [13, 22, 24, 25, 79], "eq1": 40, "equal": [5, 8, 10, 13, 16, 17, 22, 24, 25, 27, 28, 31, 34, 35, 39, 40, 53, 54, 57, 63, 76, 78, 79, 82, 83, 84], "equal_idx": 25, "equal_index": 25, "equal_token_id": 25, "equat": [14, 17, 22, 23, 25, 27, 29, 31, 33, 36, 39, 40, 42, 73, 78, 79], "equation_to_str": 25, "equidist": 27, "equip": [16, 65, 76], "equival": [5, 8, 16, 19, 22, 23, 29, 31, 37, 38, 39, 43, 55, 76, 78, 80], "era": 55, "erasur": 6, "erf": [22, 24, 70], "erfbackward0": 70, "err": [4, 6, 8, 9, 25, 45, 80], "erron": 4, "error": [3, 4, 6, 7, 8, 9, 11, 19, 25, 27, 28, 29, 31, 32, 35, 39, 42, 44, 45, 52, 54, 55, 56, 59, 60, 62, 63, 64, 66, 68, 71, 75, 82], "error_if_nonfinit": [25, 74], "error_queu": 44, "errorn": 4, "escal": 23, "especi": [6, 10, 17, 24, 25, 27, 28, 34, 35, 38, 39, 40, 42, 51, 53, 54, 55, 56, 57, 59, 60, 62, 72, 73, 76, 78, 80, 83, 84], "essenc": [3, 16, 17, 23, 24, 37, 38], "essenti": [4, 6, 8, 9, 11, 14, 16, 17, 22, 23, 24, 25, 27, 31, 34, 35, 37, 38, 39, 40, 42, 45, 51, 52, 55, 56, 57, 60, 62, 65, 66, 67, 74, 79], "essentiali": 24, "establish": [3, 4, 5, 8, 14, 16, 17, 23, 25, 27, 37, 40, 51, 54, 56, 58, 74, 75, 78, 85], "estim": [22, 24, 25, 27, 28, 31, 35, 57, 59, 62, 63, 78, 79], "estimate_mfu": 73, "estimate_token": 76, "estimate_training_dai": 73, "estimated_byt": 73, "estimated_bytes_in_byt": 73, "et": [17, 22, 23, 24, 25, 31, 34, 35, 39, 78, 79], "eta": [25, 31, 78], "eta_": [25, 78], "eta_0": [25, 78], "eta_1": 78, "eta_2": 78, "eta_3": 78, "eta_4": 78, "eta_5": 78, "eta_6": 78, "eta_7": 78, "eta_max": 78, "eta_min": [25, 74, 75, 78], "eta_t": [25, 78], "etc": [5, 6, 7, 14, 22, 24, 25, 27, 29, 35, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 73, 74, 75, 76, 79, 83, 84, 85], "etern": 30, "ethan": 30, "ethic": 52, "etl": [53, 56], "euclidean": [24, 27, 28, 29, 35, 40, 42, 58], "euclidean_dist": 28, "eugen": [23, 24, 61], "euphoria": 59, "eval": [24, 25, 32, 74, 75, 76, 77, 82], "eval_accumulation_step": 76, "eval_accuraci": [32, 75], "eval_brier_scor": [32, 75], "eval_confusion_matrix": [32, 75], "eval_dataset": [32, 75, 76], "eval_delai": 76, "eval_every_n_step": [25, 74], "eval_f1_score_macro": [32, 75], "eval_f1_score_micro": [32, 75], "eval_log_loss": [32, 75], "eval_loss": 32, "eval_pr_auc": [32, 75], "eval_pr_auc_class_": [32, 75], "eval_pr_auc_class_0": 32, "eval_pr_auc_class_1": 32, "eval_pr_auc_class_2": 32, "eval_precision_macro": [32, 75], "eval_precision_micro": [32, 75], "eval_predict": [32, 75], "eval_recall_macro": [32, 75], "eval_recall_micro": [32, 75], "eval_roc_auc": [32, 75], "eval_roc_auc_class_": [32, 75], "eval_roc_auc_class_0": 32, "eval_roc_auc_class_1": 32, "eval_roc_auc_class_2": 32, "eval_runtim": 32, "eval_samples_per_second": 32, "eval_step": [32, 75, 76], "eval_steps_per_second": 32, "eval_strategi": [32, 75], "evalpredict": [32, 75, 76, 77], "evalu": [3, 5, 16, 17, 22, 23, 24, 25, 33, 42, 48, 51, 52, 56, 57, 58, 60, 62, 64, 65, 66, 73, 74, 76, 79, 80, 83], "evaluate_and_generate_on_valid_epoch_end": 25, "evaluate_funct": 70, "evaluate_on_reverse_dataset": 74, "evaluation_loop": 76, "evaluation_strategi": [32, 75, 76], "even": [3, 4, 6, 8, 9, 10, 14, 16, 23, 24, 25, 27, 31, 35, 37, 39, 42, 44, 46, 52, 53, 54, 56, 57, 58, 59, 60, 61, 65, 66, 67, 73, 78, 79, 80, 84], "evenli": [62, 79], "event": [17, 25, 33, 45, 52, 54, 57, 59, 66, 67, 71, 72, 79], "eventu": [14, 16, 17, 27, 52, 71], "everi": [4, 5, 8, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 34, 35, 38, 39, 42, 46, 52, 54, 57, 58, 59, 64, 65, 69, 71, 73, 74, 75, 79, 80], "every_sav": 76, "everyon": 54, "everyth": [4, 44, 57, 60, 85], "everywher": [9, 22, 24, 57, 58], "evid": [16, 31, 79], "evolut": 64, "evolutionari": 60, "evolv": [17, 51, 54, 62, 65, 66], "exacerb": 31, "exact": [3, 7, 9, 13, 16, 17, 19, 25, 32, 46, 54, 60, 62, 69, 82], "exactli": [8, 14, 16, 22, 24, 25, 28, 39, 40, 45, 78, 80], "examin": [3, 17, 24, 25, 35, 51, 54, 57, 79], "exampl": [3, 5, 10, 11, 17, 23, 27, 28, 31, 35, 37, 39, 42, 44, 45, 56, 58, 60, 61, 62, 63, 67, 69, 71, 73, 74, 75, 76, 77, 79, 82, 83, 84, 85], "example_attention_weight": 25, "example_input": 25, "example_logit": 25, "example_predict": 25, "example_target": 25, "exc": 68, "exce": [14, 23, 40, 79, 80], "excel": [19, 23, 53, 55], "except": [4, 6, 8, 9, 14, 19, 24, 25, 38, 44, 54, 68, 71, 76, 80, 84], "exception": 14, "excerpt": [7, 73], "exchang": [14, 17, 23, 24, 35, 40, 53], "exclud": [16, 17, 25, 32, 73, 78], "exclude_kei": 82, "exclus": [3, 21, 23, 24, 25, 52, 65, 69], "exec": [76, 80], "execut": [4, 6, 9, 14, 17, 19, 22, 23, 24, 43, 46, 53, 54, 56, 57, 67, 68, 73, 76, 80, 87], "execute_search": 14, "exemplifi": [6, 23], "exercis": [17, 68, 70], "exhaust": [14, 17, 51, 52, 62, 80], "exhibit": [5, 9, 16, 38], "exist": [3, 5, 14, 16, 17, 23, 24, 25, 27, 28, 29, 34, 35, 37, 38, 42, 45, 51, 56, 57, 58, 64, 76, 79, 83, 87], "exist_ok": 24, "exit": [14, 76, 80], "exorbit": 23, "exp": [22, 23, 24, 25, 70, 77, 79], "expand": [13, 23, 24, 25, 35, 43, 55, 68, 70, 74, 75], "expans": [13, 14, 23, 24], "expbackward0": 70, "expect": [3, 4, 5, 6, 8, 9, 10, 14, 16, 19, 23, 24, 25, 27, 29, 42, 45, 48, 51, 56, 57, 61, 62, 63, 64, 65, 73, 76], "expected_param": 73, "expens": [16, 24, 29, 31, 54, 61, 62, 73], "experi": [11, 16, 17, 25, 31, 45, 51, 52, 58, 61, 62, 64, 65, 73, 78, 79, 82, 84], "experienc": [16, 53], "experiment": [29, 52, 62, 70, 75], "experiment_id": 83, "experiment_nam": 83, "experimental_config": 70, "expert": [57, 72], "explain": [3, 6, 22, 23, 24, 25, 27, 31, 52, 55, 58, 59, 73], "explan": [7, 16, 17, 19, 25, 54, 64, 73, 77], "explanatori": [25, 35], "explicit": [3, 7, 10, 17, 22, 24, 25, 35, 52, 71, 78, 79], "explicitli": [3, 6, 10, 22, 23, 25, 27, 37, 54, 65, 66, 71, 78, 79, 80], "explod": [24, 31, 60], "exploit": 31, "explor": [5, 10, 14, 16, 17, 23, 24, 25, 29, 35, 37, 38, 39, 40, 48, 78], "exploratori": [56, 57], "explos": 62, "expon": [13, 14, 24, 58, 73, 79], "exponenti": [19, 23, 24, 27, 77], "export": [24, 44, 45, 65, 70, 71], "export_chrome_trac": [69, 70, 71], "export_memory_snapshot": 71, "export_memory_timelin": [70, 71], "export_stack": 70, "expos": [6, 56, 65, 66, 87], "exposur": 23, "express": [4, 5, 6, 10, 13, 16, 17, 22, 23, 24, 25, 27, 29, 35, 37, 38, 39, 40, 51, 58, 73, 78, 79], "ext": 82, "extend": [3, 5, 8, 13, 17, 23, 24, 25, 38, 40, 76, 79, 80], "extens": [4, 9, 22, 24, 25, 35, 39, 53, 56, 62, 73], "extent": [5, 24, 40], "extern": [14, 23, 24, 32, 56, 76, 80, 85], "extra": [14, 16, 17, 24, 25, 80], "extra_repr": [24, 76], "extract": [22, 24, 25, 27, 29, 33, 42, 48, 52, 54, 65, 76, 79, 87], "extract_from_connect": 56, "extractor": 74, "extrem": [24, 27, 52, 82], "ey": [24, 35], "f": [2, 3, 4, 5, 6, 8, 10, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 28, 29, 31, 32, 37, 38, 39, 40, 44, 46, 53, 54, 56, 58, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 80, 82, 85, 87], "f1": [32, 44, 51, 52, 59, 62, 63, 64, 66, 75], "f1_score": [32, 75, 77], "f2": 44, "f_": [22, 23, 24, 31, 77, 79], "f_1": 5, "f_2": 5, "f_n": [5, 27], "f_t": [59, 77], "fabric": 39, "face": [23, 27, 30, 45, 51, 54], "facebook": [52, 53, 82], "facial": 51, "facil": [62, 65], "facilit": [4, 22, 23, 24, 25, 51, 53, 54, 55, 56, 60], "fact": [4, 5, 6, 8, 9, 10, 17, 22, 23, 24, 25, 27, 31, 37, 40, 44, 65, 79, 82, 84, 87], "facto": 24, "factor": [13, 14, 16, 19, 22, 23, 24, 25, 30, 38, 51, 52, 53, 55, 57, 60, 65, 66, 73, 78, 79], "factori": [32, 76, 87], "factory_kwarg": 24, "fail": [24, 35, 45, 51, 52, 54, 56, 58, 59, 71, 80], "failur": [4, 43, 45, 52, 54, 56, 65, 79], "fair": [44, 59], "fairli": [8, 16], "faisal": [1, 34, 35, 39], "fall": [16, 27, 71], "fallback": 76, "fals": [3, 4, 6, 8, 10, 16, 17, 19, 22, 24, 25, 28, 31, 32, 38, 44, 46, 51, 53, 56, 59, 60, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83], "falsi": 10, "famili": [21, 22, 42, 52, 54], "familiar": [27, 34, 37, 38, 39, 40, 51, 54, 80], "famish": 24, "famou": 3, "fanci": 25, "fantat": 27, "far": [16, 17, 24, 25, 27, 28, 32, 40, 57], "fare": 54, "fashion": [8, 23, 24, 27, 28, 76], "fast": [1, 7, 14, 16, 19, 23, 51, 53, 54, 55, 56, 58, 62, 63, 65, 67], "fastapi": 65, "faster": [16, 17, 23, 24, 25, 27, 44, 46, 53, 54, 80], "fastest": 16, "favor": [51, 52], "favour": 24, "fc": 82, "feasibl": [31, 51, 80], "featur": [3, 9, 21, 22, 23, 24, 25, 27, 28, 29, 31, 35, 39, 40, 42, 53, 54, 55, 56, 60, 62, 64, 66, 74, 75, 76, 79, 80, 82, 83], "feature_dim": [24, 25, 74, 75], "feb": [2, 11], "fed": 56, "feed": [23, 25, 52, 53, 55, 56, 57, 73, 75], "feed_forward": [24, 25, 74, 75], "feed_forward_config": [24, 25, 74], "feedback": [51, 53, 62, 65], "feel": 22, "feet": 42, "fetch": [3, 4, 5, 45, 65, 84, 85], "few": [7, 17, 22, 23, 25, 27, 29, 40, 44, 51, 52, 53, 54, 58, 62, 65, 66, 76, 82], "fewer": [16, 31], "ff": [22, 24], "ffn": [22, 25, 68, 70, 74, 75], "ffw": 73, "ffw1": 73, "ffw2": 73, "ffw_size": 73, "fi": 45, "fiat": 53, "field": [3, 16, 17, 23, 24, 32, 33, 36, 37, 38, 39, 40, 44, 45, 53, 56, 59, 65, 68, 73, 76, 82, 83, 84, 87], "field_valid": [24, 82, 84], "fiesta": 53, "fig": [13, 24, 25, 28, 29, 35, 37, 38, 39, 40, 78, 79], "fig_functionclass": 24, "figsiz": [24, 25, 28, 29, 37, 38, 39, 40, 74, 78, 79], "figur": [4, 22, 23, 24, 25, 27, 28, 29, 32, 38, 39, 43, 54, 74, 75, 79], "figure_kwarg": [24, 25], "file": [4, 9, 14, 24, 25, 28, 29, 44, 52, 53, 55, 56, 57, 60, 69, 70, 71, 73, 76, 82, 83, 84], "file_download": [24, 73], "file_path": 80, "file_prefix": [70, 71], "file_reader_using_gener": 80, "file_reader_using_iter": 80, "filehandl": 82, "filenam": [80, 82], "filepath": [24, 83], "filipino": 55, "fill": [6, 10, 17, 19, 22, 25], "filter": [24, 45, 51, 52, 54, 55, 56, 65, 71, 76], "filtered_us": 54, "final": [9, 14, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 35, 39, 51, 52, 53, 55, 64, 73, 75, 78, 82, 83], "financi": [24, 51, 53], "financial_phrasebank": [32, 75, 77], "financialdataset": 75, "financialphrasecol": 77, "financialphrasedataset": 77, "find": [4, 6, 16, 17, 23, 24, 25, 28, 29, 31, 32, 35, 39, 40, 42, 51, 52, 54, 56, 57, 60, 62, 65, 78, 79, 82], "find_free_port": [44, 46], "find_min_max": 6, "find_root_dir": [25, 28, 29], "finder": [61, 62], "fine": [8, 9, 10, 24, 25, 29, 30, 32, 33, 45, 71, 76, 78, 85], "finer": 84, "finetun": 72, "finish": [16, 19, 27, 83], "finit": [16, 17, 22, 23, 26, 42, 79], "finn": [1, 23], "fire": [8, 59], "first": [6, 8, 9, 13, 14, 17, 19, 23, 24, 27, 28, 29, 31, 32, 33, 34, 35, 38, 39, 41, 44, 45, 51, 52, 53, 54, 55, 56, 64, 65, 66, 67, 69, 71, 73, 74, 75, 78, 79, 80, 82, 83, 85], "first_el": 6, "first_row": 80, "first_sentence_norm": 24, "first_sequ": 24, "first_sequence_": 24, "first_sequence_decod": 24, "first_sequence_mean": 24, "first_sequence_var": 24, "firstli": [23, 24, 25, 31, 35, 52, 54, 74, 75, 78, 79], "firstrow": 73, "fit": [3, 9, 14, 22, 25, 28, 29, 35, 43, 53, 54, 55, 58, 59, 62, 63, 74, 78, 79, 84], "five": 62, "fivetran": 56, "fix": [6, 13, 16, 19, 22, 23, 24, 25, 27, 28, 31, 35, 42, 54, 60, 62, 71, 73, 74, 78], "fixm": [24, 83], "fixtur": 61, "flag": [9, 17, 25, 31, 57, 62, 82], "flags_help": 82, "flamegraph": 69, "flat": [24, 53], "flatten": [24, 25, 78], "flexibl": [3, 4, 6, 7, 19, 54, 56, 82, 84, 85], "flink": 55, "flip": [57, 74], "float": [3, 4, 5, 6, 7, 8, 9, 10, 17, 22, 24, 25, 28, 29, 32, 53, 67, 68, 69, 70, 74, 75, 76, 77, 78, 79, 82, 83, 84, 87], "float16": [68, 73], "float32": [24, 67, 79], "float64": [7, 28], "float_valu": 3, "floatfmt": 73, "floating_point_op": 76, "floatingpointprecis": 73, "floattensor": [24, 68, 70, 75], "floor": [14, 16], "flop": [33, 52, 69], "flops_achieved_per_second": 73, "flops_need": 73, "flops_per_iter_per_fwdbwd": 73, "flops_per_sequence_per_fwdbwd": 73, "flops_per_token_per_fwdbwd": 73, "flops_throughput": 73, "flops_tot": 73, "flour": 35, "flow": [19, 22, 24, 27, 31, 56, 84], "fluff_ratio": 73, "fly": [3, 4, 17, 31, 65, 80], "flyabl": [3, 4], "fmt": [17, 24, 25, 28, 31, 60, 68, 70, 73, 74], "fn": [28, 44, 46, 51, 59], "fn_kwarg": [32, 75], "fnr": 51, "focal": 52, "focu": [3, 21, 23, 24, 25, 31, 34, 53, 54, 55, 56, 57], "focus": [3, 7, 9, 14, 16, 17, 19, 21, 23, 24, 38, 73, 75], "fold": [31, 62, 63, 64], "folder": [24, 60, 82], "follow": [4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 45, 48, 52, 53, 54, 55, 56, 58, 59, 60, 62, 65, 67, 70, 71, 73, 74, 75, 76, 78, 79, 80, 82, 85], "font": 17, "fontsiz": [24, 37, 38, 39, 40], "foo": 82, "footag": 35, "footbal": 29, "footer": 82, "footnotes": 17, "footprint": [24, 31, 58, 60, 80], "foral": [3, 5, 14, 16, 22], "forc": [7, 17, 24, 25, 57, 67, 68, 69, 70, 71, 73, 75, 80], "force_download": [24, 73], "force_memory_leak": 71, "ford": 53, "foreach": [17, 25, 74], "forecast": 58, "forefront": 21, "foreign": 54, "foresight": [16, 68, 70, 75], "forest": [52, 58, 70, 87], "forget": 52, "forgiv": 74, "forgot": 71, "fork": 75, "form": [3, 4, 9, 10, 14, 17, 22, 23, 25, 27, 28, 29, 31, 34, 37, 38, 42, 45, 52, 53, 56, 57, 62, 63, 65, 74, 76, 78, 85], "formal": [3, 4, 5, 10, 11, 16, 17, 22, 23, 24, 25, 26, 27, 35, 38, 39, 42, 52, 64, 78, 79, 80, 85], "format": [4, 9, 13, 14, 23, 24, 25, 29, 45, 51, 52, 54, 56, 57, 64, 65, 67, 68, 69, 70, 71, 73, 75, 82], "formatt": [75, 77, 82], "former": [8, 24, 27, 29, 54, 76], "formul": [5, 14, 22, 23, 24, 25, 33, 48, 52], "formula": [13, 22, 24, 25, 29, 40, 66, 73, 78, 79], "forth": 69, "fortran": 53, "fortun": [52, 66], "forum": 55, "forward": [23, 25, 31, 32, 60, 68, 70, 71, 74, 75, 76], "forward_backward": 68, "forward_pass": 70, "forward_tot": 73, "found": [4, 5, 6, 9, 14, 16, 17, 23, 24, 25, 27, 28, 29, 40, 44, 45, 55, 76], "foundat": [4, 5, 23, 34, 35, 40, 42, 54, 58, 69], "four": [25, 29, 35, 43, 52, 53, 59, 65], "fowler": 85, "fp": [51, 59], "fp16": [73, 76], "fp16_backend": 76, "fp16_full_ev": 76, "fp16_opt_level": 76, "fp32": 73, "fp64": 73, "fpr": [32, 51, 75], "frac": [13, 14, 16, 17, 22, 23, 24, 25, 27, 28, 29, 31, 34, 39, 40, 42, 43, 58, 59, 73, 77, 78, 79], "fraction": [22, 25, 73], "fragil": 23, "frame": [14, 22, 23, 31, 33, 37, 48, 51, 56, 57, 65, 74], "framework": [3, 5, 16, 21, 23, 24, 25, 27, 34, 53, 60, 80], "frank": 1, "fraud": [51, 52, 54, 57, 59, 65], "fraudul": [52, 65], "free": [25, 31, 37, 38, 44, 54, 66, 68, 71], "freedom": 31, "freeli": [7, 52], "freez": [31, 32], "french": [23, 52], "frequenc": [24, 57, 59], "frequent": [17, 19, 29, 52, 53, 54, 55, 65, 71], "fresh": [57, 62], "friedman": [26, 27], "friend": [52, 54], "friendli": [51, 56], "frighteningli": 28, "frobeniu": 31, "from": [3, 4, 5, 6, 7, 8, 10, 13, 14, 16, 17, 19, 21, 22, 25, 27, 28, 29, 30, 31, 32, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 80, 82, 83, 84, 85, 87], "from_dict": [82, 84], "from_numpi": 24, "from_pretrain": [24, 32, 73, 75, 76, 77], "from_token": 25, "fromnumer": 28, "front": 25, "frozen": [23, 31, 80, 83], "frozen_out": 32, "frustrat": 52, "fsdp": [44, 76], "fsdp_config": 76, "fsdp_min_num_param": 76, "fsdp_transformer_layer_cls_to_wrap": 76, "fsdpoption": 76, "fsx": [45, 55], "fulfil": [3, 4, 25, 40], "full": [9, 14, 21, 23, 25, 27, 31, 54, 56, 61, 62, 65, 74, 77, 79], "full_determin": 76, "full_parameter_nam": 25, "fullfil": 52, "fulli": [24, 28, 51, 54, 60, 62, 73], "fun": [39, 83], "func": [53, 69, 76], "func_all_memb": 76, "func_or_class": 76, "func_or_method": [25, 76], "func_sig": 76, "function": [1, 3, 4, 7, 10, 11, 14, 17, 19, 28, 29, 31, 33, 39, 40, 42, 44, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 67, 69, 71, 73, 77, 78, 82, 83, 85, 87], "function_with_bound": 7, "function_with_union": 7, "functionev": 69, "functool": [25, 28, 53, 74, 78], "fundament": [3, 5, 14, 16, 17, 19, 25, 34, 35, 37, 38, 39, 40, 42, 53, 54, 56, 57, 63, 66, 75, 80], "funtion": 27, "furri": 54, "further": [22, 59], "furthermor": [3, 7, 8, 13, 16, 17, 19, 22, 23, 24, 25, 27, 31, 35, 39, 52, 53, 56, 58, 60, 61, 62, 78, 79, 84, 85], "fuse": [25, 52], "futil": 16, "futur": [21, 22, 23, 31, 35, 58, 74, 75], "future_mask": [24, 25, 74, 75], "future_masks_expand": 25, "futurewarn": [24, 25, 32, 73, 75, 77], "fwd": 73, "g": [3, 5, 8, 9, 10, 13, 14, 16, 19, 22, 23, 24, 25, 28, 29, 37, 38, 39, 42, 43, 44, 45, 51, 52, 53, 54, 55, 56, 57, 61, 62, 64, 65, 66, 73, 76, 77, 79, 80, 85], "g4dn": [43, 45], "g4dn12xlarg": 45, "g4dn2x": 44, "g4dn2xlarg": [44, 45], "g_i": 79, "ga": 65, "gain": [16, 17, 23, 24, 65, 79], "gambler": 58, "game": [17, 52], "gamma": [22, 24, 25], "gamma_": 24, "gamma_d": [22, 24], "gan": 52, "gao": [1, 2, 21, 23, 25, 78], "gaohn": [28, 45, 56, 82], "gap": 34, "garbag": 80, "gareth": [26, 27], "garner": 23, "gate": [22, 24], "gate_proj": 32, "gatewai": 45, "gather": [51, 54, 55, 59], "gather_backward": 70, "gatherbackward0": 70, "gaug": [51, 52, 53, 62, 73], "gaussian": [26, 27, 29, 31], "gave": [4, 8, 54], "gb": [70, 73], "gc": [68, 71, 77], "gc_collect_interv": 71, "gc_interv": 71, "gca": [25, 78], "gcp": 65, "gdpr": 55, "ge": [82, 84], "gear": [52, 62, 65], "geeksforgeek": [18, 19, 20], "gelu": [23, 25, 68, 70, 74, 75], "gelu_new": 24, "gemini": 24, "gen": 80, "gender": 52, "gener": [1, 2, 3, 4, 5, 8, 9, 11, 14, 16, 27, 28, 29, 31, 32, 33, 42, 45, 51, 52, 53, 54, 56, 57, 58, 60, 62, 63, 65, 66, 68, 70, 71, 74, 75, 76, 78, 79, 81, 83, 87], "general_util": 25, "generalis": 24, "generaliz": 23, "generalpurpos": 45, "generate_config": 25, "generated_equ": 25, "generated_token": 25, "generation_util": 32, "generational_gc_": 71, "generationmixin": 76, "generator_config": 74, "generatorconfig": [25, 74], "generatorexit": 80, "generic_anim": 4, "generic_animal_sound": 4, "generic_cat": 4, "generic_cat_sound": 4, "generic_dog": [4, 5], "generic_dog_sound": 4, "genericalia": 8, "genet": 51, "genexpr": 80, "genom": 53, "genr": 66, "gentl": [25, 78], "geograph": [51, 53, 64], "geometr": [19, 39], "geometri": [27, 29, 35, 39, 40], "geospati": 53, "geq": [13, 14, 16, 17, 22, 25, 27, 39, 42, 58, 78, 79], "get": [3, 6, 8, 9, 10, 13, 14, 16, 22, 23, 24, 25, 27, 28, 29, 31, 40, 44, 45, 48, 52, 53, 54, 56, 57, 59, 61, 63, 65, 73, 74, 75, 78, 79, 80, 82, 84, 85], "get_adapter_state_dict": 76, "get_all_arg": 76, "get_args_pars": [44, 46], "get_base_class": 76, "get_batch": 24, "get_buff": 76, "get_constructor_field_annot": 76, "get_context": 44, "get_cosine_annealing_with_warmup": [25, 78], "get_decay_parameter_nam": 76, "get_default": 76, "get_employe": 8, "get_encod": 24, "get_eval_dataload": 76, "get_extended_attention_mask": 76, "get_extra_st": 76, "get_field_annot": [25, 76], "get_first": 6, "get_head_mask": 76, "get_height": 79, "get_hostnam": 44, "get_image_compression_ratio": 29, "get_image_compression_ratio_for_kmean": 29, "get_input_embed": 76, "get_ipython": [24, 76], "get_kei": 6, "get_last_lr": 78, "get_learning_r": [25, 78], "get_linear_schedule_with_warmup": [76, 77], "get_manag": 8, "get_members_of_function_or_method": 76, "get_memory_footprint": 76, "get_optimizer_cls_and_kwarg": 76, "get_output_embed": 76, "get_paramet": 76, "get_position_embed": 76, "get_process_id": 44, "get_random_batch": [68, 70], "get_second": 6, "get_sorted_us": 54, "get_sorted_users_by_ag": 54, "get_submodul": 76, "get_test_dataload": 76, "get_test_transform": 85, "get_train_dataload": 76, "get_train_transform": 85, "get_training_strategi": 87, "get_type_hint": 76, "get_valu": 6, "get_width": 79, "get_with_not_given": 10, "get_x": 79, "getattr": 82, "getcwd": 25, "getdoc": 25, "gethostnam": [70, 71], "getlogg": [67, 68, 69, 70, 71, 75, 77, 82], "getmro": 76, "getsizeof": [29, 80], "getter": 8, "gif": 48, "gigabyt": 73, "git": [25, 28, 29, 45, 56, 60], "git_commit_hash": 56, "github": [1, 10, 28, 30, 32, 35, 45, 56, 68, 70, 71, 72, 73, 75, 77], "githubusercont": [24, 25], "gitignor": 60, "give": [9, 13, 16, 17, 22, 24, 25, 26, 27, 31, 35, 42, 45, 55, 56, 61, 62, 63, 66, 67, 73, 77, 79, 80], "given": [3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 35, 37, 38, 39, 40, 44, 51, 52, 54, 58, 59, 65, 69, 71, 73, 74, 75, 76, 77, 78, 79], "glanc": [27, 52, 78], "global": [23, 26, 55, 60, 68, 76, 82], "global_": [25, 74], "global_config": 25, "global_pool": [82, 84], "global_rank": [44, 46], "global_step": [32, 75], "globaln": 76, "gloo": [25, 46, 74], "glove": 23, "gmm": 27, "gnn": 52, "go": [4, 9, 16, 23, 24, 25, 29, 31, 39, 45, 52, 53, 54, 55, 56, 60, 62, 65, 71, 82], "goal": [16, 17, 22, 23, 24, 27, 31, 51, 55, 56, 57, 58, 62, 76, 79], "god": 51, "goe": [14, 17, 23, 24, 25, 59, 64, 80, 85], "goku": 55, "golang": 3, "gomez": [1, 2, 21, 23, 30, 31], "gone": 16, "good": [3, 8, 14, 17, 24, 27, 31, 32, 35, 45, 51, 52, 56, 57, 58, 59, 60, 62, 64, 65, 66, 68, 71, 74, 75, 82], "goodboychan": [26, 28], "goodfellow": [1, 2, 79], "googl": [23, 24, 27, 35, 48, 51, 52, 53, 54, 55, 56, 59, 62, 65, 73], "googleapi": 29, "got": [24, 25, 44, 75], "govern": [46, 53, 55, 84], "gpt": [21, 22, 31, 33, 52, 56, 57, 68, 72, 75, 79, 83], "gpt2": [24, 73, 75, 76], "gpt2_checkpoint_size_estimated_in_byt": 73, "gpt2_checkpoint_size_estimated_in_gb": 73, "gpt2_checkpoint_size_measured_in_byt": 73, "gpt2_checkpoint_size_measured_in_gb": 73, "gpt2_config": 73, "gpt2_flops_using_own_flops_calcul": 73, "gpt2_flops_using_palm_flops_calcul": 73, "gpt2_larg": 73, "gpt2_medium": 73, "gpt2_params_no_bia": 73, "gpt2_params_no_bias_manu": 73, "gpt2_params_with_bia": 73, "gpt2_xl": 73, "gpt2attent": 24, "gpt2block": 24, "gpt2config": 24, "gpt2forsequenceclassif": [75, 77], "gpt2lmheadmodel": [24, 73, 76], "gpt2lmheadmodel_methods_using_getmemb": 76, "gpt2mlp": 24, "gpt2model": 24, "gpt2modeltyp": 73, "gpt2pretrainedmodel": 76, "gpt2token": [75, 77], "gpt_config": 68, "gpt_larg": 24, "gpt_medium": 24, "gpt_small": 68, "gpt_small_config": [68, 70], "gpt_with_head": 24, "gpt_xl": 24, "gptbackbon": 75, "gptblock": [68, 70], "gptconfig": [68, 70, 73], "gptdecod": [24, 25, 74], "gptdecoderblock": [24, 25, 74, 75], "gptdecoderrevers": 74, "gptforsequenceclassif": 75, "gptpretrainedmodel": 75, "gpu": [23, 24, 31, 43, 44, 51, 53, 60, 64, 66, 67, 68, 69, 70, 72, 76], "gpu_flop": 73, "gpu_memori": 73, "gpu_promised_flop": 73, "gpu_usag": 83, "gpumemori": 73, "grad": [58, 71, 79], "grad_accum": 73, "grad_fn": [24, 25, 79], "grade": 53, "gradient": [1, 2, 22, 23, 25, 31, 34, 39, 44, 52, 58, 60, 62, 71, 73, 78, 83, 87], "gradient_accumul": 73, "gradient_accumulation_step": [25, 32, 74, 75, 76], "gradient_boost": 87, "gradient_checkpoint": 76, "gradient_checkpointing_dis": 76, "gradient_checkpointing_en": 76, "gradient_checkpointing_kwarg": 76, "gradientboostingstrategi": 87, "gradscal": 25, "gradual": [4, 25, 27, 64, 78], "grafana": 66, "grain": [10, 29, 71, 84], "gram": [21, 23], "grammar": 24, "grant": 69, "granular": [25, 54, 55], "graph": [52, 53, 56, 71], "graphic": [35, 66], "graphql": 53, "grappl": 23, "grasp": [16, 19, 29, 37, 38, 62], "grayscal": 53, "great": [14, 60, 65], "greater": [4, 7, 13, 14, 16, 17, 27, 39, 54, 66, 78, 79, 82, 84], "greater_is_bett": 76, "greedi": [24, 25, 74], "greedili": [24, 27], "greedy_search": 76, "green": [17, 29, 35, 38, 39, 64], "greet": 24, "grid": [28, 39, 53, 60, 62], "grossli": 56, "ground": [25, 27, 40, 66, 74], "groundwork": 16, "group": [6, 24, 25, 26, 27, 29, 42, 45, 46, 52, 56, 61, 62, 64, 65, 66, 82], "group_beam_search": 76, "group_by_length": 76, "grouping_vari": 56, "groupkfold": 62, "grow": [14, 16, 17, 19, 24, 55, 56, 78], "growth": [16, 17, 19, 24], "growth_factor": [25, 74], "growth_interv": [25, 74], "gt": [24, 25, 28, 75, 76, 79, 80], "guarante": [4, 6, 14, 16, 17, 23, 24, 27, 31, 34, 35, 46, 54, 56, 79], "guard": [16, 57], "guava": 54, "guess": [24, 25, 27], "guest": 24, "gui": 25, "guid": [8, 11, 15, 16, 17, 29, 39, 45, 51, 52, 55, 57, 59, 63, 85], "guidanc": 85, "guidelin": [5, 65], "guido": [8, 11], "gz": [70, 71], "h": [1, 2, 8, 16, 21, 22, 23, 24, 25, 27, 29, 42, 52, 58, 62, 68, 70, 71, 73, 74, 75, 78, 79, 82], "h2": [35, 36, 41], "h_": [23, 24, 42, 70, 71, 79], "h_0": 23, "h_1": 52, "h_2": 52, "h_k": 79, "ha": [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 21, 22, 25, 27, 28, 29, 32, 35, 37, 39, 42, 43, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 63, 64, 65, 66, 68, 69, 71, 73, 74, 75, 76, 78, 79, 80, 83], "habit": [53, 74], "hackerllama": [23, 24], "had": 71, "hadamard": 22, "hadoop": [53, 55, 56], "haha": 25, "haitongli": 77, "haken": 13, "hal": [26, 27], "half": [14, 16, 24, 25, 43, 74, 76, 78], "half_precision_backend": [32, 75, 76], "hallmark": 17, "hallucin": 76, "halt": [4, 10], "halv": [14, 16], "hame": 25, "hampton": [2, 11], "han": [1, 2, 21, 23, 78], "hand": [3, 4, 6, 7, 16, 23, 24, 25, 27, 35, 39, 52, 54, 58, 62, 65, 78, 79, 80, 85], "handbook": [19, 20], "handcraft": [57, 61], "handi": 82, "handl": [3, 4, 8, 10, 14, 16, 22, 23, 25, 28, 29, 51, 53, 54, 55, 56, 57, 58, 60, 65, 73, 76, 77, 78, 80, 85], "handler": [67, 68, 69, 70, 75, 77, 82], "handout": 14, "handwritten": 52, "hang": 80, "hanin": [2, 79], "haom": 1, "happen": [3, 4, 14, 19, 24, 28, 42, 46, 52, 56, 66, 68, 71, 74, 79, 80], "happi": 9, "happili": [3, 4, 5, 59], "har": 23, "hard": [5, 16, 26, 27, 76, 77, 82, 84], "hard_loss": 77, "hardcod": [25, 82], "hardcor": 72, "harder": [6, 71], "hardwar": [51, 53, 60, 64, 65, 73], "harm": [57, 59], "harmon": 59, "harri": 54, "harvard": [23, 24], "hasattr": [3, 24, 25, 68, 70, 75, 76], "hash": [27, 56, 60], "hashtag": [48, 51], "hasn": [10, 62, 63, 76], "hasti": [26, 27], "hat": [22, 23, 24, 27, 29, 31, 35, 42, 52, 79], "have": [3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85, 87], "haven": 66, "hazard": 65, "hazi": 54, "hdf": [53, 55], "he": [1, 2, 21, 23, 24, 27, 48, 54, 55, 73, 78], "head": [23, 25, 32, 37, 38, 44, 60, 68, 70, 73, 75, 79], "head_attent": 24, "head_bia": 75, "head_nod": 45, "head_node_ip": 45, "head_siz": 73, "header": [29, 55, 73, 82], "headnod": 45, "headphon": 17, "health": [53, 55, 56], "healthcar": [51, 52, 53, 59], "healthi": 59, "heap": [16, 17], "hear": 24, "heart": [14, 35, 52], "heavi": 13, "heavili": [17, 24, 25, 54, 73, 82], "hei": 74, "height": [14, 19, 29], "held": [52, 62, 64, 80], "hell": 24, "hello": [4, 6, 24], "helmet": 52, "help": [5, 8, 11, 16, 17, 22, 23, 24, 25, 27, 29, 37, 42, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 65, 66, 71, 73, 78, 79, 82], "helper": [25, 28], "hematoxylin": 29, "henc": [3, 14, 16, 23, 24, 25, 27, 28, 38, 39, 42, 46, 66, 70, 73, 77, 78, 79, 80], "her": [16, 58, 65], "here": [3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 70, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83], "hestain": 29, "heterogen": 52, "heurist": [23, 25, 27, 58, 78], "hh": [56, 82], "hi": [4, 24, 25, 73], "hidden": [4, 22, 23, 24, 31, 74, 75], "hidden_s": 24, "hierarch": [7, 82], "hierarchi": [5, 82], "high": [14, 16, 17, 23, 24, 25, 27, 28, 31, 39, 42, 44, 45, 51, 52, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 73, 78, 79, 80], "higher": [16, 17, 23, 25, 29, 31, 35, 42, 51, 52, 53, 58, 59, 73, 77, 79], "highest": [17, 24, 28, 78, 79], "highli": [16, 23, 24, 27, 54, 55, 56, 57, 58, 62, 80], "highlight": [6, 17, 23, 24, 28, 34, 39, 59, 61, 62, 71, 76, 79, 82], "hilbert": [1, 39], "him": 24, "himself": 73, "hing": [23, 25, 34], "hint": [4, 5, 6, 7, 8, 9, 11, 19, 68, 70, 76, 80, 82, 85], "hinton": 77, "hipaa": 55, "histor": [17, 65], "histori": [19, 23, 24, 25, 51, 52, 54, 65, 71, 74, 83], "hit": [14, 32, 58, 80], "hline": [22, 66], "hobbit": 54, "hoc": [25, 56], "hold": [3, 5, 6, 8, 13, 14, 16, 17, 24, 34, 35, 38, 39, 40, 44, 54, 58, 79, 80, 84, 85], "holdout": [23, 48, 58, 63], "holdout_perform": 83, "holm": 54, "home": [25, 45, 76], "home_dir": 56, "homebrew": 28, "homogen": [39, 52, 59], "honestli": [46, 52], "hongnan": [23, 25, 37, 38, 44, 46], "hood": [68, 80, 82], "hook": 44, "hop": 54, "hope": 58, "horizont": [37, 39, 55], "horizontal_component_v": 39, "hors": 23, "hospit": 51, "host": [14, 24, 65, 82], "host_nam": [70, 71], "hostedtoolcach": [24, 73, 76, 78], "hostnam": [44, 45, 46], "hot": [55, 57, 65, 79], "hour": [16, 23, 24, 52, 57, 65, 66], "hous": [23, 35, 42, 52], "how": [4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 29, 31, 32, 33, 35, 37, 38, 39, 40, 44, 47, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 71, 72, 78, 79, 82, 83, 84, 85], "how_many_l": [3, 4], "how_to": 77, "howev": [3, 4, 5, 6, 8, 10, 14, 16, 17, 19, 22, 23, 24, 25, 26, 27, 28, 29, 31, 35, 38, 39, 40, 42, 43, 44, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 66, 67, 71, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85], "hpc": [45, 55], "hspace": 24, "htan": 44, "html": [1, 8, 28, 29, 31, 32, 47, 53, 55, 70, 71, 77], "htod": 69, "http": [1, 8, 24, 25, 29, 30, 31, 32, 45, 47, 53, 68, 70, 71, 73, 75, 77, 82], "hu": [1, 24, 30, 31], "hub": [56, 76], "hub_always_push": 76, "hub_model_id": 76, "hub_private_repo": 76, "hub_strategi": 76, "hub_token": 76, "hubstrategi": 76, "hudi": 55, "hug": [23, 30], "huge": [24, 31, 58], "huggingfac": [32, 52, 77, 78], "huggingface_hub": [24, 73], "human": [23, 52, 53, 56, 65], "humid": 53, "hutter": [1, 2, 21, 23, 25, 78], "huyen": [26, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 65], "hybrid": [53, 55, 56], "hydra": [24, 80], "hydra_config": 82, "hydra_config_group": 82, "hydra_help": 82, "hydra_log": 82, "hydra_pydantic_config_manag": 82, "hydra_to_pydant": 82, "hydraconfig": 82, "hype": [54, 56], "hyper": 76, "hyperparamet": [24, 31, 48, 52, 61, 63, 77, 78, 82, 84], "hyperparameter_search": 76, "hypotenus": 39, "hypothes": [31, 42], "hypothesi": [14, 17, 23, 31, 42, 52, 57, 58, 62], "hypothet": [6, 8, 14, 51, 66], "h\u00f6lder": 58, "i": [1, 2, 4, 7, 9, 10, 11, 13, 14, 16, 17, 19, 21, 25, 26, 28, 29, 30, 31, 32, 33, 35, 39, 42, 43, 44, 46, 48, 51, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 82, 83, 84, 85], "i1": [22, 35], "i2": [22, 35], "ian": 1, "ic": [2, 11], "iceberg": 54, "id": [6, 17, 24, 43, 44, 52, 54, 65, 68, 69, 70, 74, 75, 82], "id2label": [32, 75], "idea": [3, 10, 14, 16, 22, 24, 25, 27, 30, 31, 37, 44, 45, 52, 54, 56, 57, 60, 62, 75, 78, 82], "ideal": [6, 9, 16, 17, 19, 25, 35, 42, 53, 54, 55, 59, 65, 73], "idempot": 8, "idenf": 45, "ident": [23, 25, 34, 37, 39, 52, 54, 76, 79], "identif": [6, 51], "identifi": [6, 15, 16, 23, 24, 27, 29, 37, 40, 43, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 73], "idf": [52, 57], "idiomat": 35, "idl": 45, "idx": [24, 77, 80], "ieee": 33, "iff": [14, 27, 39], "ignor": [5, 6, 8, 9, 16, 24, 28, 44, 46, 68, 70, 74, 75, 78, 82], "ignore_data_skip": 76, "ignore_index": [24, 25, 74], "igw": 45, "igw_id": 45, "iid": [24, 42, 62, 79], "iii": [26, 27], "iinfo": 31, "ij": [22, 35, 40, 73, 79], "ik": [22, 73], "ill": [25, 40, 78], "illia": 1, "illumin": 16, "illustr": [3, 5, 6, 8, 10, 14, 16, 19, 23, 24, 31, 34, 35, 37, 38, 39, 40, 51, 55, 59, 78, 80], "iloc": 53, "ilya": 1, "imag": [13, 14, 16, 23, 24, 25, 26, 31, 33, 35, 39, 40, 45, 48, 51, 52, 53, 54, 55, 57, 58, 62, 65, 71, 74, 78, 80, 82, 85], "image_classif": 52, "image_classification_transform": 85, "image_path": 29, "image_s": [82, 84], "image_segmentation_transform": 85, "image_shap": 29, "image_size_in_bit": 29, "image_url": 53, "imagecaptioningtransform": 85, "imageclassif": 85, "imageclassificationtransform": 85, "imageri": [26, 28], "imagesegment": 85, "imagesegmentationtransform": 85, "imagin": [3, 16, 19, 24, 27, 35, 44, 54, 56, 57, 65], "imbalanc": [57, 59, 62], "imdb": 55, "immedi": [7, 9, 14, 17, 23, 35, 56, 57, 59, 65, 76, 80], "immut": [10, 24, 25, 44, 56], "immutablelist": 8, "impact": [24, 25, 31, 39, 51, 55, 56, 58, 59, 60, 62, 64, 65, 66, 78, 79], "imper": 17, "implement": [2, 4, 5, 6, 8, 10, 11, 21, 22, 27, 30, 33, 48, 51, 54, 55, 56, 58, 64, 65, 68, 70, 74, 82, 83, 85], "impli": [3, 4, 6, 7, 8, 14, 16, 17, 23, 24, 27, 31, 37, 38, 39, 40, 43, 57, 58, 73, 79, 83], "implic": [4, 23, 38, 40, 51, 53, 59], "implicit": [3, 16, 22, 23, 24, 25, 31, 71], "implicitli": [3, 16, 23, 27, 44, 74, 80], "import": [3, 4, 5, 6, 7, 8, 10, 16, 17, 22, 23, 24, 25, 27, 29, 31, 32, 35, 37, 38, 39, 40, 42, 44, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 87], "importantli": [61, 79], "importerror": [24, 25, 28, 29], "impos": [8, 16, 58], "imposs": [4, 16, 34], "impract": 6, "impress": 14, "improperli": 76, "improv": [1, 2, 14, 16, 17, 21, 22, 23, 24, 25, 27, 48, 51, 52, 53, 54, 55, 57, 58, 60, 62, 64, 65, 66, 76, 77, 78, 79, 80, 84], "imread": 29, "imshow": [24, 29], "in_chan": [82, 84], "in_channel": [82, 84], "in_dim": 32, "in_featur": [24, 25, 31, 32, 68, 70, 74, 75, 82], "in_indic": [68, 70], "in_jupyt": 24, "in_proj_weight": 25, "inabl": 82, "inaccur": [57, 69, 79], "inadmiss": 13, "inadvert": [23, 24, 56], "inappropri": 57, "inc": [26, 27, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 65, 71], "inclin": 35, "includ": [3, 4, 5, 6, 7, 11, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 32, 34, 35, 39, 43, 44, 45, 51, 52, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 76, 79, 80, 83, 84, 85], "include_bas": 76, "include_bia": 73, "include_extra": 76, "include_inputs_for_metr": 76, "include_num_input_tokens_seen": 76, "include_self": 76, "include_tokens_per_second": 76, "inclus": [14, 29], "incom": [52, 65, 68, 70], "incompat": [4, 6, 8, 9, 19, 70, 75], "incomplet": [25, 55, 79], "inconsist": [35, 54, 55, 56], "incorpor": [17, 22, 23, 40, 52, 65, 72], "incorrect": [3, 6, 8, 57, 59], "incorrect_pair": 6, "incorrectli": [6, 51, 59], "increas": [8, 16, 19, 22, 23, 24, 25, 27, 31, 38, 51, 52, 53, 57, 59, 60, 65, 66, 71, 78, 79, 83], "increasingli": [24, 25, 60], "increment": [16, 17, 28, 31, 55, 56, 80, 83], "incur": [25, 51], "inde": [3, 5, 6, 8, 9, 14, 17, 19, 23, 24, 25, 27, 35, 39, 45, 58, 59, 65, 73, 75, 79], "indefinit": [10, 80], "indent": [44, 46, 68], "indeped": 25, "independ": [23, 29, 31, 43, 46, 59, 73, 79, 85, 87], "index": [1, 8, 9, 14, 17, 19, 24, 27, 28, 29, 31, 40, 42, 43, 44, 45, 54, 55, 59, 74, 75, 79, 80, 82, 83, 85], "index_select": 70, "index_to_token": 25, "indic": [3, 4, 5, 6, 10, 14, 16, 17, 22, 24, 25, 27, 28, 29, 31, 37, 38, 40, 42, 51, 52, 57, 59, 60, 64, 65, 66, 69, 74, 77, 79, 80, 82], "indices_logit": 79, "indices_prob": 79, "indices_to_remov": 24, "indirect": 23, "indiscern": 39, "indiscrimin": 6, "indispens": 39, "indistinguish": 80, "individu": [16, 19, 22, 24, 25, 35, 40, 42, 52, 53, 54, 56, 58, 65, 73, 78, 79], "individual_test": [14, 16, 17], "indonesian": 55, "induc": [23, 24, 27, 39, 79], "induct": 14, "industri": [51, 53, 55, 56], "ineffect": 51, "ineffici": [6, 16, 24, 51, 53, 57, 73, 80], "inequ": [8, 16, 27, 39], "inertia": 28, "inertia_": 28, "inevit": 31, "inf": [10, 22, 24, 25, 27, 28, 68, 70, 74], "infer": [6, 9, 24, 32, 51, 52, 54, 56, 58, 64, 73, 75, 77, 79, 83], "infin": [3, 22, 23, 79], "infinit": [27, 42, 45, 65], "infinite_sequ": 80, "influenc": [22, 24, 39, 51, 52, 53, 58, 84], "influenci": 24, "influenti": [57, 60], "info": [6, 24, 25, 28, 44, 45, 46, 56, 67, 68, 69, 70, 71, 74, 75, 77, 82], "inform": [1, 2, 4, 6, 9, 11, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 29, 30, 31, 34, 43, 45, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 71, 73, 74, 75, 76, 79, 82, 84], "infrastructur": [33, 48, 56, 57, 64, 65, 66], "infrequ": 19, "infti": [3, 16, 22, 24, 42, 74, 79], "ing": 24, "ingest": [56, 66], "ingrain": 39, "ingredi": 35, "inher": [3, 4, 5, 9, 16, 17, 22, 23, 24, 31, 40, 51, 53, 54], "inherit": [3, 4, 5, 6, 7, 19, 24, 32, 56, 75, 76, 82], "init": [24, 28, 29, 32, 44, 45, 68, 70, 74, 75], "init_bodi": 76, "init_hf_repo": 76, "init_method": [25, 44, 46, 74], "init_param": 76, "init_process": [44, 46], "init_process_group": 44, "init_scal": [25, 74], "init_weight": 76, "initi": [14, 16, 17, 19, 22, 24, 27, 28, 30, 31, 32, 35, 51, 52, 56, 57, 58, 60, 62, 64, 66, 71, 74, 75, 76, 77, 78, 79, 80, 82, 84, 87], "initial_lr": [25, 78], "initialize_model": [68, 70], "initializer_rang": 24, "inject": [6, 31, 44, 80, 82], "inlin": 8, "inner": [22, 23, 39, 76], "inner_dim": 24, "innov": 23, "inord": 14, "inplac": [24, 25, 32, 68, 70, 74, 75], "input": [5, 8, 9, 10, 13, 27, 29, 31, 32, 39, 42, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79], "input_id": [32, 74, 75, 77], "input_larg": 79, "input_layernorm": 32, "input_sequ": 25, "input_smal": 79, "input_token": [24, 25, 75], "inputs_pad": 25, "insert": [8, 14, 19], "insid": [56, 72, 78, 80, 82, 83, 85], "insight": [10, 16, 17, 23, 24, 35, 38, 40, 42, 44, 48, 52, 56, 57, 58, 60, 62, 63, 65, 66, 73, 79, 83], "inspect": [17, 25, 27, 33, 35, 45, 80], "inspector": 25, "inspir": [6, 10, 24, 25, 73, 78, 82, 83], "instabl": [22, 23, 31], "instagram": 52, "instal": [32, 45, 56, 57, 60, 67, 68, 69, 70, 71, 74, 75, 77], "instanc": [3, 4, 5, 6, 7, 8, 10, 13, 14, 17, 19, 22, 23, 24, 25, 27, 28, 31, 32, 34, 35, 38, 39, 40, 43, 44, 51, 52, 53, 54, 56, 57, 58, 59, 62, 64, 65, 66, 69, 71, 79, 82, 83, 84, 85], "instance_attr": 76, "instance_child": 76, "instance_child_all_memb": 76, "instance_method": 76, "instance_not_in_constructor_attr": 76, "instance_par": 76, "instanceid": 45, "instancetyp": 45, "instanti": [6, 8, 19, 24, 25, 29, 76, 84, 85], "instantli": [16, 65], "instead": [3, 4, 6, 8, 14, 16, 19, 22, 23, 24, 25, 27, 28, 31, 32, 35, 44, 54, 55, 56, 57, 58, 62, 65, 74, 75, 76, 79, 80, 82, 84, 85, 87], "instinct": 16, "institut": [2, 11, 24], "instruct": [54, 80], "instructgpt": [23, 24], "insuffici": 16, "int": [3, 4, 5, 6, 7, 8, 9, 10, 14, 16, 17, 19, 24, 25, 28, 29, 31, 32, 44, 46, 54, 60, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85], "int32": [25, 28, 53], "int64": [14, 24, 25, 28], "int_": 42, "int_valu": 3, "integ": [4, 6, 8, 9, 14, 16, 17, 19, 22, 24, 25, 28, 34, 37, 44, 53, 54, 74, 80, 82], "integr": [4, 5, 22, 23, 24, 33, 34, 42, 48, 51, 52, 54, 55, 56, 60, 64, 76, 82], "intellig": [7, 31, 48, 57], "intend": [6, 10, 17, 25, 51, 56, 78], "intens": [29, 48, 51, 52, 53, 54, 56, 57, 58, 65], "intent": [10, 17, 23, 35, 80], "intention": [10, 52], "intenum": 73, "inter": 43, "inter_param": 25, "interact": [1, 3, 14, 23, 24, 38, 40, 51, 54, 55, 56, 57, 65, 71, 74, 76, 80, 82], "interactiveshel": 76, "intercept": 35, "interchang": [14, 17, 24, 39, 42, 43, 53, 73], "interclass": 42, "interconnect": 54, "interest": [10, 16, 23, 24, 27, 42, 51, 52, 54, 55, 62, 63, 65, 68, 70, 79], "interf": 54, "interfac": [3, 4, 6, 7, 9, 45, 51, 56, 82, 85, 87], "interface_id": 45, "interfer": 83, "intermedi": [6, 14, 22, 24, 47, 55, 56, 73], "intern": [3, 6, 22, 23, 24, 32, 54, 55, 56, 71, 76, 77, 80], "internet": [23, 45, 65], "internetgatewai": 45, "internetgatewayid": 45, "interoper": [4, 56], "interplai": 16, "interpol": 82, "interpret": [1, 5, 17, 23, 24, 25, 27, 37, 39, 42, 52, 53, 59, 63, 71, 72, 78], "interrel": 52, "interrupt": [76, 80], "intersect": [27, 35, 57], "intertia": 28, "interv": [14, 16, 24, 25, 53, 56, 57, 65, 66, 71, 78, 79], "intervalstrategi": 76, "interview": [19, 20, 26, 48, 52, 56], "intpair": 6, "intra": [27, 43], "intraclass": 42, "intract": [14, 16], "intric": [22, 24, 31], "intrins": [22, 23, 35, 37], "introduc": [8, 10, 14, 16, 17, 22, 23, 24, 25, 40, 56, 73, 75, 78, 79, 80, 85], "introduct": [1, 20, 26, 27, 29, 33, 35, 39, 40, 48, 81], "introductori": [40, 72], "introspect": 76, "intuit": [8, 23, 25, 31, 34, 35, 38, 44, 54, 56, 58, 61, 68, 79], "intvalu": 6, "invalid": [6, 28, 45, 68, 85, 87], "invari": [11, 14, 16, 33, 39], "inventori": 65, "invers": [6, 33, 34, 57, 79, 82, 84, 86], "invert": 85, "invert_attention_mask": 76, "investig": 52, "invok": [6, 9, 27, 46, 69, 71, 76, 82], "involv": [3, 7, 16, 17, 22, 23, 24, 25, 38, 39, 40, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 73, 74, 79, 84, 85], "io": [1, 8, 51, 71, 77], "iot": [51, 53, 55], "ip": [22, 44, 45], "ipex_optimize_model": 76, "ipkernelapp": 24, "ipu": 76, "ipykernel": 76, "ipykernel_2585": 76, "ipython": [24, 74, 76], "ir": 30, "irregardless": 5, "irrelev": [37, 52, 55, 73], "irrespect": [3, 24, 35, 37], "irrespons": 58, "is_async": 69, "is_avail": [32, 44, 67, 68, 69, 70, 71, 75, 77], "is_bf16_support": 68, "is_empti": 19, "is_fast": 75, "is_flyabl": 3, "is_free_port": [44, 46], "is_in_train": 76, "is_legaci": 69, "is_local_process_zero": 76, "is_model_parallel": 76, "is_police_dog_instance_of_anim": 5, "is_police_dog_instance_of_dog": 5, "is_remot": 69, "is_stag": 56, "is_valid": 56, "is_world_process_zero": 76, "isbn": 1, "isbuiltin": 76, "isclos": 5, "isfunct": 76, "isgener": 80, "isin": 68, "isinst": [3, 5, 9, 10, 24, 25, 32, 68, 70, 74, 75, 78, 80, 83, 85], "ismethod": 76, "ismethoddescriptor": 76, "isn": [4, 8, 16, 23, 24, 25, 53, 54, 57, 58, 65, 66, 87], "isol": 43, "isoton": 59, "isotrop": 27, "isroutin": 76, "issu": [3, 4, 6, 7, 8, 10, 14, 16, 23, 24, 25, 27, 32, 51, 55, 56, 57, 58, 60, 62, 65, 70, 73, 74, 75, 76, 77, 79, 80, 82, 85], "issubclass": 25, "item": [6, 8, 17, 19, 24, 25, 28, 39, 54, 65, 68, 73, 74, 75, 76, 77, 79, 80, 82, 83, 85], "item_sep": 82, "iter": [4, 8, 13, 19, 24, 25, 27, 28, 29, 31, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 65, 68, 69, 70, 71, 73, 74, 75, 76, 78], "iter_cont": 24, "iterabledataset": 76, "iterativebinarysearchexactmatch": 14, "itertool": 68, "ito": 22, "its": [3, 5, 6, 7, 8, 10, 11, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 30, 31, 34, 35, 37, 38, 39, 40, 42, 43, 44, 48, 51, 52, 54, 55, 56, 58, 59, 62, 63, 64, 65, 66, 73, 74, 76, 78, 79, 80, 82, 84, 85, 87], "itself": [3, 5, 6, 7, 10, 13, 14, 16, 17, 22, 23, 24, 25, 27, 28, 31, 37, 39, 40, 51, 52, 55, 65, 69, 73, 74, 79, 80, 84, 85], "ivan": 11, "iwslt": [25, 78], "j": [1, 2, 11, 16, 21, 22, 23, 24, 27, 28, 29, 30, 31, 39, 42, 45, 52, 54, 69, 70, 72, 73, 77, 78], "j_": 79, "j_f": 58, "jackpot": 58, "jacobian": 58, "jai": [23, 24], "jakob": 1, "jam": 57, "jame": [13, 26, 27], "jan": [2, 21, 23], "januari": [26, 27], "jason": 82, "java": [3, 4, 6, 9, 11], "javascript": [53, 55], "jax": 75, "jeff": 1, "jeremi": 4, "jerom": [26, 27], "jianfeng": 1, "jiang": [1, 2, 21, 23, 78], "jiawei": 1, "jibberish": 25, "jimmi": 1, "jit_mode_ev": 76, "job": [7, 25, 27, 44, 45, 65, 82, 87], "job_log": 82, "jobless": 56, "joe": 23, "john": 53, "john_do": 6, "johnson": 9, "join": [25, 44, 46, 54, 55, 56, 76], "join_data": 56, "joined_data": 56, "joint": [22, 24, 31, 42, 58, 79], "jointli": [1, 23, 24, 27], "joke": 57, "jolli": 52, "jon": 13, "jone": [1, 2, 21, 23, 30, 31], "joseph": 1, "journei": 16, "jpeg": 53, "jpg": 53, "jq": 56, "json": [44, 45, 54, 55, 65, 69, 70, 71, 82], "judg": 4, "jump": [17, 79], "jun": [2, 30, 31, 79], "junction": 14, "junctur": [24, 37, 79], "jung": [1, 26, 27, 42], "jupyt": [28, 70], "jupyterlab": 70, "jurafski": [2, 21, 23, 24], "just": [3, 4, 7, 8, 9, 11, 14, 16, 17, 19, 22, 24, 25, 27, 28, 31, 34, 35, 39, 40, 42, 43, 44, 45, 46, 52, 54, 56, 57, 58, 59, 60, 61, 62, 66, 67, 72, 73, 74, 75, 76, 80, 82, 85, 87], "justifi": [52, 55], "justin": [23, 24], "k": [2, 6, 13, 16, 17, 21, 22, 23, 24, 25, 31, 32, 33, 35, 39, 42, 51, 54, 58, 62, 63, 64, 68, 70, 73, 74, 77, 79], "k0": 24, "k_": [16, 24, 27], "k_1": [16, 24], "k_2": [16, 24], "k_3": 24, "k_nearest_neighbor": 87, "k_proj": 32, "k_t": 24, "kafka": [53, 55, 56], "kaggl": [53, 58, 62, 63, 67], "kaim": 32, "kaiming_uniform_": 32, "kaiser": [1, 2, 21, 23, 30, 31], "kappa": 13, "karma": 23, "karpathi": [23, 25, 61, 62, 68, 70, 73], "karthik": 1, "karv": 9, "kb": 73, "kd": [27, 28], "keen": 40, "keep": [14, 19, 24, 31, 38, 43, 44, 51, 53, 57, 60, 64, 66, 68, 71, 80, 83], "keepdim": [22, 24, 79], "kei": [3, 5, 6, 7, 8, 10, 14, 16, 17, 25, 27, 35, 37, 38, 39, 40, 48, 51, 53, 55, 56, 57, 60, 63, 64, 66, 68, 69, 70, 73, 74, 75, 76, 79, 80, 83], "kenneth": 35, "kept": 8, "kera": [28, 70, 73, 77], "keras_recip": 77, "kernel": [24, 58, 69, 70, 71], "keskar": 1, "kevin": [1, 26, 27, 29], "key_averag": [69, 70], "keymateri": 45, "keynam": 45, "keyword": [24, 54, 55, 65, 75, 80], "kick": [56, 71], "kill": 24, "kilobyt": 73, "kind": [6, 8, 51, 53, 54, 55, 66, 76, 83], "kinesi": 55, "kingma": [1, 2, 21, 23, 25], "kj": [22, 73], "kl": 77, "kldivloss": 77, "kleppmann": [48, 51, 53, 54, 56], "kmean": [28, 29], "kmeans_compress": 29, "kmeans_kwarg": [28, 29], "kmeans_sklearn": 28, "kmeansifittedkmean": 28, "kmeanslloyd": [28, 29], "knn": 87, "knnstrategi": 87, "know": [3, 6, 7, 8, 9, 14, 16, 23, 24, 25, 27, 31, 35, 40, 42, 44, 46, 51, 52, 53, 54, 56, 58, 62, 65, 69, 71, 72, 74, 76, 78, 79, 80, 82, 84, 87], "knowledg": [16, 17, 23, 24, 31, 35, 52, 53, 54, 58], "knowledge_distil": 77, "knowledge_distillation_tutori": 77, "known": [3, 5, 6, 11, 14, 16, 17, 21, 22, 23, 24, 25, 27, 28, 34, 38, 39, 40, 53, 54, 58, 59, 60, 62, 65, 79], "koko": [15, 33], "kpi": 64, "kqv": 73, "kubernet": 56, "kudugunta": 73, "kumar": 30, "kuttler": 35, "kv_sep": 82, "kwarg": [25, 28, 32, 53, 75, 76, 77, 78], "kxd": 28, "kyunghyun": 1, "l": [1, 2, 14, 16, 21, 23, 24, 25, 27, 30, 31, 42, 43, 45, 52, 55, 58, 62, 73, 74, 75, 77, 78], "l119": 32, "l2": 25, "l2_norm": 39, "l_": [16, 25, 77], "l_1": 25, "l_b": 25, "l_hard": 77, "l_n": 25, "l_soft": 77, "l_t": 16, "lab": [51, 52], "label": [17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 35, 37, 38, 39, 40, 42, 58, 59, 62, 63, 71, 74, 75, 76, 77, 78, 79, 82], "label2id": [32, 75], "label2rgb": 29, "label_count": 75, "label_id": [32, 75], "label_nam": 76, "label_propag": 52, "label_smooth": 74, "label_smoothing_factor": [32, 75, 76], "labels": 24, "labels_": [28, 29], "labels_allagre": 75, "labor": [56, 57], "lack": [6, 24, 34], "lai": 16, "lake": [52, 57, 65], "lakehous": [55, 56], "lamar": 35, "lambda": [24, 25, 38, 39, 40, 54, 71, 74, 75, 85], "lambda_1": 40, "lambda_2": 40, "lambdalr": [25, 76, 77, 78], "lambdalrconfig": 25, "lan": 73, "land": [25, 27, 78, 79], "landscap": [24, 75, 79], "langl": 24, "languag": [1, 2, 4, 6, 8, 9, 11, 14, 19, 21, 22, 24, 25, 29, 31, 32, 33, 39, 43, 44, 52, 53, 55, 56, 65, 73, 78, 79, 83], "lapack": 53, "laptop": 17, "larg": [1, 13, 14, 16, 19, 21, 22, 24, 25, 27, 28, 31, 32, 33, 39, 40, 42, 43, 44, 51, 52, 53, 56, 57, 58, 59, 60, 62, 65, 66, 73, 75, 76, 77, 78, 79, 82], "larger": [5, 7, 14, 16, 19, 22, 23, 24, 25, 27, 29, 42, 51, 52, 71, 77, 78, 79, 80, 85], "largest": [6, 14, 16, 24, 25, 42, 78, 79], "lasso": 39, "last": [1, 2, 9, 14, 19, 21, 22, 23, 25, 33, 45, 52, 58, 62, 73, 74, 76, 78, 79, 80], "last_decoder_block": [25, 74], "last_epoch": [25, 74, 78], "last_hidden_st": 75, "lastli": [7, 14, 24, 25, 27, 31, 45, 52, 66, 75], "lasttokenpool": 75, "late": 11, "latenc": [45, 51, 54, 55, 57, 58, 64, 65, 66], "latent": [23, 27, 58], "later": [3, 6, 10, 14, 16, 17, 23, 24, 25, 27, 29, 31, 32, 35, 37, 39, 40, 52, 53, 56, 60, 65, 69, 74, 79, 82], "latest": [1, 21, 45, 60], "latex": 8, "latter": [8, 22, 24, 27, 29, 54, 59, 78], "launch": [43, 44, 45], "launcher": [44, 82], "law": [31, 34, 53, 54, 79], "layer": [16, 17, 23, 25, 31, 32, 52, 54, 60, 62, 66, 68, 70, 73, 74, 75, 76, 77, 78, 79], "layer_norm": [24, 25, 74, 75], "layer_norm_epsilon": 24, "layernorm": [22, 25, 73, 74, 75], "layout": 39, "lazi": [25, 45], "lazili": 80, "lceil": [16, 29], "ldot": [5, 13, 14, 16, 17, 22, 23, 24, 25, 27, 29, 31, 35, 37, 38, 39, 42, 58, 73, 77, 79], "lead": [3, 4, 6, 7, 9, 13, 16, 17, 19, 22, 23, 25, 27, 29, 31, 35, 51, 52, 53, 56, 57, 58, 59, 62, 66, 71, 75, 78, 79, 80, 84, 85], "leaf": 13, "leak": [24, 57, 60, 71], "leakag": [23, 24, 60], "lear": 24, "learn": [1, 4, 9, 11, 17, 21, 24, 26, 27, 28, 29, 33, 35, 40, 43, 45, 48, 50, 54, 55, 57, 58, 59, 60, 61, 63, 64, 66, 71, 72, 74, 75, 77, 79, 80, 82, 83, 84], "learnabl": [22, 68, 70, 73], "learner": [1, 2, 21, 23, 27, 31, 42, 56], "learning_r": [32, 75, 76], "learnt": [27, 42], "least": [5, 8, 16, 23, 29, 35, 45, 56, 79, 80], "leav": [13, 22, 57, 72, 74, 75, 77], "lectur": [14, 27, 68, 69, 70, 72], "led": 62, "lee": [1, 23, 24], "leetcod": [14, 16], "left": [5, 6, 7, 13, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 58, 68, 70, 73, 75, 77, 78, 79, 80], "left_index": 14, "leftarrow": [14, 22, 31], "leftmost": [14, 29], "leftward": 23, "legaci": [51, 74], "legal": 53, "legend": [25, 28, 56, 78, 79], "legisl": 53, "legitim": [10, 51], "legitimaci": 5, "lei": [22, 23, 24], "leiserson": [1, 13], "len": [3, 7, 9, 14, 16, 17, 19, 24, 25, 27, 28, 32, 35, 54, 75, 76, 77, 79, 80], "lend": 16, "length": [6, 7, 14, 16, 17, 19, 22, 25, 27, 31, 37, 38, 39, 40, 42, 65, 68, 70, 73, 74, 75, 76], "length_column_nam": 76, "leq": [4, 8, 13, 14, 16, 17, 22, 23, 25, 27, 31, 39, 40, 42, 58, 78], "less": [8, 13, 14, 16, 19, 22, 24, 27, 28, 29, 31, 35, 39, 43, 51, 52, 53, 54, 55, 56, 57, 58, 65, 67, 78, 82, 84, 85], "lesser": [13, 17, 71], "lesson": [26, 59, 66], "let": [3, 5, 6, 7, 8, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 38, 39, 40, 42, 43, 44, 51, 52, 54, 55, 56, 57, 58, 59, 62, 65, 66, 73, 74, 78, 80, 82, 84, 85], "letter": 24, "level": [6, 13, 14, 16, 23, 24, 25, 42, 44, 45, 46, 52, 54, 56, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 80, 82, 84], "levelnam": [67, 68, 69, 70, 71, 75, 77, 82], "leverag": [14, 17, 23, 24, 44, 48, 52, 53, 55, 56, 73, 79, 80, 82], "levin": 1, "levkivskyi": 11, "lfloor": [14, 16], "li": [1, 2, 14, 16, 17, 21, 23, 24, 30, 31, 35, 38, 40, 78, 79, 80], "lib": [24, 28, 32, 56, 71, 73, 75, 76, 77, 78], "librari": [10, 25, 29, 44, 53, 55, 69, 72, 76, 82, 83], "libretext": 35, "licens": [54, 55], "lie": [14, 16, 24, 35, 38, 59], "life": [16, 51], "lifecycl": [33, 55, 56, 62, 64], "lifo": 19, "light": [57, 68, 70], "lightblu": 28, "lightgreen": 28, "lightn": [82, 84], "lightweight": [51, 53], "like": [3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 31, 32, 34, 35, 37, 38, 39, 40, 43, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 73, 74, 75, 76, 78, 79, 82, 84], "likelihood": [17, 22, 23, 25, 31, 52, 79], "likewis": 24, "lilian": [22, 23, 24], "lim_": 58, "limit": [4, 6, 7, 8, 10, 16, 23, 24, 27, 29, 45, 51, 55, 56, 58, 65, 75, 82], "limitless": 65, "linalg": 39, "line": [6, 8, 19, 22, 23, 24, 25, 27, 32, 37, 38, 39, 45, 59, 66, 74, 76, 80, 82], "lineag": [3, 11, 56, 64], "linear": [14, 16, 19, 23, 25, 28, 30, 31, 32, 34, 36, 37, 38, 40, 42, 53, 63, 68, 70, 73, 74, 75, 76, 78, 79, 82, 87], "linear_regress": 87, "linearli": [16, 17, 22, 23, 24, 25, 31, 35, 40, 58, 78], "linearregressionstrategi": 87, "lineno": 80, "linestyl": 38, "linewidth": 38, "linger": [45, 71], "link": [9, 14, 22, 23, 24, 29, 31, 55, 71, 79, 87], "lint": 56, "linux": 45, "lipp": [1, 24, 25, 78], "lipschitz": 58, "lipton": [1, 2, 21, 23, 24, 78, 79], "liskov": [3, 8], "list": [4, 6, 7, 9, 14, 16, 17, 24, 25, 27, 28, 32, 38, 42, 45, 51, 52, 54, 55, 56, 57, 58, 59, 62, 65, 68, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 87], "list_": [6, 9], "list_encoding_nam": 24, "list_of_dynamic_typ": 6, "list_of_employe": 6, "list_of_int": 6, "list_of_str": 6, "listcomp": 80, "listen": [52, 65], "listproxi": 8, "liter": [6, 7, 9, 10, 14, 24, 25, 27, 28, 68, 70, 73, 76, 80, 85], "literatur": [22, 35, 57], "littl": [7, 40, 52], "liu": [1, 2, 21, 23, 25, 73, 78, 82], "live": [3, 4, 57, 64, 65, 76], "liyuan": 1, "ll": [10, 22, 24, 25, 31, 35, 40, 43, 48, 53, 54, 55, 58, 60, 65, 66, 79, 80], "llama": 30, "llion": 1, "lll": 66, "llm": [23, 30, 72, 82, 83], "lloyd": [26, 33], "lm": [23, 24], "lm_profiler_stack": 70, "ln": 73, "ln1": 24, "ln1_pytorch": 24, "ln_1": [22, 24], "ln_2": 24, "ln_before_head": 24, "ln_f": 73, "ln_final": [68, 70], "load": [28, 43, 45, 52, 53, 57, 61, 64, 65, 82, 83], "load_adapt": 76, "load_best_model_at_end": [32, 75, 76], "load_data": 28, "load_dataset": [32, 75, 77], "load_digit": 28, "load_iri": 28, "load_snapshot": 83, "load_state_dict": [76, 83], "load_tf_weight": 76, "load_tf_weights_in_gpt2": 76, "load_to_product": 56, "load_to_stag": 56, "load_yaml_config": 25, "loader": [19, 53, 80], "loader_config": 25, "loadtolak": 56, "loadtowarehous": 56, "loaf": 35, "loav": 35, "local": [6, 14, 17, 25, 26, 28, 44, 46, 52, 53, 54, 55, 58, 71, 78, 80], "local_rank": [44, 46, 76], "local_world_s": [44, 46], "local_xla": 32, "localhost": [25, 44, 46, 74], "localn": 76, "locat": [14, 17, 25, 27, 35, 52, 53, 54, 56], "lock": 83, "log": [6, 13, 14, 16, 22, 23, 24, 25, 27, 28, 31, 32, 44, 53, 54, 55, 56, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 79, 82, 84], "log2": 29, "log_2": [14, 16, 29], "log_artifact": 60, "log_b": [13, 14], "log_dir": [25, 44, 74], "log_every_n_step": [25, 74], "log_fil": [25, 74], "log_k": 24, "log_level": [25, 44, 74, 76], "log_level_replica": 76, "log_loss": [32, 75, 77], "log_metr": 76, "log_on_each_nod": 76, "log_on_master_or_al": [25, 44, 74], "log_param": 60, "log_root_dir": [25, 74], "log_softmax": 77, "log_time_format": [25, 74], "log_user_info": 6, "logarithm": [14, 23, 77], "logger": [25, 44, 46, 56, 67, 68, 69, 70, 71, 74, 75, 77, 82], "loggerconfig": [25, 74], "logging_dir": 76, "logging_exampl": 82, "logging_first_step": 76, "logging_nan_inf_filt": 76, "logging_step": [32, 75, 76], "logging_strategi": 76, "logic": [3, 5, 7, 8, 9, 14, 16, 17, 32, 34, 44, 53, 55, 56, 61, 75, 80, 82], "logical_and": [24, 25], "login": [45, 55], "logist": [58, 59], "logit": [22, 23, 24, 25, 32, 52, 68, 70, 74, 75, 76, 77, 82], "logits_flatten": 25, "logits_larg": 24, "logits_permut": 25, "loglevel": 45, "logs_dir": [82, 84], "logs_distribut": [25, 74], "lol": 25, "long": [3, 4, 7, 14, 23, 24, 25, 27, 35, 51, 55, 56, 68, 70, 75, 76, 77, 78, 84], "longer": [7, 23, 24, 25, 27, 38, 39, 44, 54, 78, 80, 85], "longest": [24, 25, 32, 75, 77], "longtensor": [24, 25, 68, 70, 75], "look": [6, 8, 9, 14, 16, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 38, 39, 41, 52, 54, 56, 59, 60, 62, 64, 65, 66, 69, 71, 72, 73, 78, 79, 80, 82, 83, 84, 85], "lookup": [29, 54], "loop": [4, 14, 16, 19, 22, 23, 24, 25, 27, 28, 32, 44, 62, 69, 76, 80], "loop_employe": 8, "loop_employees_using_list": 8, "loop_through_memb": 76, "loos": [3, 5, 23, 31, 79, 85], "loosen": 83, "lora": [1, 30], "lora_": 32, "lora_a": 32, "lora_alpha": 32, "lora_b": 32, "lora_config": 32, "lora_dropout": 32, "lora_finetun": 32, "lora_out": 32, "lora_paramet": 31, "lora_weight": 32, "loraconfig": 32, "loralib": 32, "loralinear": 32, "loshchilov": [1, 2, 21, 23, 25, 78], "loss": [4, 5, 24, 28, 29, 31, 32, 39, 42, 57, 60, 61, 63, 68, 70, 75, 77, 78, 79, 82, 83], "loss_fn": 71, "lossi": [29, 75], "lossless": [24, 29], "lost": [24, 51, 52, 54], "lot": [27, 29, 31, 44, 53, 54, 82, 85, 87], "love": [16, 74], "low": [1, 14, 16, 24, 25, 32, 33, 42, 44, 54, 65, 66, 79, 80], "lower": [7, 13, 14, 16, 22, 23, 24, 25, 29, 31, 53, 59, 68, 73, 74, 75, 78, 79, 85], "lowest": 78, "lr": [25, 70, 71, 74, 75, 77, 78, 82], "lr_lambda": [25, 78], "lr_schedul": [25, 74, 75, 76, 77, 78, 83], "lr_scheduler_kwarg": 76, "lr_scheduler_typ": [32, 75, 76], "lrs1": 78, "lrs2": 78, "lrs_cyclic": [25, 78], "lrs_non_cycl": [25, 78], "lrschedul": [25, 83], "lsp": [3, 5, 8, 70], "lst": 8, "lstm": [23, 24, 25], "lstrip": 75, "lt": [24, 25, 31, 69, 75, 76, 79], "lu": 1, "luan": [1, 2, 21, 23], "lucki": 24, "lukasz": 1, "lunch": 31, "luo": [2, 11], "lustr": 55, "luxuri": 27, "lvert": 24, "lxd": 24, "lxml": 55, "ly": 35, "m": [1, 2, 14, 16, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 34, 35, 39, 40, 42, 45, 51, 53, 55, 56, 71, 73, 74, 78, 79, 82], "m1": [22, 35, 73], "m2": [35, 73], "m_": [22, 70, 71], "m_i": 19, "m_t": 16, "ma": 23, "ma4270": [26, 27], "mac": [44, 46, 73], "machin": [1, 2, 23, 24, 26, 27, 29, 31, 33, 34, 35, 40, 43, 44, 48, 49, 50, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 79, 82, 83, 84], "machine_learn": [28, 29], "machine_transl": 52, "macro": [32, 75], "made": [3, 7, 9, 10, 13, 14, 17, 24, 27, 48, 53, 56, 63, 65, 76, 82, 84], "madewithml": [56, 57, 62, 63, 65], "mae": [52, 59, 62, 63, 66], "magic": [3, 55], "magnifi": 79, "magnitud": [25, 35, 37, 38, 39, 40, 51, 59, 78, 79], "mai": [3, 4, 5, 6, 7, 8, 10, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 32, 35, 37, 39, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 63, 65, 66, 70, 71, 73, 76, 78, 80, 82, 83, 85], "main": [4, 6, 16, 23, 25, 31, 45, 52, 53, 54, 55, 56, 60, 63, 67, 76, 78, 80, 82], "main_structur": 82, "mainli": [21, 25], "mainstream": 52, "maintain": [4, 5, 6, 14, 16, 17, 19, 22, 23, 24, 25, 29, 31, 34, 38, 48, 51, 54, 56, 62, 64, 65, 66, 73, 74, 78, 79, 80, 82, 84, 85], "mainten": [16, 17, 45, 65], "major": [9, 24, 42, 56, 57, 59, 62, 65, 66, 80], "make": [3, 4, 6, 8, 10, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 39, 40, 42, 44, 45, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 71, 73, 74, 75, 76, 78, 79, 80, 82, 83], "make_blob": 28, "make_dataclass": 76, "make_sound": [3, 4, 5], "malai": 55, "man": 45, "manag": [6, 8, 14, 16, 19, 24, 27, 33, 48, 53, 54, 55, 56, 57, 60, 64, 65, 79, 80, 82, 85], "mandatori": 44, "manhattan": [27, 28], "manhattan_dist": 28, "mani": [3, 6, 8, 10, 11, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 35, 38, 39, 40, 42, 51, 52, 53, 54, 56, 57, 58, 59, 60, 71, 73, 75, 76, 77, 82, 83], "manifest": [4, 51], "manipul": [35, 38, 54, 82], "manner": [4, 5, 16, 17, 22, 23, 24, 25, 27, 39, 51, 55, 56, 79], "mantissa": 73, "manual": [3, 9, 23, 24, 32, 44, 52, 55, 56, 57, 60, 73, 75, 76, 78, 82, 85], "manual_se": [24, 25, 31, 60, 82], "manual_seed_al": [24, 31, 60], "manufactur": 65, "mao": [22, 23, 24], "map": [3, 10, 16, 23, 25, 27, 29, 32, 39, 42, 43, 58, 69, 74, 75, 79, 82], "map_loc": 83, "mape": 52, "mappingproxi": 76, "mapsto": [23, 24, 39, 42, 79], "marc": 1, "marcel": [70, 72], "marcelro": [68, 70], "marciu": 24, "margin": [23, 58], "mari": 24, "mark": [9, 23, 24, 25, 28, 51], "markdown": 9, "markedli": 14, "marker": [10, 24, 25, 28, 29, 78], "markeredgecolor": 24, "markers": 24, "market": [51, 52, 53, 65, 66], "markup": [25, 74], "martin": [2, 21, 23, 24, 48, 51, 53, 54, 56, 85], "mask": [21, 29, 52, 68, 70, 75, 77], "masked_attention_scor": 24, "masked_attention_weight": 24, "masked_fil": [22, 24, 68, 70, 74], "masked_self_attention_mha": [24, 25, 74, 75], "masked_self_attention_mha_config": [24, 25, 74], "maskedfillbackward0": 70, "maskedmultihead": 22, "mass": [23, 24], "massiv": 23, "master": [12, 33, 68, 70, 84], "master_addr": [25, 44, 46, 74], "master_info": 44, "master_port": [25, 44, 46, 74], "mat": [23, 24], "match": [5, 9, 17, 22, 23, 25, 28, 29, 32, 54, 59, 73, 74, 77, 79], "materi": [6, 35, 52], "math": [5, 14, 16, 23, 24, 25, 29, 30, 31, 32, 35, 39, 40, 75, 78], "math11112451": 1, "mathbb": [5, 8, 14, 16, 22, 23, 24, 25, 27, 29, 31, 35, 37, 38, 39, 40, 42, 58, 77, 79], "mathbf": [23, 24, 25, 27, 29, 31, 34, 35, 37, 38, 39, 40, 42, 58, 73, 74], "mathcal": [3, 5, 13, 14, 16, 19, 22, 23, 24, 25, 27, 29, 31, 38, 39, 42, 52, 58, 61, 62, 73, 74, 75, 76, 78], "mathemat": [1, 3, 5, 6, 8, 11, 22, 24, 25, 27, 28, 34, 35, 36, 37, 38, 39, 40, 41, 51, 58, 69, 73, 79], "mathematicalmonk": 26, "mathrm": [24, 27, 42, 58, 62, 79], "mathsf": 40, "mathwork": 29, "matlab": 53, "matmul": [22, 24, 67, 68, 70, 73, 74, 79], "matplotlib": [24, 25, 28, 29, 38, 70, 74, 78, 79, 80], "matric": [24, 27, 30, 31, 35, 37, 40, 53, 73, 79], "matrix": [13, 23, 25, 27, 29, 30, 32, 37, 38, 42, 53, 58, 63, 74, 75], "matter": [10, 14, 24, 37, 52, 55, 57, 60, 62, 79], "matur": [48, 51], "max": [16, 24, 25, 27, 28, 31, 42, 68, 70, 71, 75, 77, 78, 79, 80, 82, 84], "max_": [16, 31], "max_batch_s": 82, "max_clust": 28, "max_entri": [70, 71], "max_epoch": [25, 74], "max_grad_norm": [32, 75, 76], "max_i": 79, "max_int": 29, "max_it": [27, 28, 29], "max_len": [25, 75], "max_length": [24, 32, 75, 77], "max_norm": [25, 74], "max_num": 25, "max_num_of_mem_events_per_snapshot": 71, "max_seed_valu": 31, "max_seq_len": [24, 25], "max_step": 76, "max_tim": 68, "max_token": [24, 25, 74], "max_val": 6, "max_z": 79, "maxbackward0": 70, "maxcount": 45, "maxim": [22, 23, 25, 27, 31, 35, 40, 42, 52, 79], "maxima": 79, "maximum": [6, 10, 14, 16, 22, 23, 25, 28, 29, 31, 45, 56, 62, 68, 73, 76, 78, 79, 80], "maxsiz": [6, 8], "maxwell_sgemm_128x64_nn": 70, "maxwell_sgemm_128x64_tn": 70, "mayb": [24, 31, 44, 51, 52, 75], "maybeconst": [25, 74], "maybeglob": [25, 74], "mb": [70, 71, 73], "mccann": [1, 23], "mcnemar": 64, "mdpi": 1, "me": [11, 24, 25, 45, 56, 76, 83], "mean": [3, 4, 5, 6, 7, 8, 9, 10, 14, 16, 17, 19, 22, 23, 24, 25, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 45, 46, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 82, 84, 85], "mean1": 66, "mean2": 66, "mean_tim": 68, "meaning": [10, 16, 29, 52, 53], "meaningless": 57, "meant": [29, 56], "meantion": 16, "measur": [5, 7, 17, 22, 23, 24, 25, 27, 28, 29, 31, 39, 40, 42, 52, 53, 55, 56, 59, 60, 62, 63, 64, 66, 67, 68, 69, 73, 77, 79], "measured_byt": 73, "measured_throughput": 73, "measured_tim": 73, "mechan": [3, 4, 6, 9, 14, 17, 21, 25, 28, 34, 43, 51, 53, 56, 60, 64, 72, 73, 78, 80, 83, 84, 85], "media": [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65], "median": 68, "median_tim": 68, "medic": [35, 53, 54, 59, 62], "medium": [3, 24, 68, 73], "medium_backward_warmup_0_mixed_fals": 68, "medium_backward_warmup_0_mixed_tru": 68, "medium_backward_warmup_1_mixed_fals": 68, "medium_backward_warmup_1_mixed_tru": 68, "medium_forward_backward_warmup_0_mixed_fals": 68, "medium_forward_backward_warmup_0_mixed_tru": 68, "medium_forward_backward_warmup_1_mixed_fals": 68, "medium_forward_backward_warmup_1_mixed_tru": 68, "medium_forward_warmup_0_mixed_fals": 68, "medium_forward_warmup_0_mixed_tru": 68, "medium_forward_warmup_1_mixed_fals": 68, "medium_forward_warmup_1_mixed_tru": 68, "meet": [5, 16, 45, 51, 55, 56, 64], "megabyt": 73, "mehdi": 30, "mehryar": 42, "mem": 70, "member": [3, 23, 52, 60], "memcpi": 69, "memmap": 24, "memor": 62, "memori": [14, 17, 23, 25, 29, 31, 33, 43, 44, 46, 53, 58, 60, 65, 66, 68, 72], "memory_leak": 71, "memory_mask": 24, "memory_ratio": 73, "memory_snapshot": 70, "memory_usag": 83, "memory_viz": 70, "memoryerror": 80, "mental": [8, 16, 27, 46], "mention": [6, 14, 16, 23, 24, 25, 27, 29, 31, 35, 39, 40, 42, 54, 56, 58, 60, 65, 79], "meow": [3, 4], "mere": [3, 6, 23, 25, 27, 34, 35, 75, 79, 82], "merg": [13, 14, 22, 24, 55, 56, 68, 70, 82], "merge_and_unload": 32, "merge_and_unload_model": 32, "merge_config": 25, "merged_linear": 32, "mess": 25, "messag": [8, 45, 46, 53, 56, 67, 68, 69, 70, 71, 75, 77, 80, 82], "met": [5, 16, 17, 25, 54], "meta": [1, 17, 19, 23, 71], "metaclass": 3, "metadata": [52, 53, 54, 56, 64, 82], "meteorolog": 53, "method": [1, 2, 3, 4, 5, 7, 8, 9, 10, 13, 14, 16, 21, 22, 23, 24, 25, 28, 29, 35, 38, 42, 44, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 74, 82, 84, 85, 87], "methodologi": [17, 55, 85], "meticul": 62, "metric": [1, 27, 29, 39, 48, 55, 56, 57, 62, 63, 64, 66, 72, 73, 75, 76, 77, 83], "metric_for_best_model": [32, 75, 76], "metric_key_prefix": 32, "metrics_format": 76, "mf": 73, "mf_per_sequ": 73, "mf_per_token": 73, "mfu": 52, "mfu_estim": 73, "mfu_result": 73, "mfuestimationresult": 73, "mha": [22, 25], "michel": 73, "micro": [32, 75], "microsecond": 69, "microservic": 48, "microsoft": [32, 55, 56, 58, 77], "mid": [14, 16, 22, 23, 24, 27, 31, 37, 42, 58, 66, 79], "mid_index": 14, "mid_strategi": 14, "middl": [14, 17, 27], "midpoint": [14, 16], "might": [3, 4, 5, 6, 7, 8, 10, 14, 16, 19, 22, 23, 24, 25, 29, 31, 35, 37, 39, 42, 44, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 73, 74, 78, 79, 80, 83, 84], "migrat": 55, "mill": [69, 70, 72], "miller": [23, 24], "million": [23, 24, 57], "mimic": [22, 64, 83], "mimick": [25, 77], "min": [16, 25, 31, 68, 74, 77, 78], "min_": [16, 27, 29], "min_clust": 28, "min_dist": 28, "min_eating_spe": 16, "min_index": 28, "min_seed_valu": 31, "min_tim": 68, "min_val": 6, "minbp": [23, 24], "mincount": 45, "mind": [7, 25, 59, 66], "mine": [28, 74], "mingpt": [25, 45], "minhyeok": 1, "mini": [21, 24, 33, 44, 46], "minibatch": 22, "miniconda": 28, "miniconda3": 45, "miniforg": 28, "minim": [16, 22, 23, 24, 26, 31, 35, 39, 42, 51, 52, 54, 56, 62, 79], "minima": [25, 26, 78, 79], "minimum": [6, 14, 16, 17, 19, 23, 24, 25, 26, 28, 31, 32, 45, 56, 58, 62, 68, 78], "minimum_spe": 16, "minlength": 79, "minor": [23, 24, 51, 57], "minu": 79, "minut": 24, "miracl": 51, "mirror": [6, 23, 24, 32], "misc": [8, 28], "miscalibr": 59, "misclassifi": [51, 64], "misinform": 52, "mislead": [52, 54, 57, 59], "mismatch": 6, "misnom": 79, "miss": [6, 25, 51, 52, 53, 55, 56, 57, 59, 74], "mistak": [32, 34, 60, 62, 71, 82], "mistakenli": 6, "mistral": 30, "mit": [1, 2, 26, 27, 29, 42, 79], "mitig": [24, 57, 66, 76, 79], "mix": [6, 7, 52, 53, 68], "mixed_": 68, "mixed_context": 68, "mixed_precis": [68, 70], "mixed_precision_opt": 68, "mixtur": [27, 29, 58], "mj": 22, "mkdir": 24, "ml": [26, 42, 48, 52, 53, 55, 56, 62, 64, 66], "mlflow": [60, 64], "mlop": [33, 48, 56], "mlp": [24, 32, 73, 75, 77], "mlxtend": 63, "mm": [56, 70, 82], "mmbackward0": 70, "mml": 1, "mn": [22, 35, 73], "mnist": [30, 52], "mnli": 77, "mobil": [48, 51, 53], "mock": 61, "mod": 22, "modal": 23, "mode": [10, 24, 25, 27, 31, 44, 55, 56, 60, 63, 64, 65, 68, 69, 70, 72, 74, 75, 76, 77, 82], "model": [1, 2, 8, 9, 16, 19, 21, 22, 26, 28, 29, 31, 33, 35, 39, 42, 43, 44, 45, 46, 48, 51, 52, 53, 55, 56, 57, 68, 70, 71, 72, 76, 77, 78, 79, 80, 82, 83, 84, 87], "model_a": 83, "model_artifact": 83, "model_artifacts_dir": [82, 84], "model_b": 83, "model_config": [24, 25, 74, 75], "model_config_dict": 82, "model_dump": [24, 25, 68, 75, 82], "model_dump_json": [44, 46, 68], "model_field": 76, "model_flop": 73, "model_init": 76, "model_max_length": 75, "model_nam": [82, 84], "model_s": 25, "model_select": 28, "model_total_paramet": 73, "model_typ": [24, 73, 87], "model_util": [75, 77], "model_valid": 24, "model_vers": 83, "model_wrap": 76, "modelconfig": [82, 84], "modeling_gpt2": 76, "modeling_output": 77, "modeling_util": 76, "models_equ": 83, "modeltyp": 87, "moder": [57, 59], "modern": [22, 23, 24, 25, 29, 52, 54, 55, 56, 65], "modif": [14, 76, 84], "modifi": [8, 13, 14, 17, 19, 22, 23, 24, 27, 45, 54, 55, 71, 79, 80, 85, 87], "modul": [3, 7, 22, 24, 25, 32, 44, 45, 58, 62, 68, 70, 73, 74, 75, 76, 77, 78, 80, 83], "modular": [73, 82, 84, 85], "module1": 45, "module_nam": [25, 32, 74], "moduledict": [24, 25, 68, 70, 74, 75], "modulefil": 45, "modulelist": [24, 25, 32, 68, 70, 75], "modules_to_sav": 32, "moduleshelp": 45, "moduleutilsmixin": 76, "mohanda": 55, "mohri": 42, "moment": [4, 25, 31, 71, 73, 78], "momentum": [25, 71, 73, 78], "monei": [23, 29, 54], "monetari": 51, "mongodb": [52, 53, 55], "monitor": [25, 33, 48, 52, 57, 60, 64, 65, 73, 74, 79], "monkei": 16, "monoton": [8, 15, 24, 25, 78], "monster": [15, 16], "monthli": 57, "more": [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 21, 22, 23, 25, 27, 28, 29, 31, 32, 35, 37, 39, 40, 42, 43, 44, 45, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85], "moreov": [16, 23, 57, 80], "mosaicml": [25, 73, 78, 83], "most": [9, 11, 14, 16, 17, 19, 23, 24, 25, 27, 28, 29, 31, 34, 35, 37, 39, 42, 44, 52, 53, 54, 57, 58, 59, 60, 62, 63, 65, 66, 72, 73, 74, 76, 78, 82], "mostli": [23, 24], "motiv": [16, 22, 24, 51, 66], "mount": [45, 55], "mountdir": 45, "mous": [22, 24, 42, 71], "move": [8, 16, 17, 23, 24, 25, 35, 37, 38, 44, 55, 56, 57, 60, 62, 75, 78, 80], "movement": [37, 56], "movi": [23, 52, 54, 55, 65, 66, 74], "mp": [22, 24, 44, 46], "mp4": 53, "mp_paramet": 76, "mqan": 23, "mrc": 31, "mri": [52, 53], "mro": [3, 76], "mse": [52, 59, 63, 66], "msg": [24, 44, 79], "mu": [1, 24, 27, 29], "mu_": [24, 27], "mu_1": 28, "mu_2": 28, "mu_k": 28, "mu_t": [22, 24], "much": [3, 10, 14, 16, 17, 23, 24, 25, 31, 32, 35, 40, 42, 51, 54, 55, 56, 58, 59, 60, 62, 66, 68, 71, 73, 74, 77, 78, 80, 87], "mul": [69, 70], "mulbackward0": 70, "multi": [16, 25, 31, 35, 39, 42, 45, 53, 54, 65, 77, 78, 82], "multi_class": [32, 75], "multi_gpu_train": 45, "multi_instance_learn": 52, "multiclass": [52, 79], "multicollinear": 57, "multidimension": 53, "multihead": [22, 24], "multiheadattent": 24, "multiheadedattent": [24, 25, 74, 75, 77], "multiheadedattentionconfig": [24, 25, 74, 75, 77], "multiheadselfattent": [68, 70], "multilabel": 52, "multilay": [22, 24], "multimedia": [52, 53, 54, 55], "multinod": 45, "multinomi": [24, 79], "multinoulli": 79, "multipl": [5, 9, 16, 19, 23, 24, 25, 27, 28, 29, 31, 34, 35, 37, 39, 42, 43, 44, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 74, 76, 78, 80, 82, 83, 84], "multipli": [16, 17, 22, 23, 24, 25, 31, 34, 38, 40, 73, 79, 82], "multiprocess": [8, 44, 46, 75], "multirun": 82, "multitask": [1, 2, 21, 23, 56], "multithread": 75, "multitud": [52, 84], "multivari": [27, 79], "murphi": [1, 26, 27, 29], "muscat": [1, 39], "museum": 24, "music": 52, "must": [3, 5, 6, 7, 8, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 31, 34, 35, 39, 42, 44, 46, 51, 52, 53, 54, 55, 60, 62, 65, 73, 75, 76, 78, 79, 82, 84, 85, 87], "mustang": 53, "mutabl": 83, "mutablemap": 82, "mutablesequ": 8, "mutat": [8, 28, 32], "mutual": [52, 59, 65], "mu\u00f1oz": [2, 11], "my": [24, 25, 45, 56, 61, 73, 74, 75, 78, 83, 85], "my_good_employe": 8, "my_jacobian": 79, "my_list": 8, "my_manag": 8, "my_softmax": 79, "my_softmax_output": 79, "my_softmax_prob": 79, "myclass": 76, "mydataset": 80, "myestim": 9, "mypi": [3, 4, 6, 7, 8, 9, 19, 24, 25], "myspecificvalid": 56, "mysql": [53, 54, 55], "mysteri": 58, "n": [1, 2, 5, 8, 13, 14, 16, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 34, 35, 37, 38, 40, 42, 43, 44, 45, 52, 58, 59, 68, 73, 74, 76, 79, 80, 82], "n1": [22, 35, 66, 73], "n2": [35, 45, 66, 73], "n3": 35, "n_": [23, 24, 29, 42], "n_0": [14, 16, 17], "n_1": 35, "n_2": 35, "n_3": 35, "n_cluster": [27, 28, 29], "n_col": 53, "n_ctx": 24, "n_digit": 28, "n_embd": [24, 73], "n_featur": 28, "n_head": [24, 73], "n_init": [28, 29], "n_inner": 24, "n_j": 35, "n_k": 27, "n_layer": [24, 73], "n_n": 35, "n_posit": 24, "n_row": 53, "n_sampl": [27, 28], "n_test": 63, "n_vocab": 24, "nabla": 31, "nabla_": [23, 79], "naiv": [8, 17, 35, 39, 51, 52, 57, 58, 62, 69, 77, 83], "name": [3, 6, 8, 9, 13, 14, 17, 19, 22, 23, 24, 25, 28, 29, 32, 39, 44, 45, 53, 54, 56, 58, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 82], "name_or_path": 75, "named_buff": 76, "named_children": [32, 76], "named_modul": [25, 32, 76], "named_paramet": [24, 25, 32, 68, 70, 73, 74, 75, 76], "namedtemporaryfil": 71, "nameerror": 68, "namespac": [44, 46, 76], "nan": [28, 79], "nano": 45, "nanogpt": [25, 73], "narasimhan": [1, 2, 21, 23], "narr": 16, "narrow": [6, 8, 9, 14, 16], "narrowli": 23, "nat": 45, "nat_id": 45, "natgatewai": 45, "natgatewayid": 45, "nathaniel": [26, 27, 28], "nation": [2, 6, 11], "nativ": [54, 55, 67, 69, 72], "nativelayernormbackward0": 24, "natur": [1, 6, 8, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 34, 35, 37, 38, 39, 42, 46, 52, 53, 55, 58, 62, 65, 66, 77, 78, 79, 80, 82], "navig": [16, 19, 45], "nbsp": 28, "nbviewer": 28, "ncall": 80, "nccl": 44, "ncentroid": 29, "nclass": 76, "nclass_child": 76, "nclass_par": 76, "ncol": [24, 29, 38, 40], "ncompress": 29, "nd": [17, 27, 35, 73], "ndarrai": [7, 24, 28, 29, 53, 79], "ndcg": 51, "ndef": 76, "ndim": 24, "nearest": [16, 27, 29, 39, 58, 65], "nearli": [54, 80], "neat": [14, 24], "neatli": [19, 22, 54], "necess": [25, 34, 78], "necessari": [3, 5, 16, 19, 22, 23, 25, 29, 31, 45, 51, 52, 53, 55, 56, 57, 58, 62, 65, 66, 71, 84], "necessarili": [6, 8, 13, 16, 25, 27, 35, 38, 42, 52, 53, 55, 65, 74, 78], "necessit": [10, 23, 24], "neclueu": 24, "need": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 30, 31, 32, 35, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 65, 66, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85], "neftune_noise_alpha": 76, "neg": [3, 5, 16, 17, 22, 23, 24, 29, 31, 32, 39, 40, 42, 51, 52, 59, 60, 70, 75], "negat": [8, 22, 23, 31], "negatively_scaled_vector": 38, "neglig": 24, "neighbor": [27, 29, 39, 57, 58, 65], "neighborhood": 24, "neighbour": 27, "neither": [8, 23, 24], "neo4j": 54, "neq": [8, 14, 17, 24, 25, 27, 39, 66], "nest": [24, 53, 76, 84], "net": [25, 44], "netflix": [52, 65], "network": [1, 16, 21, 23, 25, 31, 39, 40, 51, 52, 54, 58, 61, 62, 63, 73, 77, 78, 79, 87], "networkinterfac": 45, "networkinterfaceid": 45, "neural": [1, 2, 21, 22, 23, 24, 25, 30, 31, 39, 40, 51, 52, 54, 58, 61, 62, 63, 73, 77, 78, 79, 87], "neural_network": 87, "neuralnetworkstrategi": 87, "neuron": [31, 62, 82], "neutral": [32, 52, 75], "never": [4, 6, 16, 24, 25, 27, 35, 39, 63, 65, 74], "nevertheless": [6, 23, 44], "new": [2, 3, 4, 6, 8, 14, 16, 17, 22, 23, 24, 25, 26, 27, 28, 29, 32, 37, 38, 42, 45, 51, 52, 53, 54, 55, 56, 57, 60, 62, 64, 65, 66, 69, 73, 76, 78, 79, 80, 82, 83, 87], "new_empti": 70, "new_equ": 25, "new_list_of_int": 6, "new_list_of_str": 6, "new_stat": 83, "new_zero": 70, "newli": [32, 64, 71, 75, 76, 77], "newton": [23, 79], "nexampl": 24, "next": [4, 13, 14, 17, 19, 22, 23, 24, 25, 27, 29, 31, 32, 45, 46, 52, 54, 55, 56, 57, 58, 60, 62, 65, 67, 68, 69, 73, 74, 75, 79, 82, 83], "next_token": 24, "nexti": 17, "nfrom": 76, "nfutur": 74, "ng": 42, "nh": 73, "nice": 65, "niki": 1, "ninstance_par": 76, "ninth": 25, "nitish": 1, "nj": 22, "nk": 28, "nkd": 27, "nl2sql": 31, "nlabel": 74, "nleq": 8, "nllloss2dbackward0": 25, "nlllossbackward0": 25, "nloop_through_memb": 76, "nlp": [21, 23, 24, 29, 52], "nlu": 23, "nn": [22, 24, 25, 31, 32, 58, 68, 70, 71, 73, 74, 75, 76, 77, 78, 79, 82, 83], "nnode": [25, 44, 45, 46, 74], "no_cuda": 76, "no_decai": 25, "no_grad": [24, 25, 32, 74, 75, 77], "no_type_hint": 76, "noam": [1, 25], "noam_lr_decai": 25, "node": [13, 14, 17, 19, 53, 54, 60, 71, 73, 82], "node_id": 69, "node_rank": [25, 44, 46, 74], "nodelist": 45, "nodes_arrai": 45, "nois": 65, "nomin": [4, 5, 53], "non": [5, 8, 13, 14, 16, 22, 23, 24, 25, 26, 27, 28, 31, 32, 35, 39, 40, 42, 51, 55, 58, 59, 60, 68, 69, 71, 73, 74, 76, 78], "non_block": [24, 25], "non_default_trace_": 69, "non_ignore_count": 25, "none": [3, 4, 5, 6, 8, 9, 10, 14, 19, 22, 24, 25, 28, 29, 31, 32, 40, 44, 45, 46, 53, 56, 60, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87], "nonempti": 27, "nonetheless": 23, "nonetyp": 76, "nonnegativeint": 14, "noqa": [10, 24, 25, 68, 70, 76], "nor": [8, 23, 24, 25], "norm": [27, 31, 32, 33, 40, 41, 42, 58, 60, 62], "norm_typ": [25, 74], "normal": [6, 23, 25, 27, 32, 38, 39, 45, 55, 57, 68, 70, 75, 76, 78, 82], "normal_": [24, 68, 69, 70, 74, 75], "normal_init_modul": [24, 68, 70, 75], "normalized_embed": 24, "normalized_shap": 24, "north": [17, 19], "nosql": [53, 55, 65], "not_given": [10, 24, 25], "notabl": [6, 39, 58, 76], "notat": [5, 13, 16, 21, 23, 31, 35, 37, 40, 47, 53, 73, 75, 78, 79, 82], "note": [3, 4, 6, 7, 8, 9, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 35, 37, 38, 39, 40, 42, 44, 45, 46, 51, 52, 55, 56, 57, 58, 60, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 87], "notebook": [1, 28, 35, 58, 73, 74, 75, 76, 77], "noteworthi": 38, "notgiven": [24, 25], "noth": [23, 29], "notic": [6, 16, 17, 22, 24, 27, 35, 39, 40, 66, 74, 76, 79], "notif": [52, 56], "notifi": 56, "notimpl": 3, "notimplementederror": [5, 24, 28], "notion": [3, 4, 23, 24, 39, 43], "notori": 23, "notwithstand": 23, "noun": 24, "nov": [1, 2, 21, 23], "novel": 3, "now": [3, 4, 5, 6, 7, 8, 9, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 38, 39, 40, 42, 43, 44, 45, 46, 52, 53, 54, 55, 56, 57, 60, 62, 63, 65, 67, 68, 70, 71, 73, 74, 75, 78, 79, 80, 82, 83, 85, 87], "nowadai": 54, "np": [7, 22, 24, 27, 28, 29, 31, 32, 37, 39, 53, 60, 68, 73, 74, 75, 77, 79], "nproc": [44, 46], "nproc_per_nod": [25, 44, 45, 46, 74], "npt": 53, "nrow": [24, 29, 38, 40], "nsfw": 52, "nsubseteq": 24, "nswap": 87, "ntarget": 74, "ntask": 45, "nuanc": [3, 5, 16, 31, 38, 59], "null": [24, 68, 82], "nullcontext": [68, 70], "num": [6, 14, 25, 74, 80, 82], "num_banana": 16, "num_batches_to_ev": [25, 74], "num_bit": 29, "num_block": [68, 70], "num_class": [24, 28, 32, 74, 75, 82, 84], "num_clust": [28, 29], "num_decoder_block": [24, 25, 73, 74, 75], "num_digit": 25, "num_embed": [24, 68, 70], "num_epoch": [75, 77, 82, 84], "num_exampl": 76, "num_experi": 79, "num_featur": [28, 82], "num_gpu": 73, "num_head": [24, 25, 68, 70, 73, 74], "num_it": 71, "num_kei": 25, "num_label": [32, 74, 75, 77], "num_nod": 45, "num_paramet": 76, "num_proc": [32, 75], "num_queri": 25, "num_round": 63, "num_row": [53, 75], "num_sampl": [24, 28, 74, 79], "num_target_modul": 32, "num_token": 76, "num_train_epoch": [32, 75, 76], "num_training_step": [25, 77, 78], "num_warmup_step": [25, 77, 78], "num_work": [25, 74, 80, 82, 84], "numalign": 73, "number": [3, 6, 8, 9, 10, 13, 16, 17, 19, 22, 23, 24, 25, 26, 28, 31, 32, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 51, 52, 53, 54, 57, 59, 60, 61, 62, 63, 65, 68, 74, 75, 78, 79, 80, 82, 83], "numel": [24, 32, 73, 74], "numer": [3, 5, 14, 16, 17, 22, 23, 25, 31, 42, 52, 53, 57, 58, 60, 69, 73], "numexpr": 17, "numpi": [24, 25, 28, 29, 31, 32, 39, 40, 53, 55, 60, 68, 70, 74, 75, 77, 79, 80], "numref": 24, "nums_squared_gener": 80, "nums_squared_list_comprehens": 80, "nvidia": [22, 23, 31, 44, 73], "ny": [26, 27], "n\u00e9e": 13, "o": [13, 14, 16, 19, 22, 24, 25, 27, 28, 29, 31, 35, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 65, 73, 75, 77, 78], "o1": 76, "o_": [22, 24], "o_proj": 32, "o_t": 59, "oad": 55, "obei": [5, 22, 24, 25, 40, 60], "obj": [3, 4, 76], "object": [4, 5, 6, 7, 8, 9, 10, 14, 22, 24, 25, 26, 29, 31, 35, 39, 40, 44, 53, 54, 55, 56, 59, 62, 76, 77, 80, 82, 83, 84, 85, 87], "object_detect": 52, "objectdetectiontransform": 85, "observ": [16, 22, 23, 25, 27, 29, 31, 35, 42, 53, 56, 58, 71, 73, 78, 79], "observe_tensor_cycl": 71, "obtain": [13, 19, 22, 23, 24, 27, 29, 31, 35, 39, 40, 52, 53, 55, 59, 73, 76, 80], "obtus": 40, "obviat": 23, "obviou": [8, 24, 25, 27, 55, 56, 85], "obvious": [6, 24], "occasion": [16, 19], "occupi": [14, 16, 17, 73], "occur": [3, 4, 6, 13, 14, 16, 17, 19, 23, 28, 40, 56, 57, 59, 60, 62, 66, 71], "ocr": 52, "oct": [1, 2, 21, 23, 30, 31, 78], "od": 24, "odd": 24, "odot": [22, 24], "off": [3, 16, 17, 19, 24, 25, 27, 28, 29, 31, 32, 39, 51, 52, 54, 56, 58, 60, 68, 69, 70, 71, 73, 74, 79, 80, 84], "offens": 52, "offer": [3, 5, 6, 7, 16, 17, 23, 24, 31, 35, 40, 51, 53, 54, 56, 58, 62, 65, 75, 82], "offlin": [51, 58, 59, 60, 62, 63], "often": [4, 6, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 35, 37, 38, 39, 42, 43, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 65, 71, 73, 76, 78, 79, 84, 85], "oh": [22, 75, 80], "okai": [7, 24, 25], "olap": 54, "old": [4, 28, 35, 60, 65, 83], "old_centroid": 28, "older": [24, 64], "oltp": 54, "om": 25, "omega": [13, 79], "omegaconf": [25, 82], "omit": [24, 25, 52, 75], "omnivault": [19, 25, 28, 29, 32, 44, 46, 68, 70, 71, 74, 75, 77], "omnivers": [6, 25, 28, 32, 67, 68, 69, 70, 71, 74, 75, 76, 77, 82], "omnixampl": [44, 46, 82], "on_trace_readi": [69, 70, 71], "on_valid_epoch_end": [25, 74], "onc": [3, 14, 16, 17, 22, 24, 27, 31, 46, 52, 53, 54, 55, 56, 57, 59, 60, 62, 63, 65, 66, 67, 71, 76, 78, 80, 82], "one": [3, 4, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 32, 35, 37, 39, 40, 42, 43, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 87], "one_hot": 24, "ones": [22, 24, 25, 27, 51, 52, 57, 62, 68, 70, 73, 74, 75, 77, 78, 87], "ones_": 24, "ong": [1, 34, 35, 39], "ongo": [56, 62, 66], "onli": [3, 4, 5, 6, 7, 8, 9, 10, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 68, 70, 73, 76, 78, 79, 80, 82, 83, 84, 87], "onlin": [30, 31, 35, 48, 51, 54, 77], "onto": [14, 19, 40], "onward": 74, "oom": 71, "op": [25, 44], "open": [8, 24, 25, 29, 31, 52, 53, 54, 65, 66, 72, 75, 76, 80], "openai": [10, 16, 22, 23, 24, 80], "opencv": [53, 55], "opengl": 53, "oper": [3, 4, 5, 6, 7, 8, 9, 14, 16, 17, 23, 25, 29, 31, 32, 34, 37, 39, 40, 41, 42, 43, 44, 48, 51, 52, 53, 54, 55, 56, 57, 59, 60, 62, 65, 68, 71, 72, 76, 78, 79], "operand": [6, 7, 9, 25], "operation": 57, "operatornam": [22, 23, 24, 27, 31, 40, 73], "oplu": [22, 24, 31, 34], "opportun": 51, "oppos": 22, "opposit": [8, 34, 38, 40, 53], "opt": [24, 28, 32, 53, 56, 71, 73, 75, 76, 77, 78], "optic": 52, "optim": [1, 2, 13, 14, 16, 21, 22, 24, 28, 29, 31, 32, 35, 39, 44, 48, 51, 52, 53, 54, 56, 59, 60, 62, 63, 64, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 82, 83, 84], "optim_arg": 76, "optim_group": 25, "optima": 27, "optimist": [57, 59, 62], "optimizer_config": 25, "optimizer_config_cl": [25, 74], "optimizer_nam": [82, 84], "optimizer_param": [82, 84], "optimizer_pydantic_config": [25, 74], "optimizer_registri": [25, 74], "optimizerconfig": [25, 82, 84], "optimizernam": 76, "optimum": 27, "option": [10, 13, 22, 24, 25, 28, 29, 31, 32, 38, 44, 51, 55, 71, 73, 75, 76, 77, 79, 80, 82], "optional_field": 76, "optuna": 76, "oracl": 55, "orang": [28, 35], "orchestr": [56, 66], "order": [5, 6, 7, 8, 14, 16, 19, 22, 23, 24, 25, 27, 31, 33, 34, 37, 38, 39, 44, 46, 51, 52, 54, 55, 56, 66, 73, 80], "ordered_label_count": 75, "ordereddict": [73, 75, 77], "ordin": [44, 53], "ordinari": 40, "org": [1, 28, 30, 31, 32, 47, 70, 71, 73, 77], "organ": [51, 52, 53, 54, 55, 56, 64, 66, 84], "organiz": 53, "orient": [4, 5, 9, 35, 38, 40, 55, 85], "origin": [4, 8, 10, 13, 14, 16, 22, 23, 24, 25, 28, 29, 31, 32, 35, 37, 38, 39, 40, 52, 56, 63, 73, 76, 79, 85, 87], "original_linear": 32, "original_s": 29, "original_shap": 29, "original_vector": 38, "orthogon": [31, 35, 39, 40], "other": [3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 16, 17, 19, 22, 23, 24, 25, 28, 29, 31, 34, 35, 38, 39, 40, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 67, 68, 69, 71, 73, 74, 76, 78, 79, 80, 82, 83, 84, 85, 87], "otherwis": [14, 16, 19, 22, 24, 25, 27, 28, 37, 56, 76, 78, 79], "otim": [34, 40], "our": [3, 5, 6, 7, 8, 10, 14, 16, 17, 19, 22, 23, 24, 27, 28, 29, 31, 32, 35, 37, 38, 39, 40, 42, 44, 46, 51, 52, 53, 55, 56, 59, 62, 65, 66, 67, 69, 72, 73, 74, 75, 76, 78, 79, 80, 82, 83, 85], "ourself": 24, "ourselv": [27, 39, 77, 79], "out": [3, 4, 6, 11, 19, 22, 23, 24, 25, 27, 29, 32, 42, 44, 51, 52, 54, 55, 56, 57, 59, 62, 63, 64, 65, 68, 70, 71, 73, 76, 78, 79, 80, 82, 85], "out_dim": 32, "out_featur": [24, 25, 31, 32, 68, 70, 74, 75], "outag": 54, "outbound": 23, "outcom": [5, 16, 23, 24, 25, 31, 35, 38, 51, 58, 59, 60, 66, 79], "outcome_count": 79, "outdat": 65, "outer": [17, 22, 23, 79], "outer_": 79, "outlier": [56, 57], "outlin": [22, 35, 51, 52, 56], "output": [5, 6, 14, 16, 17, 23, 25, 27, 28, 29, 31, 32, 42, 44, 45, 48, 53, 54, 55, 56, 58, 59, 61, 64, 65, 66, 69, 72, 73, 74, 75, 77, 80, 82], "output_dir": [32, 75, 76, 82], "output_path": 25, "output_subdir": 82, "outset": 51, "outsid": [6, 14, 24, 32, 55, 57, 73, 80, 85], "over": [4, 16, 17, 19, 22, 24, 25, 27, 28, 31, 34, 35, 37, 38, 39, 40, 42, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 73, 77, 78, 79, 80, 82], "overal": [17, 19, 24, 25, 27, 39, 51, 52, 53, 56, 59, 62, 74], "overall_accuraci": 74, "overarch": [23, 52], "overcom": [23, 25, 78, 80], "overdraft": 54, "overfit": [22, 24, 31, 39, 52, 57, 61, 62, 63, 64], "overflow": [17, 18, 23, 79], "overhead": [31, 44, 73, 84], "overkil": [56, 76], "overlap": [9, 23, 24, 53, 80], "overli": [25, 57, 62], "overlin": [22, 24], "overload": [8, 11, 24, 33, 75, 76, 77], "overlook": 17, "overnight": [51, 65], "overrid": [3, 10, 24, 25, 70, 73, 82], "overridden": 76, "override_dirnam": 82, "overset": [22, 24, 27, 31, 42, 58, 62, 79], "overshadow": 24, "oversight": 56, "overview": [30, 34, 52, 53, 55, 56, 66], "overwhelm": [37, 52], "overwrit": [14, 24], "overwrite_output_dir": [32, 75, 76], "overwritten": 14, "ovr": [32, 75], "ow": [22, 23, 31], "own": [5, 10, 14, 19, 22, 24, 25, 29, 31, 43, 52, 54, 55, 56, 58, 61, 72, 73, 75, 76, 80, 82, 85, 87], "owner": [45, 54], "ownership": 54, "ozan": [17, 18], "p": [1, 2, 5, 13, 16, 17, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 34, 35, 42, 43, 58, 59, 66, 68, 69, 70, 73, 74, 75, 77, 78, 79], "p1": 19, "p100": [67, 73, 77], "p100_16gb": 73, "p2": 19, "p50k_base": 24, "p50k_edit": 24, "p_": [24, 31, 43, 66, 77], "p_0": 35, "p_1": [16, 27], "p_2": [16, 27], "p_3": 27, "p_i": 77, "p_j": 27, "p_k": 27, "p_n": 16, "p_t": 77, "p_visual": 24, "packag": [24, 28, 32, 45, 53, 56, 57, 62, 70, 71, 73, 75, 77, 78], "packet": 16, "pad": [22, 24, 32, 74, 75, 76, 77], "pad_": 25, "pad_length": 77, "pad_numb": 25, "pad_sequ": 77, "pad_tensor": 77, "pad_token": [75, 77], "pad_token_id": [25, 32, 74, 75, 77], "padded_a": 25, "padded_b": 25, "padded_c": 25, "padding_mask": 74, "padding_masks_padded_and_expand": 25, "padding_sid": [32, 75, 77], "page": [6, 13, 14, 19, 23, 24, 28, 29, 35, 52, 53, 55, 57, 73, 79], "pageabl": 69, "pagin": 55, "pai": [24, 32, 74, 84], "pain": 54, "pair": [24, 28, 31, 34, 35, 39, 42, 53, 54, 73], "pairwis": [22, 24, 28], "palm_flop": 73, "panda": [28, 53, 55, 68, 69, 71, 75, 77, 80], "paper": [21, 22, 24, 25, 31, 52, 53, 56, 59, 62, 68, 70, 74, 75, 78], "paperback": 54, "par": 31, "paradigm": [53, 56, 74], "paradox": 11, "paragraph": 42, "parallel": [17, 22, 23, 33, 35, 43, 47, 55, 56, 64, 65, 76, 80, 82], "parallelclust": [33, 47], "param": [24, 25, 32, 73, 74, 76, 82], "param_a": 83, "param_b": 83, "param_dict": 25, "param_group": [25, 78], "param_str": 76, "paramet": [4, 7, 9, 10, 14, 16, 22, 24, 25, 28, 29, 32, 35, 39, 42, 44, 45, 60, 62, 64, 68, 70, 71, 74, 75, 76, 77, 78, 79, 82, 84, 85], "parameter": [6, 7, 8, 14, 23, 79], "parameter_nam": [24, 25, 32, 68, 70, 74, 75], "parameters_a": 31, "parameters_b": 31, "parametr": [8, 31], "paramount": [23, 24], "params_and_buffers_byt": 73, "params_byt": 73, "params_count": 73, "params_dict": 73, "parent": [3, 5, 24, 25, 28, 29], "parent_class_attr": 76, "parent_instance_attr": 76, "parent_method": 76, "parentclass": 76, "parenthes": 78, "pareto": 52, "pari": 24, "parmar": [1, 2, 21, 23, 30, 31, 73], "parquet": [53, 54], "pars": [53, 55, 60], "parse_arg": [44, 46, 71], "parser": [44, 46, 71], "part": [5, 6, 14, 17, 23, 24, 25, 27, 29, 32, 35, 40, 48, 51, 54, 57, 62, 66, 70, 71, 72, 73, 78, 80, 83, 84, 85], "parti": [24, 53, 55], "partial": [23, 25, 27, 28, 31, 74, 78, 79], "particip": 43, "particular": [6, 7, 14, 16, 17, 19, 23, 25, 27, 31, 34, 37, 43, 53, 55, 62, 73, 78, 79, 80, 85], "particulari": 8, "particularli": [3, 10, 14, 17, 19, 21, 23, 24, 25, 35, 38, 39, 40, 54, 57, 59, 65, 73, 79, 80], "partit": [13, 29, 42, 45, 55, 56, 57], "pass": [3, 4, 6, 7, 8, 9, 10, 13, 14, 16, 17, 22, 23, 24, 25, 29, 31, 32, 44, 52, 53, 56, 65, 68, 70, 71, 74, 75, 76, 80, 82, 84, 85, 87], "passiv": [10, 23, 76], "past": [17, 23, 24, 52, 54, 57, 65, 73], "past_index": 76, "past_key_valu": 32, "pastri": 35, "path": [3, 14, 23, 25, 28, 29, 37, 38, 39, 45, 52, 53, 54, 56, 82, 84], "pathcollect": 28, "pathlib": [24, 25, 28, 29, 82, 84], "pathologist": 29, "pathwai": 73, "patient": [35, 51, 52, 53, 54, 59, 62], "pattern": [1, 2, 3, 6, 9, 10, 15, 16, 17, 19, 22, 24, 25, 26, 27, 29, 31, 33, 51, 52, 54, 57, 65, 71, 78, 79, 80, 82, 83, 84, 85], "paul": 35, "paus": [25, 80], "pca": [27, 31, 57], "pcluster": 45, "pcm": 24, "pd": [28, 53, 68, 69, 71, 73, 75, 77], "pdf": [53, 68, 70], "pdrop": [68, 70], "pe": 24, "peac": 59, "peak": [57, 64, 71, 73], "peaki": 24, "pearson": [2, 21, 23], "peculiar": 16, "pedagog": 3, "pedant": [14, 28, 39, 42, 52, 67, 74, 75], "pedestrian": 52, "peek": 19, "peel": 16, "peft": 76, "peftadaptermixin": 76, "pem": 45, "penal": [25, 39], "pengcheng": 1, "peopl": [3, 24, 25, 28, 40, 54, 57, 65, 73, 75, 76, 79, 84, 85], "pep": [3, 4, 5, 6, 8, 9, 10, 11, 80], "pep484": 7, "per": [14, 16, 19, 22, 25, 27, 28, 43, 44, 45, 53, 60, 62, 68, 70, 74, 75], "per_clust": 28, "per_device_eval_batch_s": [32, 75, 76], "per_device_train_batch_s": [32, 75, 76], "per_gpu_eval_batch_s": 76, "per_gpu_train_batch_s": 76, "percal": 80, "percent": [59, 74], "percentag": [51, 59, 64, 69, 73, 79], "perceptron": [22, 24, 30, 31], "perf401": 76, "perfect": [28, 59], "perfectli": [25, 37, 42], "perform": [3, 4, 5, 8, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 32, 34, 38, 39, 40, 42, 43, 44, 45, 48, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 72, 73, 84, 85], "perform_kmeans_on_iri": 28, "perform_kmeans_on_mnist": 28, "perform_matrix_multipl": 67, "performancemod": 45, "perhap": [24, 54, 62, 66, 69, 83], "perimet": 5, "period": [16, 25, 46, 51, 57, 64, 65, 66, 78], "perk": 76, "perman": 54, "permiss": [5, 45, 53], "permit": 9, "permut": [7, 22, 25, 28], "perpendicular": 35, "perplex": 25, "persist": [24, 58, 82], "person": [24, 31, 51, 54, 55, 64, 65], "perspect": [3, 8, 24, 27, 29, 31, 37], "pertain": [38, 58], "pertub": 31, "perturb": [23, 79], "peter": 1, "phase": [11, 23, 24, 25, 52, 56, 57, 60], "phenomenon": 62, "phew": 56, "phi": [22, 24, 31, 42], "phi_j": 42, "phillip": 1, "phone": 53, "phrase": [24, 27, 65], "physic": [35, 43, 65], "pi": [5, 8, 22, 24, 25, 78, 79], "pick": [9, 22, 74, 80], "pickl": [70, 71], "pictur": [6, 40, 53, 54, 63], "pid": 75, "piec": [4, 7, 8, 23, 65], "piecewis": 59, "pieter": 1, "pil": 29, "pile": 16, "pin": [24, 25, 78], "pin_memori": [24, 25, 74, 75], "pineappl": 54, "pink": 29, "pioneer": 21, "pip": [32, 45, 56, 60, 67, 68, 69, 70, 71, 74, 75, 77], "pipelin": [33, 48, 53, 54, 55, 57, 61, 62, 64, 82, 83, 84], "pipeline_dataop": 56, "pipeline_train": 56, "pitfal": 62, "pivot": [14, 35, 38, 40], "pixel": [25, 29, 31, 52, 53], "pkg": 82, "place": [4, 6, 7, 8, 9, 14, 17, 19, 23, 27, 38, 39, 44, 51, 52, 60, 64, 73, 76, 80, 82, 85, 87], "place_model_on_devic": 76, "placehold": 6, "placement": 45, "placementgroup": 45, "plagu": 23, "plai": [3, 8, 14, 17, 25, 38, 39, 40, 51, 52, 54, 55, 60, 62, 65, 76, 78, 79], "plain": 55, "plan": [3, 35, 52, 55, 57, 65], "plane": [5, 27], "plant": 65, "plate": 54, "platform": [17, 51, 52, 53, 54, 55, 56, 57, 71], "platt": 59, "playbook": 76, "player": 16, "pleas": [16, 17, 24, 25, 28, 32, 44, 71, 74, 75, 78], "plot": [24, 25, 27, 28, 35, 37, 38, 39, 40, 59, 62, 66, 78], "plot_kmean": 28, "plot_kmeans_clusters_and_elbow": 28, "plot_kwarg": 24, "plot_learning_r": [25, 78], "plot_positional_encod": 24, "plot_scatt": 28, "plotter": [37, 38, 39], "plotter3d": 38, "plotter_add": 38, "plotter_case1": 40, "plotter_case2": 40, "plotter_case3": 40, "plotter_case4": 40, "plotter_neg": 38, "plotter_po": 38, "plotter_sub": 38, "plt": [24, 25, 28, 29, 37, 38, 39, 40, 74, 78, 79], "plu": [4, 24, 25, 73], "plug": [3, 14, 70], "plugin": 32, "plus_idx": 25, "pm": 38, "pmatrix": 22, "pmf": [23, 24], "pn": 24, "png": [29, 53, 65], "po": 24, "poc": 84, "point": [3, 5, 6, 7, 14, 16, 17, 19, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 37, 38, 39, 40, 42, 44, 46, 51, 52, 54, 55, 56, 58, 60, 62, 66, 67, 76, 78, 79, 80, 82], "pointer": [14, 24, 80], "pointpat": 70, "police_dog": 5, "policedog": 5, "polici": [45, 52, 53, 55, 65, 85], "policy_gradi": 52, "polosukhin": [1, 2, 21, 23, 30, 31], "polygon": 27, "polymorph": [3, 4, 5, 6, 9, 82], "polynomi": [13, 57], "polytop": 27, "pool": [24, 33, 52, 74, 82], "pooled_hidden_st": 75, "pooled_logit": 75, "pooler": [75, 77], "poor": [23, 27, 28, 45, 53], "poorli": [23, 24, 55], "pop": [8, 19], "pop1": 19, "pop_callback": 76, "popen_fork": 75, "popul": [24, 63], "popular": [13, 17, 27, 52, 53, 54, 55, 59, 65, 66, 79, 80], "portabl": 17, "portalock": 80, "portion": [17, 24, 25, 53, 73, 79, 80], "pos_emb": [24, 25, 75], "pos_embed_visu": 24, "pos_label": [32, 75], "pose": [45, 51], "posit": [3, 4, 13, 14, 16, 17, 19, 23, 25, 27, 28, 32, 37, 39, 40, 51, 52, 59, 62, 65, 68, 70, 73, 74, 75, 79], "position": 22, "position_embed": [68, 70], "positional_embed": [24, 68, 70], "positional_encod": 24, "positionalembed": 24, "positionalencod": 24, "positionwisefeedforward": [24, 25, 68, 70, 74, 75, 77], "positionwisefeedforwardconfig": [24, 25, 74, 75, 77], "positionwiseffn": 24, "posixpath": [24, 76, 82], "possess": [3, 37, 40, 43], "possibl": [3, 5, 6, 8, 16, 17, 22, 23, 24, 25, 27, 28, 34, 35, 42, 52, 55, 59, 60, 62, 66, 67, 71, 73, 78, 79, 80, 85], "possibli": [3, 4, 6, 17], "post": [3, 5, 11, 17, 22, 23, 24, 25, 30, 44, 52, 56, 64, 68, 69, 70, 71, 72, 73, 76, 78, 82], "post1": 70, "post_attention_layernorm": 32, "post_init": 76, "postcondit": 5, "poster": 52, "posterior": 79, "postgresql": [52, 53, 54, 55], "postprocess": 52, "potenti": [3, 4, 6, 7, 9, 14, 16, 17, 23, 24, 25, 31, 42, 51, 52, 53, 54, 57, 58, 64, 65, 66, 73, 78, 80], "potter": 54, "pow": [24, 69, 70], "powbackward0": 70, "power": [10, 13, 16, 17, 19, 23, 24, 25, 48, 52, 54, 58, 62, 69, 73, 78, 80, 82], "pp": [2, 11, 21, 23, 30, 31, 34, 79], "pprint": [6, 7, 8, 19, 24, 25, 28, 29, 32, 44, 46, 68, 71, 73, 74, 75, 76, 77, 79, 80, 82, 83, 85], "pr": [24, 32, 75], "pr_auc": [32, 75], "practic": [3, 5, 6, 8, 17, 22, 23, 24, 25, 27, 30, 31, 34, 35, 40, 42, 43, 44, 52, 53, 54, 55, 57, 58, 59, 60, 62, 64, 71, 72, 78, 85], "praction": 74, "practition": 72, "prai": 51, "praw": 55, "pre": [1, 2, 16, 25, 27, 31, 32, 33, 51, 52, 55, 57, 65, 74, 75, 78, 79, 82], "pre_head": 75, "pre_head_pool": 75, "precalcul": 24, "precalculu": 40, "preced": [23, 24, 25, 67], "precid": [22, 23, 31], "preciou": 56, "precis": [5, 9, 14, 16, 24, 27, 29, 32, 34, 40, 51, 52, 59, 62, 63, 66, 69, 73, 75, 79, 80], "precision_recall_curv": [32, 75, 77], "precision_scor": [32, 75, 77], "precomput": 65, "precondit": 5, "precursor": 5, "pred": [28, 32, 71, 75, 77], "predefin": [22, 24, 54, 62, 64], "predetermin": [24, 25, 78], "predic": [5, 76], "predict": [4, 17, 22, 23, 24, 25, 27, 28, 29, 32, 35, 42, 48, 51, 57, 59, 60, 61, 62, 63, 64, 66, 74, 75, 76, 77, 79], "prediction_loop": 76, "prediction_loss_onli": 76, "prediction_step": 76, "prefer": [51, 52, 54, 58, 59, 66, 76], "prefetch": 80, "prefix": [25, 69, 70, 71, 83], "preliminari": [33, 56, 57], "prematur": 16, "premis": [16, 53, 55], "prepar": [33, 48, 51, 52, 55, 61, 62, 85], "preparatori": 25, "prepare_inputs_for_gener": 76, "prepend": [45, 76], "preprint": [1, 2, 21, 23, 30, 31, 73, 77, 78, 79], "preprocess": [23, 55, 56, 57, 62, 65, 76], "preprocess_funct": [32, 75, 77], "preprocess_logits_for_metr": 76, "prescrib": 16, "presenc": [3, 8, 9, 17, 24, 51, 52, 56, 65], "present": [3, 10, 11, 13, 14, 16, 17, 22, 23, 24, 25, 27, 28, 35, 51, 52], "preserv": [6, 8, 14, 22, 24, 25, 33, 38, 65, 80], "press": [1, 2, 21, 23, 26, 27, 29, 34, 35, 39, 42, 54, 78, 79], "pressur": [52, 53, 71], "presum": 4, "pretend": [22, 24], "pretrain": [23, 31, 52, 56, 82, 83, 84], "pretrainedmodel": [75, 76, 77], "pretrainedtoken": [75, 77], "pretrainedtokenizerbas": [75, 76, 77], "pretrainedtokenizerfast": [75, 77], "pretti": [6, 7, 25, 28, 29, 31, 32, 44, 46, 58, 68, 71, 73, 74, 75, 76, 77, 79, 82, 83, 85], "pretty_print": [25, 44, 74, 83], "preval": [23, 51], "prevent": [5, 6, 14, 22, 24, 39, 53, 57, 62, 65, 73, 75, 79, 85], "previou": [3, 14, 16, 17, 21, 22, 23, 24, 25, 27, 28, 35, 40, 45, 52, 64, 65, 67, 74, 75, 80, 82], "previous": [5, 6, 14, 22, 23, 35, 39, 40, 66, 80], "price": [25, 42, 52, 53, 54, 55, 66], "primari": [3, 10, 17, 19, 23, 27, 54, 56, 57, 73, 82], "primarili": [10, 16, 22, 25, 62, 85], "prime": [22, 23, 24, 40], "primer": [23, 24], "princeton": 45, "princip": [19, 27, 31, 57], "principl": [2, 3, 4, 8, 11, 14, 17, 19, 27, 33, 40, 45, 55, 56, 57, 62, 63, 66, 79, 86], "print": [3, 4, 5, 6, 8, 9, 10, 19, 24, 25, 28, 29, 31, 32, 37, 39, 44, 46, 53, 67, 69, 70, 73, 74, 76, 77, 79, 80, 83, 87], "println": [4, 6], "prior": [17, 23, 25, 54, 79], "priori": [24, 27], "priorit": [17, 23, 51, 52, 58], "prioriti": [17, 51], "privaci": [51, 53, 55, 65], "privat": [55, 56, 76], "privateuse1_memory_usag": 69, "privateuse1_time_tot": 69, "privileg": 45, "pro": [17, 65], "prob": [24, 32, 68, 70, 75, 77, 79], "probabilist": [1, 22, 24, 26, 27, 29, 66], "probabilsit": [23, 24], "probabl": [22, 24, 25, 27, 29, 31, 32, 42, 52, 58, 59, 62, 65, 69, 75, 76, 77, 80], "problem": [1, 4, 8, 9, 13, 14, 22, 23, 24, 25, 31, 33, 35, 44, 48, 54, 56, 57, 58, 59, 62, 63, 64, 66, 74, 78, 80, 82], "problem_typ": [32, 75], "problemat": [7, 28], "probml": 1, "proc": 45, "proce": [3, 14, 16, 23, 24, 25, 27, 29, 51, 52, 80], "procedur": [13, 14, 16, 17, 22, 34, 56, 64, 79], "proceed": [44, 45, 46, 58], "process": [2, 3, 5, 6, 8, 10, 14, 16, 17, 19, 21, 23, 25, 29, 30, 31, 38, 39, 45, 46, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 69, 70, 71, 73, 76, 78, 80, 82, 83, 84], "process_0": 44, "process_1": 44, "process_ceo": 8, "process_employe": 8, "process_id": [44, 46], "process_manag": 8, "process_misleading_pair": 6, "process_silent_error_pair": 6, "processcontext": 44, "processor": [16, 73], "procur": [23, 51], "prod_": [22, 23, 31], "produc": [8, 22, 23, 24, 25, 35, 42, 60, 61, 64, 73, 77, 79, 80], "product": [4, 16, 23, 25, 31, 33, 34, 38, 39, 41, 45, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 62, 63, 65, 66, 68, 73, 74, 79, 84], "product_id": 53, "production_lak": 56, "production_warehous": 56, "prof": [69, 70, 71], "profil": [33, 45, 67, 71], "profile_kwarg": 70, "profile_memori": [70, 71], "profile_model": 68, "profile_one_step": 70, "profile_step": [68, 70], "profile_with_ev": 69, "profiler_config": 68, "profileract": [69, 70, 71], "profilerconfig": 68, "profilerstep": 69, "profilingresult": 68, "profit": 52, "program": [3, 4, 5, 6, 7, 8, 10, 11, 14, 19, 24, 28, 33, 43, 53, 54, 71, 76, 85], "programm": [6, 16, 80], "programmat": 24, "progress": [14, 17, 25, 45, 51, 78], "progress_bar": 74, "prohibit": [16, 31], "proj": [22, 40, 73], "project": [25, 31, 32, 33, 38, 39, 48, 51, 56, 57, 58, 59, 68, 70, 73, 74, 75, 76, 79, 83], "project_nam": [82, 84], "projected_context_vector": [22, 68, 70], "promin": 34, "promis": [23, 73], "promot": [25, 39, 84], "prompt": [16, 23, 31], "prone": [56, 58, 82], "pronounc": 79, "proof": [14, 17, 24, 25, 26, 27, 35, 52, 79], "proofwiki": 40, "propag": [14, 24, 25, 52, 74, 80], "propagate_args_to_deepspe": 76, "propel": 21, "proper": [9, 24, 53, 55, 75], "properit": 34, "properli": 74, "properti": [3, 7, 10, 16, 17, 19, 22, 23, 24, 25, 28, 29, 31, 34, 38, 39, 42, 66, 68, 70, 76, 79, 84, 87], "proport": [17, 27, 51, 59, 79], "proportion": [31, 39], "propos": [22, 24, 31, 54, 80], "proposit": 23, "proprietari": 55, "protect": [65, 76], "protected_namespac": [82, 84], "proteom": 53, "protocol": [3, 4, 7, 65, 80], "prototyp": [29, 52, 65], "provdi": 24, "prove": [6, 7, 14, 16, 17, 27, 34, 51, 78, 79], "proven": [17, 22, 23, 31], "provid": [3, 5, 6, 9, 10, 11, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 30, 31, 34, 35, 37, 39, 40, 42, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 71, 73, 75, 76, 78, 79, 80, 82, 84, 85], "prowess": 24, "prune": [52, 58], "prune_head": 76, "pry": 72, "pseudo": [23, 24, 31, 52, 57, 60, 84], "pseudocod": 76, "psutil": [32, 75, 77], "psycopg2": 55, "pt": [32, 73, 75, 77], "pth": 82, "ptxcompil": 70, "pub": [55, 56], "public": [4, 6, 45, 53, 55], "publicdn": 45, "publicdnsnam": 45, "publish": [1, 24], "pull": [57, 60, 84], "punctuat": [23, 24], "purchas": 52, "pure": [35, 56, 73], "purg": 68, "purge_global_scop": 68, "puriti": 26, "purity_per_clust": 28, "purity_scor": 28, "purpl": [22, 29], "purpos": [3, 7, 16, 19, 22, 25, 27, 28, 29, 31, 35, 37, 44, 45, 56, 62, 73, 76, 78, 80], "push": [6, 14, 19, 22, 33, 42, 48, 56, 60, 84], "push1": 19, "push2": 19, "push3": 19, "push_to_hub": 76, "push_to_hub_model_id": 76, "push_to_hub_organ": 76, "push_to_hub_token": 76, "pushtohubmixin": 76, "put": [14, 25, 28, 29, 32, 45, 55, 56, 69, 79, 82], "puzzl": 66, "pwd": 44, "py": [4, 24, 25, 28, 32, 44, 45, 46, 56, 60, 71, 73, 75, 76, 77, 78, 82, 83], "pyarrow": 70, "pydant": [24, 32, 44, 56, 68, 70, 73, 76, 80, 83, 84], "pyi": 9, "pyi034": [10, 24], "pylint": 28, "pymongo": 55, "pymysql": 55, "pyplot": [24, 25, 28, 29, 38, 74, 78, 79], "pyproxim": 30, "pythagora": 39, "python": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 17, 19, 22, 24, 25, 27, 31, 33, 35, 44, 46, 54, 55, 56, 60, 70, 71, 73, 75, 78, 81, 82], "python3": [24, 28, 32, 45, 56, 71, 73, 75, 76, 77, 78], "python_vers": 56, "pythonds3": 1, "pythonhashse": [24, 31, 60], "pythonpath": 44, "pytorch": [8, 22, 26, 27, 30, 31, 32, 33, 43, 44, 45, 47, 53, 60, 70, 71, 72, 73, 75, 76, 77, 79, 80, 82, 84], "pytorch_jacobian": 79, "pytorch_softmax": 79, "pytorch_softmax_output": 79, "pytorch_softmax_prob": 79, "q": [22, 24, 25, 27, 32, 34, 52, 67, 68, 69, 70, 71, 73, 74, 77], "q0": 24, "q_1": 24, "q_2": 24, "q_i": [24, 77], "q_learn": 52, "q_or_k_or_v": 24, "q_proj": 32, "q_t": 24, "qa": 56, "qkv": 32, "qkv_lora_weight_param": 32, "quad": [16, 17, 22, 23, 24, 25, 27, 31, 35, 37, 38, 40, 52, 73, 79], "quadrat": 24, "qualifi": 3, "qualiti": [23, 27, 29, 48, 51, 52, 55, 56, 59, 64], "quality_loss": 52, "quality_predict": 52, "quantifi": [16, 24, 39, 40, 51, 52, 63, 73, 77], "quantit": [40, 59], "quantiti": [23, 27, 35, 42, 51, 56, 63, 73], "quantiz": [16, 52, 58], "queri": [17, 25, 31, 45, 52, 53, 54, 55, 56, 65, 68, 70, 73, 74, 75, 76], "question": [1, 6, 16, 23, 24, 25, 26, 27, 30, 51, 52, 53, 82], "question_answ": 52, "question_token": 25, "questionnair": 53, "queu": 67, "queue": [44, 45, 67], "quick": [19, 31, 56, 57, 62], "quicker": 16, "quickli": [17, 28, 32, 52, 56, 58, 64, 65], "quirk": [10, 22, 24, 31], "quit": [4, 9, 17, 24, 25, 27, 29, 42, 44, 52, 63, 65, 76, 79, 80], "quiver_kwarg": 38, "quora": [17, 40], "quot": [4, 23, 24, 27, 44, 54, 71, 87], "quota": 45, "quotient": 79, "qwen": 32, "qwen1": 32, "qwen2decoderlay": 32, "qwen2forsequenceclassif": 32, "qwen2mlp": 32, "qwen2model": 32, "qwen2rmsnorm": 32, "qwen2rotaryembed": 32, "qwen2sdpaattent": 32, "qwen2token": 32, "r": [2, 5, 8, 14, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 42, 45, 52, 54, 56, 58, 59, 60, 62, 66, 77, 79, 80], "r50k_base": 24, "r_": [16, 42, 43], "r_1": [27, 35], "r_2": [27, 35], "r_3": [27, 35], "r_4": 35, "r_g": 43, "r_i": 35, "r_k": [27, 42], "r_l": 43, "r_m": 35, "r_t": 16, "r_y": 42, "rabbitmq": 53, "race": 46, "rachel": 24, "radam": [25, 78], "radford": [1, 2, 21, 22, 23, 24, 31], "radic": [21, 52], "radiu": 5, "rai": [52, 53, 76], "rain": 59, "rais": [4, 5, 6, 7, 8, 9, 10, 19, 24, 25, 28, 29, 31, 32, 44, 52, 56, 67, 68, 69, 70, 71, 76, 80, 82, 84, 85, 87], "raise_error_if_seed_is_negative_or_outside_32_bit_unsigned_integ": 31, "raise_for_statu": 24, "rand": [24, 28, 53, 59], "rand_lik": 71, "randint": [24, 25, 44, 68, 70, 74], "randn": [22, 24, 25, 31, 67, 69, 71, 79, 80], "random": [19, 23, 24, 25, 27, 28, 29, 31, 42, 45, 52, 53, 57, 58, 60, 62, 68, 70, 76, 79, 80, 87], "random_index": 24, "random_sequ": 24, "random_sequence_decod": 24, "random_split": 25, "random_st": [28, 29], "randomforest": 87, "randomli": [22, 27, 62], "rang": [3, 6, 14, 16, 17, 22, 23, 24, 25, 27, 28, 29, 31, 32, 35, 40, 44, 45, 52, 53, 54, 55, 56, 59, 62, 65, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82], "rangebound": 13, "rangl": 24, "rank": [1, 32, 33, 53, 79], "rapid": 24, "rapidli": [23, 25, 58, 65, 78], "rare": [51, 58, 62, 65], "rariti": 51, "rasbt": 30, "raschka": [23, 24, 26, 27, 30, 31], "rate": [1, 2, 16, 17, 21, 23, 24, 31, 51, 52, 55, 58, 59, 61, 62, 66, 73, 79, 82], "rather": [3, 6, 7, 8, 9, 16, 17, 22, 23, 24, 25, 27, 51, 53, 54, 56, 59, 62, 65, 66, 78, 79, 80, 84], "ratic": 29, "ratio": [13, 24, 25, 28, 29, 57, 78, 79], "ration": 34, "rational": [22, 23, 24, 52, 53, 56], "raw": [24, 25, 44, 52, 53, 54, 56, 57, 68, 77], "raw_": 56, "raw_dvc_metadata": 83, "raw_file_format": 83, "raw_file_s": 83, "raw_filepath": 83, "raw_table_nam": 56, "ray_scop": 76, "rceil": [16, 29], "rcount": 28, "rdgy": 24, "rdzv": 44, "rdzv_backend": 45, "rdzv_endpoint": 45, "rdzv_id": 45, "re": [6, 7, 14, 16, 24, 25, 28, 32, 40, 55, 57, 59, 62, 65, 66, 73, 80, 83, 84], "reach": [6, 14, 16, 17, 24, 25, 28, 40, 46, 67, 78], "react": [52, 61], "read": [45, 49, 50, 67, 74, 75], "read_only_attr": 76, "readabl": [53, 82, 84], "reader": [10, 11, 16, 24, 31, 40, 57, 79], "readi": [22, 27, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 65], "readili": [52, 79], "readthedoc": [1, 8], "real": [9, 14, 16, 17, 24, 27, 29, 31, 35, 37, 38, 39, 40, 42, 51, 52, 53, 54, 55, 56, 59, 62, 64, 66, 69, 71, 73, 76, 78, 79, 80, 85], "realis": [23, 57, 62], "realist": [51, 57, 62], "realiti": [14, 56], "realiz": [6, 17, 23, 27, 38, 42], "realli": [3, 4, 6, 7, 8, 14, 24, 28, 55, 57, 60, 62, 69, 82], "realm": [38, 39, 79], "rearch": 58, "rearrang": 35, "reason": [4, 10, 14, 16, 17, 23, 24, 25, 27, 31, 35, 38, 51, 54, 56, 57, 58, 59, 66, 73, 76, 80, 82, 83], "rebuilt": 53, "recal": [7, 14, 16, 22, 24, 25, 27, 29, 31, 32, 52, 54, 56, 59, 62, 63, 66, 69, 73, 74, 75, 79], "recalcul": 27, "recall_scor": [32, 75, 77], "recap": [6, 7, 80], "receiv": [9, 14, 23, 25, 42, 51, 52, 59, 65, 66, 76, 80], "recenc": 52, "recent": [19, 23, 60, 66], "recip": [61, 62, 69, 70, 72], "reciproc": [13, 34, 79], "reclaim": 71, "recogn": [3, 14, 16, 19, 23, 27, 34, 37, 38, 51, 52, 53, 55, 57, 65, 79], "recognit": [1, 2, 23, 26, 27, 29, 39, 51, 52, 65, 79], "recogniz": 16, "recombin": 13, "recommen": 65, "recommend": [16, 27, 31, 45, 53, 54, 55, 56, 57, 65, 66, 68], "reconcil": 24, "reconstruct": 39, "reconstruct_imag": 29, "reconstructed_imag": 29, "recontruct": 27, "record": [14, 17, 51, 52, 53, 54, 55, 56, 60, 62, 69, 71], "record_funct": [70, 71], "record_memory_histori": 71, "record_shap": [70, 71], "recov": [23, 24, 27, 39, 82], "recoveri": 55, "recreat": 24, "rectangl": [17, 19], "rectifi": [22, 24], "recur": 14, "recurr": [13, 14, 21, 23, 24], "recurs": [13, 16, 18, 32, 76], "recursivebinarysearchexactmatch": 14, "red": [22, 28, 29, 35, 38, 39, 40], "reddit": [23, 30, 53, 55], "redef": 24, "redefin": [14, 16], "redi": [53, 55], "redshift": [54, 55], "reduc": [13, 14, 17, 23, 24, 25, 27, 28, 29, 31, 44, 45, 48, 51, 52, 53, 54, 55, 57, 58, 65, 73, 78, 79, 85], "reduceop": 44, "reduct": [29, 39, 52, 57, 58, 73, 74, 77, 78], "redund": [25, 31, 53, 54], "ref": 66, "refactor": 85, "refcount": 71, "refer": [11, 32, 42, 59, 87], "referenc": [19, 24, 80], "refin": [14, 25, 48, 52, 56, 59, 78], "reflect": [8, 11, 17, 22, 25, 40, 51, 52, 55, 73, 76, 78, 79], "reformul": 79, "refram": [16, 35], "refresh": [29, 35, 56], "regard": [7, 25, 28], "regardless": [3, 8, 14, 17, 22, 23, 24, 25, 35, 38, 39, 60], "regex": 32, "regim": [13, 23, 25, 78], "region": [29, 42, 45, 64], "regist": [32, 44, 64, 68, 70], "register_backward_hook": 76, "register_buff": [24, 68, 70, 76], "register_for_auto_class": 76, "register_forward_hook": 76, "register_forward_pre_hook": 76, "register_full_backward_hook": 76, "register_full_backward_pre_hook": 76, "register_load_state_dict_post_hook": 76, "register_modul": 76, "register_paramet": [24, 76], "register_state_dict_pre_hook": 76, "registr": 54, "registri": [6, 33, 48, 56, 62, 82], "regress": [22, 25, 27, 34, 42, 52, 58, 62, 63, 64, 66, 79, 87], "regul": 53, "regular": [1, 2, 6, 13, 17, 21, 22, 23, 24, 25, 39, 56, 57, 58, 63, 64, 65, 66, 68, 70], "regularli": [55, 62, 66], "regulatori": 55, "regurgit": 79, "reighn": 29, "reilli": [48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 65], "reinforc": 52, "reiniti": 28, "reiter": [24, 57], "reject": 4, "rel": [10, 13, 14, 23, 24, 25, 27, 28, 35, 40, 51, 66, 73, 77, 78, 79], "relat": [3, 4, 5, 7, 8, 13, 14, 16, 17, 22, 23, 24, 25, 40, 51, 53, 55, 56, 60, 65, 69, 75, 80, 85], "relationship": [3, 4, 7, 8, 11, 13, 14, 16, 17, 19, 22, 23, 24, 35, 40, 42, 53, 54, 57, 58, 62, 66, 73, 78, 85], "relax": 17, "releas": 46, "relev": [8, 14, 16, 17, 22, 24, 25, 31, 34, 45, 51, 52, 53, 56, 57, 59, 62, 64, 65, 66, 79, 85], "reli": [3, 6, 8, 17, 23, 24, 25, 34, 54, 58, 62, 65, 73, 78, 85], "reliabl": [25, 34, 48, 51, 54, 56, 59, 62, 64, 65, 66, 76], "religi": 24, "relu": [22, 24, 74], "remain": [14, 16, 17, 19, 22, 24, 27, 35, 37, 38, 39, 43, 54, 55, 56, 59, 62, 78, 79, 80, 82, 85], "remedi": 27, "rememb": [7, 25, 31, 39, 44, 45, 52, 57, 58, 59, 60, 62, 66], "remind": [27, 31, 56], "remot": [45, 56, 60], "remov": [8, 16, 19, 24, 25, 32, 55, 56, 57, 62, 73, 74, 75, 76], "remove_callback": [25, 76], "remove_column": [32, 75], "remove_special_token": 25, "remove_unused_column": 76, "removed_item": 19, "rename_column": [32, 75, 77], "renda": 30, "render": [28, 45, 85], "rendezv": 44, "rent": 54, "rental": 51, "reorder": 17, "reorder_and_upcast_attn": 24, "rep": [2, 11], "repeat": [6, 22, 24, 25, 27, 62, 69, 70, 71, 78, 79], "repeatedli": [14, 16, 31, 60, 82], "repetit": 24, "rephras": [6, 27], "replac": [3, 5, 6, 7, 8, 13, 22, 23, 24, 25, 27, 29, 32, 34, 35, 45, 62, 63, 64, 74, 76, 78, 79], "replic": [24, 25, 44, 53, 55], "replica": [53, 56, 84], "repo": [24, 45], "report": [45, 52, 54, 55, 56, 59, 62, 73], "report_to": [32, 75, 76], "reposit": [23, 24], "repositori": [10, 25, 35, 53, 54, 55, 56, 60, 70, 72], "repr": 76, "repres": [3, 5, 6, 7, 8, 10, 14, 16, 17, 19, 22, 23, 24, 25, 28, 29, 31, 34, 35, 37, 38, 39, 40, 42, 44, 52, 53, 54, 55, 56, 57, 59, 62, 65, 66, 69, 73, 74, 78, 83], "represent": [3, 8, 19, 27, 28, 29, 31, 34, 35, 38, 52, 53, 54, 57, 58, 73, 74, 75, 76, 79, 82], "reproduc": [28, 32, 44, 56, 62, 66, 68, 70, 71, 75, 77], "request": [24, 29, 54, 55, 65, 66, 80, 85], "requir": [3, 4, 5, 7, 8, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 35, 39, 44, 52, 53, 54, 56, 57, 58, 59, 60, 64, 65, 67, 70, 71, 73, 76, 78, 79, 80, 84, 85], "required_field": 76, "requirements_dev": 56, "requires_grad": [24, 31, 32, 73, 79], "requires_grad_": 76, "rerun": [28, 76], "resampl": [23, 57, 58], "research": [16, 23, 25, 53, 58, 73], "reserv": [14, 45], "reservoir": 57, "reset": [28, 80, 83], "reset_memory_hooks_st": 76, "reset_orig": 24, "reset_paramet": 24, "reshap": [24, 25, 28, 29, 56, 70], "resid": [14, 24, 27, 29, 31, 35, 37, 40, 73], "resid_dropout": [22, 68, 70], "resid_pdrop": [24, 68, 70], "residu": [23, 66, 68, 70, 74, 75], "residualblock": 24, "resiz": [19, 82], "resize_": 70, "resize_position_embed": 76, "resize_token_embed": 76, "resnet": [23, 24, 25, 78], "resnet18": 82, "resnet50": [71, 82], "resnext": 24, "resolut": 52, "resolv": [6, 23, 24, 25, 28, 29, 46, 55, 70, 82], "reson": [51, 65], "resort": 16, "resourc": [16, 31, 35, 43, 46, 51, 52, 54, 56, 57, 60, 62, 65, 73, 85], "respect": [5, 6, 14, 16, 22, 24, 25, 27, 31, 34, 35, 39, 40, 42, 55, 56, 73, 74, 76], "respond": [10, 65, 79], "respons": [10, 24, 25, 35, 44, 52, 54, 55, 56, 65, 66, 78, 79, 80, 83, 85, 87], "rest": [16, 17, 22, 24, 27, 45, 48, 52, 53, 56, 73, 79, 82], "restart": [1, 2, 25, 27, 70, 71, 78], "restaur": 19, "restrict": [3, 6, 7, 19, 23, 24, 25, 42, 52, 53, 55, 74, 85], "restructur": 56, "result": [3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 38, 39, 40, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 79, 80, 85], "result_typ": 69, "results_to_datafram": 68, "resum": [24, 25, 60, 73, 80, 83], "resume_download": [24, 73], "resume_from_checkpoint": 76, "resumpt": 60, "resurfac": 54, "ret": [28, 71], "retain": [22, 24, 31, 35, 51, 52], "retain_graph": 79, "retent": 65, "rethink": 7, "retrain": [24, 31, 52, 60, 62, 66], "retri": 56, "retriev": [14, 19, 22, 24, 53, 54, 55, 60, 65, 84], "retrieve_modules_from_nam": 76, "retrospecit": 54, "retrospect": 27, "return": [3, 4, 5, 6, 7, 9, 10, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 37, 39, 44, 45, 52, 53, 54, 56, 60, 63, 65, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 87], "return_annot": 76, "return_invers": 28, "return_tensor": [32, 75, 77], "return_x_i": 28, "returntyp": 80, "reus": [4, 56, 71, 76, 85], "reusabl": 84, "rev": 60, "reveal": [6, 9, 16, 32, 40], "reveal_loc": 6, "reveal_typ": [6, 9], "revenu": [51, 52], "revers": [4, 8, 19, 24, 25, 38, 39, 54, 76, 85], "reverse_bettertransform": 76, "reverse_transpose_qkv": 24, "reversedataset": 74, "revert": [52, 56, 64, 82], "review": [21, 23, 52, 54, 55, 65], "revis": [1, 2, 21, 23, 30, 31, 66, 78, 79], "revisit": [24, 32, 37, 39, 40, 57, 60, 84], "revolution": [17, 23], "revolv": 51, "rewon": 1, "rewrit": [27, 31], "rf": 56, "rfloor": [14, 16], "rgb": [29, 53], "rich": [6, 24, 25, 28, 29, 32, 37, 39, 44, 46, 53, 56, 68, 71, 74, 75, 76, 77, 79, 80, 82, 83, 85], "rich_handler_config": [25, 74], "rich_traceback": [25, 74], "richard": 1, "richer": [24, 52], "richlogg": 25, "ride": [53, 54], "ridg": 39, "right": [5, 7, 13, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 34, 35, 37, 38, 39, 40, 42, 51, 55, 56, 58, 73, 74, 75, 76, 77, 78, 79, 80], "right_index": 14, "rightarrow": [3, 5, 14, 16, 22, 23, 24, 27, 29, 31, 39, 42, 58, 66, 75, 79], "rightfulli": [9, 74], "rightmost": [14, 29], "rigor": [14, 16, 17, 23, 24, 31, 35, 39, 40, 46, 55, 64, 79], "rigour": [25, 62], "ring": 54, "rise": [21, 27, 66, 71, 79, 82], "risk": [8, 24, 42, 45, 51, 56, 62, 65, 76, 79], "river": [23, 24], "rivest": [1, 13], "rm": [40, 56], "rmns_1": [68, 70], "rmns_2": [68, 70], "rmse": [52, 59, 62, 63, 64, 66], "rmsnorm": [68, 70], "rng": [25, 31, 60, 76], "rng_seed": 25, "rnn": [23, 24, 25], "ro": [70, 72], "road": 24, "rob": 3, "robert": [2, 26, 27, 73, 79], "roberta": 30, "robit": 3, "robot": [3, 4, 55], "robot_sound": 4, "robust": [4, 56, 61, 62, 63, 64, 84], "roc": [32, 59, 63, 64, 66, 75], "roc_auc": [32, 75], "roc_auc_scor": [32, 75, 77], "roc_curv": [32, 75, 77], "rohrer": [23, 24], "role": [17, 34, 38, 39, 40, 51, 52, 55, 79], "roll": [54, 64], "rollback": [56, 64], "ronald": 1, "room": [16, 27, 35, 73], "root": [3, 11, 13, 14, 22, 24, 25, 28, 29, 39, 45, 59, 62, 63, 66, 73, 82], "root_dir": [25, 28, 29], "rossum": [8, 11], "rostamizadeh": 42, "rotary_emb": 32, "rotat": [37, 57], "rotten": 55, "rough": [16, 31, 45, 79], "roughli": [5, 27, 28, 73], "round": [16, 29, 56, 63], "roundabout": 57, "rout": 45, "routet": 45, "routetableid": 45, "row": [22, 24, 25, 28, 29, 31, 37, 42, 62, 63, 68, 69, 74, 79, 80], "row_ax": 24, "row_count": 80, "row_idx": 53, "row_limit": [69, 70], "row_v": 37, "rowl": 54, "rstrip": [75, 80], "rtol": [24, 28, 79], "rudimentari": [33, 35, 81], "rule": [3, 6, 16, 22, 25, 27, 31, 34, 37, 40, 51, 54, 55, 60, 65, 66, 79, 85], "run": [6, 7, 8, 10, 13, 16, 19, 22, 24, 25, 27, 28, 29, 43, 44, 46, 53, 54, 55, 56, 57, 58, 61, 62, 64, 65, 66, 67, 68, 71, 73, 76, 78, 79, 80, 82, 83, 84], "run_id": [82, 83], "run_nam": 76, "run_profil": [68, 70], "run_resnet50": 71, "run_train": 84, "run_warmup": 70, "run_with_barri": 46, "run_with_no_barri": 46, "runeston": [1, 14, 17, 18, 19, 20], "runnabl": 28, "runner": [25, 56, 76], "runtim": [3, 4, 6, 13, 43, 71, 82, 85], "runtime_check": [3, 4], "runtimeerror": 67, "runtimewarn": [28, 75], "rush": 51, "russel": 11, "rvert": 24, "s3": [45, 52, 53, 54, 55], "s_1": 79, "s_2": 79, "s_i": 79, "s_j": 79, "s_k": 79, "saa": 55, "sacrific": 6, "saddl": 79, "safe": [6, 7, 8, 9, 17, 19, 52, 54], "safeguard": 32, "safer": 14, "safeti": [5, 6, 8, 11, 19, 24, 33, 44, 52, 65], "sagemak": 65, "sai": [4, 5, 6, 7, 8, 14, 16, 17, 23, 24, 25, 27, 29, 31, 32, 34, 37, 38, 39, 40, 43, 44, 46, 52, 53, 55, 57, 59, 62, 65, 66, 69, 73, 74, 75, 79, 80], "said": [3, 31, 58, 73, 79], "sake": [7, 14, 17, 23, 24, 25, 27, 35, 38, 40, 56, 57, 78], "salari": 8, "sale": 52, "saliman": [1, 2, 21, 23], "same": [3, 4, 5, 6, 7, 8, 9, 10, 14, 16, 17, 22, 24, 25, 27, 28, 29, 31, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 65, 66, 69, 71, 74, 76, 79, 82, 83, 84, 85, 87], "sampl": [22, 23, 27, 28, 31, 35, 42, 53, 56, 58, 59, 61, 62, 63, 66, 73, 74, 75, 76, 80, 83], "sample_data_schema": 53, "sample_index": [25, 28], "sampler": 53, "sampling_result": 79, "sandbox": [4, 44], "saniti": [32, 61, 82], "satellit": 53, "satisfact": [51, 57], "satisfactori": [62, 66], "satisfi": [13, 16, 17, 23, 25, 27, 34, 35, 39, 51, 54, 79], "save": [16, 24, 29, 32, 37, 38, 51, 52, 53, 55, 56, 60, 65, 71, 76, 80, 82, 83], "save_best_onli": [25, 74], "save_dir": [25, 74], "save_every_epoch": [25, 74], "save_metr": 76, "save_model": 76, "save_on_each_nod": 76, "save_only_model": 76, "save_path": [37, 38], "save_pretrain": 76, "save_safetensor": 76, "save_snapshot": 83, "save_st": [25, 76], "save_step": [32, 75, 76], "save_strategi": [32, 75, 76], "save_total_limit": [32, 75, 76], "savefig": 29, "saw": [31, 74], "sax": 13, "sbatch": 45, "sbatch_run": 45, "scalabl": [23, 44, 48, 51, 53, 54, 56, 62, 64, 65], "scalar": [22, 24, 25, 27, 28, 34, 37, 39, 79], "scale": [16, 17, 23, 25, 27, 31, 32, 33, 34, 39, 40, 52, 53, 54, 55, 56, 57, 58, 59, 65, 68, 70, 73, 74, 75, 77, 78], "scale_attn_by_inverse_layer_idx": 24, "scale_attn_weight": 24, "scaled_dot_product": 24, "scaled_logit": [24, 79], "scaled_prob": 79, "scaled_vari": 24, "scaled_vector": 38, "scaleddotproductattent": [24, 25, 68, 70, 74, 75, 77], "scaler": 25, "scaler_config": [25, 74], "scaling_factor": 24, "scan": [51, 52, 53, 54], "scarciti": 23, "scatter": [9, 24, 28, 68], "scatter_1": 28, "scatter_2": 28, "scatter_3": 28, "scenario": [3, 4, 6, 8, 10, 14, 16, 19, 22, 23, 25, 31, 38, 43, 52, 57, 58, 63, 64, 65, 77, 79, 80, 85], "scene": [19, 56], "schedul": [31, 45, 55, 56, 57, 69, 70, 71, 74, 75, 76, 77, 78, 83, 84], "scheduler_config_cl": [25, 74], "scheduler_cycl": [25, 78], "scheduler_non_cycl": [25, 78], "scheduler_pydantic_config": [25, 74], "scheduler_registri": [25, 74], "schedulertyp": 76, "schema": [3, 53, 54, 55, 56, 65], "scheme": [3, 4, 24, 25, 56], "schwartz": 23, "scienc": [1, 8, 11, 14, 16, 17, 19, 23, 24, 34, 48], "scientif": 53, "scientist": [48, 58, 60, 64], "scikit": [26, 27, 28, 58, 59, 62], "scipi": [32, 75, 77], "scontrol": 45, "scope": [7, 16, 23, 24, 33, 45, 48, 51, 56, 58, 62, 68, 71, 76, 80], "score": [22, 25, 26, 32, 51, 52, 58, 59, 62, 63, 64, 65, 66, 73, 74, 75, 77, 79], "scrape": [23, 53, 55], "scrapi": 55, "scratch": [21, 23, 24, 25, 28, 30, 43, 44, 68, 70, 74], "script": [9, 44, 55, 56, 82, 85], "scroll": 57, "sdk": 55, "seaborn": [24, 25, 28, 70, 74, 80], "seach": 14, "seamlessli": 3, "search": [3, 5, 6, 13, 25, 28, 29, 33, 39, 54, 60, 62, 65, 82], "searchcontext": 14, "searchpath": 82, "season": 16, "sebastian": [23, 24, 26, 27, 30, 31], "second": [6, 8, 9, 10, 13, 14, 16, 19, 22, 23, 24, 25, 29, 31, 32, 34, 38, 44, 51, 53, 58, 67, 69, 71, 74, 75, 76, 78, 79, 80, 85], "second_el": 6, "second_row": 80, "secondari": 23, "secondli": [25, 78, 79, 80], "secret": 45, "section": [3, 4, 6, 7, 8, 14, 16, 22, 24, 25, 27, 29, 31, 35, 39, 40, 42, 52, 53, 54, 55, 56, 60, 65, 74, 78, 79, 82], "secur": [45, 51, 53], "see": [3, 6, 7, 8, 9, 13, 14, 16, 17, 22, 23, 24, 25, 27, 28, 29, 31, 32, 35, 37, 38, 39, 40, 42, 44, 45, 46, 51, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84], "seed": [24, 25, 27, 28, 31, 32, 44, 68, 70, 71, 74, 75, 76, 77, 82, 84], "seed_al": [24, 25, 28, 31, 32, 44, 60, 68, 70, 71, 74, 75, 77], "seed_torch": [24, 25, 28, 31, 32, 44, 60, 74, 75, 77], "seed_work": 31, "seek": [14, 16, 24, 27, 29, 42, 79], "seem": [6, 8, 22, 23, 24, 25, 27, 52, 57, 62], "seemingli": 16, "seen": [14, 21, 22, 23, 24, 25, 27, 35, 38, 52, 53, 62, 63, 73, 78, 84], "segment": [24, 26, 33, 37, 51, 52, 64, 65, 85], "segmented_imag": 29, "seldom": 23, "select": [22, 24, 25, 31, 39, 48, 51, 52, 53, 54, 55, 57, 60, 62, 63, 65, 79, 87], "selectbackward0": 24, "selenium": 55, "self": [1, 3, 4, 5, 6, 8, 9, 10, 14, 16, 19, 21, 25, 28, 32, 44, 52, 56, 58, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 83, 84, 85, 87], "self_attn": 32, "self_cpu_memory_usag": 69, "self_cpu_time_tot": 69, "self_cuda_memory_usag": 69, "self_cuda_time_tot": [69, 70], "self_privateuse1_memory_usag": 69, "sell": 17, "semant": [3, 5, 6, 8, 10, 11, 23, 24, 25, 34, 54], "semi": [22, 23, 52, 53, 54, 55, 57], "semin": 4, "send": [56, 65, 69], "sendtyp": 80, "sens": [8, 9, 10, 16, 17, 19, 24, 25, 27, 28, 38, 42, 44, 65, 73, 74, 78, 79, 82, 85], "sensit": [24, 25, 27, 39, 55, 58, 62, 78, 79], "sensor": [53, 65], "sent": [25, 56, 65, 80], "sentenc": [22, 23, 24, 25, 31, 32, 39, 52, 74, 75, 77], "sentences_allagre": [32, 75, 77], "sentiment": [23, 51, 52, 55, 74], "sentiment_analysi": 52, "sentinel": [11, 33], "seonc": 25, "seonyong": [23, 24], "sep": 17, "separ": [6, 22, 23, 24, 27, 29, 31, 52, 54, 56, 58, 62, 63, 71, 74, 83, 84, 85, 87], "seq": [25, 44], "seq_len": [24, 25, 74, 75], "sequenc": [3, 8, 9, 14, 16, 17, 19, 23, 25, 27, 28, 29, 30, 31, 33, 34, 51, 52, 53, 65, 68, 70, 73, 77, 79, 80], "sequenceclassifieroutput": 77, "sequenti": [14, 18, 19, 21, 22, 23, 25, 74], "sergei": 1, "seri": [11, 22, 24, 29, 30, 35, 39, 40, 53, 54, 55, 56, 57, 58, 61, 62, 72, 73, 74, 75, 80], "serial": [24, 65, 82, 83], "serp": 30, "serv": [5, 6, 11, 16, 17, 19, 22, 23, 24, 25, 28, 29, 33, 39, 40, 48, 51, 52, 56, 57, 58, 62, 64, 78, 80, 84], "server": [10, 16, 53, 54, 55, 65], "servic": [16, 24, 51, 55, 56, 64, 65, 66, 85], "servicecount": 6, "session": [55, 65], "set": [6, 7, 8, 10, 11, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 34, 35, 37, 38, 39, 42, 43, 48, 51, 52, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 69, 76, 78, 79, 80, 82, 83, 84, 85], "set_adapt": 76, "set_debug_field": 24, "set_devic": [24, 44], "set_epoch": 76, "set_extra_st": 76, "set_input_embed": 76, "set_output_embed": 76, "set_postfix": 82, "set_them": [24, 28], "set_titl": [24, 25, 28, 29, 37, 38, 39, 40, 78, 79], "set_to_non": [70, 71], "set_torch_determinist": [24, 25, 28, 31, 32, 44, 60, 74, 75, 77], "set_train_valid_path": 24, "set_xlabel": [24, 25, 28, 37, 38, 39, 40, 78, 79], "set_xlim": [37, 38, 39, 40], "set_xtick": 24, "set_ylabel": [24, 25, 28, 37, 38, 39, 40, 78, 79], "set_ylim": [24, 37, 38, 39, 40], "set_ytick": 24, "set_zlim": 38, "setattr": 32, "setfit": 77, "setformatt": [75, 77], "setlevel": [71, 75, 77], "setter": [8, 87], "setuo": 79, "setup": [24, 25, 33, 47, 55, 56, 65, 73, 78], "sever": [7, 23, 24, 38, 39, 42, 52, 53, 54, 56, 59, 60, 62, 65], "sgd": [23, 25, 71, 78, 79], "sgdr": [1, 2, 25, 78], "sgemm_128x128x8_nt_vec": 70, "sgemm_128x128x8_tn_vec": 70, "sh": [44, 45, 56], "shadow": [24, 64], "shall": [5, 24, 29, 39, 56, 79, 82], "shap": 64, "shape": [16, 19, 22, 24, 25, 27, 28, 29, 31, 32, 35, 37, 53, 68, 70, 73, 74, 75, 78], "shaplei": 64, "share": [3, 4, 9, 24, 44, 52, 53, 54, 55, 57, 60, 64, 73], "share_memori": 76, "sharedstorag": 45, "sharei": [24, 29], "sharex": [24, 29], "sharp": 79, "sharpen": 24, "sharper": 79, "sharpli": 71, "shatter": 42, "shazeer": [1, 2, 21, 23, 30, 31, 73], "she": [16, 24, 54, 58, 65], "shean": 1, "shen": [1, 30, 31], "sherlock": 54, "shift": [14, 17, 19, 22, 23, 24, 25, 31, 54, 66, 74, 78, 79], "shirish": 1, "shock": 60, "shop": [17, 27, 65], "short": [4, 17, 23, 27, 78], "shortcom": 66, "shorter": [24, 25], "shortest": [39, 54], "shorthand": [16, 42], "shortli": [27, 31, 44, 54, 56], "shot": 51, "should": [3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 35, 42, 44, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 73, 74, 75, 76, 77, 78, 80, 84, 85], "shouldn": 85, "show": [5, 6, 9, 14, 16, 17, 22, 23, 24, 25, 27, 28, 31, 32, 34, 38, 40, 44, 45, 52, 54, 57, 66, 69, 71, 74, 76, 78, 79, 80, 82], "show_attention_heatmap": [24, 25], "show_level": [25, 74], "show_path": [25, 74], "show_special_token": 25, "show_tick": 38, "show_tim": [25, 74], "show_titl": [24, 25], "show_valu": 25, "showcas": [23, 79], "showindex": 73, "shown": [5, 23, 25, 27, 38, 43, 51, 52, 54, 65, 79, 80, 82, 83], "shrink": [19, 24, 57], "shuf": 44, "shuffl": [25, 32, 54, 60, 74, 75, 77, 80, 82, 84], "side": [5, 8, 23, 27, 38, 39, 44, 52, 55, 73, 77], "sidestep": 19, "siek": 4, "sig": 76, "sigma": [22, 24, 27, 31, 68, 70, 79], "sigma_": 24, "sigma_t": [22, 24], "sigma_z": [22, 24], "sigmoid": 79, "sign": [14, 16, 25, 29, 38, 39, 59, 73], "signal": [9, 10, 23, 24, 44, 52, 69], "signatur": [3, 5, 6, 8, 9, 33], "signifi": [10, 14, 17, 22, 23, 24, 25, 28, 29, 37, 38, 39, 54, 56, 73], "signific": [16, 17, 19, 23, 25, 29, 34, 38, 51, 52, 53, 56, 57, 60, 62, 64, 65, 66, 73, 78, 80], "significand": 73, "significantli": [14, 17, 23, 24, 28, 29, 51, 52, 53, 58, 59, 62, 66, 73, 76, 80], "sigopt": 76, "silent": [4, 6], "silhouett": 59, "silu": 32, "silver": [15, 16], "sim": [5, 22, 23, 24, 31, 42, 58, 62, 79], "simiarli": 27, "similar": [3, 6, 8, 9, 14, 17, 19, 22, 23, 24, 25, 26, 28, 29, 31, 35, 39, 40, 42, 52, 54, 55, 56, 57, 58, 59, 64, 65, 73, 75, 78, 80], "similarli": [6, 8, 16, 19, 24, 25, 34, 37, 39, 40, 44, 51, 53, 54, 79], "simpl": [6, 7, 9, 10, 14, 17, 22, 24, 27, 29, 31, 35, 40, 42, 44, 51, 52, 53, 54, 56, 57, 58, 60, 62, 64, 71, 74, 76, 78, 79, 80, 82, 85], "simple_data_load": 80, "simple_leak": 71, "simplelist": 9, "simplequeu": 44, "simpler": [5, 31, 52, 53, 58, 63, 65], "simplest": [16, 17, 52, 57], "simpli": [5, 6, 9, 14, 16, 22, 23, 24, 25, 27, 31, 45, 56, 59, 73, 74, 75, 78, 79, 80, 85], "simplic": [6, 7, 17, 19, 22, 23, 24, 25, 27, 31, 32, 44, 53, 56, 73, 78, 79], "simplif": 58, "simplifi": [4, 14, 16, 21, 22, 23, 24, 25, 31, 38, 43, 48, 52, 56, 57, 58, 65, 79, 80], "simul": [56, 63, 80], "simultan": [23, 24, 35, 46, 59, 80], "sin": [22, 24], "sinc": [4, 5, 7, 8, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 35, 40, 43, 44, 45, 46, 51, 52, 54, 55, 56, 59, 60, 62, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 78, 79, 80, 82, 85], "sine": 24, "sinfo": 45, "singapor": [1, 6, 26, 27, 42], "singl": [13, 14, 16, 19, 22, 23, 24, 25, 26, 27, 28, 29, 31, 35, 37, 39, 40, 42, 43, 44, 52, 53, 54, 56, 58, 59, 60, 62, 64, 65, 74, 75, 76, 78, 79, 80, 82, 85, 87], "single_item_test": 85, "single_item_train": 85, "single_label_classif": [32, 75], "single_word": 75, "singleton": 10, "singular": [21, 23, 31], "sinusoid": [22, 24], "siri": 65, "site": [23, 24, 27, 28, 32, 51, 52, 55, 65, 71, 73, 75, 77, 78], "situat": [10, 14, 16, 17, 25, 35, 40, 65, 66, 78, 79], "six": 19, "sizabl": 3, "size": [3, 13, 14, 16, 17, 19, 22, 23, 25, 27, 28, 31, 32, 35, 38, 39, 40, 42, 51, 52, 53, 55, 58, 60, 62, 63, 66, 68, 70, 71, 74, 75, 76, 77, 79, 80], "size_averag": 74, "sk_contingency_matrix_": 28, "sk_kmean": 28, "sk_y_pr": 28, "skew": [16, 53, 57, 71], "skim": 11, "skimag": 29, "skip": [22, 24, 35, 69, 76], "skip_memory_metr": 76, "skip_special_token": 75, "sklearn": [28, 29, 32, 75, 77], "sla": [16, 64], "sleep": [45, 52], "slice": [8, 9, 22, 24, 25, 28, 75, 85], "slice_items_test": 85, "slice_items_train": 85, "slide": 66, "slight": [14, 22, 23, 78], "slightli": [24, 31, 60, 78], "slim": 56, "slip": 6, "slope": [25, 35, 78], "slot": 76, "slow": [16, 23, 27, 29, 53, 54, 79], "slower": [16, 23, 51, 67], "slowest": 16, "slowli": [16, 27, 45], "slurm": [33, 44, 47, 55], "slurm_job_nodelist": 45, "slurmctld": 45, "slurmqueu": 45, "small": [6, 16, 22, 23, 24, 25, 27, 31, 33, 40, 45, 52, 54, 58, 62, 64, 68, 72, 73, 78, 79, 80], "small_backward_warmup_0_mixed_fals": 68, "small_backward_warmup_0_mixed_tru": 68, "small_backward_warmup_1_mixed_fals": 68, "small_backward_warmup_1_mixed_tru": 68, "small_forward_backward_warmup_0_mixed_fals": 68, "small_forward_backward_warmup_0_mixed_tru": 68, "small_forward_backward_warmup_1_mixed_fals": 68, "small_forward_backward_warmup_1_mixed_tru": 68, "small_forward_warmup_0_mixed_fals": 68, "small_forward_warmup_0_mixed_tru": 68, "small_forward_warmup_1_mixed_fals": 68, "small_forward_warmup_1_mixed_tru": 68, "smaller": [5, 13, 14, 17, 29, 31, 32, 51, 58, 60, 65, 71, 73, 79, 80], "smallest": [6, 13, 16, 25, 29, 73, 78, 79], "smart": 53, "smarter": 27, "smartphon": [17, 51, 52, 65], "smartwatch": 17, "smola": [1, 2, 21, 23, 24, 78, 79], "smooth": [22, 24, 25, 77, 78], "smoother": [23, 24, 39], "smoothli": [3, 56, 78], "smote": 57, "sn": [24, 25, 28, 74], "snapshot": [23, 71], "sne": [52, 57], "snippet": [6, 22, 44, 53, 60, 71, 73, 83], "snowflak": [54, 55], "so": [3, 4, 6, 7, 8, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 35, 37, 39, 40, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 65, 67, 68, 69, 70, 71, 73, 74, 75, 76, 78, 80, 82, 84, 87], "soap": 53, "socg2006": 27, "socher": 1, "social": [52, 53, 54, 55, 57], "socket": [70, 71], "soft": 77, "soft_loss": 77, "soft_prob": 77, "soft_target": 77, "softargmax": 79, "soften": 79, "softer": 77, "softmax": [23, 25, 32, 33, 42, 68, 70, 73, 74, 75, 77], "softmax_larg": [24, 79], "softmax_result": 79, "softmax_sc": 24, "softmax_smal": 79, "softmax_unsc": 24, "softmaxbackward0": [24, 79], "softmaxst": [68, 70], "softwar": [10, 14, 55, 56, 61, 64, 66, 85], "software_engin": 82, "sold": 57, "solda": 54, "sole": [3, 6, 14, 24, 25, 29, 38, 40], "solid": [38, 40, 58], "solidifi": 29, "soloviev": [2, 11], "solut": [6, 13, 14, 17, 25, 27, 39, 48, 51, 52, 53, 55, 56, 65, 66, 78], "solv": [1, 6, 13, 14, 16, 17, 22, 23, 24, 25, 27, 28, 35, 51, 52, 55, 58, 78, 82], "some": [3, 4, 5, 6, 7, 9, 13, 14, 16, 17, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 40, 42, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 66, 68, 69, 70, 74, 75, 76, 77, 78, 82, 83, 84, 85], "some_obj": 9, "somehow": [7, 23, 24, 27], "someon": [24, 54], "someth": [4, 5, 7, 10, 14, 16, 19, 23, 25, 45, 52, 56, 66, 69, 80, 83, 87], "sometim": [3, 4, 23, 27, 28, 40, 42, 45, 46, 52, 53, 57, 58, 65, 66, 73, 76, 79], "somewhat": 23, "somewher": [56, 65, 82], "song": 52, "soon": [1, 24, 65, 85], "sophist": [17, 25, 56, 58, 62], "sort": [8, 13, 14, 24, 25, 44, 54, 55, 75, 76, 79], "sort_bi": [69, 70], "sort_valu": [68, 69], "sortabl": 16, "sorted_indic": 24, "sorted_indices_to_remov": 24, "sorted_logit": 24, "sorted_us": 54, "sota": [58, 62], "sought": 23, "sound": [3, 4, 5, 53, 57], "soup": 55, "sourc": [4, 22, 23, 24, 25, 31, 42, 44, 45, 51, 52, 54, 56, 64, 69, 70, 74, 75, 76], "south": [17, 19, 55], "southeast": 45, "space": [1, 5, 23, 25, 29, 31, 37, 38, 42, 43, 52, 53, 57, 58, 60, 62, 77, 78, 79], "spaghetti": 70, "spam": [51, 52, 65], "span": [16, 23, 24, 25, 35, 39, 43, 52, 62, 78], "spark": [54, 55, 56], "spars": 24, "sparsiti": 39, "spatial": [17, 25, 29, 31, 35, 37], "spawn": [44, 46], "speak": [24, 25], "special": [3, 9, 22, 23, 24, 25, 27, 32, 34, 37, 53, 68, 70, 74, 75, 77], "special_token": 75, "special_tokens_map": 75, "specif": [3, 5, 6, 7, 8, 10, 11, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 32, 34, 35, 37, 38, 39, 40, 42, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 73, 78, 79, 82, 84, 85, 87], "specifi": [3, 6, 7, 10, 16, 19, 22, 25, 26, 27, 28, 32, 44, 45, 51, 52, 54, 55, 56, 60, 62, 73, 76, 82], "spectacularli": 58, "spectral": 27, "spectrogram": 52, "spectrum": 23, "specul": 23, "speech": [2, 21, 23, 24, 51, 52, 53], "speed": [4, 14, 16, 25, 51, 52, 53, 65, 73], "spell": [23, 24, 54], "spend": [16, 52], "spent": [25, 31, 69], "sphere": 27, "spheric": 27, "spike": [23, 24, 71], "split": [13, 14, 17, 22, 23, 24, 27, 40, 57, 62, 63, 74, 76, 80], "split_batch": 76, "split_dataset": 25, "spoken": 52, "spopt": 70, "spot": [6, 7], "spotifi": 65, "spread": [19, 25, 27, 51, 52, 79], "spring2024": [68, 70, 72], "springer": [1, 2, 26, 27, 29, 37, 38, 39, 42, 79], "sprinkl": 82, "sqcup": 27, "sql": [31, 53, 54, 55, 56, 65], "sqlalchemi": 55, "sqrt": [22, 23, 24, 31, 32, 39, 40, 66, 68, 70, 73, 74, 75], "squar": [8, 22, 24, 25, 27, 28, 35, 39, 42, 52, 59, 62, 63, 66, 73, 78, 79, 80], "square_by_exponenti": 69, "square_by_multipl": 69, "squeez": [24, 25, 74, 77, 79], "squeezebackward0": 79, "squeezebackward1": 24, "squeue": 45, "sr": 52, "src": 24, "srun": 45, "ss": [44, 56, 82], "sse": [26, 27, 28], "ssh": 45, "st": [7, 44, 45, 52], "stabalis": 68, "stabil": [22, 25, 33, 58, 71, 79], "stabl": [8, 23, 24, 31, 32, 54, 55, 65, 79], "stable_softmax": 79, "stable_softmax_prob": 79, "stabliz": [25, 78], "stack": [6, 14, 16, 17, 18, 22, 23, 24, 33, 35, 40, 55, 56, 58, 62, 64, 70, 71, 74, 77, 79, 80], "stack_int": 19, "stack_item": 19, "stack_of_str": 6, "stack_str": 19, "stackexchang": 39, "stacklevel": [24, 31, 60], "stacklist": 19, "stackoverflow": 24, "stackrel": [16, 24], "stage": [5, 16, 22, 23, 24, 25, 31, 33, 45, 48, 69, 70, 71, 78, 83, 85], "staging_dir": 56, "staging_lak": 56, "staging_warehous": 56, "stai": [24, 62, 66], "stain": 29, "stakehold": [51, 64], "stale": 65, "stand": [23, 53, 71, 73], "standalon": [17, 19], "standard": [4, 9, 10, 13, 17, 22, 23, 24, 25, 38, 53, 54, 55, 56, 57, 59, 62, 66, 68, 77, 78, 79, 80], "standpoint": 3, "stanford": [23, 24, 68, 70], "start": [14, 16, 17, 19, 24, 25, 27, 28, 29, 31, 32, 35, 37, 38, 39, 44, 46, 51, 52, 53, 54, 56, 60, 65, 66, 67, 68, 69, 71, 73, 74, 76, 78, 79, 80, 83], "start_method": [44, 46], "start_process": 44, "start_record_memory_histori": 71, "start_tim": [53, 67, 83], "starting_token": [24, 25], "starting_tokens_crop": 24, "stat508": 26, "state": [4, 5, 8, 10, 16, 17, 22, 23, 24, 27, 31, 34, 35, 37, 39, 45, 53, 54, 58, 60, 65, 71, 73, 74, 75, 79, 80, 84, 85], "state_dict": [76, 82, 83], "statement": [4, 7, 9, 10, 17, 24, 27, 35, 52, 74], "static": [3, 6, 7, 8, 9, 11, 17, 19, 23, 24, 45, 53, 65, 76, 85], "static_method": 76, "staticmethod": 76, "station": 53, "stationari": 31, "statist": [1, 23, 24, 26, 27, 42, 51, 52, 55, 56, 57, 58, 60, 64, 66, 79], "statquest": 26, "statu": [5, 56, 64], "std": [22, 24, 68, 70, 74, 75, 82, 84], "std1": 66, "std2": 66, "std_dev": [24, 68, 70, 74, 75], "stderr": 45, "stdout": [67, 68, 69, 70, 82], "stealth": [17, 19], "steer": 10, "stein": [1, 13], "stem": [23, 24, 25, 27], "step": [14, 16, 17, 23, 24, 25, 26, 28, 31, 32, 39, 40, 45, 48, 51, 52, 54, 57, 58, 60, 61, 62, 63, 65, 66, 68, 69, 70, 71, 75, 76, 77, 78, 80, 82, 83], "step_index": [25, 83], "step_num": 69, "step_scheduler_on_batch_or_epoch": [25, 74], "stick": [24, 55], "still": [14, 16, 19, 22, 23, 24, 25, 27, 29, 32, 37, 44, 51, 54, 57, 58, 60, 65, 66, 71, 72, 76, 78, 79, 82], "stipul": 16, "stochast": [1, 2, 21, 23, 25, 57, 78], "stock": 53, "stoi": [22, 24], "stone": 40, "stop": [6, 14, 16, 25, 27, 56, 62, 71, 74, 78, 79, 80], "stop_record_memory_histori": 71, "stopiter": 80, "storag": [4, 19, 29, 45, 56, 57, 65, 73], "storagetyp": 45, "store": [14, 16, 19, 24, 27, 28, 29, 31, 44, 53, 54, 56, 57, 62, 64, 65, 71, 73, 80, 82, 83, 84, 87], "store_flo": 76, "store_tru": [44, 46, 71], "storesconfig": [82, 84], "stori": 16, "str": [3, 4, 5, 6, 7, 9, 10, 19, 24, 25, 28, 29, 31, 32, 44, 46, 54, 56, 60, 68, 69, 70, 71, 73, 75, 76, 77, 78, 80, 82, 83, 84, 85], "straight": [27, 39], "straightforward": [8, 16, 17, 25, 27, 38, 52, 53, 80, 85], "strang": 27, "strat": 52, "strateg": 16, "strategi": [3, 14, 16, 19, 23, 28, 31, 33, 51, 57, 62, 64, 86], "stratif": 52, "stratifi": [57, 61, 62], "stratifiedgroupkfold": 62, "stratify_by_column": [32, 75, 77], "stream": [24, 32, 51, 52, 53, 54, 67, 75, 77, 82], "stream_executor": 32, "streamhandl": [67, 68, 69, 70, 75, 77, 82], "streamlin": [3, 23, 25, 56], "street": 39, "strength": [52, 54], "stretch": 38, "strftime": [70, 71], "strict": [4, 23, 54, 65, 82, 83, 84], "stricter": 6, "strictli": [17, 24, 65, 79], "strike": [23, 24, 63], "string": [4, 6, 9, 19, 23, 24, 25, 32, 44, 53, 54, 55, 65, 76, 80, 84], "stringvalu": 6, "strip": [23, 24, 25, 60], "strive": 23, "strncat": 14, "strong": [14, 31, 40], "stronger": 76, "strongli": 6, "structur": [1, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 20, 22, 23, 25, 27, 34, 37, 39, 52, 53, 55, 56, 57, 65, 76, 79, 80, 84, 85], "structure_data": 56, "structured_data": 56, "struggl": [23, 24, 52], "stuck": [24, 25, 27, 78], "student": [33, 53], "student_logit": 77, "student_model": 77, "student_optim": 77, "student_output": 77, "student_schedul": 77, "studi": [23, 34, 35, 38, 42, 52, 56], "stuff": 54, "style": [17, 19, 24, 28, 29, 33, 55, 75], "sub": [13, 22, 23, 24, 25, 27, 52, 55, 56, 70, 84], "subarrai": 17, "subbackward0": 70, "subcategori": 51, "subclass": [3, 4, 5, 7, 8, 9, 24, 25, 76], "subdir": 82, "subdirectori": 56, "subject": [16, 24, 27, 48, 56, 57, 66], "sublay": 24, "submit": [1, 2, 21, 23, 30, 31, 45, 78, 79], "subnet": 45, "subnet_id": 45, "subnetid": 45, "suboptim": 51, "subplot": [24, 25, 28, 29, 37, 38, 39, 40, 78, 79], "subplots_adjust": 24, "subproblem": [13, 14, 17], "subprocess": 60, "subroutin": [3, 14, 69], "subscrib": 51, "subscript": [22, 37, 42, 51], "subsequ": [17, 23, 24, 25, 27, 31, 52, 56, 71, 80], "subset": [5, 14, 16, 17, 22, 23, 24, 25, 27, 31, 44, 53, 57, 62, 65, 66, 79], "subseteq": [4, 24, 37, 42, 79], "subsitut": 6, "subspac": [14, 31, 34, 35], "substanti": [23, 24, 56, 66], "substitut": [3, 4, 8, 13, 22, 24, 35, 40, 73, 79], "subsumpt": [3, 8, 11, 33], "subtl": [17, 71], "subtract": [5, 24, 34, 35, 39, 73, 79], "subtre": 14, "subtyp": [2, 7, 8, 9, 11, 33, 53], "subword": 24, "succe": [31, 80], "succeed": 23, "success": [13, 14, 17, 23, 52, 53, 56, 57, 62, 64], "successfulli": [17, 45, 51, 54, 55, 60], "sudo": 45, "suffer": [24, 58], "suffic": [16, 51, 52, 74], "suffici": [3, 13, 16, 22, 23, 31, 35, 44, 51, 55, 59, 60, 72, 74], "suffix": 71, "sugar": 35, "suggest": [8, 23, 24, 25, 31, 51, 52, 57, 58, 61, 65, 66, 73, 78, 84, 85, 87], "suit": [16, 19, 21, 27, 52, 53, 54], "suitabl": [14, 16, 24, 25, 31, 52, 53, 54, 55, 56, 57, 61, 62, 64, 65], "sum": [13, 14, 16, 17, 19, 23, 24, 25, 27, 28, 32, 34, 37, 38, 39, 40, 42, 44, 55, 56, 59, 68, 69, 70, 73, 74, 75, 77, 79, 80], "sum_": [16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 39, 40, 42, 59, 73, 79], "sum_i": 77, "sum_j": 77, "summand": 23, "summar": [3, 14, 22, 23, 31, 52, 55, 65, 73], "summari": [16, 23, 24, 25, 29, 31, 35, 53, 54, 55, 57, 85], "summary_activ": 24, "summary_first_dropout": 24, "summary_proj_to_label": 24, "summary_typ": 24, "summary_use_proj": 24, "summat": [22, 23, 25, 40], "sunil": 30, "super": [7, 10, 24, 32, 52, 57, 68, 70, 73, 74, 75, 76], "super_large_logit": 79, "superclass": [3, 5, 8], "superfici": 7, "superscript": [22, 27, 42], "superset": 5, "supertyp": [3, 4, 5, 7, 8], "supervis": [1, 9, 24, 27, 52, 57, 58, 77], "supplementari": 23, "suppli": [6, 52], "support": [3, 7, 19, 25, 28, 32, 40, 44, 51, 53, 54, 55, 58, 65, 76, 78, 80, 82], "supportsindex": 8, "supportsrichcomparison": 8, "supportsrichcomparisont": 8, "suppos": [8, 10, 14, 23, 25, 29, 31, 38, 51, 52, 59, 62, 66, 80], "suppress": 79, "sure": [4, 8, 16, 17, 24, 25, 29, 31, 32, 44, 45, 53, 54, 60, 62, 66, 69, 73, 79, 82, 83], "surject": 27, "surpass": 23, "surpris": [4, 24, 25, 27, 59, 69], "surround": 52, "survei": [23, 53, 54], "surveil": 57, "surviv": 59, "suscept": 24, "sushi": 19, "suspect": 71, "suspici": 54, "sutskev": [1, 2, 21, 23], "svd": 31, "svg": [14, 37, 38], "svg_imag": 14, "svm": [52, 58], "swap": [6, 22, 24, 25, 40, 75, 78, 87], "sweep": 82, "sweeper": 82, "swipe": 53, "switch": [24, 60, 76, 85], "sy": [6, 8, 25, 28, 29, 67, 68, 69, 70, 71, 80, 82], "symbol": [8, 22, 23, 25, 27, 29], "symmetr": 39, "symmetri": [5, 31, 39], "symptom": [52, 62], "sync": [44, 82], "synchron": [24, 25, 33, 44, 46, 68, 69, 70, 72, 83], "syntact": 24, "syntax": [6, 7, 9], "syntaxerror": [32, 76], "synthes": 24, "synthesi": 21, "synthet": 51, "system": [2, 3, 4, 5, 6, 7, 11, 14, 16, 19, 21, 23, 29, 30, 31, 33, 34, 36, 37, 43, 44, 46, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 72, 73, 80, 84, 85], "systemat": [5, 52, 60, 64], "t": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 35, 37, 40, 42, 43, 44, 45, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87], "t2": 45, "t4": 73, "t4_16gb": 73, "t_": [25, 78], "t_co": 80, "t_max": [25, 74, 75, 78], "t_n": [22, 23, 31], "tab": [14, 44, 45], "tab_titl": 14, "tabbi": [7, 23], "tabl": [13, 23, 24, 29, 39, 45, 51, 52, 54, 55, 56, 57, 59, 65, 69, 70, 73, 77], "table_nam": 56, "tablefmt": [29, 73], "tabul": [29, 73], "tabular": 53, "tackl": [8, 16, 52], "tag": [45, 52, 53, 54, 60, 64, 68, 70], "tail": [17, 35, 37, 38], "tailor": [6, 17, 22, 23, 52, 85], "take": [3, 4, 5, 6, 7, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 34, 35, 38, 39, 40, 42, 44, 45, 51, 52, 53, 56, 58, 59, 62, 64, 65, 66, 67, 69, 70, 73, 76, 78, 79, 80, 82, 85, 87], "takeawai": 37, "taken": [4, 13, 14, 16, 17, 39, 42, 52, 56, 67, 73], "talk": [6, 8, 16, 22, 27, 35, 56, 57, 58, 79, 82], "talwalkar": 42, "tan": [26, 27], "tangibl": 40, "tanh": [22, 24, 25, 68, 70, 74, 75], "target": [9, 14, 17, 23, 27, 31, 32, 35, 44, 48, 52, 54, 55, 56, 57, 58, 62, 63, 64, 66, 68, 70, 74, 75, 77, 78], "target_batch": 25, "target_fn": 46, "target_length": 77, "target_mask": [24, 25], "target_masks_shap": [24, 25], "target_modul": 32, "target_padding_mask": [24, 25, 74], "targets_flatten": 25, "targets_pad": 25, "task": [5, 14, 16, 17, 19, 21, 22, 24, 25, 32, 35, 39, 40, 45, 51, 54, 55, 56, 57, 58, 59, 62, 64, 65, 73, 74, 75, 76, 77, 79, 82, 84, 85], "task_specific_param": 24, "tau": [14, 17, 22, 23], "tau_w": [25, 78], "taught": 6, "taxicab": 39, "td": [24, 52], "teacher": [25, 33], "teacher_logit": 77, "teacher_model": 77, "teacher_optim": 77, "teacher_output": 77, "teacher_schedul": 77, "team": [45, 48, 52, 57, 60, 71, 72, 83], "tear": 59, "tech": [2, 11, 19, 20, 53, 56], "techgear": 17, "technic": [10, 25, 31, 51, 73], "techniqu": [10, 14, 16, 21, 22, 23, 24, 25, 29, 31, 39, 44, 51, 52, 54, 56, 57, 58, 62, 63, 66, 78], "technologi": [24, 53, 56], "telecom": 52, "tell": [4, 6, 7, 9, 16, 25, 27, 28, 31, 40, 54, 56, 74, 78, 82], "temp": 79, "temperatur": [24, 25, 52, 53, 65, 74, 77], "tempfil": 71, "templat": [6, 14, 16, 45, 56, 82], "tempor": [52, 57], "temporari": [14, 17, 55], "temporarili": [55, 71], "ten": [23, 24], "tend": [23, 24, 27, 29, 52, 65, 82], "tendenc": [55, 63], "tensor": [22, 24, 25, 32, 43, 44, 53, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79], "tensor_await": 71, "tensor_s": [67, 71], "tensorboard": [60, 69], "tensorboard_trace_handl": 69, "tensorflow": [28, 70], "tenth": 25, "tepoch": 82, "terabyt": [56, 57], "teraflop": [52, 73], "term": [4, 6, 8, 13, 14, 16, 17, 22, 23, 24, 25, 27, 31, 35, 37, 38, 39, 40, 42, 43, 51, 52, 53, 54, 55, 56, 57, 58, 65, 69, 73, 77, 78, 79], "termin": [14, 16, 17, 80], "terminologi": [25, 43], "test": [22, 23, 24, 28, 32, 42, 48, 49, 51, 55, 56, 57, 58, 59, 60, 62, 63, 66, 67, 75, 77, 79, 84, 85], "test_binary_search": 14, "test_dataset": 25, "test_eval_accuraci": 32, "test_eval_brier_scor": 32, "test_eval_confusion_matrix": 32, "test_eval_f1_score_macro": 32, "test_eval_f1_score_micro": 32, "test_eval_log_loss": 32, "test_eval_pr_auc": 32, "test_eval_pr_auc_class_0": 32, "test_eval_pr_auc_class_1": 32, "test_eval_pr_auc_class_2": 32, "test_eval_precision_macro": 32, "test_eval_precision_micro": 32, "test_eval_recall_macro": 32, "test_eval_recall_micro": 32, "test_eval_roc_auc": 32, "test_eval_roc_auc_class_0": 32, "test_eval_roc_auc_class_1": 32, "test_eval_roc_auc_class_2": 32, "test_load": [25, 74], "test_loss": 32, "test_minimum_spe": 16, "test_one_epoch": 25, "test_runtim": 32, "test_samples_per_second": 32, "test_siz": [25, 28, 32, 75, 77], "test_steps_per_second": 32, "test_unordered_linear_search_iterative_for_loop": 17, "test_unordered_linear_search_iterative_while_loop": 17, "test_unordered_sequential_search_recurs": 17, "testframework": [14, 16, 17], "text": [3, 8, 13, 14, 16, 17, 21, 22, 23, 24, 25, 27, 29, 31, 37, 39, 40, 42, 45, 52, 54, 57, 65, 66, 73, 75, 77, 78, 79, 80], "text_gen": 80, "text_gen_comprehens": 80, "text_summar": 52, "textbf": [42, 58], "textbook": [13, 27, 35, 36, 41], "textrm": 79, "textsf": 40, "textual": [23, 52, 53], "tf": [14, 16, 17, 28, 52, 57, 73], "tf32": 76, "tgt": 24, "tgt_mask": 24, "th": [16, 17, 19, 22, 23, 24, 25, 27, 35, 37, 38, 42, 79], "thai": 55, "than": [3, 5, 6, 7, 8, 9, 11, 13, 14, 16, 17, 22, 23, 24, 25, 27, 29, 31, 32, 35, 39, 42, 43, 46, 48, 51, 52, 53, 54, 56, 57, 58, 59, 62, 64, 65, 66, 67, 71, 73, 76, 77, 78, 79, 80, 82, 84], "thank": 56, "thee": 3, "thei": [3, 4, 5, 6, 7, 8, 9, 13, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 34, 35, 37, 39, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 59, 62, 63, 65, 66, 71, 72, 73, 74, 76, 78, 79, 80, 82, 83, 84, 85], "them": [1, 6, 7, 8, 10, 14, 16, 19, 21, 22, 23, 24, 25, 27, 29, 31, 34, 35, 38, 39, 40, 42, 44, 45, 52, 53, 54, 56, 57, 59, 60, 63, 65, 68, 70, 71, 73, 76, 80, 84, 85], "theme": 28, "themselv": [3, 19, 24, 57], "theorem": [12, 16, 33, 79], "theoret": [5, 11, 23, 24, 25, 64, 78, 79], "theori": [2, 3, 4, 5, 6, 8, 16, 17, 24, 27, 30, 33, 42, 52, 62, 79], "theoriz": 6, "therebi": [6, 14, 16, 25, 29, 52, 65, 76, 79, 84], "therefor": [3, 4, 5, 9, 10, 13, 14, 16, 17, 22, 23, 24, 25, 27, 29, 31, 35, 39, 51, 52, 57, 58, 59, 62, 66, 69, 73, 78, 79, 80], "thereof": 52, "thesi": 53, "theta": [13, 14, 16, 22, 23, 24, 25, 31, 40, 42, 73, 78], "theta_": [31, 35, 77, 79], "theta_t": 77, "thi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87], "thick": [17, 19], "thing": [3, 6, 8, 24, 25, 27, 29, 31, 35, 44, 45, 51, 52, 56, 60, 62, 65, 71, 75, 80, 82, 85], "think": [3, 4, 8, 9, 22, 23, 24, 25, 27, 29, 31, 37, 40, 44, 45, 46, 52, 65, 74, 75, 79, 82, 85], "third": [13, 14, 19, 22, 24, 25, 29, 39, 53, 55, 69, 74], "thoma": 1, "thorough": 52, "thoroughli": [64, 66], "those": [5, 8, 9, 14, 16, 22, 24, 25, 27, 28, 35, 42, 51, 52, 53, 54, 56, 58, 59, 60, 68, 73, 76, 80, 82, 84], "though": [3, 4, 6, 8, 14, 22, 23, 24, 25, 27, 31, 35, 37, 38, 56, 57, 59, 65, 66, 71, 73, 74, 78, 79], "thought": [3, 6, 10, 16, 23, 24, 25, 34, 79], "thousand": [23, 24, 65], "thread": [31, 83], "threaten": 51, "three": [5, 13, 14, 16, 17, 22, 23, 24, 31, 35, 37, 38, 44, 52, 54, 55, 58, 63], "threshold": [16, 24, 39, 61, 64, 66], "through": [3, 4, 5, 6, 8, 11, 14, 16, 17, 19, 21, 23, 24, 25, 28, 29, 35, 40, 43, 51, 52, 53, 54, 55, 56, 57, 60, 63, 65, 66, 73, 78, 79, 80, 82, 84, 87], "throughout": [14, 17, 22, 23, 24, 56, 57, 65, 82, 84], "throughput": [16, 55, 64, 66, 73], "throughputmod": 45, "throw": [4, 9, 23, 25], "thrown": 80, "thu": [4, 5, 6, 7, 13, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 35, 38, 39, 51, 52, 54, 59, 79, 80, 82, 84, 85], "ti": [23, 24, 51, 73, 85], "tibshirani": [26, 27], "tick_param": 24, "tidi": 27, "tie_weight": 76, "tight": [13, 16, 40], "tight_layout": [25, 28, 40, 78, 79], "tighten": 16, "tightli": [42, 85], "tiktok": [51, 57], "tiktoken": [23, 24, 80], "tikzpictur": [17, 19], "tild": 79, "till": [22, 25, 29], "tilt": 35, "tim": 1, "time": [4, 6, 9, 10, 11, 13, 22, 23, 24, 25, 26, 28, 29, 31, 33, 34, 35, 37, 38, 39, 40, 42, 43, 46, 51, 52, 53, 54, 55, 56, 59, 60, 62, 63, 64, 66, 68, 69, 72, 73, 74, 75, 76, 78, 79, 82, 83, 84], "time_format_str": [70, 71], "time_needed_over_all_tokens_in_second": 73, "time_sp": 69, "time_taken": [67, 83], "time_taken_per_it": 73, "timeit": [33, 67, 69, 72], "timelimit": 45, "timelin": [70, 71], "timeout": 24, "timeouterror": 10, "timer": [53, 67], "timestamp": [54, 56, 65, 70, 71], "timestep": 25, "tini": 71, "tinyshakespear": 24, "tip": [16, 30, 55, 62, 76], "tissu": 29, "titl": [4, 23, 25, 28, 35, 54, 74, 78, 79], "tmp": 76, "tmp_trainer": 76, "tn": [51, 59], "to_bettertransform": 76, "to_contain": 82, "to_empti": 76, "to_find": 6, "to_numpi": 53, "to_object": 82, "to_panda": 75, "to_yaml": 82, "tobyt": 29, "todai": 23, "todo": [24, 25, 28, 75, 76], "tofil": 24, "togeth": [6, 7, 13, 14, 16, 22, 23, 25, 27, 29, 31, 39, 40, 42, 43, 53, 54, 59, 65, 68, 70, 79, 82], "toggl": 71, "toi": [3, 28, 43, 79], "tok_emb": [24, 25, 75], "token": [31, 32, 33, 52, 55, 73, 74, 76, 77, 79, 83], "token_embed": [24, 68, 70], "token_id": 24, "token_position_pdrop": [68, 70], "token_to_index": 25, "tokenembed": 24, "tokenis": 24, "tokenization_utils_bas": [75, 76, 77], "tokenized_train_dataset": [32, 75], "tokenized_valid_dataset": [32, 75], "tokenizedbatch": [32, 75, 77], "tokenizer_kwarg": [75, 77], "tokens_per_it": 25, "tol": 28, "told": [25, 79], "toler": [28, 51], "tolist": [25, 32, 68, 75], "tolkien": 54, "tomato": 55, "tomorrow": 59, "too": [6, 14, 16, 24, 25, 31, 38, 43, 52, 53, 57, 58, 60, 62, 66, 69, 74, 76, 78, 83, 84], "took": [14, 53, 67, 68, 70], "tool": [17, 33, 39, 48, 51, 53, 56, 58, 60, 62, 64, 66, 67, 71, 72], "toolkit": [17, 39], "top": [13, 14, 19, 22, 23, 24, 25, 27, 37, 38, 39, 40, 42, 52, 58, 69, 73, 79], "top_item": 19, "top_k": [24, 25, 74], "top_k_valu": 24, "top_p": [24, 25, 74], "top_p_logit": 24, "topic": [35, 52, 56, 58], "topk": 24, "topmost": [19, 76], "torch": [22, 24, 25, 28, 31, 32, 44, 46, 60, 67, 68, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83], "torch_compil": 76, "torch_compile_backend": 76, "torch_compile_mod": 76, "torch_jit_model_ev": 76, "torch_util": [68, 75, 77], "torchdynamo": 76, "torchinfo": [24, 80], "torchmetr": [59, 80], "torchrun": [44, 45], "torchtext": 80, "torchtun": [32, 70, 72], "torchvis": [71, 80, 82], "toronto": [23, 24], "total": [13, 22, 24, 25, 27, 28, 29, 31, 32, 35, 43, 44, 51, 55, 59, 68, 69, 70, 78, 79, 80], "total_batch_loss": 25, "total_bit": 29, "total_correct": 74, "total_flo": [32, 75], "total_flops_need": 73, "total_hour": 16, "total_loss": [25, 75, 77], "total_paramet": [24, 32], "total_predict": 77, "total_sampl": 74, "total_tim": 68, "total_tokens_in_corpu": 73, "total_trainable_paramet": [24, 25, 31, 32, 73, 75, 77], "total_training_time_dai": 73, "total_training_time_second": 73, "totensor": 82, "tottim": 80, "touch": [14, 17, 35, 72, 79], "toward": [16, 17, 22, 23, 25, 27, 40, 52, 62, 66, 78, 79], "toxic": 65, "tp": [51, 59], "tpr": [32, 75], "tpu": 64, "tpu_metrics_debug": 76, "tpu_num_cor": 76, "tqdm": [25, 68, 71, 74, 75, 77, 82], "trace": [6, 11, 70, 71], "trace_handl": [69, 70, 71], "tracing_garbage_collect": 71, "track": [6, 19, 43, 51, 54, 55, 56, 57, 62, 64, 65, 66], "tractabl": [16, 22, 23, 31], "trade": [51, 52, 53, 54, 58], "tradeoff": [42, 62, 63], "tradit": [17, 21, 22, 23, 24, 25, 52, 54, 55, 61, 65, 66, 74, 85], "tradition": [22, 23, 25, 31, 44, 66], "traffic": [57, 64], "trailer": 51, "train": [1, 2, 9, 27, 28, 31, 33, 39, 42, 43, 44, 45, 48, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 69, 71, 72, 73, 76, 77, 80, 82, 83, 84, 85, 87], "train_accuraci": [75, 77], "train_batch": 24, "train_batch_index": [25, 83], "train_data": 24, "train_data_dtyp": 24, "train_data_shap": 24, "train_dataload": [75, 77], "train_dataset": [25, 32, 75, 76, 77], "train_df": 75, "train_gpt_": 45, "train_id": 24, "train_load": [25, 74], "train_loss": [32, 75, 77], "train_model": [75, 77], "train_one_epoch": [75, 77], "train_path": 24, "train_runtim": [32, 75], "train_sampl": 74, "train_samples_per_second": [32, 75], "train_set_s": 25, "train_siz": 25, "train_steps_per_second": [32, 75], "train_student_model": 77, "train_student_one_epoch": 77, "train_test_split": [28, 32, 75, 77], "train_valid_split": [32, 75, 77], "trainabl": [24, 25, 31, 32], "trainconfig": [82, 84], "trained_model": 25, "trainer": [32, 44, 53, 73, 74, 75, 76, 77, 84, 87], "trainer_all_memb": 76, "trainer_callback": 76, "trainer_config": [25, 74], "trainer_util": [32, 75, 76, 77], "trainercallback": 76, "trainerconfig": [25, 74], "trainerev": [25, 74], "training_arg": [32, 75, 76], "training_dai": 73, "training_loss": [32, 75], "training_step": 76, "trainingargu": [32, 75, 76, 77], "trainingstrategi": 87, "trainoutput": [32, 75], "transact": [52, 53, 55, 65], "transcend": 23, "transfer": [24, 54, 55], "transform": [1, 3, 16, 22, 25, 31, 32, 33, 34, 38, 40, 51, 52, 53, 54, 57, 58, 64, 68, 70, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85], "transformconfig": [82, 84], "transformers_vers": 24, "transformfunc": 85, "transit": [5, 16, 19, 23, 25, 39, 56, 58, 65, 78, 79], "translat": [1, 6, 17, 23, 24, 33, 35, 38, 51, 52, 54], "translated_logit": 79, "translated_prob": 79, "transpar": 52, "transpos": [23, 24, 31, 53, 68, 70, 73, 74], "transpose_qkv": 24, "transposit": [22, 24, 37, 53], "travel": [24, 39], "travers": [13, 14, 16, 17, 24, 53, 54], "traverse_dataframe_by_column": 53, "traverse_dataframe_by_row": 53, "traverse_numpy_by_column": 53, "traverse_numpy_by_row": 53, "treat": [3, 4, 5, 6, 8, 16, 17, 19, 22, 23, 24, 25, 26, 27, 29, 31, 39, 40, 52, 53, 54, 57, 62, 73, 74, 79], "treatment": [35, 42, 51, 57, 59, 79], "tree": [13, 14, 52, 57, 58, 62, 63, 82, 87], "trend": [48, 51, 53, 55, 66], "trepid": 16, "trevor": [26, 27], "tri": [9, 25, 27, 78], "trial": [62, 76, 79], "triangl": [25, 39], "triangular": [22, 24, 25, 74, 75], "trick": [24, 62, 80], "tricki": [25, 67], "trigger": [10, 52, 54, 55, 62, 65, 66, 87], "tril": [24, 74, 75], "tril_mask": 24, "trillion": 73, "tripl": 73, "triplet": [34, 52, 79], "triu": [25, 68, 70], "trivial": [14, 16, 17, 24, 27, 52, 55], "troubl": 54, "truck": 57, "true": [3, 4, 5, 6, 8, 9, 14, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 32, 35, 38, 42, 44, 45, 46, 51, 53, 54, 56, 58, 59, 60, 63, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84], "truli": 80, "truncat": [4, 32, 75, 77], "truncation_sid": 75, "trust": [28, 51], "trust_remote_cod": [32, 75, 77], "trut": 25, "truth": [17, 24, 25, 27, 64, 66, 74], "try": [3, 4, 6, 8, 9, 16, 19, 24, 25, 28, 42, 52, 54, 58, 62, 66, 68, 71, 76, 80], "tsv": [53, 55], "tu": 23, "tuition": 35, "tumor": 52, "tune": [24, 25, 30, 32, 33, 48, 51, 52, 61, 63, 64, 76, 78, 84], "tupl": [6, 7, 17, 24, 25, 27, 28, 29, 32, 35, 37, 38, 44, 54, 67, 68, 70, 74, 75, 76, 77, 79], "turk": 53, "turn": [4, 16, 17, 27, 52, 53, 69, 76], "tutor": [14, 17], "tutori": [1, 14, 23, 24, 30, 32, 44, 47, 60, 70, 72, 77], "tweak": [52, 60, 76], "tweepi": 55, "twice": [24, 58], "twitter": [48, 51, 53, 55], "two": [3, 5, 6, 7, 8, 9, 10, 14, 16, 17, 19, 21, 22, 23, 24, 27, 28, 29, 31, 33, 34, 35, 37, 38, 39, 43, 44, 51, 52, 53, 54, 55, 56, 59, 63, 66, 69, 73, 76, 77, 78, 79, 82, 83, 84, 85], "txt": [24, 25, 44, 53, 55, 56, 60, 70, 80], "type": [2, 5, 9, 13, 14, 16, 20, 24, 25, 28, 29, 32, 33, 35, 38, 43, 44, 45, 46, 51, 54, 56, 58, 59, 60, 62, 65, 67, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 87], "type1": 7, "type2": 7, "type_check": 6, "type_hint": 76, "type_hint_str": 76, "type_hint_to_str": 76, "typealia": 24, "typeddict": [32, 75, 77], "typeerror": [9, 85], "typescript": 11, "typevar": [3, 6, 7, 8, 9, 17, 19, 28, 80], "typic": [3, 7, 8, 9, 10, 16, 17, 19, 22, 24, 25, 27, 29, 31, 35, 37, 39, 42, 43, 45, 51, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 65, 70, 74, 77, 78, 79, 82], "typing_extens": [24, 82, 84], "u": [5, 6, 7, 8, 9, 13, 16, 19, 23, 24, 25, 27, 28, 29, 31, 32, 35, 37, 38, 39, 40, 44, 45, 53, 54, 56, 58, 62, 63, 66, 72, 74, 75, 77, 78, 79, 80], "u_1": [38, 40], "u_1v_1": 40, "u_1v_2": 40, "u_1v_n": 40, "u_2": [38, 40], "u_2v_1": 40, "u_2v_2": 40, "u_2v_n": 40, "u_3": 40, "u_4": 40, "u_d": 38, "u_i": 40, "u_m": 40, "u_mv_1": 40, "u_mv_2": 40, "u_mv_n": 40, "uat": 56, "uber": 54, "ubiquit": [14, 19], "ubuntu": 45, "ubuntu2004": 45, "uci": 53, "ugli": 85, "ui": [75, 77], "uint16": 24, "uint32": 31, "uint8": 29, "uk": 54, "ultim": [8, 16, 23, 52, 60, 65, 73, 79], "uml": 85, "unabl": [27, 28, 32], "unalt": 56, "unassign": 10, "unavail": 71, "unbalanc": 28, "unbatch": 25, "unbias": [22, 24, 63], "unbound": [19, 79], "unchang": [22, 35, 37, 38, 43, 79], "uncom": 25, "uncommon": [6, 52, 59], "uncov": 57, "undefin": 4, "under": [3, 5, 14, 16, 17, 22, 24, 25, 31, 33, 40, 42, 52, 56, 57, 59, 64, 68, 70, 73, 76, 80, 82], "underbrac": [22, 31, 78, 79], "underdetermin": 35, "underfit": [31, 63], "underflow": 79, "undergo": [22, 56], "underli": [16, 23, 24, 27, 29, 31, 34, 42, 44, 46, 54, 56, 58, 62, 66, 75, 79, 84], "underperform": 23, "underpin": [14, 17, 19], "underscor": [23, 40], "underset": [22, 23, 24, 27, 31, 42], "underst": 23, "understand": [1, 2, 3, 4, 5, 6, 8, 11, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 29, 31, 34, 35, 37, 38, 39, 40, 42, 51, 53, 54, 55, 56, 57, 62, 63, 64, 65, 66, 70, 72, 73, 74, 75, 76, 78, 79, 80], "understood": [16, 17, 25, 31, 44, 55, 65, 78, 80, 83], "underutil": 52, "undesir": 7, "undo": 24, "unembed": [22, 24], "unexpect": [4, 48], "unfilt": 55, "unfold": 17, "unhandl": 76, "unidirect": [21, 23], "unifi": [13, 23, 53, 54, 55, 56], "uniform": [22, 25, 32, 79], "uniformli": [17, 27, 79], "unintend": [3, 66], "unintention": 3, "union": [9, 14, 19, 23, 24, 25, 27, 28, 32, 54, 76, 83, 85], "union_class_and_instance_attribut": 76, "union_param": 25, "uniqu": [10, 14, 21, 22, 23, 24, 27, 28, 39, 40, 43, 51, 52, 53, 54, 57, 60, 65, 80, 82], "unique_id": [6, 82, 84], "unit": [4, 5, 6, 9, 16, 23, 25, 28, 29, 31, 35, 37, 38, 43, 51, 53, 54, 56, 61, 64, 73, 79, 82], "univers": [1, 2, 5, 6, 16, 17, 21, 23, 24, 34, 35, 39, 45, 78, 79], "unix": 73, "unk": [22, 25], "unk_token": 75, "unknowingli": 4, "unknown": [21, 22, 23, 31, 32, 35, 42, 54, 58, 71, 79], "unlabel": [23, 52], "unless": [4, 8, 14, 22, 25, 29, 37, 40, 75, 76, 78], "unlik": [6, 7, 16, 17, 24, 25, 38, 40, 54, 74, 80], "unload": [31, 53], "unnecessari": [8, 59, 77], "unnorm": [22, 25, 77], "unnot": 4, "unord": 54, "unordered_linear_search_it": 17, "unordered_linear_search_iterative_for_loop": 17, "unordered_linear_search_iterative_while_loop": 17, "unordered_linear_search_recurs": 17, "unordered_linear_search_tail_recurs": 17, "unordered_list": 17, "unpack": 28, "unpredict": 65, "unprocess": [55, 56], "unproduct": 16, "unqualifi": 80, "unsaf": [3, 4], "unsafe_func": 9, "unsafeviewbackward0": 70, "unscal": 24, "unscaled_dot_product": 24, "unscaled_vari": 24, "unsearch": 17, "unseen": [23, 24, 42, 62, 63], "unsort": [14, 17], "unspecifi": 6, "unsqueez": [24, 25, 68, 70, 74, 75, 79], "unstabl": [24, 32], "unstable_softmax": 79, "unstructur": [52, 53, 55, 57], "unsuccess": 14, "unsupervis": [1, 2, 9, 21, 22, 27, 31, 52, 56, 77], "unsupport": [6, 7, 9, 28, 68, 70], "unsur": 69, "until": [4, 10, 14, 16, 17, 24, 25, 27, 28, 44, 46, 62, 67, 78, 80], "untyp": [24, 44, 46, 82], "unus": 28, "unusu": [57, 65], "unwant": [3, 52, 55], "unwind": 14, "up": [6, 7, 9, 14, 16, 22, 23, 24, 25, 27, 28, 29, 31, 35, 38, 52, 53, 55, 56, 59, 62, 64, 66, 68, 69, 70, 71, 73, 78, 79, 80, 82], "up008": [10, 24], "up_proj": 32, "updat": [14, 16, 17, 19, 24, 25, 27, 28, 39, 45, 51, 53, 55, 56, 57, 60, 64, 65, 66, 68, 70, 71, 73, 76, 78, 83, 84], "updated_at": 56, "updated_centroid": 28, "upfront": 16, "upgrad": [45, 56], "upheld": 57, "upload": [25, 52, 57, 65, 83], "upon": [6, 8, 9, 16, 17, 22, 23, 57, 64, 79, 80], "upper": [13, 14, 16, 17, 22, 23, 24, 25, 40, 78], "urgent": 65, "url": [1, 24, 25, 29, 53], "urllib": 29, "urlopen": 29, "us": [1, 3, 4, 5, 7, 8, 9, 11, 13, 14, 16, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 42, 43, 44, 46, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 77, 78, 79, 82, 83, 84, 85], "usa": [26, 27, 54], "usabl": [55, 56, 58], "usaco": [15, 16], "usag": [6, 19, 24, 31, 42, 52, 55, 56, 58, 60, 71, 73, 80, 82, 83], "use_amp": [25, 74], "use_cach": 24, "use_cpu": 76, "use_deterministic_algorithm": [24, 31, 60], "use_devic": 69, "use_ipex": 76, "use_legacy_prediction_loop": 76, "use_mps_devic": 76, "use_svg_displai": [28, 29], "useless": [25, 51], "usepackag": [17, 19], "user": [6, 10, 14, 17, 19, 29, 31, 32, 45, 51, 52, 54, 55, 56, 57, 58, 62, 64, 65, 66, 69, 72, 82], "user_id": 6, "user_info": 6, "userid": 6, "userlist": 8, "usernam": [6, 45], "userwarn": [24, 31, 60, 71, 78], "usetikzlibrari": [17, 19], "usr": [28, 44, 45], "usual": [3, 5, 6, 9, 13, 14, 17, 22, 23, 24, 25, 27, 31, 42, 44, 45, 51, 52, 54, 55, 56, 57, 58, 61, 62, 63, 65, 73, 77, 78, 79, 80, 82, 83], "uszkoreit": [1, 2, 21, 23, 30, 31], "utf": [23, 24, 60, 80], "util": [3, 4, 6, 17, 19, 22, 23, 25, 27, 28, 29, 32, 35, 39, 44, 51, 52, 53, 54, 55, 56, 62, 64, 65, 66, 68, 70, 71, 74, 75, 76, 77, 80, 82], "uva": [1, 23, 24], "uvadlc": 1, "v": [5, 6, 19, 22, 23, 24, 25, 27, 28, 31, 32, 37, 38, 39, 40, 68, 70, 73], "v0": 24, "v1": [1, 2, 21, 23, 37, 78, 79], "v100": 73, "v100_16gb": 73, "v100_32gb": 73, "v2": [2, 22, 37, 77, 79], "v3": [2, 21, 23, 37, 77, 80], "v4": [1, 2, 21, 23, 32, 75, 77, 78], "v9": [2, 21, 23], "v_": 37, "v_1": [5, 37, 38, 39, 40], "v_2": [5, 37, 38, 39, 40], "v_3": 40, "v_d": [37, 38, 39], "v_j": [24, 40], "v_n": 40, "v_proj": 32, "va": [2, 11, 79], "vacat": 51, "vacuou": 17, "vagu": [44, 52], "vaibhav": 9, "val": 24, "val_accuraci": [75, 77], "val_correct_predict": 75, "val_loss": [75, 77], "valid": [3, 4, 5, 6, 10, 14, 16, 19, 22, 23, 24, 32, 33, 35, 42, 44, 48, 52, 53, 54, 55, 57, 58, 59, 63, 66, 75, 77, 79, 82, 84], "valid_accuraci": 74, "valid_data": 24, "valid_dataload": [75, 77], "valid_dataset": [25, 32, 75, 77], "valid_df": 75, "valid_id": 24, "valid_load": [25, 74], "valid_metr": 32, "valid_one_epoch": 77, "valid_path": 24, "valid_s": 25, "valid_sampl": 74, "valid_this_epoch_average_loss": [25, 74], "validate_global_pool": [82, 84], "validate_one_epoch": 75, "valu": [3, 4, 6, 8, 9, 10, 13, 14, 16, 19, 25, 27, 28, 29, 31, 35, 39, 40, 42, 45, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 64, 65, 66, 68, 70, 73, 74, 75, 76, 78, 79, 80, 82, 84], "valuabl": [23, 24, 51, 55, 59, 65], "value_dp": 25, "value_selecting_reduction_backward": 70, "valueerror": [6, 25, 28, 31, 68, 70, 76, 80, 82, 84, 87], "van": [8, 11], "vanilla": 77, "vanish": [23, 24, 31, 60, 62], "vapnik": 42, "var": [24, 31, 45, 56, 60, 69], "vari": [14, 19, 24, 25, 35, 37, 63, 65, 78], "variabl": [4, 5, 8, 9, 11, 13, 14, 16, 19, 23, 24, 25, 27, 28, 29, 33, 35, 42, 44, 45, 52, 56, 57, 58, 59, 60, 65, 66, 68, 75, 77, 78, 79, 80, 84], "variable_name_or_nam": 68, "varianc": [1, 2, 21, 22, 23, 25, 27, 31, 42, 62, 67, 73, 78], "variant": [27, 55, 62, 74, 77, 79], "variat": [17, 25, 57, 58, 59, 65, 66, 80], "varieti": [17, 52, 53], "variou": [6, 9, 17, 19, 22, 23, 24, 31, 34, 35, 38, 39, 40, 42, 43, 48, 51, 52, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 73, 84], "vassilvitskii": 27, "vast": [23, 51, 52, 56, 57], "vastli": 52, "vaswani": [1, 2, 21, 22, 23, 24, 30, 31], "vc": [42, 62], "vcpu": 45, "vcpulimitexceed": 45, "vdot": [14, 22, 24, 35, 37, 38, 39, 40, 73, 79], "ve": [6, 16, 25, 40, 59, 62, 66], "vec": 37, "vector": [6, 22, 23, 25, 27, 28, 31, 33, 42, 52, 53, 56, 57, 58, 60, 68, 70, 73, 74], "vector1": 37, "vector2": 37, "vector2d": [37, 38, 39, 40], "vector3": 37, "vector3d": 38, "vectorized_elementwise_kernel": 69, "vectorplotter2d": [37, 38, 39, 40], "vectorplotter3d": 38, "vectors_add": 38, "vectors_case1": 40, "vectors_case2": 40, "vectors_case3": 40, "vectors_case4": 40, "vectors_sub": 38, "vehicl": [51, 52, 54, 57, 65], "veloc": [57, 73], "venv": [45, 56], "venv_dir": 56, "venv_nam": 56, "verb": 24, "verbatim": [4, 87], "verbatin": 13, "verbos": [8, 9, 24, 25, 37, 70, 74, 78, 80, 82], "veri": [3, 5, 6, 14, 22, 23, 24, 25, 27, 29, 31, 33, 35, 42, 44, 45, 52, 53, 54, 56, 59, 61, 62, 63, 65, 66, 67, 72, 73, 76, 78, 79, 80, 82, 83, 85], "verif": 4, "verifi": [3, 5, 16, 19, 24, 25, 29, 39, 45, 56, 62, 64, 78], "verlag": [26, 27, 29], "vers": 67, "versa": [6, 8, 27, 37, 58], "versatil": [6, 35, 53, 57], "version": [1, 2, 9, 13, 14, 17, 21, 22, 23, 24, 28, 31, 32, 38, 40, 45, 52, 55, 56, 62, 64, 73, 75, 77, 78, 79, 82, 83], "version_bas": 82, "version_info": 8, "versu": [23, 24, 31, 39, 80], "vert": [27, 40, 77], "vertic": [27, 37, 39, 54], "vertical_component_v": 39, "vest": 52, "via": [3, 5, 6, 7, 8, 14, 16, 22, 27, 32, 44, 45, 54, 56, 60, 62, 73, 74, 76, 80, 82, 84], "vibrat": 65, "vice": [6, 8, 27, 37, 58], "victori": 16, "video": [51, 52, 53, 54, 55, 57, 65], "vietnames": 55, "view": [16, 17, 19, 22, 24, 25, 29, 37, 40, 45, 51, 52, 65, 68, 70, 71, 82], "view_dim": 71, "viewbackward0": 70, "viewer": [14, 51], "viewership": [51, 52], "viewpoint": 37, "vincent": [26, 27], "vinyal": 77, "violat": [3, 5, 6, 8, 13, 65, 79], "viridi": [24, 25, 28, 74], "virtual": [24, 65], "visibl": 25, "vision": [35, 52, 57, 77], "visit": [19, 24, 62, 74], "visitor": 52, "visual": [17, 22, 23, 25, 27, 28, 29, 31, 35, 37, 38, 51, 52, 53, 54, 56, 57, 59, 69, 79], "vit": 52, "vital": [39, 51], "vivid": 19, "viz": 71, "vocab": [25, 74], "vocab_s": [24, 25, 68, 70, 73, 74, 75], "vocabulari": [23, 31, 32, 74, 75, 83], "voic": 65, "void": [4, 6, 23, 69], "vol": [2, 11, 78], "volum": [23, 45, 51, 53, 54, 56, 57, 65, 66], "voraci": 16, "voronoi": 26, "vpc": 45, "vpc_id": 45, "vpcid": 45, "vscode": 45, "w": [2, 21, 23, 24, 25, 30, 31, 35, 37, 39, 40, 42, 43, 45, 71, 78], "w1": [68, 70], "w2": [68, 70], "w_": [22, 25, 37], "w_1": 22, "w_2": 22, "w_3": 22, "w_4": 22, "w_5": 22, "w_6": 22, "w_c": 25, "w_e": 24, "w_j": 22, "w_k": [22, 24, 25, 68, 70, 74, 75], "w_o": [24, 25, 68, 70, 74, 75], "w_q": [22, 24, 25, 68, 70, 74, 75], "w_v": [22, 24, 25, 68, 70, 74, 75], "wa": [8, 10, 13, 16, 17, 23, 24, 25, 29, 45, 54, 60, 64, 65, 66, 71, 74, 75, 77, 79, 80, 83], "wai": [3, 4, 5, 7, 8, 10, 14, 16, 17, 19, 22, 23, 25, 27, 29, 31, 35, 39, 40, 44, 45, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 65, 67, 69, 74, 75, 76, 78, 80, 82, 84, 85, 87], "wait": [10, 24, 45, 46, 65, 67, 69, 70, 71, 74], "waiter": 19, "walk": [6, 11, 23, 24], "walkthrough": [23, 24], "walli": [1, 30, 31], "wang": [1, 30, 31], "want": [3, 6, 7, 8, 10, 16, 17, 22, 23, 24, 25, 27, 28, 31, 32, 35, 39, 42, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 65, 66, 68, 70, 72, 73, 74, 75, 76, 78, 80, 82, 83, 85], "warc": 55, "warcio": 55, "warehous": [52, 57], "warm": [25, 27, 68, 69, 70, 71, 78], "warmup": [33, 68, 69, 70, 71], "warmup_": 68, "warmup_ratio": [32, 75, 76], "warmup_step": [25, 68, 69, 76], "warn": [24, 25, 31, 32, 44, 45, 60, 68, 70, 71, 73, 75, 76, 77, 78, 82], "warn_if_padding_and_no_attention_mask": 76, "warn_onli": [24, 31, 60], "warn_tensor_cycl": 71, "warrant": [52, 82], "wast": [23, 24, 35], "watch": [51, 57, 66, 82], "wave": [25, 78], "wavelength": 24, "wb": 24, "wc": 73, "we": [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87], "weak": [24, 57], "weakest": 24, "wealth": 62, "wear": 65, "wearabl": [52, 53], "weather": 53, "web": [19, 23, 51, 52, 53, 55, 56], "webpag": 19, "websit": [23, 52, 53, 55, 57, 65], "week": 65, "weekli": [57, 66], "weigh": 51, "weight": [1, 2, 21, 23, 25, 30, 32, 35, 39, 42, 54, 57, 59, 60, 68, 70, 73, 74, 75, 77, 78], "weight_decai": [25, 32, 74, 75, 76, 82], "weight_ti": [68, 70], "weiji": 35, "weird": 22, "weizhu": 1, "well": [3, 6, 7, 14, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 31, 34, 35, 39, 42, 44, 45, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 75, 76, 77, 78, 79, 80, 82, 84], "weng": [22, 23, 24], "went": [19, 22, 23, 24, 25, 75, 80], "wer": 24, "were": [4, 8, 14, 16, 23, 24, 25, 32, 44, 52, 54, 60, 66, 75, 77, 78, 79, 80, 85], "wget": 45, "what": [4, 6, 7, 8, 9, 10, 11, 16, 17, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 37, 39, 40, 44, 45, 51, 52, 54, 56, 57, 58, 60, 61, 62, 65, 66, 69, 72, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85], "what_i": 25, "whati": 45, "wheat": 35, "wheel": 45, "when": [3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 31, 32, 35, 37, 38, 39, 40, 42, 44, 46, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 65, 66, 69, 71, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85], "whenev": [23, 25, 62, 65, 74], "where": [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 51, 52, 53, 54, 56, 57, 58, 59, 60, 63, 64, 65, 66, 73, 74, 76, 77, 78, 79, 80, 82, 84], "where_equal_index": 25, "wherea": [3, 7, 10, 23, 24, 53, 58, 59, 62, 74], "wherev": 8, "whether": [3, 4, 5, 8, 10, 14, 16, 19, 25, 29, 35, 39, 44, 51, 52, 53, 59, 62, 65, 66, 71, 76, 79, 80], "which": [3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85, 87], "while": [3, 4, 6, 8, 9, 10, 14, 16, 17, 19, 22, 23, 24, 25, 27, 29, 31, 35, 38, 39, 42, 43, 44, 45, 51, 52, 53, 54, 55, 56, 58, 59, 62, 65, 66, 72, 76, 79, 80, 82, 83, 85], "whimsic": 16, "whistl": 76, "whitelist": 25, "whitelist_weight_modul": 25, "whitespac": [23, 24], "who": [24, 27, 51, 54, 56, 64, 65, 79], "whole": [3, 5, 14, 22, 24, 25, 35, 56, 62, 74, 80, 83], "wholesom": 52, "whoop": 79, "whose": [19, 23, 27, 31], "why": [7, 8, 9, 10, 17, 23, 24, 26, 27, 29, 31, 32, 33, 34, 35, 39, 40, 42, 52, 55, 57, 58, 60, 62, 66, 67, 68, 71, 73, 76, 79, 80, 83], "wide": [13, 16, 17, 23, 24, 27, 28, 34, 45, 53, 65, 73, 82], "widehat": [27, 42], "wider": [31, 52], "widespread": 53, "width": [19, 29], "wiki": 71, "wikiextractor": 55, "wikipedia": [3, 5, 8, 13, 14, 17, 18, 23, 26, 27, 29, 30, 31, 35, 39, 40, 55, 71, 79, 85], "wild": 85, "window": [22, 24, 25, 66], "winter": [23, 24], "wise": [23, 25, 27, 31, 37, 38, 69, 73, 75], "wish": 23, "with_flop": 70, "with_stack": [70, 71], "withdraw": 23, "within": [3, 5, 6, 7, 8, 10, 14, 16, 17, 22, 23, 24, 25, 27, 28, 31, 34, 35, 37, 38, 42, 43, 44, 51, 53, 54, 55, 56, 59, 64, 65, 73, 76, 78, 79, 80, 85, 87], "without": [3, 4, 5, 6, 7, 8, 10, 13, 14, 16, 17, 19, 22, 23, 24, 25, 28, 29, 31, 34, 35, 38, 39, 44, 51, 52, 53, 54, 55, 56, 58, 59, 64, 65, 69, 73, 74, 77, 78, 79, 80, 82, 84, 85, 87], "witten": [26, 27], "won": [4, 6, 9, 16, 25, 31, 35, 44, 52, 56, 57, 60, 62, 65, 69, 71, 82], "wonder": [6, 24, 40, 54], "woof": [3, 4, 5], "word": [3, 4, 5, 10, 14, 16, 17, 22, 24, 27, 28, 29, 31, 32, 34, 35, 39, 42, 44, 52, 53, 54, 57, 65, 67, 85], "word2vec": 23, "work": [4, 6, 7, 8, 13, 14, 16, 17, 19, 23, 24, 25, 27, 28, 29, 31, 32, 35, 39, 40, 44, 45, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 65, 66, 73, 74, 76, 78, 79, 82, 85, 87], "workdir": 56, "worker": [25, 43, 44, 52, 56, 65, 80], "workflow": [56, 64, 71, 72], "workload": [54, 55, 71], "workplac": 65, "workshop": 45, "workspac": 31, "world": [4, 6, 14, 16, 17, 24, 27, 52, 56, 58, 59, 62, 64, 65], "world_siz": [25, 44, 46, 74], "worri": [9, 25, 44, 54, 57, 59], "wors": [4, 6, 24, 27, 51], "worsen": 57, "worst": 27, "worth": [3, 4, 16, 22, 23, 24, 25, 27, 31, 37, 58, 60, 65, 73, 74, 78, 79, 82], "would": [3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 32, 34, 35, 39, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 69, 71, 72, 73, 74, 78, 79, 82, 83], "wouldn": 80, "wrap": [24, 32, 53, 56, 65, 76], "wrapper": [53, 76], "write": [6, 7, 19, 21, 22, 23, 24, 25, 27, 29, 31, 42, 44, 45, 53, 54, 61, 62, 71, 79, 85], "write_and_log": 71, "writeup": [68, 70], "written": [3, 4, 6, 8, 11, 22, 24, 27, 29, 40, 42, 52, 54, 61, 71, 79], "wrong": [6, 9, 25, 27, 32, 59, 78, 80], "wrote": 73, "wu": [1, 2, 21, 23], "wurlitz": 70, "www": [1, 29], "x": [2, 4, 6, 7, 8, 9, 13, 16, 21, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 52, 53, 54, 56, 58, 59, 62, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 85, 87], "x0": 24, "x0_decod": 24, "x0_ohe": 24, "x0_ohe_tok_emb": 24, "x0_tok_emb": 24, "x27": 28, "x3": 53, "x5": 53, "x64": [24, 73, 76, 78], "x86_64": 45, "x_": [22, 23, 24, 25, 31, 35, 42, 73], "x_0": 35, "x_1": [8, 22, 23, 24, 25, 27, 31, 35, 42, 73], "x_2": [8, 22, 23, 24, 25, 27, 31, 35, 73], "x_3": [23, 24, 35], "x_boot": 63, "x_d": [27, 35], "x_i": [24, 31, 77, 79], "x_j": [35, 77], "x_list": 9, "x_m": 42, "x_n": 35, "x_t": [22, 23, 24, 31], "x_test": 28, "x_train": 28, "xarg": 45, "xavier": 24, "xavier_uniform_": 24, "xd": 16, "xferd": 25, "xiaodong": 1, "xiong": 1, "xl": [24, 73], "xla": 32, "xlabel": [24, 25, 28, 37, 38, 39, 40, 74], "xlarg": 77, "xml": [53, 54, 55], "xpu": 76, "xrightarrow": 22, "xsmall": 77, "xtick": 25, "xticklabel": [25, 74], "xtract": 55, "xu": 54, "xue": [2, 11], "xxx": 45, "xxxxxxxxxxxxxxxxx": 45, "xy": 25, "xyz": 25, "y": [2, 5, 6, 7, 9, 22, 23, 24, 25, 27, 28, 29, 30, 31, 35, 37, 38, 39, 40, 42, 45, 52, 56, 58, 59, 62, 66, 71, 73, 74, 77, 79, 82, 87], "y_": [23, 25, 31], "y_0": 35, "y_1": [23, 25, 35, 42], "y_2": [23, 25, 35], "y_boot": 63, "y_i": [31, 77, 79], "y_j": 79, "y_m": 42, "y_n": [23, 25, 35], "y_pred": [28, 29], "y_t": 31, "y_test": 28, "y_train": 28, "y_true": 28, "yaida": [2, 79], "yaml": [25, 45], "yaml_cfg": 25, "yaml_path": 25, "yan": [23, 24, 61], "ydata": 70, "ye": [8, 13, 25, 31, 51, 53, 56], "year": [23, 42, 54], "yeast": 35, "yellow": 39, "yelong": 1, "yet": [9, 10, 17, 24, 27, 54, 62, 65, 79], "yield": [5, 6, 7, 8, 9, 10, 13, 14, 16, 19, 23, 25, 33, 35, 38, 39, 58, 60, 62, 68, 73, 76, 79, 81], "yieldtyp": 80, "ylabel": [24, 25, 28, 37, 38, 39, 40, 74], "yolo": 52, "yolov5": 51, "york": [2, 26, 27, 29, 37, 38, 79], "yoshua": 1, "you": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 14, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 39, 40, 42, 44, 45, 46, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87], "your": [3, 7, 9, 19, 24, 25, 31, 35, 44, 45, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 70, 73, 76, 80, 82, 83, 84, 85], "yourkeynam": 45, "yourself": [6, 71, 82], "yshift": [17, 19], "ytick": 25, "yticklabel": [25, 74], "yuanzhi": 1, "yval": 79, "yyyi": [56, 82], "z": [2, 5, 8, 9, 11, 16, 17, 21, 22, 23, 24, 27, 29, 30, 31, 34, 35, 39, 42, 45, 58, 68, 70, 73, 75, 77, 78], "z0": 24, "z0_ohe": 24, "z0_pos_emb": 24, "z0_tok_emb": 24, "z0_tok_embed_add_pos_emb": 24, "z0_tok_embed_matmul": 24, "z0_tok_embed_with_pos_emb": 24, "z0_tok_embed_with_pos_embed_ln1": 24, "z0_tok_embed_with_pos_embed_ln1_pytorch": 24, "z0_tok_embed_with_pos_embed_with_mha_and_addnorm1": 24, "z0_tok_embed_with_pos_embed_with_mha_and_addnorm1_and_ffn_addnorm2": 24, "z_": [24, 77], "z_0": 35, "z_0_tok_embed_with_pos_emb": 24, "z_1": 79, "z_2": 79, "z_3": 79, "z_4": 79, "z_5": 79, "z_a": 79, "z_b": 79, "z_i": [24, 79], "z_j": [24, 79], "z_k": 79, "z_mha": 24, "z_t": 77, "z_with_pos_encod": 24, "zachari": [1, 24], "zebra": 23, "zero": [13, 16, 19, 22, 24, 25, 27, 28, 30, 31, 32, 34, 35, 39, 40, 54, 64, 68, 70, 71, 75, 76, 78, 79], "zero_divis": [32, 75], "zero_grad": [70, 71, 75, 76, 77, 82], "zeror": 59, "zeros_": [24, 32, 68, 70, 75], "zeyuan": 1, "zfill": 25, "zhang": [1, 2, 21, 23, 24, 25, 30, 78, 79], "zhenzhong": 54, "zhu": [1, 30, 31, 73], "zip": [24, 74, 79, 83], "zmqexitautocal": 76, "zmqinteractiveshel": 76, "zmqshell": 76, "zoom": [17, 22, 25, 74, 78], "zsl": 23, "\u0142": [2, 21, 23, 30, 31], "\u03b1": 77}, "titles": ["API Reference", "Bibliography", "IEEE (Style) Citations", "Subtypes", "Type Safety", "Subsumption", "Generics and Type Variables", "Bound and Constraint in Generics and Type Variables", "Invariance, Covariance and Contravariance", "Function Overloading", "Sentinel Types", "Type Theory, A Very Rudimentary Introduction", "Complexity Analysis", "Master Theorem ", "Concept", "Binary Search", "Koko Eating Bananas", "Concept", "Linear Search", "Concept", "Stack", "Generative Pre-trained Transformers", "Notations", "The Concept of Generative Pre-trained Transformers (GPT)", "The Implementation of Generative Pre-trained Transformers (GPT)", "Training a Mini-GPT to Learn Two-Digit Addition", "K-Means", "Concept: K-Means Clustering", "Implementation: K-Means (Lloyd)", "Application: Image Compression and Segmentation", "Low-Rank Adaptation Of Large Language Models", "Concept", "Implementation", "\ud83c\udf0c Omniverse: A Journey Through Knowledge", "Fields", "Systems of Linear Equations", "Preliminaries", "Vector and Its Definition", "Vector and Its Operations", "Vector Norm and Distance", "A First Look at Vector Products", "Vectors", "Machine Learning Notations", "Notations", "Basics Of Distributed Data Parallelism", "How to Setup SLURM and ParallelCluster in AWS", "Ablations", "Distributed Systems", "The Lifecycle of an AIOps System", "Stage 10. Continuous Integration, Deployment, Learning and Training (DevOps, DataOps, MLOps)", "Stage 11. Infrastructure and Tooling for MLOps", "Stage 1. Problem Formulation", "Stage 2. Project Scoping And Framing The Problem", "Stage 3.1. Data Source and Formats", "Stage 3.2. Data Model and Storage", "Stage 3.3. Extract, Transform, Load (ETL)", "Stage 3. Data Pipeline (Data Engineering and DataOps)", "Stage 4. Data Extraction (MLOps), Data Analysis (Data Science), Data Preparation (Data Science)", "Stage 5.1. Model Selection", "Stage 5.2. Metric Selection", "Stage 5.3. Experiment Tracking And Versioning", "Stage 5.4. Model Testing", "Stage 5. Model Development and Training (MLOps)", "Stage 6. Model Evaluation (MLOps)", "Stage 7. Model Validation, Registry and Pushing Model to Production (MLOps)", "Stage 8. Model Serving (MLOps)", "Stage 9. Model Monitoring (MLOps)", "Synchronize CUDA To Time CUDA Operations", "Profiling Code With Timeit", "PyTorch\u2019s Event And Profiler", "Profile GPT Small Time And Memory", "CUDA Memory Allocations", "Profiling", "How to Calculate the Number of FLOPs in Transformer Based Models?", "How To Fine-Tune Decoder-Only Models For Sequence Classification With Cross-Attention?", "How To Fine-Tune Decoder-Only Models For Sequence Classification Using Last Token Pooling?", "How to Inspect Function and Class Signatures in Python?", "How To Do Teacher-Student Knowledge Distillation?", "Why Does Cosine Annealing With Warmup Stabilize Training?", "Softmax Preserves Order, Is Translation Invariant But Not Invariant Under Scaling.", "A Rudimentary Introduction to Generator and Yield in Python", "Concurrency, Parallelism and Asynchronous Programming", "Pydantic And Hydra", "State And Metadata Management", "Configuration Management", "Dependency Inversion Principle", "Design Patterns", "Strategy Pattern"], "titleterms": {"": [24, 27, 35, 69, 73, 78], "0": 55, "1": [5, 10, 13, 16, 22, 23, 24, 27, 29, 35, 45, 51, 53, 55, 56, 57, 58, 60, 71, 78, 79], "10": [22, 49, 56], "11": [22, 50, 56], "2": [5, 13, 14, 16, 22, 23, 24, 27, 29, 35, 45, 52, 54, 55, 56, 57, 59, 60, 66, 73, 74, 78, 79], "2d": [5, 35], "3": [5, 13, 22, 23, 24, 27, 29, 35, 40, 45, 53, 54, 55, 56, 57, 60, 78, 79], "39": 14, "3d": 35, "4": [22, 23, 56, 57, 61], "5": [22, 23, 56, 58, 59, 60, 61, 62], "6": [22, 23, 56, 63], "7": [22, 23, 56, 64], "8": [22, 29, 56, 65], "9": [22, 56, 66], "A": [4, 9, 11, 16, 25, 29, 31, 33, 40, 54, 56, 62, 74, 78, 80, 85], "And": [22, 31, 32, 43, 44, 52, 53, 54, 58, 59, 60, 68, 69, 70, 75, 77, 82, 83, 84], "But": 79, "By": 29, "For": [22, 53, 55, 74, 75, 84], "In": [31, 56, 62], "Its": [37, 38], "No": [31, 35, 46, 58], "Not": [9, 79], "Of": [30, 31, 44, 52, 55, 57, 79, 84], "On": [4, 51, 52, 55, 62, 65], "One": [22, 24], "TO": 66, "The": [6, 8, 16, 17, 19, 22, 23, 24, 27, 31, 34, 40, 43, 48, 52, 55, 59, 62, 65, 79, 80], "To": [24, 25, 43, 67, 74, 75, 77, 79], "With": [25, 32, 44, 46, 68, 74, 78, 79], "_": 22, "_2": 34, "__dict__": 76, "ablat": [46, 62], "about": 74, "abstract": 23, "abus": 22, "access": [45, 55], "accuraci": 58, "acid": 54, "activ": [22, 24], "ad": 80, "adapt": [30, 31], "add": [7, 25], "adder": 25, "addit": [25, 31, 38, 79], "addnorm": 24, "address": 44, "advanc": 65, "advantag": [54, 65], "affin": 24, "after": [14, 56], "aiop": [48, 51], "alert": 56, "algebra": [33, 35, 37, 38, 40], "algorithm": [13, 14, 16, 17, 27, 28, 31, 33], "all": [6, 24, 55, 65, 71, 76, 80], "alloc": 71, "also": [54, 59, 62], "altern": 22, "am": 55, "amort": 19, "an": [17, 24, 29, 43, 48, 51, 52, 53, 55, 57, 78, 80], "analogi": [16, 19, 24, 35], "analysi": [12, 14, 16, 17, 57], "analyt": 54, "andrej": 24, "angl": 40, "ani": 6, "anneal": [25, 78], "annot": 76, "antisymmetri": 5, "api": [0, 33], "appli": [24, 29], "applic": [5, 13, 22, 24, 29], "approach": [16, 23], "approxim": [22, 24], "ar": [3, 6, 24, 27, 54, 55, 80], "architectur": [22, 24, 56, 75], "argument": [6, 8, 44], "arrai": [16, 17], "artifact": 60, "assign": 27, "assumpt": [14, 16, 23, 58], "asynchron": [24, 65, 81], "atom": 54, "attent": [22, 23, 24, 25, 74], "attribut": 76, "augment": 57, "auroc": 59, "autom": 56, "autoregress": [22, 23, 31], "auxiliari": [14, 16, 17, 23], "averag": [14, 16, 17], "aw": 45, "axiom": [34, 79], "back": 74, "backbon": 22, "backend": 44, "background": 17, "bad": 24, "bakeri": 35, "banana": 16, "barrier": 46, "base": [9, 32, 73], "baselin": [51, 58], "basic": [44, 73], "batch": [22, 24, 25, 55, 57, 65], "befor": [22, 53], "behavior": [9, 10], "benchmark": 73, "benefit": [51, 59], "best": [14, 16, 17], "between": [4, 40, 54, 65], "bia": 63, "bibliographi": 1, "big": [17, 80], "bigqueri": 56, "binari": [14, 15, 16, 25, 29, 34, 53], "bit": 29, "block": [22, 24], "boldsymbol": 79, "book": [26, 54], "boolean": 16, "bound": 7, "boundari": 58, "bpe": 23, "break": 16, "brier": 59, "broadcast": 24, "brute": 27, "budget": 55, "busi": [51, 52], "byte": 23, "calcul": [17, 73], "calibr": [59, 63, 79], "callabl": 8, "callback": 74, "came": 6, "can": [27, 55], "cancer": 51, "capac": 23, "car": 54, "case": [10, 13, 14, 16, 17, 19, 24, 35, 79], "cauchi": 40, "caus": 14, "causal": [24, 74], "caution": 62, "cd": 56, "ceil": 16, "center": [16, 27], "centroid": 27, "chain": 23, "chaotic": 58, "characterist": [54, 58], "chatgpt": 52, "check": [4, 28, 73], "checkpoint": 73, "child": 76, "choos": [27, 52, 59], "chronicl": 62, "ci": 56, "circl": 5, "citat": [2, 11, 21, 23, 30, 78, 79], "clarifi": 51, "clariti": 7, "class": [3, 57, 76], "classif": [25, 51, 59, 74, 75], "clerk": 24, "cli": 45, "close": [27, 39, 80], "cloud": 65, "cluster": [27, 45, 59], "code": [17, 19, 29, 44, 53, 60, 68, 70], "coerciv": 3, "collat": [24, 25, 75], "collect": 55, "column": [40, 53], "columnar": 53, "combin": 52, "combo": 59, "come": 53, "command": [44, 45], "commerc": [52, 53], "common": [13, 26, 42, 55, 60, 68, 70], "commoncrawl": 23, "commut": 38, "comparison": [4, 14], "compet": 23, "compil": 3, "complex": [12, 14, 16, 17, 19, 24, 27], "complianc": 55, "compon": 52, "compos": [24, 25, 78], "composit": [82, 84], "compress": [29, 65], "comput": [2, 24, 25, 33, 45, 58], "con": [3, 53, 82], "concaten": 22, "concept": [14, 17, 19, 23, 27, 31, 53, 66], "conclus": 29, "concurr": 81, "condit": [23, 27, 42], "config": [24, 25, 82, 84], "configur": [24, 45, 73, 82, 84], "connect": [5, 8, 22, 24, 52], "conquer": 13, "consider": [55, 73], "consist": 54, "consolid": 45, "constant": 73, "constrain": 7, "constraint": [7, 14, 16, 51, 55], "construct": [23, 24, 25, 74, 76], "contain": [6, 9], "container": 56, "content": [11, 12, 15, 18, 20, 21, 26, 36, 41, 47, 48, 72, 81, 86], "context": [23, 24], "contextu": 23, "contig": 28, "continu": [23, 24, 49, 62, 79], "contravari": 8, "convent": 42, "converg": [23, 27], "coordin": 37, "corpu": 22, "correct": [14, 16, 17, 85], "correspond": 52, "cosin": [25, 40, 78], "cosineannealinglr": 78, "cosineannealingschedul": 78, "cost": [27, 52], "count": 73, "counterpart": 17, "covari": 8, "cpu": 44, "creat": [25, 45], "creation": 45, "criteria": 5, "criterion": [5, 25], "cross": [22, 62, 74], "cuda": [44, 67, 69, 71], "curv": 62, "cycl": 71, "d": [24, 39], "dag": 56, "dampen": 79, "dashboard": 66, "data": [16, 17, 19, 24, 33, 44, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 75, 80], "databas": [24, 54], "dataload": [24, 25, 75, 80], "dataop": [49, 56], "dataset": [23, 24, 25, 32, 74, 75, 77], "deal": 55, "decai": 78, "declar": [3, 54], "decod": [22, 24, 74, 75], "decompos": 23, "decomposit": 31, "decoupl": 52, "decreas": 27, "deep": [2, 34, 39, 52, 73], "defin": [7, 17, 27, 55], "definit": [8, 16, 22, 24, 25, 34, 37, 38, 40, 55, 65, 78, 85], "delet": 45, "delta": [54, 79], "demo": 44, "demonstr": 5, "depend": [24, 28, 32, 62, 74, 75, 77, 84, 85], "deploi": 56, "deploy": [49, 56, 64, 65], "deprec": 25, "deriv": [16, 79], "descript": 22, "deseri": 53, "design": 86, "destin": 55, "detect": [52, 59], "determin": [3, 40], "develop": [56, 62], "devic": [44, 65], "devop": 49, "diagnosi": [51, 52], "diagram": 52, "differ": [54, 84], "differenti": 79, "digit": [25, 29], "dimens": [22, 24, 25, 39], "dimension": [24, 40, 54, 58], "dir": 76, "direct": 22, "disadvantag": [54, 65], "discret": 24, "dispatch": 9, "distanc": 39, "distil": 77, "distinct": 65, "distribut": [17, 23, 24, 44, 46, 47, 53, 58, 79], "divid": 13, "do": [55, 77], "document": 54, "doe": [59, 65, 78, 80], "don": 55, "dot": [22, 24, 40], "down": [16, 24], "draw": 8, "drift": [62, 66], "driven": 82, "dropout": 22, "dry": 75, "dunder": 19, "durabl": 54, "dynam": [4, 9, 24], "e": [17, 22, 52, 53], "earli": 52, "eat": 16, "ec2": 45, "edg": [14, 16, 65], "effect": 53, "effici": [17, 73, 80], "elbow": 27, "elementwis": 22, "ell": 22, "elt": 55, "eltl": 55, "embed": [22, 23, 24], "enabl": 24, "encod": [22, 23, 24, 25], "engin": [33, 54, 55, 56, 57], "enough": 79, "ensembl": 58, "ensur": 7, "entropi": [22, 23], "enum": 73, "environ": [45, 56], "equal": 37, "equat": [13, 35], "equip": 52, "equival": [27, 40], "error": [22, 24], "establish": 52, "estim": [9, 23, 42, 73], "etl": 55, "euclidean": [5, 39], "evalu": [28, 32, 59, 63], "event": 69, "everyth": 24, "eviron": 84, "evolut": 55, "exact": [14, 24], "exampl": [4, 6, 7, 8, 9, 13, 14, 16, 19, 22, 24, 25, 29, 34, 40, 43, 51, 52, 53, 54, 55, 57, 59, 65, 66, 78, 80], "expect": 17, "experi": [56, 60], "expert": 23, "explan": 14, "exponenti": 79, "express": 80, "extens": [13, 17], "extern": 16, "extract": [53, 55, 56, 57], "f": [34, 79], "factor": 31, "fail": [23, 27], "failurecod": 45, "failurereason": 45, "famili": [23, 24, 79], "faq": 26, "far": 79, "favour": 51, "feasibl": 16, "featur": [51, 52, 57, 58, 65], "feed": [22, 24], "feedback": 56, "feedforward": [22, 24], "ffn": 24, "field": 34, "file": [45, 80], "final": 62, "find": [14, 27, 45, 55, 71], "fine": [23, 31, 74, 75], "finit": [27, 65], "first": [16, 22, 25, 40], "fit": 27, "flexibl": 55, "float": 73, "flop": 73, "fluff": 73, "footprint": 73, "forc": 27, "form": [13, 24, 35, 79], "formal": 14, "format": [53, 55], "formul": [16, 27, 51, 79], "forward": [22, 24, 73], "foundat": 16, "fourth": 25, "fraction": 78, "frame": [16, 52], "framework": 55, "free": 58, "from": [23, 24, 35, 51, 65, 74, 79], "fulfil": 5, "full": 24, "function": [5, 6, 8, 9, 16, 22, 23, 24, 25, 27, 52, 68, 70, 76, 79, 80], "further": [3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 84, 85], "fusion": 52, "futur": [24, 25], "g": 17, "gaussian": [22, 24], "gc": 56, "gelu": [22, 24], "gener": [6, 7, 13, 19, 21, 22, 23, 24, 25, 35, 39, 80], "generalist": 23, "geometr": [35, 37, 38, 40], "geometri": 5, "get": 76, "getmemb": 76, "global": [27, 43, 44], "gloo": 44, "goal": 52, "good": 9, "gpt": [23, 24, 25, 70, 73, 74], "gpu": [45, 71, 73], "gradient": [24, 79], "graph": 54, "greedi": 27, "group": 44, "ha": [23, 24, 31], "handl": 24, "har": 17, "head": [22, 24, 45, 74], "headnodebootstrapfailur": 45, "health": 66, "heatmap": [24, 25, 74], "hessian": 79, "hierarchi": 3, "high": [54, 85], "higher": [22, 24], "hot": [22, 24], "how": [3, 27, 45, 55, 73, 74, 75, 76, 77, 80], "http": 10, "huggingfac": [24, 75], "hybrid": [52, 65], "hydra": 82, "hyperparamet": [60, 62], "hyperplan": 35, "hypothesi": 27, "hypothet": 76, "i": [3, 5, 6, 8, 22, 23, 24, 27, 34, 37, 38, 40, 45, 52, 55, 62, 79, 80], "iam": 45, "id": 45, "idea": [23, 33], "ident": [22, 24, 45, 58], "identifi": [51, 52, 53], "ieee": 2, "ignor": 25, "iid": [23, 58], "illustr": [25, 43], "imag": [29, 56], "imbal": 57, "immut": 8, "imper": 54, "implement": [3, 9, 14, 16, 17, 19, 23, 24, 25, 26, 28, 29, 32, 78, 79, 80], "implic": 16, "import": [19, 28, 34], "inadmissbl": 13, "inclus": [3, 5], "independ": [22, 24, 35, 58], "index": [22, 25], "indic": 73, "individu": 27, "induct": 17, "inequ": 40, "infer": [23, 27, 31, 65], "infinit": 35, "influenti": 33, "inform": 44, "infrastructur": 50, "ingest": [55, 57], "initi": [23, 25, 44, 54], "inject": [84, 85], "input": [14, 16, 17, 22, 23, 24, 25, 52, 65], "inspect": 76, "instabl": 79, "instanc": [45, 76], "instanti": 82, "integ": [3, 5, 29], "integr": 49, "interpret": [35, 38, 40, 58, 79], "intrins": 31, "introduct": [11, 13, 14, 16, 17, 19, 23, 34, 51, 52, 80], "intuit": [14, 16, 17, 19, 24, 27, 53, 55, 66, 78], "invari": [5, 8, 17, 24, 37, 38, 79], "invers": 85, "iri": 28, "isol": 54, "item": [14, 52], "iter": [14, 16, 17, 22, 80], "its": 53, "j": 79, "jacobian": 79, "job": 16, "joint": 23, "journei": 33, "json": 53, "just": 6, "k": [14, 26, 27, 28, 29], "karpathi": 24, "keep": 55, "kei": [22, 23, 24, 45, 52, 54, 62], "kind": 27, "knowledg": [33, 77], "koko": 16, "kolmogorov": 79, "kroneck": 79, "l": [22, 39, 79], "l2": 39, "l_1": 39, "l_2": 39, "l_p": 39, "label": [52, 57], "lake": [54, 55, 56], "lakehous": 54, "languag": [3, 23, 30, 54], "larg": [23, 30, 54, 55, 80], "last": [24, 75], "late": 52, "latenc": 31, "law": 40, "layer": [22, 24, 56], "layernorm": 24, "lazi": 80, "lead": 24, "leakag": [57, 62], "learn": [2, 16, 19, 22, 23, 25, 31, 34, 37, 38, 39, 42, 49, 51, 52, 53, 56, 62, 65, 73, 78], "learnabl": 24, "lectur": 26, "left": 14, "lemma": 27, "length": [23, 24], "level": 85, "lifecycl": 48, "likelihood": 42, "line": [35, 44], "linear": [17, 18, 22, 24, 33, 35, 58], "link": 35, "liskov": 5, "list": [8, 19, 80], "lloyd": [27, 28], "load": [24, 29, 55, 56, 73, 80], "local": [27, 43], "locat": 84, "log": 45, "logit": 79, "look": 40, "lookup": [22, 24], "loop": [17, 56], "lora": [31, 32], "loss": [22, 23, 25, 27, 52, 62], "low": [30, 31, 85], "lunch": 58, "machin": [39, 42, 51, 52, 53, 56, 65], "madewithml": 66, "mai": 14, "main": [68, 70], "mainten": 5, "major": [53, 54], "man": 24, "manag": [45, 83, 84], "manhattan": 39, "mani": 45, "map": [22, 24], "markov": 23, "mask": [22, 24, 25, 74], "master": [13, 14, 24, 44], "match": [14, 24], "mathbb": [17, 34], "mathbf": [22, 79], "mathcal": [17, 79], "mathemat": [14, 16, 17, 42, 78], "matric": 22, "matrix": [22, 24, 28, 31, 40, 73, 79], "matter": 59, "maximum": [24, 42], "me": 55, "mean": [26, 27, 28, 29, 55, 65], "measur": 51, "mechan": [22, 23, 24], "medic": [51, 52], "medoid": 27, "member": 76, "membership": 5, "memori": [24, 70, 71, 73, 80], "merg": [25, 31, 32], "mermaid": 52, "metadata": [60, 83], "method": [6, 17, 19, 27, 76, 80], "metric": [28, 32, 51, 52, 59, 60], "mfu": 73, "mind": 55, "mineatingspe": 16, "mini": 25, "miniconda": 45, "minim": 27, "minima": 27, "minimum": [27, 52], "miss": 10, "mlop": [49, 50, 57, 62, 63, 64, 65, 66], "mnist": 28, "modal": 52, "model": [23, 24, 25, 27, 30, 32, 54, 58, 59, 60, 61, 62, 63, 64, 65, 66, 73, 74, 75], "modern": 53, "modif": [23, 24], "modifi": 74, "modul": [0, 85], "monitor": [45, 55, 56, 62, 66], "monoton": [16, 27, 79], "moot": 6, "more": 24, "motiv": [6, 8, 9, 10, 23, 25, 31, 35, 76, 78], "movi": 51, "multi": [22, 23, 24, 44, 52], "multimod": [52, 53], "multipl": [22, 38, 40, 73], "multipli": 78, "mutabl": 8, "mvp": 52, "my": [55, 66], "n": 17, "nacent": 23, "naiv": [16, 24, 56, 80], "narrow": [5, 23], "necessari": 27, "need": [29, 55], "neg": [38, 79], "neq": 79, "network": [22, 24, 45], "newsfe": 52, "next": 80, "node": [43, 44, 45], "nomin": 3, "non": [34, 52, 79], "norm": [24, 39], "normal": [22, 24, 35, 54, 79], "nosql": 54, "notat": [14, 17, 22, 24, 27, 33, 42, 43], "note": 62, "notebook": 26, "notgiven": 10, "notion": 27, "number": [5, 14, 27, 29, 34, 73], "numer": [24, 79], "o": 17, "obei": 79, "object": [3, 16, 17, 19, 23, 27, 34, 37, 38, 51, 52], "offlin": [52, 64], "old": 66, "omnivers": 33, "onli": [65, 74, 75], "onlin": [17, 26, 52, 64, 65], "oper": [19, 22, 24, 33, 38, 67, 69, 73], "optim": [17, 23, 25, 27, 55, 73], "option": 56, "order": [17, 53, 76, 79, 82], "ordinari": 8, "orient": [3, 37], "oscil": [25, 78], "other": [27, 59], "our": 25, "out": 45, "outcom": 17, "outer": 40, "output": [22, 24, 52, 79], "over": [23, 71], "overflow": 14, "overload": 9, "overview": [17, 23, 25], "p": [24, 39], "pad": 25, "pair": [6, 23, 45], "pairwis": 59, "palm": 73, "paper": [23, 33, 73], "paradigm": [22, 23, 25, 31, 52, 62], "parallel": [24, 44, 53, 81], "parallelclust": 45, "paramet": [6, 23, 31, 73], "parametr": 35, "parent": 76, "part": 56, "partit": 27, "pass": 73, "patch": 24, "path": 24, "pattern": [86, 87], "pe": 22, "per": [24, 73], "perform": [28, 51, 52, 53, 55, 80], "permut": 24, "perplex": 23, "person": 52, "phase": [22, 78], "pigeonhol": 16, "pipelin": [56, 65], "plane": 35, "plate": 19, "playbook": 33, "playground": 54, "point": [35, 73], "pool": 75, "poor": 24, "port": 44, "posit": [22, 24, 29, 35, 38], "positionwis": [22, 24], "possibl": 65, "potenti": 55, "ppe": 52, "practic": [16, 73], "pre": [21, 22, 23, 24], "precondit": 16, "precurs": 65, "predict": [52, 58, 65], "prefetch": 24, "preliminari": 36, "prepar": [32, 57], "preserv": [5, 79], "pretrain": 32, "pretti": 24, "priest": 24, "primer": [22, 29], "primit": 3, "principl": [5, 16, 85], "pro": [3, 53, 82], "probabilist": [17, 79], "probabl": [17, 23, 79], "problem": [6, 16, 17, 27, 29, 42, 51, 52, 79], "process": [22, 24, 43, 44, 52, 54, 55, 65], "product": [17, 22, 24, 35, 40, 52, 56, 64], "profil": [68, 69, 70, 72, 80], "program": 81, "project": [22, 24, 40, 52, 55], "promot": 64, "proof": [16, 34, 40], "properti": [5, 35, 37, 40, 54], "protect": 52, "pseudocod": [14, 16, 17], "publish": 54, "puriti": 28, "purpos": 10, "push": 64, "put": 24, "pydant": 82, "pydra": 82, "pythagorean": 39, "python": [45, 53, 76, 80], "pytorch": [24, 25, 69, 78], "quantiz": [29, 32], "queri": [22, 24], "quot": 55, "random": 17, "rank": [30, 31, 43, 44, 52, 59], "rate": [25, 78], "ratio": 73, "raw": 55, "re": 27, "read": [3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 84, 85], "real": [5, 8, 19, 23, 34, 57, 58, 65], "recal": 51, "recommend": [51, 52], "reconstruct": 29, "recov": 60, "recurs": [14, 17], "redo": 25, "reduc": 16, "reduct": [25, 31], "refer": [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 84, 85], "refin": 66, "reflex": 5, "region": 27, "registri": 64, "regress": [35, 59], "reject": 23, "relat": [54, 73], "relationship": [5, 52], "relev": [39, 55], "remark": [19, 27], "remov": 71, "repeat": 14, "repres": [27, 79], "represent": [14, 16, 17, 22, 23, 24, 37], "reproduc": [24, 25, 31, 60, 74], "request": 10, "requir": [51, 55], "reshap": 22, "residu": [22, 24], "resolut": 76, "resourc": [26, 33, 45, 58], "respect": [23, 79], "retriev": [59, 76], "return": [8, 80], "revers": 74, "review": 45, "revis": 24, "revisit": [6, 7], "right": [14, 52, 59], "rng": 0, "roadmap": 33, "role": 45, "rotat": 38, "rough": 73, "row": [40, 53, 54], "rudimentari": [11, 80], "rule": 23, "run": [3, 45, 60, 75], "runtim": 9, "safe": 4, "safeti": [4, 7], "sale": 17, "same": 23, "sampl": [24, 25, 45, 57, 79], "saniti": [28, 73], "satisfi": 5, "satur": 24, "scalabl": 55, "scalar": [35, 38, 40], "scale": [22, 24, 38, 51, 79], "scenario": [17, 24], "schedul": [16, 25], "schema": 82, "schwarz": 40, "scienc": [2, 33, 57], "scope": [6, 52, 53, 55], "score": [24, 28], "script": 45, "search": [14, 15, 16, 17, 18, 27], "second": [27, 73], "section": 23, "secur": 55, "see": [54, 59, 62], "seed": [0, 60], "segment": 29, "select": [58, 59], "self": [22, 23, 24, 31], "semant": [7, 22], "send": 80, "sentinel": 10, "sequenc": [22, 24, 74, 75], "sequenti": [17, 24], "serial": 53, "serv": 65, "servic": 84, "set": [3, 5, 32, 44, 45, 65, 75, 77], "setup": [44, 45], "shape": 5, "shard": 53, "share": [22, 45], "sharpen": 79, "shot": 23, "should": 55, "shuffl": 24, "sign": 40, "signatur": 76, "similar": 27, "simpl": 25, "simplif": 23, "singl": [9, 73], "singleton": 25, "singular": 45, "size": [7, 24, 29, 43, 44, 73], "slurm": 45, "small": 70, "smaller": 25, "smooth": [23, 58, 79], "so": [9, 79], "softmax": [22, 24, 79], "softwar": 33, "solut": [16, 35], "some": [8, 19, 45, 60, 62, 73, 79], "sort": [16, 17], "sourc": [53, 55], "space": [14, 16, 17, 19, 22, 24, 27, 34, 35, 39, 40, 65], "specif": 31, "split": 25, "squar": 69, "stabil": [23, 24, 78], "stabilis": 24, "stack": [19, 20], "stage": [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 84], "standard": [14, 16, 37], "state": [14, 25, 83], "statement": [16, 29, 80], "static": 4, "statu": 45, "step": [22, 27, 29, 53, 55, 56, 64, 79], "stirl": 27, "stop": 45, "storag": [53, 54, 55], "store": [17, 55], "strategi": [25, 52, 65, 87], "stream": [55, 57, 65, 80], "string": 22, "structur": [3, 19, 33, 51, 54, 59, 82], "student": 77, "studi": 62, "style": 2, "subsequ": 22, "subspac": 24, "substitut": [5, 14], "subsumpt": 5, "subtract": 38, "subtyp": [3, 4, 5], "success": 51, "sum": 22, "summari": [17, 34, 56], "supervis": [22, 23, 31], "synchron": 67, "system": [35, 45, 47, 48, 51, 53, 65, 66], "t": [17, 55], "tabl": [11, 12, 14, 15, 17, 18, 20, 21, 22, 26, 36, 41, 47, 48, 53, 72, 81, 86], "target": [24, 25], "task": [23, 31, 52], "tau": 78, "teacher": 77, "techniqu": [55, 64], "temperatur": 79, "templat": 55, "terminologi": 42, "test": [14, 16, 17, 25, 61, 64], "text": [53, 55], "tflop": 73, "th": 14, "theorem": [13, 14, 17, 24, 27, 39, 58], "theoret": [16, 73], "theori": 11, "theta": 79, "thi": 55, "three": 79, "through": [22, 33], "throw": 80, "tikz": [17, 19], "tild": 22, "time": [3, 14, 16, 17, 19, 27, 45, 57, 58, 65, 67, 70, 71, 80], "timeit": 68, "timeout": 10, "tip": 79, "togeth": 24, "token": [22, 23, 24, 25, 75], "tool": [50, 55], "torch": 69, "total": [14, 16, 17, 73], "total_hours_to_finish_": 16, "trace": 69, "track": 60, "tractabl": 58, "tradeoff": 16, "train": [21, 22, 23, 24, 25, 32, 49, 62, 74, 75, 78], "trainabl": 73, "trainer": 25, "transact": 54, "transfer": 23, "transform": [21, 23, 24, 37, 55, 56, 73], "transiv": 5, "translat": [16, 79], "transpos": [22, 37, 40], "trigger": 56, "troubleshoot": 45, "true": 16, "tune": [23, 31, 60, 62, 74, 75], "two": [25, 40], "type": [3, 4, 6, 7, 8, 10, 11, 19, 52, 53, 55, 57, 76], "unbound": 65, "under": [37, 38, 79], "underli": 19, "understand": [52, 58, 71], "unifi": 65, "uniform": [17, 24], "union": 7, "uniqu": 35, "unit": [22, 24], "unload": 32, "unnorm": 79, "unord": 17, "unsaf": 9, "unsign": 29, "unstructur": 54, "unsupervis": 23, "up": [32, 44, 45, 65, 75, 77], "updat": [22, 31, 54], "upper": 7, "us": [6, 10, 17, 19, 24, 27, 45, 55, 74, 75, 76, 80], "util": [24, 73], "v": [3, 4, 8, 10, 35, 53, 54, 55, 58, 65, 78, 80], "valid": [25, 56, 62, 64], "valu": [5, 17, 22, 24], "var": 76, "variabl": [6, 7, 17], "varianc": [8, 24, 63], "variant": [9, 23, 24], "vector": [24, 29, 34, 35, 37, 38, 39, 40, 41, 54, 79], "vectorwis": 22, "veri": 11, "version": 60, "versu": [7, 37], "via": [23, 24, 29, 31, 79], "viabl": 52, "video": 24, "violat": [4, 85], "virtual": 45, "visual": [14, 16, 24, 65, 71], "visualis": 24, "vocabulari": [22, 24, 25], "volum": 55, "voronoi": 27, "w": 22, "wai": [6, 24], "walkthrough": 78, "want": 14, "warehous": [54, 55, 56], "warmup": [25, 78], "we": [14, 74], "webtext": 23, "weight": [22, 24, 31, 79], "what": [3, 14, 53, 55], "when": [27, 55], "where": [55, 62], "whiteboard": 16, "why": [3, 6, 14, 16, 19, 25, 56, 59, 78], "widen": 5, "window": 23, "wise": [22, 24, 40, 59], "word": [23, 25, 78], "work": 80, "workflow": [53, 55], "world": [8, 19, 23, 43, 44], "worst": [14, 16, 17, 19], "write": 56, "x": [17, 22], "yaml": 82, "ye": 52, "yield": 80, "your": 59, "z": 79, "zero": 23}})