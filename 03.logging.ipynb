{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "XTCw21r3Urh1",
   "metadata": {
    "id": "XTCw21r3Urh1"
   },
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LYhq4w6rncaG",
   "metadata": {
    "id": "LYhq4w6rncaG"
   },
   "source": [
    "## Intuition\n",
    "\n",
    "Logging is the process of tracking and recording key events that occur in our applications. We want to log events so we can use them to inspect processes, fix issues, etc. They're a whole lot more powerful than print statements because they allow us to send specific pieces of information to specific locations, not to mention custom formatting, shared interface with other Python packages, etc. This makes logging a key proponent in being able to surface insightful information from the internal processes of our application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BK8pxvGzYFot",
   "metadata": {
    "id": "BK8pxvGzYFot"
   },
   "source": [
    "## Components\n",
    "\n",
    "There are a few overarching concepts to be aware of first before we can create and use our loggers.\n",
    "\n",
    "- `Logger`: the main object that emits the log messages from our application.\n",
    "- `Handler`: used for sending log records to a specific location and specifications for that location (name, size, etc.).\n",
    "- `Formatter`: used for style and layout of the log records.\n",
    "\n",
    "There is so much [more](https://docs.python.org/3/library/logging.html) to logging such as filters, exception logging, etc. but these basics will allows us to do everything we need for our application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zmHFsdESYokM",
   "metadata": {
    "id": "zmHFsdESYokM"
   },
   "source": [
    "## Logging Levels\n",
    "\n",
    "The numeric values of logging levels are given in the following table. These are primarily of interest if you want to define your own levels, and need them to have specific values relative to the predefined levels. If you define a level with the same numeric value, it overwrites the predefined value; the predefined name is lost.\n",
    "\n",
    "| Level | Value |\n",
    "| ----- | ----- |\n",
    "| DEBUG | 10    |\n",
    "| INFO  | 20    |\n",
    "| WARN  | 30    |\n",
    "| ERROR | 40    |\n",
    "| FATAL | 50    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oz9jKtaRZ6wI",
   "metadata": {
    "id": "oz9jKtaRZ6wI"
   },
   "source": [
    "Before we create our specialized, configured logger, let's look at what logged messages even look like by using a very basic configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PcSIPhNkYkxk",
   "metadata": {
    "id": "PcSIPhNkYkxk"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BgwN96MU0HkU",
   "metadata": {
    "id": "BgwN96MU0HkU"
   },
   "source": [
    "These are the basic levels of logging, where `DEBUG` is the lowest priority and `CRITICAL` is the highest. We defined our logger using `basicConfig` to emit log messages to our `stdout` console (we also could've written to any other stream or even a file) and to be sensitive to log messages starting from level `DEBUG`. This means that all of our logged messages will be displayed since `DEBUG` is the lowest level. Had we made the level `ERROR`, then only `ERROR` and `CRITICAL` log message would be displayed. (madewithml.com)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yDTeDH-d03Rr",
   "metadata": {
    "id": "yDTeDH-d03Rr"
   },
   "source": [
    "In our first example, we set the `level` to be `logging.DEBUG` and all $5$ messages are logged, as can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lbOALlNDziQG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 792,
     "status": "ok",
     "timestamp": 1651046532356,
     "user": {
      "displayName": "HONGNAN GAO",
      "userId": "14684257183016239750"
     },
     "user_tz": -480
    },
    "id": "lbOALlNDziQG",
    "outputId": "a12f9cd6-7a7e-4810-d3f8-ef59ba026d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:root:There's been a mistake with the process.\n",
      "CRITICAL:root:There is something terribly wrong and process may terminate.\n"
     ]
    }
   ],
   "source": [
    "# Create super basic logger\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "\n",
    "# Logging levels (from lowest to highest priority)\n",
    "logging.debug(\"Used for debugging your code.\")\n",
    "logging.info(\"Informative messages from your code.\")\n",
    "logging.warning(\"Everything works but there is something to be aware of.\")\n",
    "logging.error(\"There's been a mistake with the process.\")\n",
    "logging.critical(\"There is something terribly wrong and process may terminate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mqEytKd004o1",
   "metadata": {
    "id": "mqEytKd004o1"
   },
   "source": [
    "In the next example, we set the `level` to be `logging.ERROR`, this means all messages lower than `error` is ignored, as can be seen here! Note, if you are working in google colab, one should factory reset the notebook so that the `logger` can be refreshed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UwfMSrBnzZhn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1651053197551,
     "user": {
      "displayName": "HONGNAN GAO",
      "userId": "14684257183016239750"
     },
     "user_tz": -480
    },
    "id": "UwfMSrBnzZhn",
    "outputId": "92a9626a-e1b2-4590-8d51-49e31650decc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:root:There's been a mistake with the process.\n",
      "CRITICAL:root:There is something terribly wrong and process may terminate.\n"
     ]
    }
   ],
   "source": [
    "# Create super basic logger\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.ERROR)\n",
    "\n",
    "# Logging levels (from lowest to highest priority)\n",
    "logging.debug(\"Used for debugging your code.\")\n",
    "logging.info(\"Informative messages from your code.\")\n",
    "logging.warning(\"Everything works but there is something to be aware of.\")\n",
    "logging.error(\"There's been a mistake with the process.\")\n",
    "logging.critical(\"There is something terribly wrong and process may terminate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B3NFSHSS1Pab",
   "metadata": {
    "id": "B3NFSHSS1Pab"
   },
   "source": [
    "## Custom Logger Function\n",
    "\n",
    "We will define a custom logger function for our purpose. \n",
    "\n",
    "> If you encounter `logger` printing the same line multiple times, we should factory reset runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5sCOe9M_1XSl",
   "metadata": {
    "id": "5sCOe9M_1XSl"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5tnQrLVUc4eC",
   "metadata": {
    "id": "5tnQrLVUc4eC"
   },
   "source": [
    "We created a logging directory in the section **Organization**, however, for clarity, we create the `LOGS_DIR` again below (won't be overwritten). We will send all our logs to this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4p-RvPtG1s1z",
   "metadata": {
    "id": "4p-RvPtG1s1z"
   },
   "outputs": [],
   "source": [
    "# Creating Directories\n",
    "BASE_DIR = Path(\"__file__\").parent.absolute()\n",
    "LOGS_DIR = Path(BASE_DIR, \"logs\")\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apWCd7xFzCkE",
   "metadata": {
    "id": "apWCd7xFzCkE"
   },
   "outputs": [],
   "source": [
    "# Logger\n",
    "def init_logger(\n",
    "    logs_dir: Path,\n",
    "    default_level=logging.DEBUG,\n",
    "    stream_level=logging.INFO,\n",
    "    module_name: Optional[str] = None,\n",
    ") -> logging.Logger:\n",
    "    \"\"\"Initialize logger.\n",
    "\n",
    "    Args:\n",
    "        logs_dir (Path): Path to log directory.\n",
    "        default_level (int, optional): Default logging level. Defaults to logging.DEBUG.\n",
    "        stream_level (int, optional): Stream logging level. Defaults to logging.INFO.\n",
    "        module_name (Optional[str]): Module name to be used in logger. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: The logger object.\n",
    "\n",
    "    Example:\n",
    "        >>> import logging\n",
    "        >>> import sys\n",
    "        >>> from pathlib import Path\n",
    "        >>> from typing import Optional\n",
    "        >>> # Creating Directories\n",
    "        >>> BASE_DIR = Path(\"__file__\").parent.parent.absolute()\n",
    "        >>> LOGS_DIR = Path(BASE_DIR, \"logs\")\n",
    "        >>> LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        >>> train_logger = init_logger(LOGS_DIR, module_name=\"train\")\n",
    "        >>> # Logging levels (from lowest to highest priority)\n",
    "        >>> try:\n",
    "        >>>     train_logger.info(\"I am trying to divide by zero!\")\n",
    "        >>>     1 / 0\n",
    "        >>> except ZeroDivisionError as e:\n",
    "        >>>     train_logger.error(e)  # ERROR:root:division by zero\n",
    "        >>>     train_logger.critical(e, exc_info=True)  # Logs error with stack trace\n",
    "    \"\"\"\n",
    "\n",
    "    if module_name is None:\n",
    "        logger = logging.getLogger(__name__)\n",
    "        info_log_filepath = Path(logs_dir, \"info.log\")\n",
    "        error_log_filepath = Path(logs_dir, \"error.log\")\n",
    "    else:\n",
    "        # get module name, useful for multi-module logging\n",
    "        logger = logging.getLogger(module_name)\n",
    "        info_log_filepath = Path(logs_dir, f\"{module_name}_info.log\")\n",
    "        error_log_filepath = Path(logs_dir, f\"{module_name}_error.log\")\n",
    "\n",
    "    logger.setLevel(default_level)\n",
    "    stream_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "    stream_handler.setLevel(stream_level)\n",
    "    stream_handler.setFormatter(\n",
    "        logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s: %(message)s\",\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    info_file_handler = logging.FileHandler(filename=info_log_filepath)\n",
    "    info_file_handler.setLevel(logging.INFO)\n",
    "    info_file_handler.setFormatter(\n",
    "        logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s: %(message)s\",\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # add error file handler\n",
    "    error_file_handler = logging.FileHandler(filename=error_log_filepath)\n",
    "    error_file_handler.setLevel(logging.ERROR)\n",
    "    error_file_handler.setFormatter(\n",
    "        logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s: %(message)s\",\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(info_file_handler)\n",
    "    logger.addHandler(error_file_handler)\n",
    "    logger.propagate = False\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0jM4wp6i2H5Q",
   "metadata": {
    "id": "0jM4wp6i2H5Q"
   },
   "outputs": [],
   "source": [
    "train_logger = init_logger(\n",
    "    logs_dir = LOGS_DIR,\n",
    "    default_level = logging.DEBUG,\n",
    "    stream_level=logging.INFO,\n",
    "    module_name = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xRLY2J4G8Nh2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1651053330276,
     "user": {
      "displayName": "HONGNAN GAO",
      "userId": "14684257183016239750"
     },
     "user_tz": -480
    },
    "id": "xRLY2J4G8Nh2",
    "outputId": "ddbe43eb-10dd-4c46-dee2-358be9009d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 09:55:29 - train - INFO: Informative messages from your code.\n",
      "2022-04-27 09:55:29 - train - WARNING: Everything works but there is something to be aware of.\n",
      "2022-04-27 09:55:29 - train - ERROR: There's been a mistake with the process.\n",
      "2022-04-27 09:55:29 - train - CRITICAL: There is something terribly wrong and process may terminate.\n"
     ]
    }
   ],
   "source": [
    "# Logging levels (from lowest to highest priority)\n",
    "train_logger.debug(\"Used for debugging your code.\")\n",
    "train_logger.info(\"Informative messages from your code.\")\n",
    "train_logger.warning(\"Everything works but there is something to be aware of.\")\n",
    "train_logger.error(\"There's been a mistake with the process.\")\n",
    "train_logger.critical(\"There is something terribly wrong and process may terminate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qGqTso7a9Ni_",
   "metadata": {
    "id": "qGqTso7a9Ni_"
   },
   "source": [
    "Lo and behold, the `train_logger` is behaving properly:\n",
    "- console level: all messages above `INFO` are printed.\n",
    "- info file: all messages above `INFO` are logged in the file.\n",
    "- error file: all messages above `DEBUG` are logged in the file, in particular, messages of lower priority like `.info` and `.debug` are not logged.\n",
    "\n",
    "The reason of having $2$ log files is that one file (info) logs almost everything, while the other (error) only logs the error messages etc. This avoids clutter and eases developer to pin-point errors when reviewing the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x3xuf3R7AXty",
   "metadata": {
    "id": "x3xuf3R7AXty"
   },
   "source": [
    "For completeness sake, we define another `logger` called `inference_logger` and see that it behaves the same, except for the fact that it is logging messages for another module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-nYQMLXI8KHj",
   "metadata": {
    "id": "-nYQMLXI8KHj"
   },
   "outputs": [],
   "source": [
    "inference_logger = init_logger(\n",
    "    logs_dir = LOGS_DIR,\n",
    "    default_level = logging.DEBUG,\n",
    "    stream_level=logging.INFO,\n",
    "    module_name = \"inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15LL61w1_0mR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1651053334037,
     "user": {
      "displayName": "HONGNAN GAO",
      "userId": "14684257183016239750"
     },
     "user_tz": -480
    },
    "id": "15LL61w1_0mR",
    "outputId": "e9cb036f-c36d-4874-cc45-65303c2de4d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 09:55:33 - inference - INFO: Informative messages from your code.\n",
      "2022-04-27 09:55:33 - inference - WARNING: Everything works but there is something to be aware of.\n",
      "2022-04-27 09:55:33 - inference - ERROR: There's been a mistake with the process.\n",
      "2022-04-27 09:55:33 - inference - CRITICAL: There is something terribly wrong and process may terminate.\n"
     ]
    }
   ],
   "source": [
    "# Logging levels (from lowest to highest priority)\n",
    "inference_logger.debug(\"Used for debugging your code.\")\n",
    "inference_logger.info(\"Informative messages from your code.\")\n",
    "inference_logger.warning(\"Everything works but there is something to be aware of.\")\n",
    "inference_logger.error(\"There's been a mistake with the process.\")\n",
    "inference_logger.critical(\"There is something terribly wrong and process may terminate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XwPFDT2LECRd",
   "metadata": {
    "id": "XwPFDT2LECRd"
   },
   "source": [
    "## Example Usage\n",
    "\n",
    "The below small example shows how one can log messages. In particular, in the `except` clause, we called `logging.error(e)` to log the error messages and `logging.critical(e, exc_info=True)` to log both the message and the stack trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kDPF5lkrf473",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1651054242016,
     "user": {
      "displayName": "HONGNAN GAO",
      "userId": "14684257183016239750"
     },
     "user_tz": -480
    },
    "id": "kDPF5lkrf473",
    "outputId": "fa99ecd3-c9ab-44d3-e9bf-101a8533d562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/reighns/config/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CONFIG_DIR}/config.py\n",
    "import logging\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "import datetime\n",
    "\n",
    "# Creating Directories\n",
    "BASE_DIR = Path(__file__).parent.parent.absolute()\n",
    "\n",
    "CONFIG_DIR = Path(BASE_DIR, \"config\")\n",
    "LOGS_DIR = Path(BASE_DIR, \"logs\")\n",
    "SRC_DIR = Path(BASE_DIR, \"src\")\n",
    "DATA_DIR = Path(BASE_DIR, \"data\")\n",
    "STORES_DIR = Path(BASE_DIR, \"stores\")\n",
    "TEST_DIR = Path(BASE_DIR, \"tests\")\n",
    "\n",
    "## Local stores\n",
    "MODEL_REGISTRY = Path(STORES_DIR, \"model\")\n",
    "RAW_DATA = Path(DATA_DIR, \"raw\")\n",
    "PROCESSED_DATA = Path(DATA_DIR, \"processed\")\n",
    "\n",
    "## Create dirs\n",
    "for d in [\n",
    "    CONFIG_DIR,\n",
    "    LOGS_DIR,\n",
    "    DATA_DIR,\n",
    "    STORES_DIR,\n",
    "    TEST_DIR,\n",
    "    MODEL_REGISTRY,\n",
    "    RAW_DATA,\n",
    "    PROCESSED_DATA,\n",
    "]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Logger\n",
    "def init_logger(\n",
    "    logs_dir: Path,\n",
    "    default_level=logging.DEBUG,\n",
    "    stream_level=logging.INFO,\n",
    "    module_name: Optional[str] = None,\n",
    ") -> logging.Logger:\n",
    "    \"\"\"Initialize logger.\n",
    "\n",
    "    Args:\n",
    "        logs_dir (Path): Path to log directory.\n",
    "        default_level (int, optional): Default logging level. Defaults to logging.DEBUG.\n",
    "        stream_level (int, optional): Stream logging level. Defaults to logging.INFO.\n",
    "        module_name (Optional[str]): Module name to be used in logger. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: The logger object.\n",
    "\n",
    "    Example:\n",
    "        >>> import logging\n",
    "        >>> import sys\n",
    "        >>> from pathlib import Path\n",
    "        >>> from typing import Optional\n",
    "        >>> # Creating Directories\n",
    "        >>> BASE_DIR = Path(\"__file__\").parent.parent.absolute()\n",
    "        >>> LOGS_DIR = Path(BASE_DIR, \"logs\")\n",
    "        >>> LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        >>> train_logger = init_logger(LOGS_DIR, module_name=\"train\")\n",
    "        >>> # Logging levels (from lowest to highest priority)\n",
    "        >>> try:\n",
    "        >>>     train_logger.info(\"I am trying to divide by zero!\")\n",
    "        >>>     1 / 0\n",
    "        >>> except ZeroDivisionError as e:\n",
    "        >>>     train_logger.error(e)  # ERROR:root:division by zero\n",
    "        >>>     train_logger.critical(e, exc_info=True)  # Logs error with stack trace\n",
    "    \"\"\"\n",
    "\n",
    "    datetime_ = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if module_name is None:\n",
    "        logger = logging.getLogger(__name__)\n",
    "        info_log_filepath = Path(logs_dir, f\"{datetime_}_info.log\")\n",
    "        error_log_filepath = Path(logs_dir, f\"{datetime_}_error.log\")\n",
    "    else:\n",
    "        # get module name, useful for multi-module logging\n",
    "        logger = logging.getLogger(module_name)\n",
    "        info_log_filepath = Path(\n",
    "            logs_dir, f\"{datetime_}_{module_name}_info.log\"\n",
    "        )\n",
    "        error_log_filepath = Path(\n",
    "            logs_dir, f\"{datetime_}_{module_name}_error.log\"\n",
    "        )\n",
    "\n",
    "    logger.setLevel(default_level)\n",
    "    stream_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "    stream_handler.setLevel(stream_level)\n",
    "    stream_handler.setFormatter(\n",
    "        logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s: %(message)s\",\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    info_file_handler = logging.FileHandler(filename=info_log_filepath)\n",
    "    info_file_handler.setLevel(logging.INFO)\n",
    "    info_file_handler.setFormatter(\n",
    "        logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s: %(message)s\",\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # add error file handler\n",
    "    error_file_handler = logging.FileHandler(filename=error_log_filepath)\n",
    "    error_file_handler.setLevel(logging.ERROR)\n",
    "    error_file_handler.setFormatter(\n",
    "        logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s: %(message)s\",\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(info_file_handler)\n",
    "    logger.addHandler(error_file_handler)\n",
    "    logger.propagate = False\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BSJlP-mmgJuB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1651054509956,
     "user": {
      "displayName": "HONGNAN GAO",
      "userId": "14684257183016239750"
     },
     "user_tz": -480
    },
    "id": "BSJlP-mmgJuB",
    "outputId": "475ea833-c534-4c95-f6db-b7793671f9b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/reighns/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {BASE_DIR}/main.py\n",
    "import logging\n",
    "from config import config\n",
    "\n",
    "def divide_by_zero(logger: logging.Logger):\n",
    "    try:\n",
    "        logger.info(\"I am trying to divide by zero!\")\n",
    "        1 / 0\n",
    "    except ZeroDivisionError as e:\n",
    "        logger.error(e)  # ERROR:root:division by zero\n",
    "        logger.critical(e, exc_info=True)  # Logs error with stack trace\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_logger = config.init_logger(\n",
    "            logs_dir = config.LOGS_DIR,\n",
    "            default_level = logging.DEBUG,\n",
    "            stream_level=logging.INFO,\n",
    "            module_name = \"train\")\n",
    "    divide_by_zero(train_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oX9Usi75ED_3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1651054511033,
     "user": {
      "displayName": "HONGNAN GAO",
      "userId": "14684257183016239750"
     },
     "user_tz": -480
    },
    "id": "oX9Usi75ED_3",
    "outputId": "537ef071-aa73-4240-c9a5-29b5ad551cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 10:15:10 - train - INFO: I am trying to divide by zero!\n",
      "2022-04-27 10:15:10 - train - ERROR: division by zero\n",
      "2022-04-27 10:15:10 - train - CRITICAL: division by zero\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 7, in divide_by_zero\n",
      "    1 / 0\n",
      "ZeroDivisionError: division by zero\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PRVGzMkNo9X3",
   "metadata": {
    "id": "PRVGzMkNo9X3"
   },
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NDqFg1mAo_ON",
   "metadata": {
    "id": "NDqFg1mAo_ON"
   },
   "source": [
    "### Workflow in IDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TKuEDAtlpCaV",
   "metadata": {
    "id": "TKuEDAtlpCaV"
   },
   "source": [
    "### Workflow in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DFPSJ107pLkb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1651054242016,
     "user": {
      "displayName": "HONGNAN GAO",
      "userId": "14684257183016239750"
     },
     "user_tz": -480
    },
    "id": "DFPSJ107pLkb",
    "outputId": "fa99ecd3-c9ab-44d3-e9bf-101a8533d562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/reighns/config/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CONFIG_DIR}/config.py\n",
    "import logging\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "# Creating Directories\n",
    "BASE_DIR = Path(__file__).parent.parent.absolute()\n",
    "\n",
    "CONFIG_DIR = Path(BASE_DIR, \"config\")\n",
    "LOGS_DIR = Path(BASE_DIR, \"logs\")\n",
    "SRC_DIR = Path(BASE_DIR, \"src\")\n",
    "DATA_DIR = Path(BASE_DIR, \"data\")\n",
    "STORES_DIR = Path(BASE_DIR, \"stores\")\n",
    "TEST_DIR = Path(BASE_DIR, \"tests\")\n",
    "\n",
    "## Local stores\n",
    "MODEL_REGISTRY = Path(STORES_DIR, \"model\")\n",
    "RAW_DATA = Path(DATA_DIR, \"raw\")\n",
    "PROCESSED_DATA = Path(DATA_DIR, \"processed\")\n",
    "\n",
    "## Create dirs\n",
    "for d in [\n",
    "    CONFIG_DIR,\n",
    "    LOGS_DIR,\n",
    "    DATA_DIR,\n",
    "    STORES_DIR,\n",
    "    TEST_DIR,\n",
    "    MODEL_REGISTRY,\n",
    "    RAW_DATA,\n",
    "    PROCESSED_DATA,\n",
    "]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Logger\n",
    "def init_logger(\n",
    "    logs_dir: Path,\n",
    "    default_level=logging.DEBUG,\n",
    "    stream_level=logging.INFO,\n",
    "    module_name: Optional[str] = None,\n",
    ") -> logging.Logger:\n",
    "    \"\"\"Initialize logger.\n",
    "\n",
    "    Args:\n",
    "        logs_dir (Path): Path to log directory.\n",
    "        default_level (int, optional): Default logging level. Defaults to logging.DEBUG.\n",
    "        stream_level (int, optional): Stream logging level. Defaults to logging.INFO.\n",
    "        module_name (Optional[str]): Module name to be used in logger. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: The logger object.\n",
    "\n",
    "    Example:\n",
    "        >>> import logging\n",
    "        >>> import sys\n",
    "        >>> from pathlib import Path\n",
    "        >>> from typing import Optional\n",
    "        >>> # Creating Directories\n",
    "        >>> BASE_DIR = Path(\"__file__\").parent.parent.absolute()\n",
    "        >>> LOGS_DIR = Path(BASE_DIR, \"logs\")\n",
    "        >>> LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        >>> train_logger = init_logger(LOGS_DIR, module_name=\"train\")\n",
    "        >>> # Logging levels (from lowest to highest priority)\n",
    "        >>> try:\n",
    "        >>>     train_logger.info(\"I am trying to divide by zero!\")\n",
    "        >>>     1 / 0\n",
    "        >>> except ZeroDivisionError as e:\n",
    "        >>>     train_logger.error(e)  # ERROR:root:division by zero\n",
    "        >>>     train_logger.critical(e, exc_info=True)  # Logs error with stack trace\n",
    "    \"\"\"\n",
    "\n",
    "    if module_name is None:\n",
    "        logger = logging.getLogger(__name__)\n",
    "        info_log_filepath = Path(logs_dir, \"info.log\")\n",
    "        error_log_filepath = Path(logs_dir, \"error.log\")\n",
    "    else:\n",
    "        # get module name, useful for multi-module logging\n",
    "        logger = logging.getLogger(module_name)\n",
    "        info_log_filepath = Path(logs_dir, f\"{module_name}_info.log\")\n",
    "        error_log_filepath = Path(logs_dir, f\"{module_name}_error.log\")\n",
    "\n",
    "    logger.setLevel(default_level)\n",
    "    stream_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "    stream_handler.setLevel(stream_level)\n",
    "    stream_handler.setFormatter(\n",
    "        logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s: %(message)s\",\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    info_file_handler = logging.FileHandler(filename=info_log_filepath)\n",
    "    info_file_handler.setLevel(logging.INFO)\n",
    "    info_file_handler.setFormatter(\n",
    "        logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s: %(message)s\",\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # add error file handler\n",
    "    error_file_handler = logging.FileHandler(filename=error_log_filepath)\n",
    "    error_file_handler.setLevel(logging.ERROR)\n",
    "    error_file_handler.setFormatter(\n",
    "        logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s: %(message)s\",\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(info_file_handler)\n",
    "    logger.addHandler(error_file_handler)\n",
    "    logger.propagate = False\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4AiCGAIvpLkc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1651054509956,
     "user": {
      "displayName": "HONGNAN GAO",
      "userId": "14684257183016239750"
     },
     "user_tz": -480
    },
    "id": "4AiCGAIvpLkc",
    "outputId": "475ea833-c534-4c95-f6db-b7793671f9b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/reighns/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {BASE_DIR}/main.py\n",
    "import logging\n",
    "from config import config\n",
    "\n",
    "def divide_by_zero(logger: logging.Logger):\n",
    "    try:\n",
    "        logger.info(\"I am trying to divide by zero!\")\n",
    "        1 / 0\n",
    "    except ZeroDivisionError as e:\n",
    "        logger.error(e)  # ERROR:root:division by zero\n",
    "        logger.critical(e, exc_info=True)  # Logs error with stack trace\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_logger = config.init_logger(\n",
    "            logs_dir = config.LOGS_DIR,\n",
    "            default_level = logging.DEBUG,\n",
    "            stream_level=logging.INFO,\n",
    "            module_name = \"train\")\n",
    "    divide_by_zero(train_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GQx946W5pLkc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1651054511033,
     "user": {
      "displayName": "HONGNAN GAO",
      "userId": "14684257183016239750"
     },
     "user_tz": -480
    },
    "id": "GQx946W5pLkc",
    "outputId": "537ef071-aa73-4240-c9a5-29b5ad551cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 10:15:10 - train - INFO: I am trying to divide by zero!\n",
      "2022-04-27 10:15:10 - train - ERROR: division by zero\n",
      "2022-04-27 10:15:10 - train - CRITICAL: division by zero\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 7, in divide_by_zero\n",
      "    1 / 0\n",
      "ZeroDivisionError: division by zero\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I0eTFyYoaBmD",
   "metadata": {
    "id": "I0eTFyYoaBmD"
   },
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O42a-78ufM_o",
   "metadata": {
    "id": "O42a-78ufM_o"
   },
   "source": [
    "## TODO Log\n",
    "\n",
    "- Each individual ML experiment should come with its own log file for clarity. That means, if we have a total of $3$ experiments of a ML project, named `exp_1, exp_2, exp_3`, then each of their log files should be separated accordingly as well.\n",
    "\n",
    "- If we find ourself adding too many `handlers` to the function, then we may define a `logging` config like in [https://madewithml.com/courses/mlops/logging/](https://madewithml.com/courses/mlops/logging/).\n",
    "\n",
    "- If can have one log file with multiple module references instead of multiple log files individually.\n",
    "\n",
    "- Add timestamp prefix for logger (experiment).\n",
    "\n",
    "- For more practices, one can refer to the references below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3KtSrTA6ITID",
   "metadata": {
    "id": "3KtSrTA6ITID"
   },
   "source": [
    "## References\n",
    "\n",
    "- https://docs.python.org/3/howto/logging-cookbook.html\n",
    "- https://docs.python.org/3/library/logging.html#\n",
    "- https://madewithml.com/courses/mlops/logging/\n",
    "- Using logging in multiple modules: https://docs.python.org/3/howto/logging-cookbook.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03.logging.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "fee21ade325d7bec1bc496fe52256a16c1a1d317ab64df50f935c606415019bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
