
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Stage 5. Model Development and Training (MLOps) &#8212; Omniverse</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=bb35926c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../../../_static/tabs.js?v=3ee01567"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-MYW5YKC2WF"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-MYW5YKC2WF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-MYW5YKC2WF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'operations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline';</script>
    <link rel="canonical" href="https://www.gaohongnan.com/operations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Stage 5.1. Model Selection" href="051_model_selection.html" />
    <link rel="prev" title="Stage 4. Data Extraction (MLOps), Data Analysis (Data Science), Data Preparation (Data Science)" href="../04_mlops_data_pipeline.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="Omniverse - Home"/>
    <script>document.write(`<img src="../../../_static/logo.png" class="logo__image only-dark" alt="Omniverse - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    ðŸŒŒ Omniverse: A Journey Through Knowledge
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Notations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../notations/machine_learning.html">Machine Learning Notations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Influential Ideas and Papers</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../influential/generative_pretrained_transformer/01_intro.html">Generative Pre-trained Transformers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../influential/generative_pretrained_transformer/02_notations.html">Notations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../influential/generative_pretrained_transformer/03_concept.html">The Concept of Generative Pre-trained Transformers (GPT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../influential/generative_pretrained_transformer/04_implementation.html">The Implementation of Generative Pre-trained Transformers (GPT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../influential/generative_pretrained_transformer/05_adder.html">Training a Mini-GPT to Learn Two-Digit Addition</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../influential/low_rank_adaptation/01_intro.html">Low-Rank Adaptation Of Large Language Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../influential/low_rank_adaptation/02_concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../influential/low_rank_adaptation/03_implementation.html">Implementation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../influential/kmeans_clustering/01_intro.html">K-Means</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../influential/kmeans_clustering/02_concept.html">Concept: K-Means Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../influential/kmeans_clustering/03_implementation.html">Implementation: K-Means (Lloyd)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../influential/kmeans_clustering/04_image_segmentation.html">Application: Image Compression and Segmentation</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Playbook</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../playbook/how_to_calculate_flops_in_transformer_based_models.html">How to Calculate the Number of FLOPs in Transformer Based Models?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../playbook/how_to_inspect_function_and_class_signatures.html">How to Inspect Function and Class Signatures in Python?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../playbook/why_cosine_annealing_warmup_stabilize_training.html">Why Does Cosine Annealing With Warmup Stabilize Training?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../playbook/why_softmax_preserves_order_translation_invariant_not_invariant_scaling.html">Softmax Preserves Order, Is Translation Invariant But Not Invariant Under Scaling.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../playbook/how_to_finetune_decoder_with_last_token_pooling.html">How To Fine-Tune Decoder-Only Models For Sequence Classification Using Last Token Pooling?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../playbook/how_to_finetune_decoder_with_cross_attention.html">How To Fine-Tune Decoder-Only Models For Sequence Classification With Cross-Attention?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../playbook/how_to_teacher_student_knowledge_distillation.html">How To Do Teacher-Student Knowledge Distillation?</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Operations</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../distributed/intro.html">Distributed Systems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../distributed/01_notations.html">Notations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../distributed/02_basics.html">Basics Of Distributed Data Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../distributed/03_how_to_setup_slurm_in_aws.html">How to Setup SLURM and ParallelCluster in AWS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../distributed/04_ablation.html">Ablations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../profiling/intro.html">Profiling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../profiling/01_synchronize.html">Synchronize CUDA To Time CUDA Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../profiling/02_timeit.html">Profiling Code With Timeit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../profiling/03_time_profiler.html">PyTorchâ€™s Event And Profiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../profiling/04_small_gpt_profile.html">Profile GPT Small Time And Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../profiling/05_memory_leak.html">CUDA Memory Allocations</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../00_intro.html">The Lifecycle of an AIOps System</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../01_problem_formulation.html">Stage 1. Problem Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02_project_scoping.html">Stage 2. Project Scoping And Framing The Problem</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../03_dataops_pipeline/03_dataops_pipeline.html">Stage 3. Data Pipeline (Data Engineering and DataOps)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../03_dataops_pipeline/031_data_source_and_format.html">Stage 3.1. Data Source and Formats</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_dataops_pipeline/032_data_model_and_storage.html">Stage 3.2. Data Model and Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_dataops_pipeline/033_etl.html">Stage 3.3. Extract, Transform, Load (ETL)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../04_mlops_data_pipeline.html">Stage 4. Data Extraction (MLOps), Data Analysis (Data Science), Data Preparation (Data Science)</a></li>
<li class="toctree-l2 current active has-children"><a class="current reference internal" href="#">Stage 5. Model Development and Training (MLOps)</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="051_model_selection.html">Stage 5.1. Model Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="052_metric_selection.html">Stage 5.2. Metric Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="053_experiment_tracking.html">Stage 5.3. Experiment Tracking And Versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="054_model_testing.html">Stage 5.4. Model Testing</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../06_model_evaluation.html">Stage 6. Model Evaluation (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../07_model_validation_registry_and_pushing_model_to_production.html">Stage 7. Model Validation, Registry and Pushing Model to Production (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_model_deployment_and_serving.html">Stage 8. Model Serving (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../09_model_monitoring.html">Stage 9. Model Monitoring (MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../010_continuous_integration_deployment_learning_and_training.html">Stage 10. Continuous Integration, Deployment, Learning and Training (DevOps, DataOps, MLOps)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../011_infrastructure_and_tooling_for_mlops.html">Stage 11. Infrastructure and Tooling for MLOps</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Software Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../software_engineering/config_management/concept.html">Configuration Management</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../software_engineering/config_management/01-pydra.html">Pydantic And Hydra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../software_engineering/config_management/02-state.html">State And Metadata Management</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../software_engineering/design_patterns/intro.html">Design Patterns</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../software_engineering/design_patterns/dependency-inversion-principle.html">Dependency Inversion Principle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../software_engineering/design_patterns/strategy.html">Strategy Pattern</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../software_engineering/design_patterns/registry.html">Registry Design Pattern</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../software_engineering/concurrency_parallelism_asynchronous/intro.html">Concurrency, Parallelism and Asynchronous Programming</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../software_engineering/concurrency_parallelism_asynchronous/generator_yield.html">A Rudimentary Introduction to Generator and Yield in Python</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Computer Science</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../computer_science/type_theory/intro.html">Type Theory, A Very Rudimentary Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../computer_science/type_theory/01-subtypes.html">Subtypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../computer_science/type_theory/02-type-safety.html">Type Safety</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../computer_science/type_theory/03-subsumption.html">Subsumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../computer_science/type_theory/04-generics.html">Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../computer_science/type_theory/05-typevar-bound-constraints.html">Bound and Constraint in Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../computer_science/type_theory/06-invariance-covariance-contravariance.html">Invariance, Covariance and Contravariance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../computer_science/type_theory/07-pep-3124-overloading.html">Function Overloading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../computer_science/type_theory/08-pep-661-sentinel-values.html">Sentinel Types</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Structures and Algorithms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../dsa/complexity_analysis/intro.html">Complexity Analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../dsa/complexity_analysis/master_theorem.html">Master Theorem </a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../dsa/stack/intro.html">Stack</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../dsa/stack/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../dsa/searching_algorithms/linear_search/intro.html">Linear Search</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../dsa/searching_algorithms/linear_search/concept.html">Concept</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../dsa/searching_algorithms/binary_search/intro.html">Binary Search</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../dsa/searching_algorithms/binary_search/concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../dsa/searching_algorithms/binary_search/problems/875-koko-eating-bananas.html">Koko Eating Bananas</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Algebra</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../linear_algebra/01_preliminaries/intro.html">Preliminaries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../linear_algebra/01_preliminaries/01-fields.html">Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../linear_algebra/01_preliminaries/02-systems-of-linear-equations.html">Systems of Linear Equations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../linear_algebra/02_vectors/intro.html">Vectors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../linear_algebra/02_vectors/01-vector-definition.html">Vector and Its Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../linear_algebra/02_vectors/02-vector-operation.html">Vector and Its Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../linear_algebra/02_vectors/03-vector-norm.html">Vector Norm and Distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../linear_algebra/02_vectors/04-vector-products.html">A First Look at Vector Products</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Probability Theory</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../probability_theory/01_mathematical_preliminaries/intro.html">Chapter 1. Mathematical Preliminaries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/01_mathematical_preliminaries/01_combinatorics.html">Permutations and Combinations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/01_mathematical_preliminaries/02_calculus.html">Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/01_mathematical_preliminaries/03_contours.html">Contour Maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/01_mathematical_preliminaries/exercises.html">Exercises</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References, Resources and Roadmap</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../citations.html">IEEE (Style) Citations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../api/reproducibility.html">API Reference</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/gao-hongnan/omniverse/blob/main/omniverse/operations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline.md" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gao-hongnan/omniverse" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gao-hongnan/omniverse/issues/new?title=Issue%20on%20page%20%2Foperations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/operations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline.ipynb" target="_blank"
   class="btn btn-sm btn-download-notebook-button dropdown-item"
   title="Download notebook file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li><a href="../../../_sources/operations/machine_learning_lifecycle/05_model_development_selection_and_training/05_ml_training_pipeline.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Stage 5. Model Development and Training (MLOps)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-model-loss-and-data-paradigm">The Model, Loss and Data Paradigm</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-curves">Learning Curves</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ablation-studies">Ablation Studies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-tuning">Hyperparameter Tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">Cross-Validation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-caution-on-data-leakage">A Caution on Data Leakage</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-model-training">Final Model Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-chronicles">Training Chronicles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-note-on-cross-validation">A Note On Cross-validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-training-dependent-on-monitoring-of-drifts">Continuous Training (Dependent on Monitoring of Drifts)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-is-the-mlops">Where Is The MLOps?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references-and-further-readings">References and Further Readings</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="stage-5-model-development-and-training-mlops">
<h1>Stage 5. Model Development and Training (MLOps)<a class="headerlink" href="#stage-5-model-development-and-training-mlops" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="https://twitter.com/gaohongnan"><img alt="Twitter Handle" src="https://img.shields.io/badge/Twitter-&#64;gaohongnan-blue?style=social&amp;logo=twitter" /></a>
<a class="reference external" href="https://linkedin.com/in/gao-hongnan"><img alt="LinkedIn Profile" src="https://img.shields.io/badge/&#64;gaohongnan-blue?style=social&amp;logo=linkedin" /></a>
<a class="reference external" href="https://github.com/gao-hongnan"><img alt="GitHub Profile" src="https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&amp;logo=github" /></a>
<img alt="Tag" src="https://img.shields.io/badge/Tag-Brain_Dump-red" />
<img alt="Tag" src="https://img.shields.io/badge/Level-Beginner-green" /></p>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#the-model-loss-and-data-paradigm" id="id1">The Model, Loss and Data Paradigm</a></p>
<ul>
<li><p><a class="reference internal" href="#learning-curves" id="id2">Learning Curves</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#ablation-studies" id="id3">Ablation Studies</a></p></li>
<li><p><a class="reference internal" href="#hyperparameter-tuning" id="id4">Hyperparameter Tuning</a></p></li>
<li><p><a class="reference internal" href="#cross-validation" id="id5">Cross-Validation</a></p>
<ul>
<li><p><a class="reference internal" href="#a-caution-on-data-leakage" id="id6">A Caution on Data Leakage</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#final-model-training" id="id7">Final Model Training</a></p></li>
<li><p><a class="reference internal" href="#training-chronicles" id="id8">Training Chronicles</a></p></li>
<li><p><a class="reference internal" href="#a-note-on-cross-validation" id="id9">A Note On Cross-validation</a></p></li>
<li><p><a class="reference internal" href="#continuous-training-dependent-on-monitoring-of-drifts" id="id10">Continuous Training (Dependent on Monitoring of Drifts)</a></p></li>
<li><p><a class="reference internal" href="#where-is-the-mlops" id="id11">Where Is The MLOps?</a></p></li>
<li><p><a class="reference internal" href="#references-and-further-readings" id="id12">References and Further Readings</a></p></li>
</ul>
</nav>
<p>In this stage, the prepared data is used to train machine learning models, some
key stages are listed below.</p>
<div class="pst-scrollable-table-container"><table class="table" id="ml-lifecycle-model-development-training-some-key-stages">
<caption><span class="caption-number">Table 24 </span><span class="caption-text">Some Key Stages In Model Development and Training</span><a class="headerlink" href="#ml-lifecycle-model-development-training-some-key-stages" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Step</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Model Selection</p></td>
<td><p>Choose suitable models based on the problem type (regression,
classification, clustering, etc.), data characteristics, and size.</p></td>
</tr>
<tr class="row-odd"><td><p>Evaluation Metric Selection</p></td>
<td><p>Decide on appropriate metrics to evaluate model performance. The choice
of metrics depends on the problem type and the business objective. For
example, accuracy, precision, recall, F1-score may be suitable for
classification problems, whereas Mean Absolute Error (MAE), Root Mean
Squared Error (RMSE), or R-squared might be chosen for regression
problems.</p></td>
</tr>
<tr class="row-even"><td><p>Baseline Model</p></td>
<td><p>Train a simple or naive model using a standard technique. This model
serves as a reference point or benchmark to compare with more
sophisticated models. You can refer to scikit-learnâ€™s
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"><code class="docutils literal notranslate"><span class="pre">Dummy</span></code></a>
module for this purpose. For instance, if you are training a binary
classification model, predicting the majority class could serve as the
baseline model.</p></td>
</tr>
<tr class="row-odd"><td><p>Training</p></td>
<td><p>Use the training dataset to train the selected models. This process
involves adjusting the model parameters to minimize a certain loss
function, relevant to the task at hand.</p></td>
</tr>
<tr class="row-even"><td><p>Cross-Validation</p></td>
<td><p>This method involves splitting the training dataset into <span class="math notranslate nohighlight">\(K\)</span> subsets,
then training the model <span class="math notranslate nohighlight">\(K\)</span> times, each time using a different subset as
the validation set and the remaining data as the training set. This
provides a robust estimate of model performance, as the modelâ€™s ability
to generalize is tested on different subsets of data. Common methods
include <span class="math notranslate nohighlight">\(K\)</span>-fold cross-validation, stratified <span class="math notranslate nohighlight">\(K\)</span>-fold (especially for
imbalanced datasets), and time series cross-validation (for time series
data).</p></td>
</tr>
<tr class="row-odd"><td><p>Hyperparameter Tuning</p></td>
<td><p>Enhance model performance by optimizing the modelâ€™s hyperparameters.
This often involves methods like grid search, random search, or Bayesian
optimization to find the optimal set of hyperparameters.</p>
<p>In the Model Training stage, cross-validation is typically used in
conjunction with hyperparameter tuning. For example, you might use
cross-validation to estimate the performance of different sets of
hyperparameters and choose the set that yields the best cross-validated
performance. In this context, cross-validation is a tool to prevent
overfitting during the model training process. Youâ€™re not so much
interested in the exact cross-validated performance estimate, but in
which set of hyperparameters performs the best on average.</p>
</td>
</tr>
<tr class="row-even"><td><p>Final Model Training</p></td>
<td><p>Once the best hyperparameters are identified, train the final model
using these optimized configurations. Ensure to evaluate the modelâ€™s
performance on a validation dataset to verify its ability to generalize
well to unseen data.</p></td>
</tr>
</tbody>
</table>
</div>
<p>In the training stage, cross-validation is used primarily for model selection
and hyperparameter tuning. Here, cross-validation helps estimate how well
different models or hyperparameters will perform on unseen data, based on
different splits of the training data. The goal is to tune and select a model
that is expected to perform well on new data.</p>
<p>Remember that the model training process can involve iterative loops of steps
like feature selection, model selection, and hyperparameter tuning until the
satisfactory performance is achieved. This process must be automated and
reproducible via pipelines - and this is where MLOps practices come into play.</p>
<section id="the-model-loss-and-data-paradigm">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">The Model, Loss and Data Paradigm</a><a class="headerlink" href="#the-model-loss-and-data-paradigm" title="Link to this heading">#</a></h2>
<p>Basically to construct a model, you need to define the model architecture
<span class="math notranslate nohighlight">\(\mathcal{G}\)</span>, the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>, and the data
<span class="math notranslate nohighlight">\(\mathcal{S} \overset{\mathrm{iid}}{\sim} \mathcal{D}\)</span>.</p>
<p>The model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> is one such choice in the hypothesis space
<span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is the objective function where
we typically employ a learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> to minimize the loss
function over the data <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
<p>This series is more on MLOps, and we wonâ€™t go too deep into the theory like the
empirical risk minimization principle, or learning theory like VC dimension,
bias-variance tradeoff, etc - which is really important to have a basic
understanding of when doing model development. For example, knowing the VC
dimension allows you to understand the modelâ€™s capacity and generalization
ability.</p>
<section id="learning-curves">
<h3><a class="toc-backref" href="#id2" role="doc-backlink">Learning Curves</a><a class="headerlink" href="#learning-curves" title="Link to this heading">#</a></h3>
<p>Although one might need to fully grasp things like VC dimension in rigour. But
one should definitely look at things like learning curves. Note that learning
curves is not just you plotting the training and validation loss over the number
of epochs. You would have the number of samples on the x-axis and the error on
the y-axis - so you can have a good gauge on the scalability of the model.</p>
<div class="seealso admonition">
<p class="admonition-title">See Also</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html">Plotting Learning Curves and Checking Modelsâ€™ Scalability</a></p></li>
</ul>
</div>
</section>
</section>
<section id="ablation-studies">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Ablation Studies</a><a class="headerlink" href="#ablation-studies" title="Link to this heading">#</a></h2>
<p>We can run a few chosen models with default hyperparameters and see which one is
doing good. But no oneâ€™s stopping you from trying multiple models. But be sure
to understand why things work or donâ€™t work. One can do ablation studies to
understand the importance of each component in the model - like for example when
you did not expect the model to perform well, but it did, you can do ablation
studies to understand why it worked (i.e. say remove or replace a component and
see if the performance drops).</p>
</section>
<section id="hyperparameter-tuning">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Hyperparameter Tuning</a><a class="headerlink" href="#hyperparameter-tuning" title="Link to this heading">#</a></h2>
<p>Once youâ€™ve selected a model, the next step is to tune its hyperparameters.
Hyperparameters are the configuration settings of the model that are set before
the learning process begins. They control the behavior of the model and can
significantly impact its performance.</p>
<p>For instance, in a decision tree, the maximum depth of the tree is a
hyperparameter. In a neural network, the learning rate, number of layers, and
number of neurons per layer are all hyperparameters.</p>
<p>There are various strategies for hyperparameter tuning, including:</p>
<ul class="simple">
<li><p><strong>Grid Search</strong>: This involves exhaustively testing a predefined set of
hyperparameters to see which combination yields the best performance.</p></li>
<li><p><strong>Random Search</strong>: Rather than testing all combinations, random search
selects random combinations of the hyperparameters to test. This can be more
efficient than grid search, especially when dealing with a large number of
hyperparameters.</p></li>
<li><p><strong>Bayesian Optimization</strong>: This is a more advanced method that uses the
concept of probability to find the minimum of a function, which in this case
is the modelâ€™s error function.</p></li>
</ul>
<p>Hyperparameter tuning can be computationally expensive, but it can also
significantly improve model performance.</p>
</section>
<section id="cross-validation">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Cross-Validation</a><a class="headerlink" href="#cross-validation" title="Link to this heading">#</a></h2>
<p>Cross-validation is a technique used to assess the predictive performance of a
model and ensure that itâ€™s not overfitting to the training data.</p>
<p>It involves splitting the dataset into <span class="math notranslate nohighlight">\(K\)</span> groups or â€˜foldsâ€™. Then, we train the
model on <span class="math notranslate nohighlight">\(K\)</span>-1 folds and test it on the remaining fold. We repeat this process
<span class="math notranslate nohighlight">\(K\)</span> times, each time testing on a different fold. The average performance across
all <span class="math notranslate nohighlight">\(K\)</span> trials is then used as the overall performance measure of the model.</p>
<p>Cross-validation provides a more robust estimate of the modelâ€™s performance on
unseen data compared to using a single train-test split. The most common form of
cross-validation is <span class="math notranslate nohighlight">\(K\)</span>-fold cross-validation, where <span class="math notranslate nohighlight">\(K\)</span> is often set to 5
or 10.</p>
<section id="a-caution-on-data-leakage">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">A Caution on Data Leakage</a><a class="headerlink" href="#a-caution-on-data-leakage" title="Link to this heading">#</a></h3>
<p>We have seen in earlier chapters that data leakage can occur when information
from the validation/test set is used to train the model. This can lead to overly
optimistic results. The most common pitfalls is for instance, perform
preprocessing on the whole dataset before splitting.</p>
<p>Another common mistake is about groups, consider the following example:</p>
<p>Consider a dataset of patients, where multiple rows belong to the same patient,
recording different visits to a medical facility. Each row represents a
different visit and includes features like the symptoms reported, tests
conducted, and the final diagnosis.</p>
<p>Letâ€™s suppose weâ€™re trying to build a model to predict a specific disease based
on the symptoms and tests. We could use cross-validation to estimate our modelâ€™s
performance, where we randomly split our data into training and validation sets.
However, this method could lead to data leakage.</p>
<p>Why? Because information about the same patient could end up in both the
training and validation set. Our model might seem to perform well because itâ€™s
not so much learning the relationship between symptoms and disease but instead
memorizing information about specific patients.</p>
<p>In such cases, it is more appropriate to use a technique like GroupKFold from
scikit-learn. This method ensures that the same group (in this case, the same
patient) does not appear in both the training and validation set. It essentially
treats each patient as a separate group and ensures that all entries from a
particular patient are either in the training set or the validation set, but not
in both.</p>
<p>By doing this, we ensure our model generalizes better to new patients since the
validation set only contains patients that the model hasnâ€™t seen during
training. This would give us a more realistic estimate of how well our model
would perform in a real-world setting, where it needs to make predictions for
new patients it hasnâ€™t seen before.</p>
<p>Furthermore, in this specific example, it is common that the label/target is
whether the patient has a certain disease, for instance, cancer. And the
positive label of cancer is rare, so you need to use <code class="docutils literal notranslate"><span class="pre">StratifiedGroupKFold</span></code> to
ensure that the positive label is distributed evenly across the folds, alongside
the grouping.</p>
</section>
</section>
<section id="final-model-training">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Final Model Training</a><a class="headerlink" href="#final-model-training" title="Link to this heading">#</a></h2>
<p>After a comprehensive process of baseline modeling, iterative experimentation,
and hyperparameter tuning, we will have identified the optimal configurations
for our chosen model. The final stage in model training involves using these
configurations to train our final model.</p>
<p>Hereâ€™s what that might look like:</p>
<ul class="simple">
<li><p><strong>Training with Optimized Configurations</strong>: Utilize the optimal
hyperparameters discovered during the tuning process to train the model.</p></li>
<li><p><strong>Full Dataset Utilization</strong>: Often, the final model is trained on the full
training dataset. Weâ€™ve already determined that our model and its
configurations are robust and reliable, so we can now use as much data as
available to optimize the modelâ€™s learning.</p></li>
<li><p><strong>Validation Performance</strong>: Despite training on the full dataset, it remains
crucial to evaluate the final modelâ€™s performance on a held-out validation
dataset. This will provide the last check on the modelâ€™s ability to
generalize to unseen data, ensuring its robustness and reliability.</p></li>
</ul>
<p>Remember, this entire process, from initial baseline model to final model
training, might be iterated several times as new insights, data, or resources
become available. Machine learning model development is a highly iterative and
evolving process, constantly moving towards better and more reliable
predictions.</p>
<p>This iterative nature of model development highlights the importance of
meticulous experiment tracking, allowing for comparison, reproducibility, and
efficient backtracking when needed.</p>
</section>
<section id="training-chronicles">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">Training Chronicles</a><a class="headerlink" href="#training-chronicles" title="Link to this heading">#</a></h2>
<p>One can write a book if they want to document all the tricks, tips and insights
they have learned during the model development and training process. For
example, a beginner might take a while to realise that the learning rate is
perhaps one of the most important hyperparameters to tune when training a large
deep neural network. One can always use a learning rate finder where the idea is
to fit a few batches to see the initial learning rate and loss and treat it as
hyperparameter tuning on a very small subset. Having a small debug dataset is
also useful for quick tuning.</p>
<p>And perhaps a bit more advanced users would know that tracking gradient norms,
activations and their distributions are important to diagnose issues such as
gradient explosion or vanishing problem. After all, deep learning models are
<em>chaotic</em> systems, deterministic yet sensitive to initial conditions.</p>
<p><a class="reference external" href="http://Fast.ai">Fast.ai</a> and Kaggle offer a wealth of model development tips and tricks,
including SOTA techniques and best practices. You can couple the tricks with
papers and you are good to go!</p>
</section>
<section id="a-note-on-cross-validation">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">A Note On Cross-validation</a><a class="headerlink" href="#a-note-on-cross-validation" title="Link to this heading">#</a></h2>
<p>The idea is usually as such, in training, say we split the dataset into 5 folds,
then we have five models, each trained on 4 folds and evaluated on the remaining
fold.</p>
<p>In <span class="math notranslate nohighlight">\(K\)</span>-fold cross-validation (along with its variants), hyperparameters are
typically chosen based on the average performance across all folds. The idea is
to identify the hyperparameters that, on average, lead to the best model
performance. Hereâ€™s how this process usually works:</p>
<ol class="arabic">
<li><p><strong>Set up a grid of hyperparameters</strong>: You specify a range of possible values
for each hyperparameter that you want to optimize.</p></li>
<li><p><strong>Train and evaluate a model for each combination of hyperparameters</strong>: For
each combination, you perform a <span class="math notranslate nohighlight">\(K\)</span>-fold cross-validation. This means
training and evaluating a model on each fold and calculating the average
performance across all folds.</p>
<p>Here you must be careful! The hyperparameters chosen are fixed for all <span class="math notranslate nohighlight">\(K\)</span>
folds!</p>
</li>
<li><p><strong>Select the best hyperparameters</strong>: The best hyperparameters are the ones
that led to the best average performance across all folds.</p></li>
</ol>
<p>In Kaggle, we always average <span class="math notranslate nohighlight">\(K\)</span> folds, this is more geared towards
stacking/ensembling, and is not part of our scope here.</p>
</section>
<section id="continuous-training-dependent-on-monitoring-of-drifts">
<h2><a class="toc-backref" href="#id10" role="doc-backlink">Continuous Training (Dependent on Monitoring of Drifts)</a><a class="headerlink" href="#continuous-training-dependent-on-monitoring-of-drifts" title="Link to this heading">#</a></h2>
<p>Continuous Training refers to the ongoing process of re-training machine
learning models on fresh data. This process is necessary because the performance
of a model might degrade over time as the underlying data distribution changes -
a phenomenon known as concept drift. So one can say that it is an extension or
part of CI/CD.</p>
<p>Machine Learning models might not always maintain their predictive power due to
changes in data over time (concept drift). Continuous Training addresses this by
regularly retraining models on new data, or whenever the model performance
degrades beyond an acceptable level. This step involves monitoring model
performance over time, collecting new training data, and re-running the training
and evaluation steps. Automated retraining pipelines can be set up for this
purpose to ensure the models stay up-to-date.</p>
<p>Note that the success of Continuous Training relies on robust monitoring, as it
is the feedback from the model monitoring that typically triggers the retraining
process. If thereâ€™s a significant drop in performance or a detected change in
the input data distribution, the model can be flagged for retraining. Therefore,
itâ€™s an iterative process that spans across multiple stages in the MLOps
lifecycle.</p>
</section>
<section id="where-is-the-mlops">
<h2><a class="toc-backref" href="#id11" role="doc-backlink">Where Is The MLOps?</a><a class="headerlink" href="#where-is-the-mlops" title="Link to this heading">#</a></h2>
<p>The model and metric selection process is more of a design process. The real
operations is to package the whole training, tuning, and evaluation process into
a pipeline that can be run automatically. At the same time, ensuring the trained
model has artifacts tracked, logged and versioned into a central store (can be
feature store) or model registry. This is especially in the context of deploying
your model to production.</p>
<figure class="align-default" id="mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-4-ml-automation-ci-cd">
<img alt="../../../_images/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-4-ml-automation-ci-cd.svg" src="../../../_images/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-4-ml-automation-ci-cd.svg" />
<figcaption>
<p><span class="caption-number">Fig. 21 </span><span class="caption-text">CI/CD and automated ML pipeline.</span><a class="headerlink" href="#mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-4-ml-automation-ci-cd" title="Link to this image">#</a></p>
<div class="legend">
<p>Image Credits: <a class="reference external" href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning">Google - MLOps: Continuous delivery and automation pipelines in machine learning</a></p>
</div>
</figcaption>
</figure>
</section>
<section id="references-and-further-readings">
<h2><a class="toc-backref" href="#id12" role="doc-backlink">References and Further Readings</a><a class="headerlink" href="#references-and-further-readings" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.fast.ai/">Fast.ai</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/">Kaggle</a></p></li>
<li><p><a class="reference external" href="https://sebastianraschka.com/pdf/manuscripts/model-eval.pdf">Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning</a></p></li>
<li><p>Huyen, Chip. â€œChapter 6. Model Development and Offline Evaluation.â€ In
Designing Machine Learning Systems: An Iterative Process for
Production-Ready Applications, Oâ€™Reilly Media, Inc., 2022.</p></li>
<li><p><a class="reference external" href="https://madewithml.com/">Madewithml</a></p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/calibration.html">Scikit-Learn: Probability Calibration</a></p></li>
<li><p><a class="reference external" href="https://www.unofficialgoogledatascience.com/2021/04/why-model-calibration-matters-and-how.html">Google: Why model calibration matters and how?</a></p></li>
<li><p><a class="reference external" href="https://karpathy.github.io/2019/04/25/recipe/">A Recipe for Training Neural Networks - Karpathy</a></p></li>
</ul>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./operations/machine_learning_lifecycle/05_model_development_selection_and_training"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../04_mlops_data_pipeline.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Stage 4. Data Extraction (MLOps), Data Analysis (Data Science), Data Preparation (Data Science)</p>
      </div>
    </a>
    <a class="right-next"
       href="051_model_selection.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Stage 5.1. Model Selection</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-model-loss-and-data-paradigm">The Model, Loss and Data Paradigm</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-curves">Learning Curves</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ablation-studies">Ablation Studies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-tuning">Hyperparameter Tuning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">Cross-Validation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-caution-on-data-leakage">A Caution on Data Leakage</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-model-training">Final Model Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-chronicles">Training Chronicles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-note-on-cross-validation">A Note On Cross-validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-training-dependent-on-monitoring-of-drifts">Continuous Training (Dependent on Monitoring of Drifts)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-is-the-mlops">Where Is The MLOps?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references-and-further-readings">References and Further Readings</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gao Hongnan
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>